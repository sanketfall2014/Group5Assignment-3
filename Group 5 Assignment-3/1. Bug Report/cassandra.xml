<!--

RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Tue Mar 08 18:01:19 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/sr/jira.issueviews:searchrequest-xml/temp/SearchRequest.xml?jqlQuery=project+%3D+CASSANDRA+AND+resolution+%3D+Unresolved+AND+issuetype+%3D+Bug+ORDER+BY+priority+DESC&amp;tempMax=100&amp;field=key&amp;field=summary
-->
<!--
 If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
<channel>
<title>ASF JIRA</title>
<link>
https://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&jqlQuery=project+%3D+CASSANDRA+AND+resolution+%3D+Unresolved+AND+issuetype+%3D+Bug+ORDER+BY+priority+DESC
</link>
<description>An XML representation of a search request</description>
<language>en-uk</language>
<issue start="0" end="100" total="240"/>
<build-info>
<version>6.3.4</version>
<build-number>6332</build-number>
<build-date>15-08-2014</build-date>
</build-info>
<item>
<title>
[CASSANDRA-11014] Repair fails with "not enough bytes"
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11014
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>After upgrading to 2.2.4, nodetool repair fails every time with the error message "Not enough bytes". It appears no data is being repaired at all. Here's some output:</p> <p>-@cas01:~$ nodetool repair<br/> <span class="error">&#91;2016-01-14 12:00:16,590&#93;</span> Starting repair command #1, repairing keyspace adsquare with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 768)<br/> <span class="error">&#91;2016-01-14 12:00:21,935&#93;</span> Repair session 61174f80-bab6-11e5-9fa9-11175757c857 for range (-3942884673882176939,-3929110923969659376] failed with error <a href="#61174f80-bab6-11e5-9fa9-11175757c857 on adsquare/device_lookup, (-3942884673882176939,-3929110923969659376">repair #61174f80-bab6-11e5-9fa9-11175757c857 on adsquare/device_lookup, (-3942884673882176939,-3929110923969659376</a>] Validation failed in /10.10.100.61 (progress: 0%)</p> <p>The system.log on the host in question shows <br/> ERROR <span class="error">&#91;ValidationExecutor:2&#93;</span> 2016-01-14 09:58:19,935 CassandraDaemon.java:185 - Exception in thread Thread<span class="error">&#91;ValidationExecutor:2,1,main&#93;</span><br/> java.lang.IllegalArgumentException: Not enough bytes<br/> at org.apache.cassandra.db.composites.AbstractCType.checkRemaining(AbstractCType.java:362) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.composites.AbstractCompoundCellNameType.fromByteBuffer(AbstractCompoundCellNameType.java:98) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.composites.AbstractCType$Serializer.deserialize(AbstractCType.java:381) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.composites.AbstractCType$Serializer.deserialize(AbstractCType.java:365) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:75) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:52) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:46) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableIdentityIterator.hasNext(SSTableIdentityIterator.java:169) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.utils.MergeIterator$OneToOne.computeNext(MergeIterator.java:202) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.collect.Iterators$7.computeNext(Iterators.java:645) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at org.apache.cassandra.db.compaction.LazilyCompactedRow.update(LazilyCompactedRow.java:172) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.repair.Validator.rowHash(Validator.java:194) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.repair.Validator.add(Validator.java:143) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1118) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager.access$700(CompactionManager.java:73) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager$10.call(CompactionManager.java:671) ~<span class="error">&#91;apache-cassandra-2.2.4.jar:2.2.4&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~<span class="error">&#91;na:1.8.0_66&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_66&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_66&#93;</span></p> <p>Thinking that there might be some corruption I ran nodetool scrub, which fills the log with statements like the one in the attachment.</p>
</description>
<environment>
<p>3 node cluster, debian jessie, cassandra 2.2.4</p>
</environment>
<key id="12930134">CASSANDRA-11014</key>
<summary>Repair fails with "not enough bytes"</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="cschjolb@gmail.com">Christian Schjolberg</reporter>
<labels></labels>
<created>Thu, 14 Jan 2016 12:42:02 +0000</created>
<updated>Tue, 19 Jan 2016 14:36:50 +0000</updated>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="15106797" author="krummas" created="Tue, 19 Jan 2016 14:36:32 +0000">
<p>Is it possible for you to identify the sstable that is broken? I think there should be a 'Scrubbing ....' log message before the error in scrub-output.txt. Could you attach it if so? We would also need the schema</p>
</comment>
</comments>
<attachments>
<attachment id="12782269" name="scrub-output.txt" size="80323" author="cschjolb@gmail.com" created="Thu, 14 Jan 2016 12:42:02 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 19 Jan 2016 14:36:32 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ramv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11315] Upgrade from 2.2.5 to 3.0.3 Fails with AssertionError
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11315
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Hi,</p> <p>when trying to upgrade our development cluster from C* 2.2.5 to 3.0.3 Cassandra fails during startup.</p> <p>Here's the relevant log snippet:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[...] INFO [main] 2016-03-08 11:42:01,291 ColumnFamilyStore.java:381 - Initializing system.schema_triggers INFO [main] 2016-03-08 11:42:01,302 ColumnFamilyStore.java:381 - Initializing system.schema_usertypes INFO [main] 2016-03-08 11:42:01,313 ColumnFamilyStore.java:381 - Initializing system.schema_functions INFO [main] 2016-03-08 11:42:01,324 ColumnFamilyStore.java:381 - Initializing system.schema_aggregates INFO [main] 2016-03-08 11:42:01,576 SystemKeyspace.java:1284 - Detected version upgrade from 2.2.5 to 3.0.3, snapshotting system keyspace WARN [main] 2016-03-08 11:42:01,911 CompressionParams.java:382 - The sstable_compression option has been deprecated. You should use class instead WARN [main] 2016-03-08 11:42:01,959 CompressionParams.java:333 - The chunk_length_kb option has been deprecated. You should use chunk_length_in_kb instead ERROR [main] 2016-03-08 11:42:02,638 CassandraDaemon.java:692 - Exception encountered during startup java.lang.AssertionError: null at org.apache.cassandra.db.CompactTables.getCompactValueColumn(CompactTables.java:90) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.config.CFMetaData.rebuild(CFMetaData.java:315) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.config.CFMetaData.&lt;init&gt;(CFMetaData.java:291) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.config.CFMetaData.create(CFMetaData.java:367) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.decodeTableMetadata(LegacySchemaMigrator.java:337) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.readTableMetadata(LegacySchemaMigrator.java:273) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.readTable(LegacySchemaMigrator.java:244) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readTables$227(LegacySchemaMigrator.java:237) ~[apache-cassandra-3.0.3.jar:3.0.3] at java.util.ArrayList.forEach(ArrayList.java:1249) ~[na:1.8.0_74] at org.apache.cassandra.schema.LegacySchemaMigrator.readTables(LegacySchemaMigrator.java:237) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.readKeyspace(LegacySchemaMigrator.java:186) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readSchema$224(LegacySchemaMigrator.java:177) ~[apache-cassandra-3.0.3.jar:3.0.3] at java.util.ArrayList.forEach(ArrayList.java:1249) ~[na:1.8.0_74] at org.apache.cassandra.schema.LegacySchemaMigrator.readSchema(LegacySchemaMigrator.java:177) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.schema.LegacySchemaMigrator.migrate(LegacySchemaMigrator.java:77) ~[apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:223) [apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:551) [apache-cassandra-3.0.3.jar:3.0.3] at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:679) [apache-cassandra-3.0.3.jar:3.0.3] </pre> </div></div>
</description>
<environment>
<p>Ubuntu 14.04, Oracle Java 8, Apache Cassandra 2.2.5 -&gt; 3.0.3</p>
</environment>
<key id="12947982">CASSANDRA-11315</key>
<summary>
Upgrade from 2.2.5 to 3.0.3 Fails with AssertionError
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="luxifer">Dominik Keil</reporter>
<labels></labels>
<created>Tue, 8 Mar 2016 11:46:22 +0000</created>
<updated>Tue, 8 Mar 2016 11:46:22 +0000</updated>
<due/>
<votes>0</votes>
<watches>4</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ubvb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12334361</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10698] Static column performance with DISTINCT
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10698
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>As described on the mailing list, with the following schema:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-sql"> CREATE TABLE akka.messages ( persistence_id text, partition_nr bigint, sequence_nr bigint, message blob, used boolean static, PRIMARY KEY ((persistence_id, partition_nr), sequence_nr) ) WITH CLUSTERING ORDER <span class="code-keyword">BY</span> (sequence_nr ASC) AND bloom_filter_fp_chance = 0.01 AND caching = '{<span class="code-quote">"keys"</span>:<span class="code-quote">"ALL"</span>, <span class="code-quote">"rows_per_partition"</span>:<span class="code-quote">"NONE"</span>}' AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 216000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE'; </pre> </div></div> <p>The following query:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-sql"> <span class="code-keyword">SELECT</span> used <span class="code-keyword">from</span> akka.messages <span class="code-keyword">WHERE</span> persistence_id = 'player-SW11f03e20b8802000' AND partition_nr = 0; </pre> </div></div> <p>is quite slow, and as slow as the <tt>distinct</tt> version:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-sql"> <span class="code-keyword">SELECT</span> DISTINCT used <span class="code-keyword">from</span> akka.messages <span class="code-keyword">WHERE</span> persistence_id = 'player-SW11f03e20b8802000' AND partition_nr = 0; </pre> </div></div> <p>As shown with this tracing from a small unloaded 3 nodes cluster:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> activity | timestamp | source | source_elapsed ---------------------------------------------------------------------------------------------------+----------------------------+----------------+---------------- Execute CQL3 query | 2015-11-13 11:04:41.771000 | 192.168.168.12 | 0 Parsing SELECT DISTINCT used .... [SharedPool-Worker-1] | 2015-11-13 11:04:41.771000 | 192.168.168.12 | 78 READ message received from /192.168.168.12 [MessagingService-Incoming-/192.168.168.12] | 2015-11-13 11:04:41.772000 | 192.168.168.29 | 22 Preparing statement [SharedPool-Worker-1] | 2015-11-13 11:04:41.772000 | 192.168.168.12 | 271 Executing single-partition query on messages [SharedPool-Worker-4] | 2015-11-13 11:04:41.772000 | 192.168.168.29 | 424 reading data from /192.168.168.29 [SharedPool-Worker-1] | 2015-11-13 11:04:41.772000 | 192.168.168.12 | 642 Acquiring sstable references [SharedPool-Worker-4] | 2015-11-13 11:04:41.772000 | 192.168.168.29 | 445 Sending READ message to /192.168.168.29 [MessagingService-Outgoing-/192.168.168.29] | 2015-11-13 11:04:41.772000 | 192.168.168.12 | 738 Merging memtable tombstones [SharedPool-Worker-4] | 2015-11-13 11:04:41.772000 | 192.168.168.29 | 476 Key cache hit for sstable 1126 [SharedPool-Worker-4] | 2015-11-13 11:04:41.773000 | 192.168.168.29 | 560 Seeking to partition beginning in data file [SharedPool-Worker-4] | 2015-11-13 11:04:41.773000 | 192.168.168.29 | 592 Skipped 0/1 non-slice-intersecting sstables, included 0 due to tombstones [SharedPool-Worker-4] | 2015-11-13 11:04:41.773000 | 192.168.168.29 | 960 Merging data from memtables and 1 sstables [SharedPool-Worker-4] | 2015-11-13 11:04:41.774000 | 192.168.168.29 | 971 Read 1 live and 0 tombstone cells [SharedPool-Worker-4] | 2015-11-13 11:04:47.301000 | 192.168.168.29 | 529270 Enqueuing response to /192.168.168.12 [SharedPool-Worker-4] | 2015-11-13 11:04:47.316000 | 192.168.168.29 | 544885 Sending REQUEST_RESPONSE message to /192.168.168.12 [MessagingService-Outgoing-/192.168.168.12] | 2015-11-13 11:04:47.317000 | 192.168.168.29 | 545042 REQUEST_RESPONSE message received from /192.168.168.29 [MessagingService-Incoming-/192.168.168.29] | 2015-11-13 11:04:47.429000 | 192.168.168.12 | 657918 Processing response from /192.168.168.29 [SharedPool-Worker-2] | 2015-11-13 11:04:47.429000 | 192.168.168.12 | 658224 Request complete | 2015-11-13 11:04:47.525892 | 192.168.168.12 | 754892 </pre> </div></div> <p>As you can see, there's a 5 seconds delay between "Merging data" and "Read 1 live and 0 tombstones" steps.<br/> Note that this row in particular is quite large, and has certainly a lots of tombstones. But I understood that when querying for a static column, cassandra shouldn't have to read everything, as the static column value exists in one place.</p> <p>Note that if the row cache is enabled, the row is then cached and it is very fast on subsequent request.</p> <p>I've attached the sstable in question, that exhibits the issue for this specific large row.<br/> Note that I didn't run any compaction on the sstable, because I'm not sure if the problem is coming from the tombstones on the said record.</p>
</description>
<environment><p>Linux, cassandra 2.1.11</p></environment>
<key id="12912785">CASSANDRA-10698</key>
<summary>Static column performance with DISTINCT</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="masterzen">Brice Figureau</reporter>
<labels>
<label>performance</label>
</labels>
<created>Fri, 13 Nov 2015 10:21:35 +0000</created>
<updated>Mon, 23 Nov 2015 08:47:04 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15021755" author="masterzen" created="Mon, 23 Nov 2015 08:47:04 +0000">
<p>Can anyone have a look to this issue, it affects us quite hard.<br/> Thanks.</p>
</comment>
</comments>
<attachments>
<attachment id="12772163" name="bug-slow-distinct.tar.gz" size="2634310" author="masterzen" created="Fri, 13 Nov 2015 10:21:35 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ocp3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10943] NullPointer during LegacySchemaMigrator
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10943
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I'm trying to upgrade my Cassandra cluster from 2.2.4 to 3.1.1.</p> <p>I used</p> <blockquote> <p>nodetool upgradesstables<br/> nodetool drain</p></blockquote> <p>before upgrading. </p> <p>The result is this:</p> <blockquote> <p>INFO <span class="error">&#91;main&#93;</span> 2015-12-26 22:41:44,114 SystemKeyspace.java:1284 - Detected version upgrade from 2.2.4 to 3.1.1, snapshotting system keyspace<br/> WARN <span class="error">&#91;main&#93;</span> 2015-12-26 22:41:44,318 CompressionParams.java:382 - The sstable_compression option has been deprecated. You should use class instead<br/> ERROR <span class="error">&#91;main&#93;</span> 2015-12-26 22:41:44,427 CassandraDaemon.java:690 - Exception encountered during startup<br/> java.lang.NullPointerException: null<br/> at org.apache.cassandra.serializers.BooleanSerializer.deserialize(BooleanSerializer.java:33) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.serializers.BooleanSerializer.deserialize(BooleanSerializer.java:24) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.db.marshal.AbstractType.compose(AbstractType.java:114) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.cql3.UntypedResultSet$Row.getBoolean(UntypedResultSet.java:272) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.decodeTableMetadata(LegacySchemaMigrator.java:264) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.readTableMetadata(LegacySchemaMigrator.java:250) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.readTable(LegacySchemaMigrator.java:221) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readTables$218(LegacySchemaMigrator.java:214) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at java.util.ArrayList.forEach(ArrayList.java:1249) ~<span class="error">&#91;na:1.8.0_66&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.readTables(LegacySchemaMigrator.java:214) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.readKeyspace(LegacySchemaMigrator.java:163) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.lambda$readSchema$215(LegacySchemaMigrator.java:154) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at java.util.ArrayList.forEach(ArrayList.java:1249) ~<span class="error">&#91;na:1.8.0_66&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.readSchema(LegacySchemaMigrator.java:154) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.schema.LegacySchemaMigrator.migrate(LegacySchemaMigrator.java:77) ~<span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:223) <span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:549) <span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span><br/> at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:677) <span class="error">&#91;apache-cassandra-3.1.1.jar:3.1.1&#93;</span></p></blockquote>
</description>
<environment>
<p>Debian Jessie<br/> java version "1.8.0_66"<br/> Cassandra 2.2.4 -&gt; 3.1.1 migration</p>
</environment>
<key id="12924375">CASSANDRA-10943</key>
<summary>NullPointer during LegacySchemaMigrator</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="wienczny">Stephan Wienczny</reporter>
<labels></labels>
<created>Sat, 26 Dec 2015 22:10:40 +0000</created>
<updated>Sun, 27 Dec 2015 18:42:21 +0000</updated>
<fixVersion>3.0.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15072179" author="snazy" created="Sun, 27 Dec 2015 16:17:23 +0000">
<p>Attached patch <b>should</b> solve the issue.<br/> /cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey" class="user-hover" rel="iamaleksey">Aleksey Yeschenko</a></p>
</comment>
<comment id="15072187" author="iamaleksey" created="Sun, 27 Dec 2015 17:11:48 +0000"><p>Why <tt>false</tt> as the default value?</p></comment>
<comment id="15072191" author="snazy" created="Sun, 27 Dec 2015 17:32:02 +0000">
<p>Oh - so, if <tt>is_dense</tt> is not present, then it defaults to true?</p>
</comment>
<comment id="15072192" author="iamaleksey" created="Sun, 27 Dec 2015 17:35:14 +0000">
<p>You have to calculate it from the rest of the schema, there isn't supposed to be a default. Thought a 2.2 node should have it always present, I think, hence it's implied to be there.</p> <p>I'll have a look next year.</p>
</comment>
<comment id="15072207" author="wienczny" created="Sun, 27 Dec 2015 18:42:21 +0000">
<p>1. If is_dense should be available in 2.2 why is it missing from my 2.2 node?<br/> 2. How do you create is_dense?</p>
</comment>
</comments>
<attachments>
<attachment id="12779587" name="10943.txt" size="953" author="snazy" created="Sun, 27 Dec 2015 16:17:23 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sun, 27 Dec 2015 16:17:23 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qbiv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10937] OOM on multiple nodes on write load (v. 3.0.0), problem also present on DSE-4.8.3, but there it survives more time
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10937
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>8 cassandra nodes.</p> <p>Load test started with 4 clients(different and not equal machines), each running 1000 threads.<br/> Each thread assigned in round-robin way to run one of 4 different inserts. <br/> Consistency-&gt;ONE.</p> <p>I attach the full CQL schema of tables and the query of insert.</p> <p>Replication factor - 2:<br/> create keyspace OBLREPOSITORY_NY with replication = </p> {'class':'NetworkTopologyStrategy','NY':2} <p>;</p> <p>Initiall throughput is:<br/> 215.000 inserts /sec<br/> or<br/> 54Mb/sec, considering single insert size a bit larger than 256byte.</p> <p>Data:<br/> all fields(5-6) are short strings, except one is BLOB of 256 bytes.</p> <p>After about a 2-3 hours of work, I was forced to increase timeout from 2000 to 5000ms, for some requests failed for short timeout.</p> <p>Later on(after aprox. 12 hous of work) OOM happens on multiple nodes.<br/> (all failed nodes logs attached)</p> <p>I attach also java load client and instructions how set-up and use it.(test2.rar)</p> <p>Update:</p> <p>Later on test repeated with lesser load (100000 mes/sec) with more relaxed CPU (idle 25%), with only 2 test clients, but anyway test failed.</p> <p>Update:</p> <p>DSE-4.8.3 also failed on OOM (3 nodes from 8), but here it survived 48 hours, not 10-12.</p> <p>Attachments:<br/> test2.rar -contains most of material<br/> more-logs.rar - contains additional nodes logs</p>
</description>
<environment>
<p>Cassandra : 3.0.0<br/> Installed as open archive, no connection to any OS specific installer.</p> <p>Java:<br/> Java(TM) SE Runtime Environment (build 1.8.0_65-b17)</p> <p>OS :</p> <p>Linux version 2.6.32-431.el6.x86_64 (mockbuild@x86-023.build.eng.bos.redhat.com) (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) #1 SMP Sun Nov 10 22:19:54 EST 2013</p> <p>We have:<br/> 8 guests ( Linux OS as above) on 2 (VMWare managed) physical hosts. Each physical host keeps 4 guests.</p> <p>Physical host parameters(shared by all 4 guests):<br/> Model: HP ProLiant DL380 Gen9<br/> Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz<br/> 46 logical processors.<br/> Hyperthreading - enabled</p> <p>Each guest assigned to have:<br/> 1 disk 300 Gb for seq. log (NOT SSD)<br/> 1 disk 4T for data (NOT SSD)<br/> 11 CPU cores</p> <p>Disks are local, not shared.</p> <p>Memory on each host - 24 Gb total.<br/> 8 (or 6, tested both) Gb - cassandra heap</p> <p>(lshw and cpuinfo attached in file test2.rar)</p>
</environment>
<key id="12924148">CASSANDRA-10937</key>
<summary>
OOM on multiple nodes on write load (v. 3.0.0), problem also present on DSE-4.8.3, but there it survives more time
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tierhetze">Peter Kovgan</reporter>
<labels></labels>
<created>Thu, 24 Dec 2015 06:43:14 +0000</created>
<updated>Mon, 25 Jan 2016 05:49:25 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15070679" author="tierhetze" created="Thu, 24 Dec 2015 07:07:19 +0000">
<p>I have one hprof, I will try analyze it and get back with results, the file is too large to upload.</p>
</comment>
<comment id="15070702" author="tierhetze" created="Thu, 24 Dec 2015 07:33:09 +0000">
<p>Important:<br/> Found on one node 224Gb of hints.<br/> And this hints directory is on small disk(the same disk is for logs).<br/> The disk is full.<br/> May be this is the part of the problem (other nodes are OK).</p>
</comment>
<comment id="15070728" author="tierhetze" created="Thu, 24 Dec 2015 07:57:24 +0000"><p>added heap pics(some-heap-stats.rar)</p></comment>
<comment id="15070794" author="tierhetze" created="Thu, 24 Dec 2015 09:19:09 +0000">
<p>Meanwhile I plan following:</p> <p>First: I will reduce the load to 70% of that we failed.<br/> In order to provide the CPU with some "space" to make GC.<br/> If that helps - may be the problem is in too extensive load...</p> <p>-may be I need smaller heap (6 instead of 8 Gb)<br/> -I reduce the max_hint_window_in_ms, because I think more hints created than my disk able to store</p>
</comment>
<comment id="15072053" author="tierhetze" created="Sun, 27 Dec 2015 05:48:26 +0000">
<p>Unfortunatelly retest with lesser load did not help.<br/> Now average CPU usage on all nodes was 60-70%.(when test started, not sure about entire test)<br/> There are still some nodes down.<br/> GC is very long (30-40 sec) before OOM occurs.</p> <p>I send logs and heap shapshot attachment (test3.rar)</p> <p>First (2015-12-24 20:51:58) OOM occured on node 69 (logs attached in test3.rar) <br/> Then (2015-12-25 03:20:28) hints ate all the disk space on node 65 and node shutdown<br/> Then (2015-12-25 13:10:20) the node 67 gone with OOM</p> <p>I will try follow that recommendation:<br/> <a href="https://docs.datastax.com/en/cassandra/3.0/cassandra/troubleshooting/trblshootDyingNodes.html" class="external-link" rel="nofollow">https://docs.datastax.com/en/cassandra/3.0/cassandra/troubleshooting/trblshootDyingNodes.html</a><br/> And then report what happens.</p> <p>This is the last status:</p> <p>&#8211; Address Load Tokens Owns Host ID Rack<br/> UN 10.20.42.68 285.06 GB 256 ? 6ce9d0bf-9569-4f4a-9769-c96f76a1c87f rack1<br/> DN 10.20.42.69 119.4 GB 256 ? 8452fbfb-c692-403e-9c43-83493ab39201 rack1<br/> UN 10.20.42.64 317.97 GB 256 ? b09eb63c-0d24-4373-8379-85d0616f488e rack1<br/> DN 10.20.42.65 197.49 GB 256 ? 61a1561a-15a4-412b-b831-b47a6e5902a9 rack1<br/> UN 10.20.42.66 276.96 GB 256 ? 22a3f2d8-39ea-4aa9-9b38-be8e850823f4 rack1<br/> DN 10.20.42.67 243.97 GB 256 ? 05672e1a-581a-45b1-92fe-9c3ce9409752 rack1<br/> UN 10.20.42.62 332.89 GB 256 ? e3e74ff4-c8f9-4186-b4ec-b66a6e05d9b4 rack1<br/> UN 10.20.42.63 330.99 GB 256 ? e51a871f-6aac-415e-9928-2ead4d3cbf6b rack1</p>
</comment>
<comment id="15072054" author="tierhetze" created="Sun, 27 Dec 2015 05:49:22 +0000">
<p>attachment of last test logs, config and heap snapshot (after OOM)</p>
</comment>
<comment id="15072106" author="tierhetze" created="Sun, 27 Dec 2015 09:42:18 +0000">
<p>Started the new test.</p> <p>Load is the same as in previous test (initial count: 116 000 mes/sec), that initially leaves ~25% idle CPU.</p> <p>Plus applied some changes:<br/> disk_optimization_strategy: spinning (because I have such disk)<br/> memtable_heap_space_in_mb: 1024 (hope, I reduced it, Xmx is 6Gb)</p> <p>Immediatelly, I see that cassandra behaviour has changed:<br/> I have periods (about 4 min each time), when insert throughput deacreases to 25% of usual (without client errors), at the same time CPU usage reduced to 10%. I think cassandra does memtables evacuation at such times at expence of insert throughput.<br/> If that what will save my memory from OOM - I will be happy.</p> <p>I have no row cache.</p> <p>I think it is strange, that OOM happened after 10 hours of work, when each node collected about 270Gb of data.<br/> It is multiple times greater than heap size(6Gb), so I wonder what could cause such unexpected change in memory usage.<br/> Compaction?</p>
</comment>
<comment id="15072449" author="tierhetze" created="Mon, 28 Dec 2015 05:43:11 +0000">
<p>The last test failed.<br/> OOM on two nodes.<br/> I attach the GC log (stats gc).<br/> I do not know what to do.<br/> If it were failed at first, second hour, I would be sure that this is a configuration/load problem.<br/> But it fails at 10-th hour, when multiple cycles whatever cassandra does already repeated.<br/> It looks like a bug.<br/> I do not know whether it worth to upgrade to more current version. I have 3.0.0.</p> <p>BTW, I discovered, that option offheap_buffers , if chosen, causes the server fail on start.<br/> Wonder, should I open another bug...Or just talk to myself is quite enough..</p>
</comment>
<comment id="15072450" author="tierhetze" created="Mon, 28 Dec 2015 05:44:15 +0000">
<p>attached GC stats from the faiield node in format JSTATS -gc<br/> like here:<br/> <a href="https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html" class="external-link" rel="nofollow">https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html</a></p> <p>stats interval is 10 sec</p> <p>We see, how old generation grows to the end...</p>
</comment>
<comment id="15072467" author="tierhetze" created="Mon, 28 Dec 2015 06:16:24 +0000">
<p>test4.rar - last test crashed node logs<br/> and JProfiler heap analysis with objects that reference most populated byte[] payload.</p>
</comment>
<comment id="15072468" author="tierhetze" created="Mon, 28 Dec 2015 06:16:35 +0000">
<p>crached heap analysis shows that most populated objects are:</p> <p>org.apache.cassandra.io.sstable.metadata.StatsMetadata-&gt;minClusteringValues <br/> org.apache.cassandra.io.sstable.metadata.StatsMetadata-&gt;maxClusteringValues <br/> org.apache.cassandra.cql3.QueryOptions$DefaultQueryOptions-&gt;values</p> <p>I will attache JProfiler snapshot of that and cassandra test logs in test4.rar</p>
</comment>
<comment id="15072473" author="tierhetze" created="Mon, 28 Dec 2015 06:21:18 +0000">
<p>My plan:</p> <p>downgrade to the older stablest cassandra version 2.1..? and retest</p>
</comment>
<comment id="15072564" author="tierhetze" created="Mon, 28 Dec 2015 09:29:18 +0000">
<p>started comparison test on base of the tarball of the recommended cassandra EE.<br/> I see that it uses G1 by default and 6Gb heap. Let's see how that one works.</p>
</comment>
<comment id="15073505" author="tierhetze" created="Tue, 29 Dec 2015 05:21:46 +0000">
<p>Confirming that DSE 4.8.3 survived the load. I will continue tests. <br/> This DSE installed as tarball, open archive. <br/> Otherwise - exactly the same installation pattern as for the test of 3.0.0.<br/> So 3.0.0 definitely has a problem.</p>
</comment>
<comment id="15075732" author="tierhetze" created="Thu, 31 Dec 2015 05:29:59 +0000">
<p>DSE 4.8.3 failed with OOM after 48 hours of work.</p>
</comment>
<comment id="15075748" author="tierhetze" created="Thu, 31 Dec 2015 06:08:38 +0000"><p>test5.rar contains logs of failed DSE-4.8.3</p></comment>
<comment id="15075820" author="tierhetze" created="Thu, 31 Dec 2015 08:00:52 +0000">
<p>Will run a test with 8192M heap and memtable_heap_space_in_mb=1024</p> <p>Just to be sure..</p>
</comment>
<comment id="15076761" author="tierhetze" created="Sun, 3 Jan 2016 05:17:11 +0000"><p>Unsuccessful.</p></comment>
<comment id="15080718" author="tierhetze" created="Mon, 4 Jan 2016 05:41:00 +0000">
<p>lesser load, dropped key cache - nothing helps.<br/> decided retest, excluding VMware from the installation.<br/> Let's see how bare iron helps.</p>
</comment>
<comment id="15081424" author="mshuler" created="Mon, 4 Jan 2016 17:34:12 +0000">
<p>I appreciate the log of load testing your infrastructure. The hardware you indicate that you are testing is not exactly what I would classify as following recommendations. Yes, "bad things" can happen with overloaded Cassandra nodes. If the nodes are too small and have poor I/O, as your environment details suggest, server overload happens and "bad things" occur.</p> <p>This is purely an observation on what you've posted so far, without digging through any of your logs.</p> <p>Your last post suggests that you'll continue testing on real servers - this is a good start on getting closer to recommended hardware.</p> <p>Is there a hint on what this "bug" is actually suggesting, other than load testing small non-recommended virtual servers?</p>
</comment>
<comment id="15081469" author="tierhetze" created="Mon, 4 Jan 2016 17:53:18 +0000">
<p>1) I've read recommendations and there were no word about VMWare (or any virtualization) as a bad choice. It is no so clear from recommendations. Shared storage (NAT drives, etc..), for example, listed as a bad thing, so we avoided it. But virtualization per ce is sort of "not mentioned". You have some recommendations for Amazon cloud , that's all. Nothing negative regarding virtualization.<br/> If you tested on VMWare and got bad results, I'd like to see that in instructions.</p> <p>2) Even with bad IO for whatever reason (and this is probably the case), I would rather expect accepting threads stop to accept new messages, not allowing memory to overpopulate and explode. So I would anyway treat it as an important feature request. May be not a bug, but vulnerability, that should be answered with some mechanism. </p> <p>Thanks for your answer.</p> <p>BTW, we will install multiple nodes on single physical machine (because the machine is quite strong for 1 node), is that also problematic? </p>
</comment>
<comment id="15081483" author="tierhetze" created="Mon, 4 Jan 2016 18:00:25 +0000">
<p>In addition, OOM happens only after 10-48 hours of test. So it is really looks like a bug, not just load problem. System accepts that load for very long time - not failing in short time - that is the sort of "accumulated" problem and so it looks like a pure bug. </p>
</comment>
<comment id="15103647" author="tierhetze" created="Sun, 17 Jan 2016 10:07:59 +0000">
<p>Test 2.1 (First test without VMWare)</p> <p>I failed "collect diagnostics" from OPS, something did not work there.<br/> But I collected a lot of data, see attachments. (see log/config/etc attachments starts from test_2.1_)</p> <p>Test conditions:</p> <p>1)	DSE – 4.8.3<br/> 2)	We ran 1 node, without replication, on 48 CPUs machine with 4 data disks(each 6Tb) and 3 separate disks for a)commitlog, b) savedcaches, c)cassandra log - all disks are not SSD, 98Gb RAM, no SWAP.<br/> 3)	OS – RHEL 7<br/> 4)	Java - 8<br/> 5) GC – G1, heap ~ 73Gb<br/> 6)	Load was quite impressive first 48 hours (like 116000 mes/sec), then I left a lesser load (for weekend), something about 90000 m/sec , each message is like 256 bytes.<br/> (reason, why I started lesser load is - I discovered , that with initial load my selects are not returning, DB became "write-only", I started suspect that 1 node is not ok for parallel Select and Insert work )</p> <p>7)	With lesser load, I connected also OPS cassandra app and have seen that all is green. (The node was "healthy").<br/> 8)	Test duration was from 12/01/2016 (time ~9.00) till 16/01/2016 : 2.00 , ~ 89 Hours (&lt; 4 days).<br/> 9)	At the end of the test, data disks utilized to 43%.</p> <p>OOM happened 16/01/2016 at 02.00.55</p> <p>Producer stats and SAR(disk/cpu) stats of cassandra node look like there was an abrupt change before OOM.<br/> So, I suspect , it is a software problem.</p> <p>(See attachments, starting from test_2.1_)</p>
</comment>
<comment id="15103649" author="tierhetze" created="Sun, 17 Jan 2016 10:09:13 +0000">
<p>I have new OOM , this time without VMWare.<br/> Attached logs, etc...</p>
</comment>
<comment id="15104854" author="tierhetze" created="Mon, 18 Jan 2016 06:46:04 +0000">
<p>Today attempted to start failed node and have OOM during start.<br/> Attached test_2.1_restart_attempt_log.rar with log.</p>
</comment>
<comment id="15105495" author="jkrupan" created="Mon, 18 Jan 2016 16:36:36 +0000">
<p>I still don't see any reason to believe that there is a bug here and that the primary issue is that you are overloading the cluster. Sure, Cassandra should do a better job of shedding/failing excessive incoming requests, and there is an open Jira ticket to add just such a freature, but even with that new feature, the net effect will be the same - it will still be up to the application and operations to properly size the cluster and throttle application load before it gets to Cassandra.</p> <p>OOM is not typically an indication of a software bug. Sure, sometimes code has memory leaks, but with a highly dynamic system such as Cassandra, it typically means either a misconfigured JVM or just very heavy load. Sometimes OOM simply means that there is a lot of background processing going on (like compactions or hinted handoff) that is having trouble keeping up with incoming requests. Sometimes OOM occurs because you have too large a heap which defers GC but then GC takes too long and further incoming requests simply generate more pressure on the heap faster than that massive GC can deal with it.</p> <p>It is indeed tricky to make sure the JVM has enough heap but not too much. DSE typically runs with a larger heap by default. You can try increasing your heap to 10 or 12G. But if you make the heap too big, the big GC can bite you as described above. In that case, the heap needs to be reduced. Typically you don't need a heap smaller than 8 GB. If OOM occurs with a 8 GB heap it typically means the load on that node is simply too heavy.</p> <p>Be sure to review the recommendations in this blog post on reasonable recommendations:<br/> <a href="http://www.datastax.com/dev/blog/how-not-to-benchmark-cassandra" class="external-link" rel="nofollow">http://www.datastax.com/dev/blog/how-not-to-benchmark-cassandra</a></p> <p>A few questions that will help us better understand what you are really trying to do:</p> <p>1. How much reading are you doing and when relative to writes?<br/> 2. Are you doing any updates or deletes? (Cause compaction, which can fall behind your write/update load.)<br/> 3. How much data is on the cluster (rows)?<br/> 4. How many tables?<br/> 5. What RF? RF=3 would be the recommendation, but if you have a heavy read load you may need RF=5, although heavy load usually means you just need a lot more nodes so that the fraction of incoming requests going to a particular node are dramatically reduced. RF&gt;3 is only needed if there is high load for each particular row or partition.<br/> 6. Have you tested using cassandra-stress? That's the gold standard around here.<br/> 7. Are your clients using token-aware routing? (Otherwise a write must be bounced from the coordinating node to the node owning the token for the partition key.)<br/> 8. Are you using batches for your writes? If, so, do all the writes in one batch have the same partition key? (If not, adds more network hops.)<br/> 9. What expectations did you have as to how many writes/reads a given number of nodes should be able to handle?</p>
</comment>
<comment id="15105572" author="tierhetze" created="Mon, 18 Jan 2016 17:46:44 +0000">
<p>I will go through all the recommendations and I will provide more detailed picture.<br/> Trust me , I look for the most sane reason to continue use cassandra and I will reduce load<br/> to find the acceptable, optimal one. I do my best!!! If load reduction helps - we will use cassandra.</p> <p>But short answer is that:<br/> I have no problem with OOM itself, assuming OOM is just a failure indicator for the case of too intensive load.<br/> My problem is this indication is too delayed in time. (48, 89 hours!!! - depends on heap size)</p> <p>There are clear signs that % of "IO wait" grows gradually throughout all the test.<br/> (sar metrics tell, that %iowait is progressively growing - time that CPU spends in IO grows day to day...gradually, slowly)<br/> It looks like problems accumulate and grow with time.</p> <p>I'm not claiming this is not workable system.<br/> I'm claiming it looks like a memory leak, based on unrestricted publishers and progressively growing IO demand.<br/> The "exit" becomes narrower and narrower and "entrance" remains the same. </p> <p>For me the best solution is to find a reason of the progressive(growing) IO and prevent this issue.<br/> How to prevent it (by restricting publishers, by optimizing IO, etc) I do not know.</p> <p>But I would be more happy to fail in first 1-5 hours , when most of cassandra processes have repeated multiple times and system had a chance to estimate its load and make conclusions.<br/> (even friendly warning "you need a rescue node, otherwise you will become unstable" is a solution)</p> <p>When it fails after 4 days of test, when everybody shanked hands and greeted each other "we like it", it is another matter.<br/> You should not convince me, because I'm a positive opportunist, I will find a way.<br/> But some people will be frustrated. That's why I would take it seriously. </p>
</comment>
<comment id="15106555" author="tierhetze" created="Tue, 19 Jan 2016 10:20:46 +0000"><p>Attached answers to Jack Krupinsky (docx)</p></comment>
<comment id="15110761" author="jkrupan" created="Thu, 21 Jan 2016 15:25:31 +0000">
<p>Sorry, <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tierhetze" class="user-hover" rel="tierhetze">Peter Kovgan</a>, but as a matter of policy I don't download or read doc/docx files. Please post the essential text here.</p>
</comment>
<comment id="15110798" author="jkrupan" created="Thu, 21 Jan 2016 15:42:55 +0000">
<p>A few more questions:</p> <p>1. When nodes do crash, what happens when you restart them? Do they immediately crash again immediately or run for many hours?<br/> 2. Is it just a single node crashing or do like all the nodes fail around the same time, like falling dominoes?</p> <p>Just to be clear, the fact that the cluster seemed fine for 48 hours does not tell us whether it might have been near the edge of failing for quite some time and maybe the precise pattern of load just statistically became the straw that broke the camel's back at that moment. That's why it's important to know what happened after you restarted and resumed the test after the crash as 48 hours.</p> <p>It it really was a resource leak, then reducing the heap would make the failure occur sooner. Determine what the minimal heap size is to run the test at all - set it low enough so the test won't run even for a minute, then increase the heap so it does run, then decrease it by less than you increased it - a binary search for the exact heap size that is needed for the test to run even for a few minutes or an hour. At least then you would have an easy to reproduce test case. So if you can tune the heap so that the test can run successfully for say 10 minutes before reliably hitting the OOM, then you can see how much you need to reduce the load (throttling the app) to be able to run without hitting OOM.</p> <p>I'm not saying that there is absolutely no chance that there is a resource leak, just simply that there are still a lot of open questions to answer about usage before we can leap to that conclusion. Ultimately, we do have to have a reliable repo test case before anything can be done.</p> <p>In any case, at least at this stage it seems clear that you probably do need a much larger cluster (more nodes with less load on each node.) Yes, it's unfortunate the Cassandra won't give you a nice clean message that says that, but that ultimate requirement remains unchanged - pending answers to all of the open questions.</p>
</comment>
<comment id="15114212" author="tierhetze" created="Sun, 24 Jan 2016 06:01:56 +0000">
<p>Thank you, Jack.</p> <p>I answer inline:</p> <p>I still don't see any reason to believe that there is a bug here and that the primary issue is that you are overloading the cluster.</p> <p>Peter: Agree and hope this is the reason</p> <p>Sure, Cassandra should do a better job of shedding/failing excessive incoming requests, and there is an open Jira ticket to add just such a feature, but even with that new feature, the net effect will be the same - it will still be up to the application and operations to properly size the cluster and throttle application load before it gets to Cassandra.</p> <p>Peter: No problem, I understand the driving force for that, I only claim that friendly warning would be appropriate in case of estimated danger of approaching OOM.It is hard to do that, I understand. Some situations are not easy to analyze and make conclusions. But see below…</p> <p>OOM is not typically an indication of a software bug. Sure, sometimes code has memory leaks, but with a highly dynamic system such as Cassandra, it typically means either a misconfigured JVM or just very heavy load. Sometimes OOM simply means that there is a lot of background processing going on (like compactions or hinted handoff) that is having trouble keeping up with incoming requests. Sometimes OOM occurs because you have too large a heap which defers GC but then GC takes too long and further incoming requests simply generate more pressure on the heap faster than that massive GC can deal with it.</p> <p>Peter: Regarding compactions.. I could imagine that. We notice progressive growth in IO demand.<br/> So, I would take IO wait progressive growth as a warning trigger for possible approaching OOM.E.g. if normal IO wait configured as 0.3%, and system progressively goes through some configured thresholds of 0.7, 1.0, 1.5 % , I would like to notice that in some warning log.This way, I can judge earlier, that I need increase the ring or wait an OOM.<br/> Now, in latest test, I see pending comactions gradually increases. Very slowely.<br/> Two days ago it was 40, now 135, I wonder, is it a sign of a pending problem?</p> <p>It is indeed tricky to make sure the JVM has enough heap but not too much. </p> <p>Peter: Aware of that. I deal with GC issues in general more frequently than others in my company. Previous DSE tests done with G1, providing multiple of 2048Mb (G1 recommendation), concretely I gave it 73728M Here I assume effective GC with G1 is more a function of available CPU, because there are a lot of “young” and “old” spaces and things are more complicated than in Concurrent collector. CPU was fine when OOM happened, a lot of idle, another sign that IO is a bottleneck.<br/> We now test 2 single node installations, one with 36G heap and one with 73gb. I want see which one is doing better. We also reduced load to 5 Mb/sec, instead of 25-30. </p> <p>DSE typically runs with a larger heap by default. You can try increasing your heap to 10 or 12G. But if you make the heap too big, the big GC can bite you as described above. In that case, the heap needs to be reduced. Typically you don't need a heap smaller than 8 GB. If OOM occurs with a 8 GB heap it typically means the load on that node is simply too heavy.<br/> Be sure to review the recommendations in this blog post on reasonable recommendations:<br/> <a href="http://www.datastax.com/dev/blog/how-not-to-benchmark-cassandra" class="external-link" rel="nofollow">http://www.datastax.com/dev/blog/how-not-to-benchmark-cassandra</a></p> <p>Peter: Done.All is by the book, except:<br/> We use custom producer and custom data model.<br/> We change data model, trying make it more effective, last change was adding day to partition, we want avoid too wide rows. Our producer is multi-threaded and configurable. </p> <p>A few questions that will help us better understand what you are really trying to do:<br/> 1. How much reading are you doing and when relative to writes?<br/> Peter: In OOM-ended tests(In all tests before) we did only writes. Just recently, with lower load I started did reads.<br/> Meanwhile it is OK. (4 days passed)</p> <p>2. Are you doing any updates or deletes? (Cause compaction, which can fall behind your write/update load.)<br/> Peter: No, no updates, and will not do. Our TTL will be set for 4 weeks in production. Now I do no TTL to test reads on greater data storage.</p> <p>3. How much data is on the cluster (rows)?</p> <p>Peter:<br/> This info is currently unavailable (for OOM-ended tests and previous particular data model). I cannot check, because Cassandra fails on OOM during restart and I have no different environment to see.<br/> But for today’s test (we added a day to partition, other parameters are the same ) estimated numbers from nodetool sfstats are:<br/> Number of keys (estimate): 2000<br/> Number of keys (estimate): 10142095<br/> Number of keys (estimate): 350<br/> Number of keys (estimate): 2000<br/> Number of keys (estimate): 350<br/> Number of keys (estimate): 12491<br/> I assume now we have more rows that in previous tests. (because we added a parameter to partition key).</p> <p>4. How many tables?<br/> Peter: 4 + 2 secondary indexes, indexes we will probably remove later. It is just to test that kind.</p> <p>5. What RF? RF=3 would be the recommendation, but if you have a heavy read load you may need RF=5, although heavy load usually means you just need a lot more nodes so that the fraction of incoming requests going to a particular node are dramatically reduced. RF&gt;3 is only needed if there is high load for each particular row or partition.</p> <p>Peter: We tested (when we tested on VMWare) with RF 2 and Consistency level ONE, but later we started test single node (without VMWare). We plan in production RF=2. To use less nodes….</p> <p>6. Have you tested using cassandra-stress? That's the gold standard around here.</p> <p>Peter: No, we need be close to our business reality to choose what is OK for us.<br/> Besides, our data model is very straightforward, so we are not so far from standard.<br/> Below I list our data model.<br/> All fields in each table are 4-8 bytes, expect one (BLOB) is 256 byte.<br/> I, probably, will remove secondary indexes and create tables instead later. I’ve noticed that their efficiency is worse than this of table.</p> <p>7. Are your clients using token-aware routing? (Otherwise a write must be bounced from the coordinating node to the node owning the token for the partition key.)<br/> Peter: No. we use default.</p> <p>8. Are you using batches for your writes? If, so, do all the writes in one batch have the same partition key? (If not, adds more network hops.)<br/> Peter: no batches. I read about their controversial efficiency , so no batches meanwhile.</p> <p>9. What expectations did you have as to how many writes/reads a given number of nodes should be able to handle?</p> <p>Peter: We have no expectations menawhile, but we started from 30Mb/sec, 120000 writes/sec and failed on OOM, today we started 5Mb/sec, 20000 mes/sec. If that works 1 week and does no OOM (and we have acceptable reads latency), then we can use that. We even ready to test 2 Mb/sec, we ready for everything that stable and gives us a hope <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/>. In future production we expect load (not from beginning) about 50-100 Mb/sec, with occasional spikes to 150 Mb/sec.<br/> We have dilemma, whether put Kafka before Cassandra or not. I mean to amortize such periodical spikes...</p> <p>A few more questions:<br/> 1. When nodes do crash, what happens when you restart them? Do they immediately crash again immediately or run for many hours?</p> <p>Peter: they crash during startup. Even without VMWare. It clashes before I apply any load. Just unable to start.</p> <p>2. Is it just a single node crashing or do like all the nodes fail around the same time, like falling dominoes?</p> <p>Peter: There was test (On VMWare environment), where 8 nodes played a cluster with RF 2. Crashed 3-4 from them. In narrow period of time. </p> <p>Just to be clear, the fact that the cluster seemed fine for 48 hours does not tell us whether it might have been near the edge of failing for quite some time and maybe the precise pattern of load just statistically became the straw that broke the camel's back at that moment. That's why it's important to know what happened after you restarted and resumed the test after the crash as 48 hours.</p> <p>Peter: got it. </p> <p>It it really was a resource leak, then reducing the heap would make the failure occur sooner. Determine what the minimal heap size is to run the test at all - set it low enough so the test won't run even for a minute, then increase the heap so it does run, then decrease it by less than you increased it - a binary search for the exact heap size that is needed for the test to run even for a few minutes or an hour. At least then you would have an easy to reproduce test case. So if you can tune the heap so that the test can run successfully for say 10 minutes before reliably hitting the OOM, then you can see how much you need to reduce the load (throttling the app) to be able to run without hitting OOM.</p> <p>Peter: I agree with that logic, but it seems to me, there is another factor (something with IO) playing a role. And this one is only accumulating within particularly long runs. But I will try this approach. Amyway, we need also test long runs to eliminate a possibility, that something accumulates only on long run.</p> <p>I'm not saying that there is absolutely no chance that there is a resource leak, just simply that there are still a lot of open questions to answer about usage before we can leap to that conclusion. Ultimately, we do have to have a reliable repo test case before anything can be done.<br/> In any case, at least at this stage it seems clear that you probably do need a much larger cluster (more nodes with less load on each node.) Yes, it's unfortunate the Cassandra won't give you a nice clean message that says that, but that ultimate requirement remains unchanged - pending answers to all of the open questions.</p> <p>Peter: Agree.</p> <p>Peter:<br/> Now is our old data model (all previous tests- ended with OOM- done with it):<br/> Load was like 20-30Mb/sec.</p> <p>create keyspace OBLREPOSITORY_NY with replication = </p> {'class':'SimpleStrategy', 'replication_factor' : 1} <p>;</p> <p>create table obl_by_security(<br/> day text,<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((security_id, day), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;</p> <p>CREATE INDEX ON obl_by_security (deal_code); <br/> CREATE INDEX ON obl_by_security (producer_id);<br/> create table obl_by_producer(<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key (producer_id, publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;<br/> create table obl_by_deal_code(<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key (deal_code, publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;<br/> create table obl_by_deal_code_per_security(<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((deal_code, security_id), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;</p> <p>Our today’s data model (very new), day added in partition to additional 3 tables to reduce ROW “wideness”. Test we started is 5.5 Mb/sec, runs already 4 days.</p> <p>create table obl_by_security(<br/> day text,<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((security_id, day), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;</p> <p>CREATE INDEX ON obl_by_security (deal_code); <br/> CREATE INDEX ON obl_by_security (producer_id);<br/> create table obl_by_producer(<br/> day text,<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((producer_id, day), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;<br/> create table obl_by_deal_code(<br/> day text,<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((deal_code, day), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;<br/> create table obl_by_deal_code_per_security(<br/> day text,<br/> security_id text,<br/> producer_id text,<br/> deal_code text,<br/> message blob,<br/> publish_time timestamp,<br/> id uuid,<br/> region text,<br/> primary key ((deal_code, security_id, day), publish_time))<br/> with CLUSTERING ORDER BY (publish_time DESC)<br/> ;</p> <p>Thank you!<br/> Peter.</p>
</comment>
<comment id="15114614" author="jkrupan" created="Mon, 25 Jan 2016 00:38:19 +0000">
<blockquote><p>Number of keys (estimate): 10142095</p></blockquote> <p>That indicates that you have over 99% of your data on a single node, which is a slam-dunk antipattern. Check the numbers to make sure what you posted are valid, and if so, you'll need to redesign your partition key to distribute the data to more partition keys so that they get assigned to other nodes.</p> <p>And if your client is sending INSERT requests to the various nodes of your cluster, five of them will have to forward those requests to that one node.</p> <p>You need to get this resolved before attempting anything else.</p> <p>Was this with RF=1? Presumably since those INSERTS are not being replicated to another node, or else the key count would have been roughly comparable on that other node.</p>
</comment>
<comment id="15114782" author="tierhetze" created="Mon, 25 Jan 2016 05:31:11 +0000">
<p>Jack.<br/> This (row count) is from last tests, where we abandoned "complex" tests with multiple nodes and only test 1 node (no ring) without replication, just to get feeling where is the maximum load for that node.</p> <p>I have no data regarding row count in tests with multiple nodes.</p> <p>Today's 5-th day of test of the low (5Mb/sec load), it is still working.<br/> I see disk IO stats, they show no increase in %iowait (as in OOM tests), so I'm pretty sure the reason was poor IO and great load.<br/> We plan increase load to find node's maximum.<br/> Then attach other nodes, do RF=2 and figure out maximum for that.</p> <p>The problem is "too high supply with gradually degrating IO".<br/> If there were some method to alert about that situation early, it would be great. (for future generations of testers).</p>
</comment>
</comments>
<attachments>
<attachment id="12783059" name="cassandra-to-jack-krupansky.docx" size="25690" author="tierhetze" created="Tue, 19 Jan 2016 10:20:46 +0000"/>
<attachment id="12779611" name="gc-stat.txt" size="799757" author="tierhetze" created="Mon, 28 Dec 2015 05:44:15 +0000"/>
<attachment id="12779393" name="more-logs.rar" size="7802634" author="tierhetze" created="Thu, 24 Dec 2015 06:43:14 +0000"/>
<attachment id="12779411" name="some-heap-stats.rar" size="46598" author="tierhetze" created="Thu, 24 Dec 2015 07:58:04 +0000"/>
<attachment id="12779392" name="test2.rar" size="13749670" author="tierhetze" created="Thu, 24 Dec 2015 06:43:14 +0000"/>
<attachment id="12779565" name="test3.rar" size="3906859" author="tierhetze" created="Sun, 27 Dec 2015 05:49:22 +0000"/>
<attachment id="12779614" name="test4.rar" size="5687328" author="tierhetze" created="Mon, 28 Dec 2015 06:16:24 +0000"/>
<attachment id="12780088" name="test5.rar" size="17462973" author="tierhetze" created="Thu, 31 Dec 2015 06:08:38 +0000"/>
<attachment id="12782760" name="test_2.1.rar" size="12649108" author="tierhetze" created="Sun, 17 Jan 2016 10:09:13 +0000"/>
<attachment id="12782761" name="test_2.1_logs_older.rar" size="9859365" author="tierhetze" created="Sun, 17 Jan 2016 10:09:13 +0000"/>
<attachment id="12782815" name="test_2.1_restart_attempt_log.rar" size="866175" author="tierhetze" created="Mon, 18 Jan 2016 06:46:22 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>11.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 4 Jan 2016 17:34:12 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qa4f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-10922] Inconsistent query results</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10922
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have a DB created with Cassandra 2.2.3. And currently I'm running it by Cassandra 3.0.2.</p> <p>The value of a particular cell is returned depending on the query I run (in cqlsh):</p> <ul class="alternate" type="square"> <li>returned when iterate all columns, i.e.<br/> SELECT value FROM "3xupsource".Content WHERE databaseid=0x21120000 LIMIT 2<br/> (I can see the columns 0x00000000 and 0x01000000 there, the values seem correct)</li> <li>not returned when I specify a particular column<br/> SELECT value FROM "3xupsource".Content WHERE databaseid=0x21120000 AND columnid=0x01000000</li> </ul> <p>Other queries like SELECT value FROM "3xupsource".Content WHERE databaseid=0x21120000 AND columnid=0x00000000 work consistently.</p> <p>There is nothing in Cassandra error log, so it does not look like a corruption.</p>
</description>
<environment/>
<key id="12923734">CASSANDRA-10922</key>
<summary>Inconsistent query results</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="maximp">Maxim Podkolzine</reporter>
<labels></labels>
<created>Tue, 22 Dec 2015 13:00:00 +0000</created>
<updated>Tue, 2 Feb 2016 16:34:46 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15101873" author="slebresne" created="Fri, 15 Jan 2016 14:59:26 +0000">
<p>This certainly look wrong, but I'm not sure how much we can move forward without more information. If you have some idea of how to reproduce that would obviously be very useful. Otherwise, have you tried running scrub just in case? Maybe also tracing the query to see if it provides any useful information. Having an idea of the schema on that table might also be helpful.</p>
</comment>
<comment id="15101962" author="maximp" created="Fri, 15 Jan 2016 15:56:07 +0000">
<p>Unfortunately, we don't know how to reproduce. But we can run any commands and provide all info that can help you.<br/> Could you please describe how to run scrub, or turn on tracing?</p>
</comment>
<comment id="15102056" author="jkrupan" created="Fri, 15 Jan 2016 16:50:38 +0000">
<p>Normally this kind of investigation should be pursued on the user list before assuming that there is an actual bug, but now that we are here...</p> <p>1. Describe how you got to this situation - did you upgrade the old cluster or copy and import sstables, or... exactly what?<br/> 2. Provide the schema. Anxious to know the type of that column and exactly why you are using hex.<br/> 3. Create a dummy table with exactly the same schema and compose INSERT statements that insert the data you are querying. Does the query work fine on that dummy table? Post that schema, INSERTS, SELECTs, and output here.<br/> 4. Create that same dummy table in a single-node test cluster running C* 2.2.3, execute those dummy INSERTs, see that the query works the way it used to, "upgrade" that test database to C* 3.0.2 the same way you did your main cluster and see if the query fails in the way you have reported. If it doesn't... then nobody here will have much to go on. IN any case, be sure to post the exact steps you used.</p> <p>That's a lot of work to do, but start by posting the schema and the output of the query that shows both rows.</p>
</comment>
<comment id="15128501" author="slebresne" created="Tue, 2 Feb 2016 16:34:46 +0000">
<blockquote><p>we can run any commands and provide all info that can help you</p></blockquote> <p>The schema and the result of both tracing and scrubbing would be a good start</p> <blockquote><p>Could you please describe how to run scrub, or turn on tracing</p></blockquote> <p>For scrub, see <a href="https://docs.datastax.com/en/cassandra/2.2/cassandra/tools/toolsScrub.html" class="external-link" rel="nofollow">https://docs.datastax.com/en/cassandra/2.2/cassandra/tools/toolsScrub.html</a>. For tracing, just do <tt>TRACING ON</tt> in cqlsh before issuing the query and you'll get a trace printed with the result of the query.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 15 Jan 2016 14:59:26 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2q7mv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12334321</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10872] Debian Package does not prompt the user to review the config files; it just replaces them causing trouble (since the daemon starts by default)
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10872
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We run Cassandra 2.0.16 on Ubuntu 12.04 and were trying to upgrade to 2.0.17 due to <a href="https://issues.apache.org/jira/browse/CASSANDRA-9662" title="compactionManager reporting wrong pendingtasks" class="issue-link" data-issue-key="CASSANDRA-9662"><del>CASSANDRA-9662</del></a>. The problem is that during the upgrade the we were not prompted how to handle cassandra-env.sh and cassandra-rackdc.properties. </p> <p>The output from the upgrade:</p> <div class="panel" style="border-width: 1px;"><div class="panelContent"> <p>...<br/> Setting up cassandra (2.0.17) ...<br/> Installing new version of config file /etc/cassandra/cassandra-env.sh ...<br/> Installing new version of config file /etc/cassandra/cassandra-rackdc.properties ...<br/> vm.max_map_count = 1048575<br/> net.ipv4.tcp_keepalive_time = 300<br/> ...</p> </div></div> <p>This meant that the nodes started automatically after the install with the wrong DC name. </p> <p>I don't think that these config files should have been replaced without the admin being asked; this doesn't appear to comply with standard Debian packages.</p> <p>Secondly if <a href="https://issues.apache.org/jira/browse/CASSANDRA-2356" title="make the debian package never start by default" class="issue-link" data-issue-key="CASSANDRA-2356">CASSANDRA-2356</a> was implemented the problem would not be as severe; i.e. it would be possible to workaround this issue. Whereas currently, there is no way to prevent the node when upgraded from starting in the wrong DC.</p>
</description>
<environment><p>Ubuntu 12.04, Cassandra 2.0.16 -&gt; 2.0.17</p></environment>
<key id="12921908">CASSANDRA-10872</key>
<summary>
Debian Package does not prompt the user to review the config files; it just replaces them causing trouble (since the daemon starts by default)
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mshuler">Michael Shuler</assignee>
<reporter username="synbit">Vasilis</reporter>
<labels>
<label>debian</label>
<label>packaging</label>
</labels>
<created>Tue, 15 Dec 2015 09:24:59 +0000</created>
<updated>Thu, 7 Jan 2016 16:33:17 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.0.x</fixVersion>
<fixVersion>3.x</fixVersion>
<component>Packaging</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15058577" author="mshuler" created="Tue, 15 Dec 2015 19:11:15 +0000">
<p>Thanks for the report, <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=synbit" class="user-hover" rel="synbit">Vasilis</a>.</p>
</comment>
<comment id="15059718" author="synbit" created="Wed, 16 Dec 2015 08:54:23 +0000">
<p>No problem and thanks for looking into this.</p> <p>I am not sure what the EOL of version 2.0 is, but it's probably worth mentioning that this bug was introduced in 2.0.17 (the upgrade to versions up to 2.0.16 did not behave like this at all). It is impossible (at least not in a safe manner) for people to upgrade safely within 2.0.x, or to upgrade from earlier versions (pre-2.0) to the latest Cassandra version, but through 2.0.x (which is necessary in situations like this).</p> <p>With that in mind, wouldn't it make more sense to create 2.0.18 with that fix instead? Any thoughts on this?</p>
</comment>
<comment id="15060160" author="mshuler" created="Wed, 16 Dec 2015 15:35:13 +0000">
<p>2.0 has been EOL for a while now, 2.1 is close to EOL (will probably get 1-2 more releases). This is why I marked 2.1.x as the fixver.</p>
</comment>
<comment id="15060339" author="synbit" created="Wed, 16 Dec 2015 17:19:58 +0000">
<p>Have you been able to reproduce it <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mshuler" class="user-hover" rel="mshuler">Michael Shuler</a>? This morning I installed Ubuntu 12.04 on two VMs, copied the 2.0.16 debian package from the live cluster, installed it using <em>dpkg --install &lt;package.deb&gt;</em>, did an update/upgrade in order to go to 2.0.17 and I got different behaviour... I wasn't prompted but the files were not replaced this time. I cannot understand why yet, but I hope this might be useful to you? Have I done something stupid here???? I followed exactly the same path in order to go from <em>2.0.16 -&gt; 2.0.17</em> in both scenarios. I also checked that the 2.0.17 package that I got from my <em>cassandra.list</em> found in <em>/var/cache/apt/archives</em> is the same as the one in the live cluster.</p> <p>On a side note, I was under the impression that DC name cannot change once set according to the <a href="http://docs.datastax.com/en/cassandra/2.0/cassandra/initialize/initializeMultipleDS.html" class="external-link" rel="nofollow">documentation</a>, but then I found <a href="https://issues.apache.org/jira/browse/CASSANDRA-9474" title="Validate dc information on startup" class="issue-link" data-issue-key="CASSANDRA-9474"><del>CASSANDRA-9474</del></a>, which in a way I am happy it hasn't been fixed for 2.0.x. So, I just changed the <em>cassandra-rackdc.properties</em> and it looks like it worked for me.</p>
</comment>
<comment id="15060486" author="mshuler" created="Wed, 16 Dec 2015 18:34:38 +0000">
<p>I have not tested this out, yet. I'm working on a package build/install job in CI, then we can use those packages to automate upgrade testing like this.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12501808">CASSANDRA-2356</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 15 Dec 2015 19:11:15 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pwdr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10777] LegacySSTableTest Test-case failure, Issue with test\data\legacy-sstables\jb\Keyspace1\Keyspace1-Standard1-jb-0-Summary.db file read on BIG ENDian systems
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10777
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I am building Cassandra 2.2.3 on BigEndian System. Cassandra builds successfully. However there are quite a few test case failures. One of the failing test case is LegacySSTableTest. This test case reads the file test\data\legacy-sstables\jb\Keyspace1\Keyspace1-Standard1-jb-0-Summary.db</p> <p>Are these existing test data files, specific to Little Endian systems?</p> <p>I have observed differences in values read on a LE Vs BE systems.</p> <p>I use the following command to run the test case. ant test -Dtest.name=LegacySSTableTest</p> <p>I get the following error:</p> <p><span class="error">&#91;junit&#93;</span> ------------- Standard Error -----------------<br/> <span class="error">&#91;junit&#93;</span> Failed to read jb<br/> <span class="error">&#91;junit&#93;</span> ------------- ---------------- ---------------<br/> <span class="error">&#91;junit&#93;</span> Testcase: testStreaming(org.apache.cassandra.io.sstable.LegacySSTableTest): FAILED<br/> <span class="error">&#91;junit&#93;</span> null<br/> <span class="error">&#91;junit&#93;</span> junit.framework.AssertionFailedError<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.IndexSummary.&lt;init&gt;(IndexSummary.java:80)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.IndexSummary$IndexSummarySerializer.deserialize(IndexSummary.java:317)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.loadSummary(SSTableReader.java:877)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:730)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:692)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:480)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:376)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:371)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:363)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.LegacySSTableTest.testStreaming(LegacySSTableTest.java:115)<br/> <span class="error">&#91;junit&#93;</span> at org.apache.cassandra.io.sstable.LegacySSTableTest.testStreaming(LegacySSTableTest.java:110)</p>
</description>
<environment><p>OS:RHEL7 and BIG ENDian system</p></environment>
<key id="12916548">CASSANDRA-10777</key>
<summary>
LegacySSTableTest Test-case failure, Issue with test\data\legacy-sstables\jb\Keyspace1\Keyspace1-Standard1-jb-0-Summary.db file read on BIG ENDian systems
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="nirav">Nirav Thakkar</reporter>
<labels></labels>
<created>Fri, 27 Nov 2015 05:42:26 +0000</created>
<updated>Thu, 17 Dec 2015 10:25:20 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15029565" author="mshuler" created="Fri, 27 Nov 2015 07:41:46 +0000">
<p>I don't have a specific answer to endian-ness of the test sstable, but it's possible. Is there a big endian AWS instance type that can be used to replicate your result? This particular test has been stable on m3.xlarge instances.</p> <p><a href="http://cassci.datastax.com/job/cassandra-2.2_utest/lastCompletedBuild/testReport/org.apache.cassandra.io.sstable/LegacySSTableTest/history/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.2_utest/lastCompletedBuild/testReport/org.apache.cassandra.io.sstable/LegacySSTableTest/history/</a></p>
</comment>
<comment id="15030367" author="nirav" created="Sat, 28 Nov 2015 04:01:32 +0000">
<p>The values on LE and BE for reading as integer has some variation.</p>
</comment>
<comment id="15030368" author="nirav" created="Sat, 28 Nov 2015 04:01:54 +0000">
<p>Sorry, but we dont have AWS instance which can be used. I am attaching the screenshots of the file- Standard-jb-Summary(LE and BE) which is used for the TestCase. The issue in the Test-case is while reading data as an integer, the value comes out to be very large, which is not the case with LE(please see the highlighted part in the attachment),and hence the assertion fails on BE system. </p> <p>Also we created a sample table, and created SSTables using "flush keyspace", and we observed difference in the file Standard-jb-Summary, for BE compared to LE. Please check the attachment for the difference, we observed.</p>
</comment>
<comment id="15030414" author="nirav" created="Sat, 28 Nov 2015 07:31:18 +0000">
<p>Though the tables contain the same values, there is difference in the SSTable Summary file on BE and LE.</p>
</comment>
<comment id="15061841" author="nirav" created="Thu, 17 Dec 2015 10:13:35 +0000">
<p>Is it possible to give me the steps or just tell me how these files are generated, so I can try generating the files on the environment I am using. If there is a difference then we can work on it.</p>
</comment>
</comments>
<attachments>
<attachment id="12774689" name="IndexSummaryBE.jpg" size="131829" author="nirav" created="Sat, 28 Nov 2015 04:01:32 +0000"/>
<attachment id="12774690" name="IndexSummaryLE.jpg" size="129389" author="nirav" created="Sat, 28 Nov 2015 04:01:32 +0000"/>
<attachment id="12774695" name="SampleTable_Summary.db_BE.jpg" size="49137" author="nirav" created="Sat, 28 Nov 2015 07:31:18 +0000"/>
<attachment id="12774696" name="SampleTable_Summary.db_LE.jpg" size="73489" author="nirav" created="Sat, 28 Nov 2015 07:31:18 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>4.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 27 Nov 2015 07:41:46 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ozv3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-9947] nodetool verify is broken</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9947
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Raised these issues on <a href="https://issues.apache.org/jira/browse/CASSANDRA-5791" title="A nodetool command to validate all sstables in a node" class="issue-link" data-issue-key="CASSANDRA-5791"><del>CASSANDRA-5791</del></a>, but didn't revert/re-open, so they were ignored:</p> <p>We mark sstables that fail verification as unrepaired, but that's not going to do what you think. What it means is that the local node will use that sstable in the next repair, but other nodes will not. So all we'll end up doing is streaming whatever data we can read from it, to the other replicas. If we could magically mark whatever sstables correspond on the remote nodes, to the data in the local sstable, that would work, but we can't.</p> <p>IMO what we should do is:</p> <ul> <li>scrub, because it's quite likely we'll fail reading from the sstable otherwise and</li> <li>full repair across the data range covered by the sstable</li> </ul> <p>Additionally,</p> <ul> <li>I'm not sure that keeping "extended verify" code around is worth it. Since the point is to work around not having a checksum, we could just scrub instead. This is slightly more heavyweight but it would be a one-time cost (scrub would build a new checksum) and we wouldn't have to worry about keeping two versions of almost-the-same-code in sync.</li> </ul>
</description>
<environment/>
<key id="12850593">CASSANDRA-9947</key>
<summary>nodetool verify is broken</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jbellis">Jonathan Ellis</reporter>
<labels></labels>
<created>Fri, 31 Jul 2015 13:09:58 +0000</created>
<updated>Mon, 7 Dec 2015 18:21:18 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>6</watches>
<comments>
<comment id="14649199" author="jbellis" created="Fri, 31 Jul 2015 13:11:26 +0000">
<p>IMO we should disable verify for 2.2.1 until we can rearchitect it since this is a nontrivial change.</p>
</comment>
<comment id="14977114" author="jjirsa" created="Tue, 27 Oct 2015 20:36:47 +0000">
<p>The intent behind marking it as unrepaired was to allow other nodes to repair this data inbound, though it does make sense that by doing so, we'll also potentially pollute that corrupt data out to other replicas. Issuing a scrub may not be the right fix, either - a single bit flip in an uncompressed table will scrub just fine, and nothing will happen except you'll write a new checksum and lose knowledge of the fact that the bit-flip happened. </p> <p>Maybe the limitation here is that we have effectively 2 states - repaired and unrepaired - when we need a third - corrupt - so we can force this local node to repair its range, without using that sstable as a source for outgoing repair streams? </p> <p>Maybe the right thing to do is just trigger disk failure policy and let the operator decide what to do with it? Then they can offline scrub and throw away data from compressed tables, or delete uncompressed and let it be repaired. </p>
</comment>
<comment id="15000955" author="aweisberg" created="Wed, 11 Nov 2015 19:39:39 +0000">
<p>The fact that we never validate checksums on uncompressed data on reads creates problems for repair even before verify is run. We can propagate corrupted data because the merkle tree is going to detect the corruption and attempt to propagate it without validating the checksum of the corrupt data.</p> <p>Right now scrub isn't going to validate checksums on uncompressed files, based on my reading, so scrubbing won't improve the situation.. I also don't see how scrub can fix a corrupted compressed tables since the checksum is not per record. It's going to be an arbitrary 64k page. You could try and parse the page anyways, but that is not what is currently done since the reader will just throw an exception if you try. Corrupted sstables work fine in the regular path because the index points you do a valid place to start reading from, but that won't work for a sequential walk through the file.</p> <p>It seems to me like we are shuffling deck chairs on the titanic once we allow repair to propagate corrupted data. You could say the same about returning corrupted data to user queries since those can be used to propagate the corruption back into C* at all replicas.</p> <p>If there are flows of handling corruption we want to have it might make sense to create some test cases for the various file formats and see what the existing code actually does. My suspicion is that sequential access is going to fail in the compressed compressed stuff and blindly succeed in uncompressed case. </p> <p>We also need to nail down fix versions since coalescing to something that works might not be possible/worthwhile against existing formats. And while we are at it maybe we should nail down file formats we are more happy with in terms of being flexible about block sizes, implementing a page cache etc.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 27 Oct 2015 20:36:47 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2i6i7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11200] CompactionExecutor thread error brings down JVM in 3.0.3
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11200
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When launching Cassandra 3.0.3, with java version "1.8.0_74", Cassandra writes the following to the debug file before a segmentation fault occurs bringing down the JVM - the problem is repeatable.</p> <p>DEBUG <span class="error">&#91;CompactionExecutor:1&#93;</span> 2016-02-20 18:26:16,892 CompactionTask.java:146 - Compacting (56f677c0-d829-11e5-b23a-25dbd4d727f6) <span class="error">&#91;/var/lib/cassandra/data/sensordb/periodicReading/ma-367-big-Data.db:level=0, /var/lib/cassandra/data/sensordb/periodicReading/ma-368-big-Data.db:level=0, /var/lib/cassandra/data/sensordb/periodicReading/ma-371-big-Data.db:level=0, /var/lib/cassandra/data/sensordb/periodicReading/ma-370-big-Data.db:level=0, /var/lib/cassandra/data/sensordb/periodicReading/ma-369-big-Data.db:level=0, &#93;</span></p> <p>The JVM error that occurs is the following:</p> <p>&#35;<br/> &#35; A fatal error has been detected by the Java Runtime Environment:<br/> &#35;<br/> &#35; SIGBUS (0x7) at pc=0x00007fa8a1052150, pid=12179, tid=140361951868672<br/> &#35;<br/> &#35; JRE version: Java(TM) SE Runtime Environment (8.0_74-b02) (build 1.8.0_74-b02)<br/> &#35; Java VM: Java HotSpot(TM) 64-Bit Server VM (25.74-b02 mixed mode linux-amd64 compressed oops)<br/> &#35; Problematic frame:<br/> &#35; v ~StubRoutines::jbyte_disjoint_arraycopy<br/> &#35;<br/> &#35; Core dump written. Default location: /tmp/core or core.12179<br/> &#35;<br/> &#35; If you would like to submit a bug report, please visit:<br/> &#35; <a href="http://bugreport.java.com/bugreport/crash.jsp" class="external-link" rel="nofollow">http://bugreport.java.com/bugreport/crash.jsp</a><br/> &#35;</p> <p>--------------- T H R E A D ---------------</p> <p>Current thread (0x00007fa89c56ac20): JavaThread "CompactionExecutor:1" daemon <span class="error">&#91;_thread_in_Java, id=12323, stack(0x00007fa89043f000,0x00007fa890480000)&#93;</span></p> <p>siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00007fa838988002</p> <p>Even if all of the files associated with "ma-<span class="error">&#91;NNN&#93;</span><b>" are removed, the JVM dies with the same error after the next group of "ma-<span class="error">&#91;NNN&#93;</span></b>" are eventually written out and compacted.</p> <p>Though this may be strictly a JVM problem, I have seen the issue in Oracle JVM 8.0_65 and 8.0_74 and I raise it in case this problem is due to JNI usage of an external compression library or some direct memory usage.</p> <p>I have a core dump if that is helpful to anyone.</p> <p>Bug <a href="https://issues.apache.org/jira/browse/CASSANDRA-11201" title="Compaction memory fault in 3.0.3" class="issue-link" data-issue-key="CASSANDRA-11201">CASSANDRA-11201</a> may also be related although when the exception referenced in the bug occurs, the JVM remains alive.</p>
</description>
<environment>
<p>debian jesse latest release, updated Feb. 20th</p>
</environment>
<key id="12940831">CASSANDRA-11200</key>
<summary>
CompactionExecutor thread error brings down JVM in 3.0.3
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="longtimer">Jason Kania</reporter>
<labels></labels>
<created>Sat, 20 Feb 2016 23:47:14 +0000</created>
<updated>Fri, 26 Feb 2016 15:42:24 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15169209" author="slebresne" created="Fri, 26 Feb 2016 15:42:24 +0000">
<p>If you know how to reproduce that would be ideal, otherwise the core dump would be indeed useful.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 26 Feb 2016 15:42:24 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t4an:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9669] If sstable flushes complete out of order, on restart we can fail to replay necessary commit log records
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9669
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>While <tt>postFlushExecutor</tt> ensures it never expires CL entries out-of-order, on restart we simply take the maximum replay position of any sstable on disk, and ignore anything prior. </p> <p>It is quite possible for there to be two flushes triggered for a given table, and for the second to finish first by virtue of containing a much smaller quantity of live data (or perhaps the disk is just under less pressure). If we crash before the first sstable has been written, then on restart the data it would have represented will disappear, since we will not replay the CL records.</p> <p>This looks to be a bug present since time immemorial, and also seems pretty serious.</p>
</description>
<environment/>
<key id="12841172">CASSANDRA-9669</key>
<summary>
If sstable flushes complete out of order, on restart we can fail to replay necessary commit log records
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="benedict">Benedict</reporter>
<labels>
<label>correctness</label>
</labels>
<created>Sun, 28 Jun 2015 13:11:35 +0000</created>
<updated>Tue, 2 Feb 2016 12:00:21 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.0.x</fixVersion>
<fixVersion>3.x</fixVersion>
<component>Local Write-Read Paths</component>
<due/>
<votes>0</votes>
<watches>11</watches>
<comments>
<comment id="14628109" author="benedict" created="Wed, 15 Jul 2015 14:18:40 +0000">
<p>So, I've been mulling this over and would like to outline the tradeoffs and get agreement before implementation:</p> <p>The simplest approach is to <em>delay flush completion</em> until all prior flushes have succeeded. i.e., all flushes for a given table will complete in the order they are submitted, i.e. in CommitLog order. They will remain as tmp files, and the memtables will continue to service requests for that data, until all earlier flushes for that table have also completed. There is one serious flaw here, though, which is that <a href="https://issues.apache.org/jira/browse/CASSANDRA-7275" title="Errors in FlushRunnable may leave threads hung" class="issue-link" data-issue-key="CASSANDRA-7275"><del>CASSANDRA-7275</del></a> becomes even more devastating. In this scenario, the server's memtable space will rapidly be completely exhausted, and there is simply no escaping it. </p> <p>In 2.1+ we can mitigate this by "opening early" (even though it's a flush) and evicting the memtable immediately, only upgrading it to a permanent file once prior flushes have completed. However 2.0's stability for some users may be significantly affected.</p> <p>Another possibility is to begin saving the start replay position with sstables (on top of end), and on restart ensure we replay anything present in a gap. This would mean a number of small changes with e.g. metadata, but would also introduce some extra compaction complexity, which I'm reticent to introduce: we would have to prevent compaction from being permitted on any sstable that was "ahead" of its prior flushes. Compaction logic is already unpleasantly complex around these kinds of decisions, especially in 2.1, and introduces risks to 2.0 and 2.1 I would like to avoid.</p> <p>Any solution is going to be more involved than I would like for 2.0 or 2.1, though.</p>
</comment>
<comment id="14628484" author="benedict" created="Wed, 15 Jul 2015 18:15:11 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=xedin" class="user-hover" rel="xedin">Pavel Yaskevich</a>: your input would be appreciated here, since you're the only user we know of to have encountered <a href="https://issues.apache.org/jira/browse/CASSANDRA-7275" title="Errors in FlushRunnable may leave threads hung" class="issue-link" data-issue-key="CASSANDRA-7275"><del>CASSANDRA-7275</del></a> (though no doubt there are others).</p>
</comment>
<comment id="14629755" author="benedict" created="Thu, 16 Jul 2015 13:51:43 +0000">
<p>I've pushed branches for <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.0" class="external-link" rel="nofollow">2.0</a> <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.1" class="external-link" rel="nofollow">2.1</a> and <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.2" class="external-link" rel="nofollow">2.2</a></p> <p>All of them are ugly.</p>
</comment>
<comment id="14631186" author="benedict" created="Fri, 17 Jul 2015 10:58:40 +0000">
<p>So, I am liking this approach less and less. It may be the least effort, but it has too many sharp edges, in critical portions of the system. It's also literally a custom endeavour for 2.0, 2.1, 2.2 <em>and</em> 3.0.</p> <p>I think I will introduce a new commit log expiration ledger, and just write to it whenever we perform a <tt>discardCompletedSegments()</tt> call. This is then replayed prior to CL replay, to build the state of what records we consider replayable. Initially, I will limit this to a simple statement of "latest replayposition we can be certain to have replayed to" since this is a uniform behaviour for 2.0+. 2.1+ easily supports ranges, which can be implemented when we deliver <a href="https://issues.apache.org/jira/browse/CASSANDRA-8496" title="Remove MemtablePostFlusher" class="issue-link" data-issue-key="CASSANDRA-8496">CASSANDRA-8496</a>.</p>
</comment>
<comment id="14631236" author="benedict" created="Fri, 17 Jul 2015 11:58:08 +0000">
<p>Ick. So, thinking about it from a 2.0 perspective, this is even more of a problem for counters. Since CL replay of a counter that is already persisted causes a double-count. </p> <p>Question is: do we care? If we do, we should probably stick with the solution I already posted for 2.0. For 2.1+ I think a ledger is a better route.</p>
</comment>
<comment id="14631764" author="xedin" created="Fri, 17 Jul 2015 19:14:27 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict" class="user-hover" rel="benedict">Benedict</a> I like min/max replay range tracking per sstable idea from <a href="https://issues.apache.org/jira/browse/CASSANDRA-8496" title="Remove MemtablePostFlusher" class="issue-link" data-issue-key="CASSANDRA-8496">CASSANDRA-8496</a> you've also mentioned here. I'm pretty sure some extra complexity in the compaction path is worth having safe reply.</p>
</comment>
<comment id="14645845" author="benedict" created="Wed, 29 Jul 2015 10:30:45 +0000">
<p>So, I have a patch available for this <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.0" class="external-link" rel="nofollow">here</a></p> <p>I managed to make it less invasive than I had anticipated, but it still requires an sstable version increment. The patch:</p> <ul> <li>Introduces a commitLogLowerBound to the memtable, which tracks the commit log position at its creation</li> <li>Changes sstable metadata's "replayPosition" into "commitLogLowerBound" and "commitLogUpperBound" in the new sstable version</li> <li>Delays exposing a new sstable to the compaction strategy until all of its preceding flushes have completed</li> <li>On compaction, extends the new sstable's lower/upper bounds to the min/max of all sstables we're replacing. Given (3), we only extend over ranges that are known to already be covered by other sstables.</li> <li>On replay, we take any range covered by an sstable to not need replay (and any range prior to the earliest known safe range is also ignored)</li> </ul> <p>Test Engineering: there are failures on dtests, but I cannot tell if these are new or existing. Mostly the look like flakey tests. The one that looks most worrisome to me is counter upgrade test, but could you take a look and tell me what you think of the test situation in general? Modifying 2.0 makes me uncomfortable</p>
</comment>
<comment id="14701436" author="blambov" created="Tue, 18 Aug 2015 15:36:34 +0000">
<p>First round of review, focussing at the replay logic:</p> <p><tt>ReplayPosition.add</tt> is suspect, as <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-2b76f3efa4aaa38339ab8f4869c9b7bfR70" class="external-link" rel="nofollow">in extending the end</a> <tt>extend != null</tt> implies <tt>extend.getKey().compareTo(end) &gt;= 0</tt> and this makes the branch reachable only if <tt>end == entend.getKey()</tt> which I don't think is what you want.</p> <p>The other direction appears correct, but the two can't be symmetrical as we can only key into starts. This is sufficient as <tt>range[i].key/lower &lt; range[i].value/upper &lt; range[i+1].key/lower</tt> (which I think you should clarify in a comment) and thus the entry we want to extend us on the right is the one before the first start larger than our end. <tt>end = max(end, floorEntry(end).value)</tt> should do it.</p> <p>There's no need to recursively rerun, extending in either direction has no effect on the other side so you can do the two in sequence.</p> <p><tt>ReplayPosition.min</tt> should be a bit more descriptively named, e.g. "minUpperBound" or "firstNotCovered".</p> <p>I'd call <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-348a1347dacf897385fb0a97116a1b5eR166" class="external-link" rel="nofollow">CommitLogReplayer.replay</a> "shouldReplay". Consider moving the containment logic (the last two lines) into <tt>ReplayPosition</tt> to keep the details of the range format within the class. I believe the intervals are start-inclusive, end-exclusive, thus the <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-348a1347dacf897385fb0a97116a1b5eR172" class="external-link" rel="nofollow">final comparison</a> should be <tt>&lt;=</tt>.</p> <p>Could you update the JavaDoc, especially returned values (e.g. <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-98f5acb96aa6d684781936c141132e2aR2498" class="external-link" rel="nofollow">here</a> and <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-f0a15c3588b56c5ce53ece7c48e325b5R247" class="external-link" rel="nofollow">here</a>)? The comment <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-348a1347dacf897385fb0a97116a1b5eR333" class="external-link" rel="nofollow">here</a> is outdated.</p> <p>Is <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-f0a15c3588b56c5ce53ece7c48e325b5R352" class="external-link" rel="nofollow">FlushRunnable.runMayThrow</a> still needed? DiskAwareRunnable?</p> <p>I'll continue looking at rest of the code tomorrow.</p>
</comment>
<comment id="14701694" author="benedict" created="Tue, 18 Aug 2015 17:55:16 +0000">
<p>Thanks. Looking at the patch, it's clear I wrote it in a bit of a rush, as there's another problem with it: it doesn't actually delay compaction with STCS. I will need to make STCS rely on the notifyAdded, much as LCS does, or introduce a new collection in <tt>DataTracker</tt> (this latter being less invasive, but uglier)</p> <p>I will look to introduce at least a basic unit test for this problem, as well as fix these problems, tomorrow. However the main thrust of the patch is still good, so it's up to you if you want to abort review in lieu of this.</p>
</comment>
<comment id="14702785" author="blambov" created="Wed, 19 Aug 2015 09:53:54 +0000">
<p>Should we really ignore the timespan before the first known sstable interval? This can break correct replay for a fresh table, can't it (if the first two flushes are initiated close together and the node dies after the latter completes early)?</p> <p><tt>CompactionManager.instance.submitBackground(cfstore)</tt> in <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-06edf300ef64021a42929f19d0cfba3bR185" class="external-link" rel="nofollow">permitCompactionOfFlush</a> is new and appears to be a change in behaviour. Could you explain in a comment why it is now necessary?</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.0#diff-0c40f7e67fc53dd15d5fe193e55b2b04R494" class="external-link" rel="nofollow">SSTableMetadata.deserialize</a>: is there a reason to pass <tt>hasCommitLogLowerBound</tt> around separately when it always matches the one in the passed descriptor?</p>
</comment>
<comment id="14702841" author="benedict" created="Wed, 19 Aug 2015 10:42:51 +0000">
<blockquote><p>Should we really ignore the timespan before the first known sstable interval? This can break correct replay for a fresh table, can't it (if the first two flushes are initiated close together and the node dies after the latter completes early)?</p></blockquote> <p>You mean the global position, I assume? I wasn't really sure the best thing to do here, since it's a major performance optimisation to skip large chunks of commit log. I'm not so sure about regressing 2.0 replay for a border case during replay of a fresh table, when we've been so broken for all tables. I'm also reticent to make more changes than absolutely necessary; tracking the commit log replay position at construction of a table would be the better solution, but I would rather wait until 3.0+ for that.</p> <p>I'm working on improving the comments as well as addressing the other issues.</p>
</comment>
<comment id="14702860" author="benedict" created="Wed, 19 Aug 2015 11:10:08 +0000">
<p>I've pushed an update that I hope addresses most of your (current) concerns. I'll now work on introducing some basic unit tests, before giving it another final review of my own.</p>
</comment>
<comment id="14703619" author="benedict" created="Wed, 19 Aug 2015 19:36:40 +0000">
<p>I've updated the patch to include a unit test, and to fix two more problems. One typo, and the <tt>shouldReplay</tt> logic was still incorrect. Whenever I interface with ReplayPosition I have a strong urge to rewrite it. It is terribly counterintuitive, but I guess that's what we have unit tests for.</p> <p>Long story short, the ranges are inclusive-start, exclusive-end, the inverse of what you expected. This confusion stems from the fact we use points to represent ranges (i.e. commit log entries) and points that demarcate ranges (those that have been persisted), which doesn't really make sense. But during replay, and on a write, the <tt>ReplayPosition</tt> for a record is the position in the segment <em>directly proceeding</em> its serialization location, i.e. it is the exclusive upper bound of its bytes. It is, in effect, represented by the one number that falls outside of its on disk representation.</p> <p>Anyway, it's good for a proper review now. I accidentally collapsed the most recent follow up commit with the one I uploaded this morning, but mostly this was just the unit test, plus those two items (one removed <tt>!</tt>, and the inverted bounds checking)</p>
</comment>
<comment id="14704693" author="blambov" created="Thu, 20 Aug 2015 11:21:27 +0000">
<p>The code looks good now, +1.</p> <blockquote><p>the ranges are inclusive-start, exclusive-end, the inverse of what you expected</p></blockquote> <p>Yes, they are the inverse of what I expected, but that's actually start-exclusive, end-inclusive, the <a href="https://github.com/apache/cassandra/commit/459b96333c84837fe757d706c2a6be91b8b27f2e#diff-2b76f3efa4aaa38339ab8f4869c9b7bfR88" class="external-link" rel="nofollow">shouldReplay comment</a> is correct. I'd also add "as a mutation's replay position is assigned after it is added to the log" to it.</p> <p>Deleting the files at <a href="https://github.com/apache/cassandra/commit/459b96333c84837fe757d706c2a6be91b8b27f2e#diff-b3802331f8dcba05356ad47ee54fe6dfR321" class="external-link" rel="nofollow">the start of the test</a> may cause problems on Windows, but I don't know how to this safely in 2.0.</p>
</comment>
<comment id="14738563" author="benedict" created="Thu, 10 Sep 2015 10:41:04 +0000">
<p>There was a consensus that it was too late in 2.0's lifecycle to fix this there, however the patch is available for anyone that wants to apply it.</p> <p>I've merged/rebased with 2.1 <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.1" class="external-link" rel="nofollow">here</a>, which necessarily changes it not insignificantly. It's ready for another round of review (although CI is screwy right now, so hard to say with certainty it hasn't introduced any regressions).</p>
</comment>
<comment id="14745367" author="blambov" created="Tue, 15 Sep 2015 12:41:15 +0000">
<p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-f0a15c3588b56c5ce53ece7c48e325b5R171" class="external-link" rel="nofollow">Memtable.isCleanAfter</a> doesn't look right. This guarantees that it does not contain data <em>before</em> the given position, and thus <tt>CFS.forceFlush(ReplayPosition)</tt> does not appear to use it correctly.</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-d1b9592895e36631679f1d5cab0f61f1R97" class="external-link" rel="nofollow">Descriptor.Version.isCompatible</a> is suspect in the context of this ticket, "ka" reader says compatible with "kb" data but read will fail. Later readers (e.g. "la") will also fail to read these tables but say they are compatible. Could this cause trouble?</p> <p>The new format needs to be added to <tt>LegacySSTableTest</tt> and <tt>test/data/legacy-sstables</tt> and included in 2.2 and 3.0 versions of the patch.</p> <p><br class="atl-forced-newline" /> <br class="atl-forced-newline" /> Nits:</p> <p><a href="https://github.com/belliottsmith/cassandra/blob/d190c29d5e24e0b2a93a844d250695107e8bb942/src/java/org/apache/cassandra/db/Memtable.java#L64" class="external-link" rel="nofollow">Memtable.approximateCommitLogLowerBound</a>: This must satisfy <tt>approximateCommitLogLowerBound &lt;= commitLogLowerBound</tt> (after discarding predecessor), mustn't it? Could you add a comment to say so?</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-98f5acb96aa6d684781936c141132e2aR972" class="external-link" rel="nofollow">Memtable.forceFlush(ReplayPosition)</a> no longer loops through index CFSes, can you add a comment to state why this is the right thing to do?</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-f0a15c3588b56c5ce53ece7c48e325b5R379" class="external-link" rel="nofollow">writeSortedContents</a>: duplicate log?</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-d1b9592895e36631679f1d5cab0f61f1R56" class="external-link" rel="nofollow">Descriptor.Version version text</a>: 2.<em>1</em>.7; j versions are compatible according to <tt>isCompatible</tt>, shouldn't comment be retained?</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-0f1c5b6135b34548f033e5168f6761a5R96" class="external-link" rel="nofollow">LegacyMetadataSerializer.serialize</a>: No need to declare <tt>commitLogUpperBound</tt> here. Declare with assignment below to ease reading.</p> <p><a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.1#diff-63785fd0e03996f22c0c2c38eb137f7fR71" class="external-link" rel="nofollow">SSTableMetadataViewer</a>: Could use some text describing what's being printed.</p>
</comment>
<comment id="14745432" author="benedict" created="Tue, 15 Sep 2015 13:10:32 +0000">
<blockquote><p>Memtable.isCleanAfter doesn't look right. </p></blockquote> <p>Good catch, I have inverted the implementation and meaning, and renamed it to <tt>mayContainDataSince</tt></p> <blockquote><p>"ka" reader says compatible with "kb" data but read will fail</p></blockquote> <p>Hmm. This is a bit of a problem. I must admit I didn't look too closely at compatibility, since I assumed the whole point of the major/minor chars was to permit intra- and extra-version sstable version increments. Without that, this seems to be a bit of a mess. I guess we will need to increment all of the sstable versions past the max of the current. We should perhaps rethink accepting all versions &lt;= first char of current, as it doesn't permit much flexibility.</p> <p>Thanks. I'll address this, your nits, and what looks like a relatively innocuous problem with DTCS shortly.</p>
</comment>
<comment id="14745464" author="benedict" created="Tue, 15 Sep 2015 13:40:55 +0000">
<blockquote><p>Hmm. This is a bit of a problem. </p></blockquote> <p>I remember now why it is not. We don't generally permit downgrades, and when upgrading you must upgrade via the latest of any intervening minor version. </p> <p>Whether or not this is a problem, I think it's probably better left for another ticket, but I think we would be best off fixing it so a given c* version knows the maximum sstable version it can read for each prior (and equal) minor cassandra version. So long as the main data format is the same (which is the case here) there shouldn't be a problem, as we only stream the data contents between nodes, so there's no reason for an old version to see a new file. However we should probably make that more robust to sstable version changes also.</p>
</comment>
<comment id="14745503" author="iamaleksey" created="Tue, 15 Sep 2015 14:03:27 +0000">
<p>FWIW we do have startup checks that do this - <a href="https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/StartupChecks.java#L209" class="external-link" rel="nofollow">https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/service/StartupChecks.java#L209</a></p>
</comment>
<comment id="14745510" author="benedict" created="Tue, 15 Sep 2015 14:08:48 +0000">
<p>Except that this won't fail the startup checks if you downgrade patch versions. Or upgrade to a non-latest patch version when upgrading your major/minor.</p>
</comment>
<comment id="14877154" author="benedict" created="Sat, 19 Sep 2015 14:44:30 +0000">
<p>I've addressed your nits, but giving the patch another review, I realise that the approach I've taken with the new parent compaction strategy isn't going to cut it in 2.1. This isn't the complete set of operations that can mark things compacting, and if we e.g. redistribute summaries (or attempt an "all sstable" operation) we may screw up the state badly. </p> <p>In 2.1, we can instead safely mark compacting before we make the sstable available in the live set, however this too has problems: any "all sstable" operation will fail if flushes have gotten far behind, or secondary index flushes are taking too long. So we will probably have to introduce a new of sstables into the DataTracker.View that tracks these <em>almost complete</em> sstables, and filters them from any "all sstable" operation. This is a really rather ugly edge case to behaviour, and in 3.X I'll see if there's anything we can do to make it more apparent to consumers of the API.</p>
</comment>
<comment id="14976411" author="benedict" created="Tue, 27 Oct 2015 13:49:48 +0000">
<p>I've pushed a new version of this <a href="https://github.com/belliottsmith/cassandra/tree/9669-2.2" class="external-link" rel="nofollow">here</a>. This introduces a new <tt>premature</tt> set into <tt>lifecycle.View</tt>, which any sstable is maintain in until all preceding (and custom 2i) writes have completed.</p> <p>This version is against 2.2, as 2.1 will go EOL soon, and I don't feel comfortable changing these semantics without any recourse if something isn't right.</p>
</comment>
<comment id="15026925" author="blambov" created="Wed, 25 Nov 2015 15:26:54 +0000">
<p>The code looks good to me.</p> <p>Nit: <a href="https://github.com/apache/cassandra/compare/trunk...belliottsmith:9669-2.2#diff-f0a15c3588b56c5ce53ece7c48e325b5R96" class="external-link" rel="nofollow">Comment to <tt>Memtable</tt> contructor</a> appears wrong as it is the one e.g. <tt>CFS.Flush</tt> uses.</p>
</comment>
<comment id="15029053" author="slebresne" created="Thu, 26 Nov 2015 16:15:06 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=blambov" class="user-hover" rel="blambov">Branimir Lambov</a> As Benedict is currently out, do you mind pushing the branch with your nit fixed and running CI on it to be sure (as I don't see a recent CI run for this).</p>
</comment>
<comment id="15029168" author="blambov" created="Thu, 26 Nov 2015 18:29:25 +0000">
<p>Rebased and uploaded <a href="https://github.com/blambov/cassandra/tree/belliottsmith-9669-2.2" class="external-link" rel="nofollow">here</a>. <a href="http://cassci.datastax.com/job/blambov-belliottsmith-9669-2.2-testall/" class="external-link" rel="nofollow">Testall</a> is clean, <a href="http://cassci.datastax.com/job/blambov-belliottsmith-9669-2.2-dtest/" class="external-link" rel="nofollow">dtest</a> has a <a href="http://cassci.datastax.com/job/blambov-belliottsmith-9669-2.2-dtest/lastCompletedBuild/testReport/thrift_hsha_test/ThriftHSHATest/test_closing_connections/" class="external-link" rel="nofollow">test_closing_connections failure</a>.</p>
</comment>
<comment id="15031619" author="blambov" created="Mon, 30 Nov 2015 10:21:38 +0000">
<p>The same failure appeared on the <a href="http://cassci.datastax.com/view/Dev/view/blambov/job/blambov-belliottsmith-9669-2.2-dtest/2/testReport/" class="external-link" rel="nofollow">second dtest run</a>, and isn't present in any of the <a href="http://cassci.datastax.com/job/cassandra-2.2_dtest/" class="external-link" rel="nofollow">base runs</a>. Looks like this is a real regression.</p>
</comment>
<comment id="15087629" author="blambov" created="Thu, 7 Jan 2016 16:09:05 +0000">
<p>Rebased and run tests again, they are flaky but doesn't appear there's any repeatable problem:</p> <table class='confluenceTable'><tbody> <tr> <td class='confluenceTd'><a href="https://github.com/blambov/cassandra/tree/belliottsmith-9669-2.2" class="external-link" rel="nofollow">code</a></td> <td class='confluenceTd'><a href="http://cassci.datastax.com/view/Dev/view/blambov/job/blambov-belliottsmith-9669-2.2-testall/" class="external-link" rel="nofollow">utests</a></td> <td class='confluenceTd'><a href="http://cassci.datastax.com/view/Dev/view/blambov/job/blambov-belliottsmith-9669-2.2-dtest/" class="external-link" rel="nofollow">dtests</a></td> </tr> </tbody></table>
</comment>
<comment id="15087701" author="benedict" created="Thu, 7 Jan 2016 17:06:50 +0000">
<p>There do seem to be some failures not on stock 2.2, but they do not seem to be plausibly related. The snitch problem appears to literally be a snitch problem, for instance.</p> <p>There do appear to be an unpleasantly large number of flaky tests for 2.2, however, so it's very hard to say much with clarity.</p>
</comment>
<comment id="15098801" author="benedict" created="Thu, 14 Jan 2016 20:37:01 +0000">
<p>According to <a href="https://wiki.apache.org/cassandra/CompatibilityGuarantees" class="external-link" rel="nofollow">https://wiki.apache.org/cassandra/CompatibilityGuarantees</a> this may have to be delayed until 4.0</p>
</comment>
<comment id="15101477" author="slebresne" created="Fri, 15 Jan 2016 08:41:41 +0000">
<blockquote><p>According to <a href="https://wiki.apache.org/cassandra/CompatibilityGuarantees" class="external-link" rel="nofollow">https://wiki.apache.org/cassandra/CompatibilityGuarantees</a> this may have to be delayed until 4.0</p></blockquote> <p>Can you clarify which rule would be broken by this patch? If that's the downgrading one due a change to the commit log format, then that's a good point but I think I'd be personally fine amending that rule slightly to say that you can downgrade but you have to drain before doing so. The other option being to proceed in 2 steps: have an intermediate version that is able to read both the old and new format of the commit log, but still write the old one, and switching to the new one in the following version. Or of course to wait for 4.0.</p>
</comment>
<comment id="15101531" author="benedict" created="Fri, 15 Jan 2016 09:22:22 +0000">
<p>The sstable version is also modified, and that clause seems to prohibit such a change.</p>
</comment>
<comment id="15101593" author="slebresne" created="Fri, 15 Jan 2016 10:33:00 +0000">
<p>That clause doesn't prevent all sstable version changes. It's ok to do a "minor" sstable version bump by adding new fields at the end of the sstable metadata since older version will just ignore it. From a quick glance to the patch, it does seem to change the metadata in a way that is not backward compatible, but it looks trivial to change it so that it is. This is listed at the end of the compatibility document btw.</p>
</comment>
<comment id="15101603" author="benedict" created="Fri, 15 Jan 2016 10:42:18 +0000">
<p>The only way to make it backwards compatible is to carry on blithely if the value is not present. I'm not sure I'm a particular fan of this approach, because this is pretty critical to correctness, and simply ignoring its absence is ripe for future bugs screwing it up.</p>
</comment>
<comment id="15101607" author="benedict" created="Fri, 15 Jan 2016 10:45:21 +0000">
<p>At the very least we should create a 4.0 line where this can be implemented properly</p>
</comment>
<comment id="15101631" author="slebresne" created="Fri, 15 Jan 2016 11:01:32 +0000">
<p>It's possible I'm missing something here, but say we commit this to 3.4, we can still bump the sstable version to <tt>"mb"</tt>, writting the new lower bound replay position at the end of the metadata and 3.4 would still <em>always</em> expect that lower bound to be present when reading <tt>"mb"</tt> sstables. But if someone decides to use a <tt>"mb"</tt> sstable with 3.3, this will still work because 1) to the best of my knowledge, 3.3 doesn't reject (sstable) version in the future (and it's the same "major" sstable version so streaming and such are not impacted) and 2) it'll just ignore the additional data it doesn't know at the end of the metadata file.</p> <p>The only ugliness I see is that in the sstable metadata the lower and upper bound are not serialized close from each other, but that's a very minor and very localized (in the code) ugliness and can be easily fixed later in 4.0.</p>
</comment>
<comment id="15101634" author="benedict" created="Fri, 15 Jan 2016 11:05:14 +0000">
<p>Hmm, I guess I was getting confused with CL versions - I thought we refused to startup if we had a newer version than we know about. My mistake</p>
</comment>
<comment id="15101643" author="benedict" created="Fri, 15 Jan 2016 11:09:37 +0000">
<p>I would still consider updating the guide to specify clearly that a drain is necessary on downgrade. In fact - and I realise this is completely off-topic now - I think we need to ensure that after a drain we leave no intact segment. Even an empty segment would cause a downgrade to fail if it's the wrong version.</p>
</comment>
<comment id="15101648" author="slebresne" created="Fri, 15 Jan 2016 11:13:28 +0000"><p>You're right, I'll add that.</p></comment>
<comment id="15112552" author="slebresne" created="Fri, 22 Jan 2016 15:41:31 +0000">
<p>I believe the patch needs at least the changes discussed above, of making the changes to the sstable metadata only be new appends to the end. <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict" class="user-hover" rel="benedict">Benedict</a> could you make those changes?</p> <p>Also, I'm slightly confused on the versions here: I see the patch for 2.2 with CI results but nothing for 3.0. Surely the patch doesn't merge up cleanly, does it?</p>
</comment>
<comment id="15112566" author="benedict" created="Fri, 22 Jan 2016 15:49:41 +0000">
<p>I've already made the changes and am working on a merge (you assume correctly; it is in fact quite painful).</p>
</comment>
<comment id="15117445" author="benedict" created="Tue, 26 Jan 2016 15:57:29 +0000">
<p>Patch for 3.0 available <a href="https://github.com/belliottsmith/cassandra/tree/9669-3.0" class="external-link" rel="nofollow">here</a></p>
</comment>
<comment id="15121813" author="slebresne" created="Thu, 28 Jan 2016 16:18:54 +0000">
<p>Seems we have both the 2.2 and 3.0 version now. <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=blambov" class="user-hover" rel="blambov">Branimir Lambov</a> can you do a last round of review, especially on the 3.0 version, when you have a minute?</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12845060">CASSANDRA-9806</issuekey>
</issuelink>
</outwardlinks>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12845951">CASSANDRA-9840</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 17 Jul 2015 19:14:27 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gljr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12327240</customfieldvalue>
<customfieldvalue>12332369</customfieldvalue>
<customfieldvalue>12332753</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>blambov</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10659] Windows CassCI: Fail on timed-out tests
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10659
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>On our Windows CassCI environments, it looks like some dtests are prone to hanging, e.g.:</p> <p><a href="https://cassci.datastax.com/view/Dev/view/josh-mckenzie/job/josh-mckenzie-10641_windows-dtest_win32/1/" class="external-link" rel="nofollow">https://cassci.datastax.com/view/Dev/view/josh-mckenzie/job/josh-mckenzie-10641_windows-dtest_win32/1/</a><br/> <a href="http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/131/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/131/</a><br/> <a href="http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/129/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/129/</a><br/> <a href="http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/128/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/128/</a><br/> <a href="http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/126/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/126/</a><br/> <a href="http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/125/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-2.2/job/cassandra-2.2_dtest_win32/125/</a></p> <p>Ideally these tests wouldn't hang, but regardless, we should figure out a way to make them fail, rather than timing out Jenkins and botching the rest of the test run.</p> <p>The built-in <a href="http://nose.readthedocs.org/en/latest/plugins/multiprocess.html" class="external-link" rel="nofollow"><tt>nosetests</tt> <tt>multiprocess</tt> plugin</a> would solve this problem for us &#8211; we could run the tests with <tt>nosetests --processes=1 --process-timeout=X</tt> and it would stop the test and fail if the test took too long. However, it's broken on Windows. I've filed <a href="https://github.com/nose-devs/nose/issues/966" class="external-link" rel="nofollow">a quick issue on the <tt>nose</tt> GitHub</a>, but in the meantime, we should figure out how to avoid this.</p> <p>Possible solutions:</p> <ol> <li><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=philipthompson" class="user-hover" rel="philipthompson">Philip Thompson</a> had a script that would shell out to <tt>nosetests</tt> for each test and kill that process if it took too long. If I understand correctly, that script is broken, or assumes things that are no longer true. We can revamp it if we want.</li> <li>We could make a patch for <tt>nose</tt> to fix the <tt>multiprocess</tt> plugin.</li> <li>We could hack in some of <tt>multiprocessing</tt>'s functionality into the <tt>dtest</tt> suite itself.</li> </ol> <p>3. may be the best workaround for this problem &#8211; our timeouts aren't caused just when a tests runs long, but when Jenkins doesn't get any output on stdout from a hanging test. We may be able to monitor stdout from a second process and fail the test before Jenkins would time out.</p> <p>Pinging <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=JoshuaMcKenzie" class="user-hover" rel="JoshuaMcKenzie">Joshua McKenzie</a> as this is a Windows issue.</p>
</description>
<environment/>
<key id="12910777">CASSANDRA-10659</key>
<summary>Windows CassCI: Fail on timed-out tests</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mambocab">Jim Witschey</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels></labels>
<created>Thu, 5 Nov 2015 17:29:50 +0000</created>
<updated>Fri, 13 Nov 2015 19:28:10 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14992110" author="philipthompson" created="Thu, 5 Nov 2015 17:56:02 +0000">
<p>I support option 3. (1) is too blunt of a solution, and fixing (2) ourselves may end up being more work than we need to solve our own problem.</p>
</comment>
<comment id="14992284" author="joshuamckenzie" created="Thu, 5 Nov 2015 19:16:13 +0000">
<p>I'd recommend a brief inspection of the amount of work required for #2 before taking on the burden of porting in and maintaining multiprocessing in the dtest suite. I agree w/Philip that #1 is best left alone.</p>
</comment>
<comment id="14996922" author="mambocab" created="Mon, 9 Nov 2015 17:14:40 +0000">
<p>Having slept on this, I think #2 is only worth it for us as a fallback &#8211; some tests run longer than 30 minutes, and this is correct behavior. The <tt>multiprocess</tt> nose plugin can't be nuanced about this and, even when if fixed to work correctly on Windows, will make those tests fail. We need to detect periods of inactivity, not long-running tests.</p>
</comment>
<comment id="14996924" author="joshuamckenzie" created="Mon, 9 Nov 2015 17:16:10 +0000"><p>Sounds reasonable.</p></comment>
<comment id="15004559" author="mambocab" created="Fri, 13 Nov 2015 19:27:16 +0000">
<p>I've made good progress on a plugin and nose-wrapping script to fail tests if they produce no output for some length of time:</p> <p><a href="https://github.com/mambocab/nose_call_on_hang" class="external-link" rel="nofollow">https://github.com/mambocab/nose_call_on_hang</a><br/> <a href="https://gist.github.com/mambocab/760928e01a5e1ee5489f" class="external-link" rel="nofollow">https://gist.github.com/mambocab/760928e01a5e1ee5489f</a></p> <p>I believe these are just about ready to use for the main CassCI jobs, though some changes to the dtests may still be necessary handle exceptions correctly. I've fixed some exception handling problems here:</p> <p><a href="https://github.com/riptano/cassandra-dtest/pull/660" class="external-link" rel="nofollow">https://github.com/riptano/cassandra-dtest/pull/660</a><br/> <a href="https://github.com/riptano/cassandra-dtest/pull/657" class="external-link" rel="nofollow">https://github.com/riptano/cassandra-dtest/pull/657</a></p>
</comment>
<comment id="15004562" author="mambocab" created="Fri, 13 Nov 2015 19:28:10 +0000">
<p>Here's the CassCI job where I've been testing this:</p> <p><a href="http://cassci.datastax.com/job/mambocab-stop_hung_jobs/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/mambocab-stop_hung_jobs/</a></p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 5 Nov 2015 17:56:02 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2o0hj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10714] tcp retransmission issue seen in cassandra cluster
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10714
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have been seen tcp package retransmission issue in various stacks in our environment. ( AWS with no VPC). I'm currently using hsha rpc server type on cassandra 2.1.6 version. The information captured by wireshark shows that the retransmission happened both between client-to-server and server-to-server. Even within a cluster that doesn't have any client traffic, sporadic retransmission still happens.</p> <p>It's pretty easy to reproduce this issue by watching "netstat -s | grep retrans". </p>
</description>
<environment/>
<key id="12913427">CASSANDRA-10714</key>
<summary>tcp retransmission issue seen in cassandra cluster</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jeffl">Jeff Liu</reporter>
<labels></labels>
<created>Mon, 16 Nov 2015 20:03:46 +0000</created>
<updated>Fri, 18 Dec 2015 16:56:51 +0000</updated>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15007390" author="mshuler" created="Mon, 16 Nov 2015 21:43:13 +0000">
<p>This could be simple network issues with a NIC, switch port, or neighbor, so TCP does its job and retransmits packets. You might see error|dropped|overruns values in ifconfig, as well. If this persists on a particular node in your cluster, it may be prudent to destroy that node and launch another one in the hopes that you get a more stable server.</p>
</comment>
<comment id="15009217" author="jeffl" created="Tue, 17 Nov 2015 18:40:27 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mshuler" class="user-hover" rel="mshuler">Michael Shuler</a>, I checked the NIC status and it shows errors:0 dropped:0 overruns:0 frame:0 on both rx and tx. I even increased the tx queue size to 5000 from default 1000 without any improvement. Specifically for linux networking settings, I also increased both net.core.rmem, net.core.wmem,, net.ipv4.tcp_rmem, net.ipv4.tcp_wmem to 32M. increasd net.core.netdev_max_backlog to 30000 with no luck to eliminate the retransmission. </p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 16 Nov 2015 21:43:13 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ogn3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10695] Thrift HSHA appears to not work in 2.1+ with high client thread counts in stress
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10695
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>In 2.2+ my stress runs make almost no progress. In 2.1 they make some progress but this assertion is still in the log. Things are generally pretty unstable. I was able to benchmark with the sync server at 500 threads without issue.</p> <p>Where I ran into trouble was attempting to benchmark with 2000 threads. The sync server crapped out due to thread counts and I didn't bother trying to fiddle with it I switched to HSHA which worked at 500, but fails at 2000.</p> <p>My test configuration is an OS X laptop running 2.2 stress (sometimes trunk, didn't seem to matter) and a quad core Linux desktop. I can reproduce this the other way around as well.</p> <p>Stress command was</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cassandra-stress write n=19000000 -rate threads=2000 -mode thrift -node 192.168.1.3 </pre> </div></div> <p>I will attach the YAML. Error was</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.RuntimeException: java.lang.AssertionError: Invoke called in invalid state: READY_TO_WRITE at com.lmax.disruptor.FatalExceptionHandler.handleEventException(FatalExceptionHandler.java:45) ~[disruptor-3.0.1.jar:na] at com.lmax.disruptor.WorkProcessor.run(WorkProcessor.java:126) ~[disruptor-3.0.1.jar:na] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_60] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~[na:1.8.0_60] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) ~[na:1.8.0_60] Caused by: java.lang.AssertionError: Invoke called in invalid state: READY_TO_WRITE at com.thinkaurelius.thrift.Message.invoke(Message.java:306) ~[thrift-server-0.3.7.jar:na] at com.thinkaurelius.thrift.Message$Invocation.execute(Message.java:90) ~[thrift-server-0.3.7.jar:na] at com.thinkaurelius.thrift.TDisruptorServer$InvocationHandler.onEvent(TDisruptorServer.java:695) ~[thrift-server-0.3.7.jar:na] at com.thinkaurelius.thrift.TDisruptorServer$InvocationHandler.onEvent(TDisruptorServer.java:689) ~[thrift-server-0.3.7.jar:na] at com.lmax.disruptor.WorkProcessor.run(WorkProcessor.java:112) ~[disruptor-3.0.1.jar:na] ... 3 common frames omitted </pre> </div></div>
</description>
<environment/>
<key id="12912562">CASSANDRA-10695</key>
<summary>
Thrift HSHA appears to not work in 2.1+ with high client thread counts in stress
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="aweisberg">Ariel Weisberg</reporter>
<labels></labels>
<created>Thu, 12 Nov 2015 18:30:05 +0000</created>
<updated>Thu, 12 Nov 2015 18:32:12 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12772023" name="cassandra.yaml" size="41357" author="aweisberg" created="Thu, 12 Nov 2015 18:32:12 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2obcn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10687] When adding new node to cluster getting Cassandra timeout during write query
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10687
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When adding one new node on 8 nodes cluster (also again after completing adding the 9th in AUS data center and again when adding the 10th node on TAM data center with same behaviour).<br/> We get many of the following errors below.<br/> First - why this, when the node is joining :<br/> LOCAL_ONE (2 replica were required but only 1 acknowledged the write<br/> Since when LOCAL_ONE requires 2 replicas ?<br/> Second, why we fill so much overhead on the all cluster, when a node is joining ?</p> <p>com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency LOCAL_ONE (2 replica were required but only 1 acknowledged the write)</p> <p>Sample stack trace<br/> …stax.driver.core.exceptions.WriteTimeoutException.copy (WriteTimeoutException.java:73)</p> <p>…m.datastax.driver.core.DriverThrowables.propagateCause (DriverThrowables.java:37)</p> <p>….driver.core.DefaultResultSetFuture.getUninterruptibly (DefaultResultSetFuture.java:214)</p> <p> com.datastax.driver.core.AbstractSession.execute (AbstractSession.java:52)</p> <p>com.wixpress.publichtml.renderer.data.access.dao.page.CassandraPagesReadWriteDao$$anonfun$insertCompressed$1.apply(CassandraPagesReadWriteDao.scala:29)<br/> com.wixpress.publichtml.renderer.data.access.dao.page.CassandraPagesReadWriteDao$$anonfun$insertCompressed$1.apply(CassandraPagesReadWriteDao.scala:25)<br/> com.wixpress.framework.monitoring.metering.SyncMetering$class.tracking(Metering.scala:58)<br/> com.wixpress.publichtml.renderer.data.access.dao.page.CassandraPagesReadOnlyDao.tracking(CassandraPagesReadOnlyDao.scala:19)<br/> com.wixpress.publichtml.renderer.data.access.dao.page.CassandraPagesReadWriteDao.insertCompressed(CassandraPagesReadWriteDao.scala:25)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor.com$wixpress$html$data$distributor$core$DaoPageDistributor$$distributePage(DaoPageDistributor.scala:36)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor$$anonfun$process$1.apply$mcV$sp(DaoPageDistributor.scala:26)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor$$anonfun$process$1.apply(DaoPageDistributor.scala:26)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor$$anonfun$process$1.apply(DaoPageDistributor.scala:26)<br/> com.wixpress.framework.monitoring.metering.SyncMetering$class.tracking(Metering.scala:58)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor.tracking(DaoPageDistributor.scala:17)<br/> com.wixpress.html.data.distributor.core.DaoPageDistributor.process(DaoPageDistributor.scala:25)<br/> com.wixpress.html.data.distributor.core.greyhound.DistributionRequestHandler.handleMessage(DistributionRequestHandler.scala:19)<br/> com.wixpress.greyhound.KafkaUserHandlers.handleMessage(UserHandlers.scala:11)<br/> com.wixpress.greyhound.EventsConsumer.com$wixpress$greyhound$EventsConsumer$$handleMessage(EventsConsumer.scala:51)<br/> com.wixpress.greyhound.EventsConsumer$$anonfun$com$wixpress$greyhound$EventsConsumer$$dispatch$1.apply$mcV$sp(EventsConsumer.scala:43)<br/> com.wixpress.greyhound.EventsConsumer$$anonfun$com$wixpress$greyhound$EventsConsumer$$dispatch$1.apply(EventsConsumer.scala:40)<br/> com.wixpress.greyhound.EventsConsumer$$anonfun$com$wixpress$greyhound$EventsConsumer$$dispatch$1.apply(EventsConsumer.scala:40)<br/> scala.util.Try$.apply(Try.scala:192)<br/> com.wixpress.greyhound.EventsConsumer.com$wixpress$greyhound$EventsConsumer$$dispatch(EventsConsumer.scala:40)<br/> com.wixpress.greyhound.EventsConsumer$$anonfun$consumeEvents$1.apply(EventsConsumer.scala:26)<br/> com.wixpress.greyhound.EventsConsumer$$anonfun$consumeEvents$1.apply(EventsConsumer.scala:25)<br/> scala.collection.Iterator$class.foreach(Iterator.scala:742)<br/> scala.collection.AbstractIterator.foreach(Iterator.scala:1194)<br/> com.wixpress.greyhound.EventsConsumer.consumeEvents(EventsConsumer.scala:25)<br/> com.wixpress.greyhound.EventsConsumer.run(EventsConsumer.scala:20)<br/> java.util.concurrent.ThreadPoolExecutor.runWorker (ThreadPoolExecutor.java:1142)</p> <p> java.util.concurrent.ThreadPoolExecutor$Worker.run (ThreadPoolExecutor.java:617)</p> <p> java.lang.Thread.run (Thread.java:745)</p> <p>caused by com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency LOCAL_ONE (2 replica were required but only 1 acknowledged the write)<br/> …stax.driver.core.exceptions.WriteTimeoutException.copy (WriteTimeoutException.java:100)</p> <p> com.datastax.driver.core.Responses$Error.asException (Responses.java:98)</p> <p> com.datastax.driver.core.DefaultResultSetFuture.onSet (DefaultResultSetFuture.java:149)</p> <p> com.datastax.driver.core.RequestHandler.setFinalResult (RequestHandler.java:183)</p> <p> com.datastax.driver.core.RequestHandler.access$2300 (RequestHandler.java:44)</p> <p>…ore.RequestHandler$SpeculativeExecution.setFinalResult (RequestHandler.java:748)</p> <p>….driver.core.RequestHandler$SpeculativeExecution.onSet (RequestHandler.java:587)</p> <p>…atastax.driver.core.Connection$Dispatcher.channelRead0 (Connection.java:1013)</p> <p>…atastax.driver.core.Connection$Dispatcher.channelRead0 (Connection.java:936)</p> <p>….netty.channel.SimpleChannelInboundHandler.channelRead (SimpleChannelInboundHandler.java:105)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p> io.netty.handler.timeout.IdleStateHandler.channelRead (IdleStateHandler.java:254)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>…etty.handler.codec.MessageToMessageDecoder.channelRead (MessageToMessageDecoder.java:103)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>…etty.handler.codec.MessageToMessageDecoder.channelRead (MessageToMessageDecoder.java:103)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>io.netty.handler.codec.ByteToMessageDecoder.channelRead (ByteToMessageDecoder.java:242)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>io.netty.channel.DefaultChannelPipeline.fireChannelRead (DefaultChannelPipeline.java:847)</p> <p>….channel.nio.AbstractNioByteChannel$NioByteUnsafe.read (AbstractNioByteChannel.java:131)</p> <p> io.netty.channel.nio.NioEventLoop.processSelectedKey (NioEventLoop.java:511)</p> <p>….channel.nio.NioEventLoop.processSelectedKeysOptimized (NioEventLoop.java:468)</p> <p> io.netty.channel.nio.NioEventLoop.processSelectedKeys (NioEventLoop.java:382)</p> <p> io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:354)</p> <p>….netty.util.concurrent.SingleThreadEventExecutor$2.run (SingleThreadEventExecutor.java:111)</p> <p> java.lang.Thread.run (Thread.java:745)</p> <p>caused by com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency LOCAL_ONE (2 replica were required but only 1 acknowledged the write)<br/> com.datastax.driver.core.Responses$Error$1.decode (Responses.java:57)</p> <p> com.datastax.driver.core.Responses$Error$1.decode (Responses.java:37)</p> <p>com.datastax.driver.core.Message$ProtocolDecoder.decode (Message.java:213)</p> <p>com.datastax.driver.core.Message$ProtocolDecoder.decode (Message.java:204)</p> <p>…etty.handler.codec.MessageToMessageDecoder.channelRead (MessageToMessageDecoder.java:89)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>…etty.handler.codec.MessageToMessageDecoder.channelRead (MessageToMessageDecoder.java:103)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>io.netty.handler.codec.ByteToMessageDecoder.channelRead (ByteToMessageDecoder.java:242)</p> <p>…hannel.AbstractChannelHandlerContext.invokeChannelRead (AbstractChannelHandlerContext.java:339)</p> <p>….channel.AbstractChannelHandlerContext.fireChannelRead (AbstractChannelHandlerContext.java:324)</p> <p>io.netty.channel.DefaultChannelPipeline.fireChannelRead (DefaultChannelPipeline.java:847)</p> <p>….channel.nio.AbstractNioByteChannel$NioByteUnsafe.read (AbstractNioByteChannel.java:131)</p> <p> io.netty.channel.nio.NioEventLoop.processSelectedKey (NioEventLoop.java:511)</p> <p>….channel.nio.NioEventLoop.processSelectedKeysOptimized (NioEventLoop.java:468)</p> <p> io.netty.channel.nio.NioEventLoop.processSelectedKeys (NioEventLoop.java:382)</p> <p> io.netty.channel.nio.NioEventLoop.run (NioEventLoop.java:354)</p> <p>….netty.util.concurrent.SingleThreadEventExecutor$2.run (SingleThreadEventExecutor.java:111)</p> <p> java.lang.Thread.run (Thread.java:745)</p> <ol> <li>nodetool status<br/> xss = -ea -javaagent:/usr/share/cassandra/lib/jamm-0.2.5.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -XX:+CMSClassUnloadingEnabled -Xms8192M -Xmx8192M -Xmn2048M -Xss256k<br/> Note: Ownership information does not include topology; for complete information, specify a keyspace<br/> Datacenter: AUS<br/> ===============<br/> Status=Up/Down <table class='confluenceTable'><tbody> <tr> <td class='confluenceTd'>/ State=Normal/Leaving/Joining/Moving</td> </tr> </tbody></table> <ul class="alternate" type="square"> <li>Address Load Tokens Owns Host ID Rack<br/> UN 172.16.213.62 85.52 GB 256 11.7% 27f2fd1d-5f3c-4691-a1f6-e28c1343e212 R1<br/> UN 172.16.213.63 83.11 GB 256 12.2% 4869f14b-e858-46c7-967c-60bd8260a149 R1<br/> UN 172.16.213.64 80.91 GB 256 11.7% d4ad2495-cb24-4964-94d2-9e3f557054a4 R1<br/> UN 172.16.213.66 84.11 GB 256 10.3% 2a16c0dc-c36a-4196-89df-2de4f6b6cae5 R1<br/> UN 172.16.144.75 95.2 GB 256 11.4% f87d6518-6c8e-49d9-a013-018bbedb8414 R1<br/> Datacenter: TAM<br/> ===============<br/> Status=Up/Down <table class='confluenceTable'><tbody> <tr> <td class='confluenceTd'>/ State=Normal/Leaving/Joining/Moving</td> </tr> </tbody></table> </li> <li>Address Load Tokens Owns Host ID Rack<br/> UJ 10.14.0.155 4.38 GB 256 ? c88bebae-737b-4ade-8f79-64f655036eee R1<br/> UN 10.14.0.106 81.57 GB 256 10.0% 3b539927-b53a-4f50-9acd-d92fefbd84b9 R1<br/> UN 10.14.0.107 80.23 GB 256 10.4% b70f674d-892f-42ff-a261-5356bee79e99 R1<br/> UN 10.14.0.108 83.64 GB 256 11.2% 6e24b17a-0b48-46b4-8edb-b0a9206314a3 R1<br/> UN 10.14.0.109 91.02 GB 256 11.2% 11f02dbd-257f-4623-81f4-b94db7365775 R1</li> </ul> </li> </ol>
</description>
<environment>
<p>Cassandra 2.0.9 using vnodes, on Debian 7.9, on two data centers (AUS &amp; TAM)</p>
</environment>
<key id="12912150">CASSANDRA-10687</key>
<summary>
When adding new node to cluster getting Cassandra timeout during write query
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="eyalso">Eyal Sorek</reporter>
<labels></labels>
<created>Wed, 11 Nov 2015 12:40:39 +0000</created>
<updated>Tue, 24 Nov 2015 16:07:40 +0000</updated>
<component>Configuration</component>
<component>Coordination</component>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="15000320" author="eyalso" created="Wed, 11 Nov 2015 12:42:30 +0000">
<p>BTW, in the joining process, when the node is still joining the - nodetool info, fails with AssertionError<br/> nodetool info<br/> xss = -ea -javaagent:/usr/share/cassandra/lib/jamm-0.2.5.jar -XX:+UseThreadPriorities -XX:ThreadPriorityPolicy=42 -XX:+CMSClassUnloadingEnabled -Xms8192M -Xmx8192M -Xmn2048M -Xss256k<br/> Exception in thread "main" java.lang.AssertionError<br/> at org.apache.cassandra.locator.TokenMetadata.getTokens(TokenMetadata.java:502)<br/> at org.apache.cassandra.service.StorageService.getTokens(StorageService.java:2165)<br/> at org.apache.cassandra.service.StorageService.getTokens(StorageService.java:2154)<br/> at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)<br/> at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)<br/> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/> at java.lang.reflect.Method.invoke(Method.java:606)<br/> at sun.reflect.misc.Trampoline.invoke(MethodUtil.java:75)<br/> at sun.reflect.GeneratedMethodAccessor7.invoke(Unknown Source)<br/> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/> at java.lang.reflect.Method.invoke(Method.java:606)<br/> at sun.reflect.misc.MethodUtil.invoke(MethodUtil.java:279)<br/> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:112)<br/> at com.sun.jmx.mbeanserver.StandardMBeanIntrospector.invokeM2(StandardMBeanIntrospector.java:46)<br/> at com.sun.jmx.mbeanserver.MBeanIntrospector.invokeM(MBeanIntrospector.java:237)<br/> at com.sun.jmx.mbeanserver.PerInterface.getAttribute(PerInterface.java:83)<br/> at com.sun.jmx.mbeanserver.MBeanSupport.getAttribute(MBeanSupport.java:206)<br/> at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.getAttribute(DefaultMBeanServerInterceptor.java:647)<br/> at com.sun.jmx.mbeanserver.JmxMBeanServer.getAttribute(JmxMBeanServer.java:678)<br/> at javax.management.remote.rmi.RMIConnectionImpl.doOperation(RMIConnectionImpl.java:1464)<br/> at javax.management.remote.rmi.RMIConnectionImpl.access$300(RMIConnectionImpl.java:97)<br/> at javax.management.remote.rmi.RMIConnectionImpl$PrivilegedOperation.run(RMIConnectionImpl.java:1328)<br/> at javax.management.remote.rmi.RMIConnectionImpl.doPrivilegedOperation(RMIConnectionImpl.java:1420)<br/> at javax.management.remote.rmi.RMIConnectionImpl.getAttribute(RMIConnectionImpl.java:657)<br/> at sun.reflect.GeneratedMethodAccessor20.invoke(Unknown Source)<br/> at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)<br/> at java.lang.reflect.Method.invoke(Method.java:606)<br/> at sun.rmi.server.UnicastServerRef.dispatch(UnicastServerRef.java:322)<br/> at sun.rmi.transport.Transport$2.run(Transport.java:202)<br/> at sun.rmi.transport.Transport$2.run(Transport.java:199)<br/> at java.security.AccessController.doPrivileged(Native Method)<br/> at sun.rmi.transport.Transport.serviceCall(Transport.java:198)<br/> at sun.rmi.transport.tcp.TCPTransport.handleMessages(TCPTransport.java:567)<br/> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run0(TCPTransport.java:828)<br/> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.access$400(TCPTransport.java:619)<br/> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$1.run(TCPTransport.java:684)<br/> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler$1.run(TCPTransport.java:681)<br/> at java.security.AccessController.doPrivileged(Native Method)<br/> at sun.rmi.transport.tcp.TCPTransport$ConnectionHandler.run(TCPTransport.java:681)<br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)<br/> at java.lang.Thread.run(Thread.java:745)</p>
</comment>
<comment id="15013864" author="iamaleksey" created="Thu, 19 Nov 2015 16:56:44 +0000">
<p>Can you reproduce with latest 2.1/2.2? We've had a few tickets to resolve this since 2.0.9.</p>
</comment>
<comment id="15024737" author="eyalso" created="Tue, 24 Nov 2015 16:07:40 +0000">
<p>Not yet. We are still on 2.0.9.<br/> After the sync is done and the node fully joins into the cluster the -<br/> nodetool info - works ok.<br/> About the LOCAL_ONE, we replaced it to ONE, which works smooth.<br/> Does adding a new node to the cluster (from 8 nodes to 9 nodes with RF=4,<br/> in NetworkTopology - DC1=2, DC2=2) supposed to affect so much the cluster<br/> performance ?<br/> We experienced significant slowness of ~200% ~ 300% slower response time.<br/> Even when adding the 12th node, after adding 3, one by one, we still<br/> experienced that slowness.<br/> We have 1GB dedicated tunnel between the Data Centers, which was not fully<br/> utilized.<br/> We have in that cluster around ~80GB per node in the cluster.</p> <p>Thanks,<br/> Eyal</p> <p>On Thu, Nov 19, 2015 at 6:57 PM, Aleksey Yeschenko (JIRA) &lt;jira@apache.org&gt;</p> <p>&#8211; </p> <p><b>Regards,</b><br/> *Eyal Sorek*DBA Team Lead<br/> Cell: 050-3137556</p> <p>40 Hanamal street, Tel Aviv, Israel</p> <p>&lt;<a href="http://www.wix.com/" class="external-link" rel="nofollow">http://www.wix.com/</a>&gt;</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 19 Nov 2015 16:56:44 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2o8tb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12326830</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12326830</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10583] After bulk loading CQL query on timestamp column returns wrong result
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10583
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have this table:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>CREATE TABLE test ( tag text, group int, timestamp timestamp, value double, PRIMARY KEY (tag, group, timestamp) ) WITH CLUSTERING ORDER BY (group ASC, timestamp DESC) </pre> </div></div> <p>First I used CQLSSTableWriter to bulk load a bunch of sstables. Then I ran this query:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>cqlsh&gt; select * from test where tag = 'MSFT' and group = 1 and timestamp ='2004-12-15 16:00:00-0500'; tag | group | timestamp | value ------+-------+--------------------------+------- MSFT | 1 | 2004-12-15 21:00:00+0000 | 27.11 MSFT | 1 | 2004-12-16 21:00:00+0000 | 27.16 MSFT | 1 | 2004-12-17 21:00:00+0000 | 26.96 MSFT | 1 | 2004-12-20 21:00:00+0000 | 26.95 MSFT | 1 | 2004-12-21 21:00:00+0000 | 27.07 MSFT | 1 | 2004-12-22 21:00:00+0000 | 26.98 MSFT | 1 | 2004-12-23 21:00:00+0000 | 27.01 MSFT | 1 | 2004-12-27 21:00:00+0000 | 26.85 MSFT | 1 | 2004-12-28 21:00:00+0000 | 26.95 MSFT | 1 | 2004-12-29 21:00:00+0000 | 26.9 MSFT | 1 | 2004-12-30 21:00:00+0000 | 26.76 (11 rows) </pre> </div></div> <p>The result is obviously wrong.</p> <p>If I run this query:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>cqlsh&gt; select * from test where tag = 'MSFT' and group = 1 and timestamp ='2004-12-16 16:00:00-0500'; tag | group | timestamp | value -----+-------+-----------+------- (0 rows) </pre> </div></div> <p>In DevCenter I tried to create a similar table and insert a few rows but couldn't reproduce this. This may have something to do with the bulk loading process. But still, the fact cqlsh returns data that doesn't match the query is concerning.</p>
</description>
<environment>
<p>Windows 2008 R2, Java x64 1.8.0_60, CentOS 7, Java 1.8.0._65</p>
</environment>
<key id="12907489">CASSANDRA-10583</key>
<summary>
After bulk loading CQL query on timestamp column returns wrong result
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="depend">Kai Wang</reporter>
<labels></labels>
<created>Fri, 23 Oct 2015 17:47:55 +0000</created>
<updated>Tue, 9 Feb 2016 19:46:25 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.x</fixVersion>
<due/>
<votes>1</votes>
<watches>5</watches>
<comments>
<comment id="14971593" author="depend" created="Fri, 23 Oct 2015 18:46:13 +0000">
<p>This seems to be related to bulk loading. </p> <p>To reproduce:</p> <p>1. Clone <a href="https://github.com/depend/issues/tree/master/CASSANDRA-10583" class="external-link" rel="nofollow">https://github.com/depend/issues/tree/master/CASSANDRA-10583</a>. Build and run it, this application will generate an sstable with 10 rows.<br/> 2. Load it into C* with sstableloader.<br/> 3. </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> cqlsh:timeseries_test&gt; select * from double_daily; tag | group | timestamp | value ------+-------+--------------------------+------- TEST | 1 | 2002-05-01 04:00:00+0000 | 0 TEST | 1 | 2002-05-02 04:00:00+0000 | 1 TEST | 1 | 2002-05-03 04:00:00+0000 | 2 TEST | 1 | 2002-05-04 04:00:00+0000 | 3 TEST | 1 | 2002-05-05 04:00:00+0000 | 4 TEST | 1 | 2002-05-06 04:00:00+0000 | 5 TEST | 1 | 2002-05-07 04:00:00+0000 | 6 TEST | 1 | 2002-05-08 04:00:00+0000 | 7 TEST | 1 | 2002-05-09 04:00:00+0000 | 8 TEST | 1 | 2002-05-10 04:00:00+0000 | 9 (10 rows) </pre> </div></div> <p>4. </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> cqlsh:timeseries_test&gt; select * from double_daily where tag='TEST' and group = 1 and timestamp &gt; '2002-05-01 00:00:00-0400'; tag | group | timestamp | value ------+-------+--------------------------+------- TEST | 1 | 2002-05-01 04:00:00+0000 | 0 TEST | 1 | 2002-05-02 04:00:00+0000 | 1 TEST | 1 | 2002-05-03 04:00:00+0000 | 2 TEST | 1 | 2002-05-04 04:00:00+0000 | 3 TEST | 1 | 2002-05-05 04:00:00+0000 | 4 TEST | 1 | 2002-05-06 04:00:00+0000 | 5 TEST | 1 | 2002-05-07 04:00:00+0000 | 6 TEST | 1 | 2002-05-08 04:00:00+0000 | 7 TEST | 1 | 2002-05-09 04:00:00+0000 | 8 TEST | 1 | 2002-05-10 04:00:00+0000 | 9 (10 rows) </pre> </div></div> <p>5. </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> cqlsh:timeseries_test&gt; select * from double_daily where tag='TEST' and group = 1 and timestamp &gt; '2002-05-02 00:00:00-0400'; tag | group | timestamp | value -----+-------+-----------+------- (0 rows) </pre> </div></div> <p>I wasn't able to find that "equal" condition which returns everything. But query #5 still shows nothing is later than 2002/5/2 which is not true.</p>
</comment>
<comment id="15076175" author="depend" created="Thu, 31 Dec 2015 22:41:59 +0000">
<p>After reporting this error, I converted all timestamps in our application to bigint and thought the workaround worked. Then I upgraded C* to 2.2.4. But once again we are seeing the same error with bigint - query returns data that clearly should not be returned.</p> <p>It could be a bug in old CQLSSTableWriter. I will use CQLSSTableWriter in 2.2.4 and regenerate sstables then bulk load to see if this still happens.</p>
</comment>
<comment id="15139275" author="yukim" created="Tue, 9 Feb 2016 17:40:26 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=depend" class="user-hover" rel="depend">Kai Wang</a> Thanks for the report.</p> <p>I used your repository and generated SSTable, create 1 node cassandra cluster for v2.1.9 and the latest cassandra-2.1, and loaded generated SSTable using sstableloader.</p> <p>Unfortunately, I could not reproduce your issue in both clusters.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cqlsh:timeseries_test&gt; select * from double_daily where tag='TEST' and group = 1 and timestamp &gt; '2002-05-05 00:00:00-0400'; tag | group | timestamp | value ------+-------+--------------------------+------- TEST | 1 | 2002-05-05 05:00:00+0000 | 4 TEST | 1 | 2002-05-06 05:00:00+0000 | 5 TEST | 1 | 2002-05-07 05:00:00+0000 | 6 TEST | 1 | 2002-05-08 05:00:00+0000 | 7 TEST | 1 | 2002-05-09 05:00:00+0000 | 8 TEST | 1 | 2002-05-10 05:00:00+0000 | 9 (6 rows) </pre> </div></div> <p>The result of <tt>sstable2json</tt> does not seem problematic.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [ {<span class="code-quote">"key"</span>: <span class="code-quote">"TEST"</span>, <span class="code-quote">"cells"</span>: [[<span class="code-quote">"1:2002-05-01 00\\:00-0500:"</span>,"",1455036610854000], [<span class="code-quote">"1:2002-05-01 00\\:00-0500:value"</span>,<span class="code-quote">"0.0"</span>,1455036610854000], [<span class="code-quote">"1:2002-05-02 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-02 00\\:00-0500:value"</span>,<span class="code-quote">"1.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-03 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-03 00\\:00-0500:value"</span>,<span class="code-quote">"2.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-04 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-04 00\\:00-0500:value"</span>,<span class="code-quote">"3.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-05 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-05 00\\:00-0500:value"</span>,<span class="code-quote">"4.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-06 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-06 00\\:00-0500:value"</span>,<span class="code-quote">"5.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-07 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-07 00\\:00-0500:value"</span>,<span class="code-quote">"6.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-08 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-08 00\\:00-0500:value"</span>,<span class="code-quote">"7.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-09 00\\:00-0500:"</span>,"",1455036610861000], [<span class="code-quote">"1:2002-05-09 00\\:00-0500:value"</span>,<span class="code-quote">"8.0"</span>,1455036610861000], [<span class="code-quote">"1:2002-05-10 00\\:00-0500:"</span>,"",1455036610862000], [<span class="code-quote">"1:2002-05-10 00\\:00-0500:value"</span>,<span class="code-quote">"9.0"</span>,1455036610862000]]} ] </pre> </div></div> <p>Is there anything special to your environment?</p>
</comment>
<comment id="15139473" author="depend" created="Tue, 9 Feb 2016 19:26:50 +0000">
<p>Yuki,</p> <p>Thanks for looking into this. I can still reproduce the problem. My sstable2json seems fine.</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[ {"key": "TEST", "cells": [["1:2002-05-01 00\\:00-0400:","",1455044687135000], ["1:2002-05-01 00\\:00-0400:value","0.0",1455044687135000], ["1:2002-05-02 00\\:00-0400:","",1455044687143000], ["1:2002-05-02 00\\:00-0400:value","1.0",1455044687143000], ["1:2002-05-03 00\\:00-0400:","",1455044687143000], ["1:2002-05-03 00\\:00-0400:value","2.0",1455044687143000], ["1:2002-05-04 00\\:00-0400:","",1455044687144000], ["1:2002-05-04 00\\:00-0400:value","3.0",1455044687144000], ["1:2002-05-05 00\\:00-0400:","",1455044687144000], ["1:2002-05-05 00\\:00-0400:value","4.0",1455044687144000], ["1:2002-05-06 00\\:00-0400:","",1455044687144000], ["1:2002-05-06 00\\:00-0400:value","5.0",1455044687144000], ["1:2002-05-07 00\\:00-0400:","",1455044687144000], ["1:2002-05-07 00\\:00-0400:value","6.0",1455044687144000], ["1:2002-05-08 00\\:00-0400:","",1455044687144000], ["1:2002-05-08 00\\:00-0400:value","7.0",1455044687144000], ["1:2002-05-09 00\\:00-0400:","",1455044687144000], ["1:2002-05-09 00\\:00-0400:value","8.0",1455044687144000], ["1:2002-05-10 00\\:00-0400:","",1455044687144000], ["1:2002-05-10 00\\:00-0400:value","9.0",1455044687144000]]} ] </pre> </div></div>
</comment>
<comment id="15139481" author="depend" created="Tue, 9 Feb 2016 19:32:53 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a></p> <p>I uploaded sstables and screenshots.</p> <p>I tried to create sstables on both Windows 10 and CentOS 7.</p> <p>I tested 2.2.4 on Windows and Linux. Both have the same problem.</p>
</comment>
<comment id="15139503" author="yukim" created="Tue, 9 Feb 2016 19:40:39 +0000">
<p>Can you post the resut with <tt>TRACING ON</tt>?</p>
</comment>
<comment id="15139626" author="depend" created="Tue, 9 Feb 2016 19:46:25 +0000"><p>uploaded</p></comment>
</comments>
<attachments>
<attachment id="12787121" name="screenshot.png" size="33625" author="depend" created="Tue, 9 Feb 2016 19:32:50 +0000"/>
<attachment id="12787120" name="timeseries_test.zip" size="3731" author="depend" created="Tue, 9 Feb 2016 19:27:35 +0000"/>
<attachment id="12787124" name="trace_on.txt" size="10220" author="depend" created="Tue, 9 Feb 2016 19:46:14 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 9 Feb 2016 17:40:26 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ng7r:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333318</customfieldvalue>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10481] Quoted capitalised keyspace doesn't work as output for Hadoop
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10481
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When using CqlOutputFormat with a quoted keyspace containing capital letters, the initialisation of the CqlRecordWriter fails.</p> <p>In the code,error is hapenning at metadata table creation in the core constructor:</p> <div class="code panel" style="border-style: solid;border-width: 1px;"><div class="codeHeader panelHeader" style="border-bottom-width: 1px;border-bottom-style: solid;"><b>CqlRecordWriter.java-main constructor</b></div><div class="codeContent panelContent"> <pre class="code-java"> CqlRecordWriter(Configuration conf) { ... <span class="code-keyword">try</span> { <span class="code-object">String</span> keyspace = ConfigHelper.getOutputKeyspace(conf); <span class="code-keyword">try</span> (Session client = CqlConfigHelper.getOutputCluster(ConfigHelper.getOutputInitialAddress(conf), conf).connect(keyspace)) { ringCache = <span class="code-keyword">new</span> NativeRingCache(conf); <span class="code-keyword">if</span> (client != <span class="code-keyword">null</span>) { TableMetadata tableMetadata = client.getCluster().getMetadata().getKeyspace(client.getLoggedKeyspace()).getTable(ConfigHelper.getOutputColumnFamily(conf)); ... } </pre> </div></div> <p>It seemed to be dues to the reused function Metadata.handleId(keyspace) that, applied mulitple times, removes uoptes and finally lowercase the keyspace name.</p> <p>A valid solution (working for us at WMF) is to reuse the keyspace variable defined earlier instead of using the client one.</p> <div class="code panel" style="border-style: solid;border-width: 1px;"><div class="codeHeader panelHeader" style="border-bottom-width: 1px;border-bottom-style: solid;"><b>CqlRecordWriter.java-main constructor</b></div><div class="codeContent panelContent"> <pre class="code-java"> CqlRecordWriter(Configuration conf) { ... <span class="code-keyword">try</span> { <span class="code-object">String</span> keyspace = ConfigHelper.getOutputKeyspace(conf); <span class="code-keyword">try</span> (Session client = CqlConfigHelper.getOutputCluster(ConfigHelper.getOutputInitialAddress(conf), conf).connect(keyspace)) { ringCache = <span class="code-keyword">new</span> NativeRingCache(conf); <span class="code-keyword">if</span> (client != <span class="code-keyword">null</span>) { TableMetadata tableMetadata = client.getCluster().getMetadata().getKeyspace(keyspace).getTable(ConfigHelper.getOutputColumnFamily(conf)); ... } </pre> </div></div>
</description>
<environment><p>Linux</p></environment>
<key id="12903394">CASSANDRA-10481</key>
<summary>
Quoted capitalised keyspace doesn't work as output for Hadoop
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jobar">Joseph Allemandou</reporter>
<labels></labels>
<created>Thu, 8 Oct 2015 15:03:15 +0000</created>
<updated>Mon, 2 Nov 2015 15:00:26 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14950822" author="philipthompson" created="Fri, 9 Oct 2015 17:29:29 +0000"><p>Which version of C* are you running?</p></comment>
<comment id="14950879" author="jobar" created="Fri, 9 Oct 2015 18:01:49 +0000"><p>We are using v2.1.8</p></comment>
<comment id="14950887" author="philipthompson" created="Fri, 9 Oct 2015 18:03:27 +0000">
<p>If you use the Hadoop integrations from 2.2.2 against your 2.1.8 cluster, does it resolve the issue? It's my understanding that this should work, and I believe this bug is already fixed in 2.2.</p>
</comment>
<comment id="14951152" author="jobar" created="Fri, 9 Oct 2015 20:35:09 +0000">
<p>In fact I use the 2.2.2 package already, in order not to have thrift protocal used anymore.<br/> So no, it's not fixed in 2.2.2 <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14951156" author="philipthompson" created="Fri, 9 Oct 2015 20:37:29 +0000">
<p>Great, I will fix that. Can you share the schema of the keyspace and table you are writing to?</p>
</comment>
<comment id="14951166" author="jobar" created="Fri, 9 Oct 2015 20:48:26 +0000">
<p>We are writing to:</p> <p>CREATE KEYSPACE "Test_Project" WITH replication = </p> {'class': 'SimpleStrategy', 'replication_factor': '1'} <p> AND durable_writes = true;</p> <p>CREATE TABLE "Test_Project".data (<br/> "_domain" text,<br/> project text,<br/> access text,<br/> agent text,<br/> granularity text,<br/> timestamp text,<br/> "_tid" timeuuid,<br/> views int,<br/> PRIMARY KEY (("_domain", project, access, agent, granularity), timestamp, "_tid")<br/> ) WITH CLUSTERING ORDER BY (timestamp ASC, "_tid" ASC)<br/> AND bloom_filter_fp_chance = 0.01<br/> AND caching = '</p> {"keys":"ALL", "rows_per_partition":"NONE"} <p>'<br/> AND comment = ''<br/> AND compaction = </p> {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} <p> AND compression = </p> {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} <p> AND dclocal_read_repair_chance = 0.1<br/> AND default_time_to_live = 0<br/> AND gc_grace_seconds = 864000<br/> AND max_index_interval = 2048<br/> AND memtable_flush_period_in_ms = 0<br/> AND min_index_interval = 128<br/> AND read_repair_chance = 0.0<br/> AND speculative_retry = '99.0PERCENTILE';</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 9 Oct 2015 17:29:29 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2mrav:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10474] Streaming should tolerate secondary index build failure
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10474
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When streaming failed to build secondary index at the end of streaming (like in <a href="https://issues.apache.org/jira/browse/CASSANDRA-10449" title="OOM on bootstrap after long GC pause" class="issue-link" data-issue-key="CASSANDRA-10449">CASSANDRA-10449</a>), streaming session can hang as it throws exception without catching it.</p> <p>Streaming should tolerate secondary index build failure, and instead of failing (hanging) streaming session, it should WARN user and go on.</p>
</description>
<environment/>
<key id="12903175">CASSANDRA-10474</key>
<summary>
Streaming should tolerate secondary index build failure
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="yukim">Yuki Morishita</reporter>
<labels>
<label>streaming</label>
</labels>
<created>Wed, 7 Oct 2015 23:23:01 +0000</created>
<updated>Mon, 7 Dec 2015 20:42:21 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14977061" author="aweisberg" created="Tue, 27 Oct 2015 20:07:31 +0000">
<p><a href="https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/streaming/StreamReceiveTask.java#L179" class="external-link" rel="nofollow">Looks like this works on trunk?</a> I see exception handling for cfs.indexManager.buildAllIndexesBlocking(readers).</p> <p>Is that enough or is there additional cleanup necessary if that throws. I know we added a lot of stuff in 3.0 to handle failure during streaming.</p>
</comment>
<comment id="14979431" author="yukim" created="Wed, 28 Oct 2015 23:03:53 +0000">
<p>For 3.0+, this is handled already.<br/> Thanks for pointing out, <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aweisberg" class="user-hover" rel="aweisberg">Ariel Weisberg</a>.</p> <p>I think it is still worth to add similar error handling to 2.1 and 2.2.<br/> I'll start work on that.</p>
</comment>
<comment id="15045670" author="pauloricardomg" created="Mon, 7 Dec 2015 20:41:51 +0000">
<p><a href="https://issues.apache.org/jira/browse/CASSANDRA-10774" title="Fail stream session if receiver cannot process data" class="issue-link" data-issue-key="CASSANDRA-10774"><del>CASSANDRA-10774</del></a> now fails stream session on any error, at least it does not hang forever. Should we still not fail the session and print a warning if secondary index rebuild fail?</p> <p>I guess its simpler to just fail the stream session. In case we decide for printing a warning instead, I think we would need to make that warning persistent if the user does not run nodetool rebuild_index, otherwise it may assume the secondary indexes are consistent, since the stream session was successful (and the initial warning was missed).</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12916306">CASSANDRA-10774</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 27 Oct 2015 20:07:31 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2mpy7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10449] OOM on bootstrap after long GC pause
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10449
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have a 20-node cluster (i2.4xlarge) with vnodes (default of 256) and 500-700GB per node. SSTable counts are &lt;10 per table. I am attempting to provision additional nodes, but bootstrapping OOMs every time after about 10 hours with a sudden long GC pause:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>INFO [Service Thread] 2015-10-05 23:33:33,373 GCInspector.java:252 - G1 Old Generation GC in 1586126ms. G1 Old Gen: 49213756976 -&gt; 49072277176; ... ERROR [MemtableFlushWriter:454] 2015-10-05 23:33:33,380 CassandraDaemon.java:223 - Exception in thread Thread[MemtableFlushWriter:454,5,main] java.lang.OutOfMemoryError: Java heap space </pre> </div></div> <p>I have tried increasing max heap to 48G just to get through the bootstrap, to no avail.</p>
</description>
<environment><p>Ubuntu 14.04, AWS</p></environment>
<key id="12902563">CASSANDRA-10449</key>
<summary>OOM on bootstrap after long GC pause</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rstrickland">Robbie Strickland</reporter>
<labels>
<label>gc</label>
</labels>
<created>Tue, 6 Oct 2015 00:41:30 +0000</created>
<updated>Wed, 28 Oct 2015 16:11:29 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>0</votes>
<watches>7</watches>
<comments>
<comment id="14944447" author="philipthompson" created="Tue, 6 Oct 2015 03:17:54 +0000">
<p>Can you attach a system.log from a node that fails to bootstrap? </p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=JoshuaMcKenzie" class="user-hover" rel="JoshuaMcKenzie">Joshua McKenzie</a>, who should this be assigned to?</p>
</comment>
<comment id="14945149" author="philipthompson" created="Tue, 6 Oct 2015 15:06:42 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a>, do you want to look at this as well?</p>
</comment>
<comment id="14946624" author="rstrickland" created="Wed, 7 Oct 2015 10:13:00 +0000">
<p>I increased max heap to 96GB and tried again. Now doing netstats shows progress ground to a halt:</p> <p>9pm:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ubuntu@eventcass4x024:~$ nodetool netstats | grep -v 100% Mode: JOINING Bootstrap 45d8dec0-6c12-11e5-90ef-f7a8e02e59c0 Receiving 139 files, 36548040412 bytes total. Already received 139 files, 36548040412 bytes total Receiving 171 files, 60000431853 bytes total. Already received 171 files, 60000431853 bytes total Receiving 147 files, 78458709168 bytes total. Already received 79 files, 55003961646 bytes total /var/lib/cassandra/xvdd/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-295-Data.db 955162267/4105438496 bytes(23%) received from idx:0/x.x.x.x Receiving 141 files, 36700837768 bytes total. Already received 141 files, 36700837768 bytes total Receiving 176 files, 79676288976 bytes total. Already received 98 files, 55932809644 bytes total /var/lib/cassandra/xvdb/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-329-Data.db 174070078/7326235809 bytes(2%) received from idx:0/x.x.x.x Receiving 170 files, 85920995638 bytes total. Already received 94 files, 54985226700 bytes total /var/lib/cassandra/xvdd/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-265-Data.db 4875660361/22821083384 bytes(21%) received from idx:0/x.x.x.x Receiving 174 files, 87064163973 bytes total. Already received 91 files, 53930233899 bytes total /var/lib/cassandra/xvdb/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-157-Data.db 17064156850/25823860172 bytes(66%) received from idx:0/x.x.x.x Receiving 164 files, 46351636573 bytes total. Already received 164 files, 46351636573 bytes total Receiving 158 files, 62899520151 bytes total. Already received 158 files, 62899520151 bytes total Receiving 164 files, 48771232182 bytes total. Already received 164 files, 48771232182 bytes total Read Repair Statistics: Attempted: 0 Mismatch (Blocking): 0 Mismatch (Background): 0 Pool Name Active Pending Completed Commands n/a 19 56 Responses n/a 0 35515795 </pre> </div></div> <p>6am:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ubuntu@eventcass4x024:~$ nodetool netstats | grep -v 100% Mode: JOINING Bootstrap 45d8dec0-6c12-11e5-90ef-f7a8e02e59c0 Receiving 139 files, 36548040412 bytes total. Already received 139 files, 36548040412 bytes total Receiving 171 files, 60000431853 bytes total. Already received 171 files, 60000431853 bytes total Receiving 147 files, 78458709168 bytes total. Already received 79 files, 55003961646 bytes total /var/lib/cassandra/xvdd/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-295-Data.db 955162267/4105438496 bytes(23%) received from idx:0/x.x.x.x Receiving 141 files, 36700837768 bytes total. Already received 141 files, 36700837768 bytes total Receiving 176 files, 79676288976 bytes total. Already received 98 files, 55932809644 bytes total /var/lib/cassandra/xvdb/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-329-Data.db 174070078/7326235809 bytes(2%) received from idx:0/x.x.x.x Receiving 170 files, 85920995638 bytes total. Already received 94 files, 54985226700 bytes total /var/lib/cassandra/xvdd/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-265-Data.db 4875660361/22821083384 bytes(21%) received from idx:0/x.x.x.x Receiving 174 files, 87064163973 bytes total. Already received 91 files, 53930233899 bytes total /var/lib/cassandra/xvdb/data/prod_analytics_events/wuevents-ffa99ad05af911e596f05987bbaaffad/prod_analytics_events-wuevents-tmp-ka-157-Data.db 17064156850/25823860172 bytes(66%) received from idx:0/x.x.x.x Receiving 164 files, 46351636573 bytes total. Already received 164 files, 46351636573 bytes total Receiving 158 files, 62899520151 bytes total. Already received 158 files, 62899520151 bytes total Receiving 164 files, 48771232182 bytes total. Already received 164 files, 48771232182 bytes total Read Repair Statistics: Attempted: 0 Mismatch (Blocking): 0 Mismatch (Background): 0 Pool Name Active Pending Completed Commands n/a 19 56 Responses n/a 0 51933813 </pre> </div></div> <p>No additional long GC pauses.</p>
</comment>
<comment id="14946803" author="rstrickland" created="Wed, 7 Oct 2015 12:58:05 +0000">
<p>I've attached a thread dump taken after the streaming hangs.</p>
</comment>
<comment id="14946842" author="pauloricardomg" created="Wed, 7 Oct 2015 13:27:20 +0000">
<p>What GC parameters are you using and what was your original heap size before increasing to 48G? Have you tried using CMS with smaller heap sizes and/or higher young generation sizes? What's your streaming_socket_timeout_in_ms and memtable_flush_writers parameters?</p> <p>ps: I'm not a gc expert, just trying to understand a bit more GC behavior on cassandra.</p>
</comment>
<comment id="14947486" author="rstrickland" created="Wed, 7 Oct 2015 20:06:47 +0000">
<p>I am going to try again after increasing streaming_socket_timeout_in_ms and memtable_flush_writers. I had not touched these values, so it's possible that was hurting me.</p>
</comment>
<comment id="14947793" author="yukim" created="Wed, 7 Oct 2015 23:19:08 +0000">
<p>There are couples of things going on.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [StreamReceiveTask:29] 2015-10-05 14:46:17,090 CassandraDaemon.java:223 - Exception in thread <span class="code-object">Thread</span>[StreamReceiveTask:29,5,main] java.lang.RuntimeException: java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.db.filter.TombstoneOverwhelmingException </pre> </div></div> <p>When rebuilding secondary index after receiving files, bootstrapping node is experiencing TombstoneOverwhelmingException.<br/> This can make streaming to hang, as it never completes the receiving task.<br/> Streaming should tolerate secondary index build failure, instead of failing entire stream session, it should just warn user and go on, so that user can manually trigger secondary index rebuild later.</p> <p>I'm not sure the above relates to OOM. From StatusLogger, FlushWriter task is glowing and that is the cause of OOM.<br/> <del>If you can capture stack using jstack, that would be greate help.</del> Missed attachment, sorry.</p> <p><del>I create separate JIRA for the former.</del> Created <a href="https://issues.apache.org/jira/browse/CASSANDRA-10474" title="Streaming should tolerate secondary index build failure" class="issue-link" data-issue-key="CASSANDRA-10474">CASSANDRA-10474</a>.</p>
</comment>
<comment id="14948566" author="rstrickland" created="Thu, 8 Oct 2015 12:16:22 +0000">
<p>Unfortunately increasing streaming_socket_timeout_in_ms and memtable_flush_writers resulted in OOMing again instead of hanging. It seems to be hanging/OOMing when it gets to larger sstables (30GB+). I will poke around some more today.</p>
</comment>
<comment id="14950528" author="rstrickland" created="Fri, 9 Oct 2015 15:01:44 +0000">
<p>After making numerous GC tweaks, including going back to default CMS settings, symptoms remain the same. Would appreciate any additional pointers, as I'm grasping at straws now.</p>
</comment>
<comment id="14954097" author="rstrickland" created="Tue, 13 Oct 2015 00:12:49 +0000">
<p>Per <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zznate" class="user-hover" rel="zznate">Nate McCall</a>'s suggestion I also tried setting compaction throughput to 0, with no effect. He also said I should try taking one of the large sstables and trying to use sstableloader on it. I will do that tomorrow.</p>
</comment>
<comment id="14959057" author="rstrickland" created="Thu, 15 Oct 2015 15:23:12 +0000">
<p>I discovered that an index on one of the tables has a wide row, and I'm wondering if that could be the root of the issue:</p> <p>Example from one node:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Compacted partition minimum bytes: 125 Compacted partition maximum bytes: 10299432635 Compacted partition mean bytes: 253692309 </pre> </div></div> <p>This seems like a problem in general for indexes, where the original data model may be well distributed but the index may have unpredictable distribution.</p>
</comment>
<comment id="14959148" author="mishail" created="Thu, 15 Oct 2015 16:15:59 +0000">
<p>I would love to get hold of a heapdump for that OOM. At least we could figure out what's consuming the heap.</p>
</comment>
<comment id="14959217" author="rstrickland" created="Thu, 15 Oct 2015 16:51:20 +0000">
<p>Ok <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mishail" class="user-hover" rel="mishail">Mikhail Stepura</a> I will re-run with heap dump enabled (we had it turned off for some reason) and post it.</p>
</comment>
<comment id="14961306" author="rstrickland" created="Fri, 16 Oct 2015 20:17:30 +0000">
<p>I've attached a screen shot of the heap dump.</p>
</comment>
<comment id="14961340" author="mishail" created="Fri, 16 Oct 2015 20:49:22 +0000">
<p>Any chance to get the dump file itself? Of course if it doesn't contain any sensible information.</p>
</comment>
<comment id="14961343" author="rstrickland" created="Fri, 16 Oct 2015 20:52:15 +0000">
<p>Yes, sorry I was working on getting it to S3. You can get it <a href="https://s3.amazonaws.com/twc-analytics-public/java_1445001330.hprof" class="external-link" rel="nofollow">here</a>.</p>
</comment>
<comment id="14961610" author="mishail" created="Sat, 17 Oct 2015 01:03:39 +0000"><p>What was the heap size for the dump? 16G?</p></comment>
<comment id="14961661" author="rstrickland" created="Sat, 17 Oct 2015 02:17:21 +0000"><p>Yes, 16GB.</p></comment>
<comment id="14961726" author="mishail" created="Sat, 17 Oct 2015 04:13:20 +0000">
<p>So, there are 2 ColumnFamilyStores with 6G of memtables each (5797 'live' memtables per intsance) in the heap, but for some reason they are not being flushed. All 32 MemtableFlushWriters (and 1 post-flush) are waiting on <tt>writeBarrier</tt> s</p>
</comment>
<comment id="14961750" author="mishail" created="Sat, 17 Oct 2015 05:11:46 +0000">
<p><a href="https://issues.apache.org/jira/browse/CASSANDRA-9681" title="Memtable heap size grows and many long GC pauses are triggered" class="issue-link" data-issue-key="CASSANDRA-9681"><del>CASSANDRA-9681</del></a>?</p>
</comment>
<comment id="14969125" author="rstrickland" created="Thu, 22 Oct 2015 13:07:30 +0000">
<p>I decided to try upgrading to 2.1.11 to see if the issue was resolved by <a href="https://issues.apache.org/jira/browse/CASSANDRA-9681" title="Memtable heap size grows and many long GC pauses are triggered" class="issue-link" data-issue-key="CASSANDRA-9681"><del>CASSANDRA-9681</del></a>. The node has been joining for over 24 hours, even though it appears to have finished streaming after about 6 hours:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ubuntu@eventcass4x087:~$ nodetool netstats | grep -v 100% Mode: JOINING Bootstrap 7047c510-7732-11e5-a7e7-63f53bbd2778 Receiving 171 files, 95313491312 bytes total. Already received 171 files, 95313491312 bytes total Receiving 165 files, 78860134041 bytes total. Already received 165 files, 78860134041 bytes total Receiving 158 files, 77709354374 bytes total. Already received 158 files, 77709354374 bytes total Receiving 184 files, 106710570690 bytes total. Already received 184 files, 106710570690 bytes total Receiving 136 files, 35699286217 bytes total. Already received 136 files, 35699286217 bytes total Receiving 169 files, 53498180215 bytes total. Already received 169 files, 53498180215 bytes total Receiving 197 files, 129020987979 bytes total. Already received 197 files, 129020987979 bytes total Receiving 196 files, 113904035360 bytes total. Already received 196 files, 113904035360 bytes total Receiving 172 files, 47685647028 bytes total. Already received 172 files, 47685647028 bytes total Read Repair Statistics: Attempted: 0 Mismatch (Blocking): 0 Mismatch (Background): 0 Pool Name Active Pending Completed Commands n/a 1 0 Responses n/a 0 83743675 </pre> </div></div> <p>It doesn't appear to still be building indexes either:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ubuntu@eventcass4x087:~$ nodetool compactionstats pending tasks: 2 compaction type keyspace table completed total unit progress Compaction prod_analytics_events wuevents 163704673 201033961 bytes 81.43% Active compaction remaining time : n/a </pre> </div></div> <p>So I'm not sure why it's still joining. Any thoughts?</p>
</comment>
<comment id="14969215" author="rstrickland" created="Thu, 22 Oct 2015 14:17:21 +0000">
<p>Also, for reference, tpstats shows nothing in the queues:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ubuntu@eventcass4x087:~$ nodetool tpstats Pool Name Active Pending Completed Blocked All time blocked MutationStage 0 0 85431226 0 0 ReadStage 0 0 0 0 0 RequestResponseStage 0 0 48 0 0 ReadRepairStage 0 0 0 0 0 CounterMutationStage 0 0 0 0 0 MiscStage 0 0 0 0 0 HintedHandoff 0 0 29 0 0 GossipStage 0 0 565556 0 0 CacheCleanupExecutor 0 0 0 0 0 InternalResponseStage 0 0 0 0 0 CommitLogArchiver 0 0 0 0 0 CompactionExecutor 0 0 12774 0 0 ValidationExecutor 0 0 0 0 0 MigrationStage 0 0 0 0 0 AntiEntropyStage 0 0 0 0 0 PendingRangeCalculator 0 0 3 0 0 Sampler 0 0 0 0 0 MemtableFlushWriter 0 0 7157 0 0 MemtablePostFlush 0 0 10083 0 0 MemtableReclaimMemory 0 0 9340 0 0 Message type Dropped READ 0 RANGE_SLICE 0 _TRACE 0 MUTATION 0 COUNTER_MUTATION 0 BINARY 0 REQUEST_RESPONSE 0 PAGED_RANGE 0 READ_REPAIR 0 </pre> </div></div>
</comment>
<comment id="14974716" author="rstrickland" created="Mon, 26 Oct 2015 18:14:25 +0000">
<p>As a workaround I was able to simply restart the node with <tt>auto_bootstrap</tt> set to false, which allowed it to successfully join. Obviously there appear to be multiple issues here, as the behavior in 2.1.7 and 2.1.11 is different with an otherwise identical setup.</p>
</comment>
</comments>
<attachments>
<attachment id="12767190" name="GCpath.txt" size="13708" author="mishail" created="Sat, 17 Oct 2015 04:13:20 +0000"/>
<attachment id="12767130" name="heap_dump.png" size="105261" author="rstrickland" created="Fri, 16 Oct 2015 20:17:30 +0000"/>
<attachment id="12765172" name="system.log.10-05" size="19803972" author="rstrickland" created="Tue, 6 Oct 2015 12:32:20 +0000"/>
<attachment id="12765385" name="thread_dump.log" size="226016" author="rstrickland" created="Wed, 7 Oct 2015 12:58:05 +0000"/>
<attachment id="12767189" name="threads.txt" size="85101" author="mishail" created="Sat, 17 Oct 2015 04:13:20 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>5.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 6 Oct 2015 03:17:54 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2mm6n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332753</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332753</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10445] Cassandra-stress throws max frame size error when SSL certification is enabled
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10445
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Running cassandra-stress when SSL is enabled gives the following error and does not finish executing:</p> <blockquote> <p>cassandra-stress write n=1000000<br/> Exception in thread "main" java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Frame size (352518912) larger than max length (15728640)!<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:144)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:110)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesThrift(SettingsSchema.java:111)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:59)<br/> at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:205)<br/> at org.apache.cassandra.stress.StressAction.run(StressAction.java:55)<br/> at org.apache.cassandra.stress.Stress.main(Stress.java:109)</p></blockquote> <p>I was able to reproduce this issue consistently via the following steps:<br/> 1) Spin up 3 node cassandra cluster running 2.1.8<br/> 2) Perform cassandra-stress write n=1000000<br/> 3) Everything works!<br/> 4) Generate keystore and truststore for each node in the cluster and distribute appropriately <br/> 5) Modify cassandra.yaml on each node to enable SSL:<br/> client_encryption_options:<br/> enabled: true<br/> keystore: /&lt;appropriate directory&gt;</p> <ol> <li>require_client_auth: false</li> <li>Set trustore and truststore_password if require_client_auth is true<br/> truststore: /&lt;appropriate directory&gt;<br/> truststore_password: &lt;appropriate password&gt;</li> <li>More advanced defaults below:<br/> protocol: ssl<br/> 6) Restart each node.<br/> 7) Perform cassandra-stress write n=1000000<br/> 8) Get Frame Size error, cassandra-stress fails</li> </ol> <p>This may be related to <a href="https://issues.apache.org/jira/browse/CASSANDRA-9325" title="cassandra-stress requires keystore for SSL but provides no way to configure it" class="issue-link" data-issue-key="CASSANDRA-9325">CASSANDRA-9325</a>.</p>
</description>
<environment/>
<key id="12902493">CASSANDRA-10445</key>
<summary>
Cassandra-stress throws max frame size error when SSL certification is enabled
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="sam.goldberg">Sam Goldberg</reporter>
<labels>
<label>stress</label>
</labels>
<created>Mon, 5 Oct 2015 20:09:42 +0000</created>
<updated>Tue, 23 Feb 2016 13:50:45 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>2</votes>
<watches>5</watches>
<comments>
<comment id="14945157" author="philipthompson" created="Tue, 6 Oct 2015 15:11:23 +0000">
<p>If you compile and use the cassandra stress from trunk against your 2.1 cluster, does this still reproduce?</p>
</comment>
<comment id="15000961" author="ccraw" created="Wed, 11 Nov 2015 19:42:01 +0000">
<p>I am having the same issue. Any updates on a workaround or fix?</p>
</comment>
<comment id="15143048" author="vara" created="Thu, 11 Feb 2016 17:02:01 +0000">
<p>Is there any feedback or workaround on this issue. Cassandra stress tool works fine without SSL but when we configured SSL in our cluster then i wasn't able to execute the stress tool.</p> <p>/usr/bin/cassandra-stress write n=100000 -rate threads\&gt;=5 threads\&lt;=9 -mode thrift user='xxx' password='"xxx' -log file=~/vara_write_100kfile.log</p> <p>please see the error below<br/> ------------------------------<br/> Exception in thread "main" java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Frame size (352518912) larger than max length (15728640)!<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:144)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:110)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesThrift(SettingsSchema.java:111)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:59)<br/> at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:205)<br/> at org.apache.cassandra.stress.StressAction.run(StressAction.java:55)<br/> at org.apache.cassandra.stress.Stress.main(Stress.java:109)<br/> Caused by: org.apache.thrift.transport.TTransportException: Frame size (352518912) larger than max length (15728640)!<br/> at org.apache.thrift.transport.TFramedTransport.readFrame(TFramedTransport.java:137)<br/> at org.apache.thrift.transport.TFramedTransport.read(TFramedTransport.java:101)<br/> at org.apache.thrift.transport.TTransport.readAll(TTransport.java:86)<br/> at org.apache.thrift.protocol.TBinaryProtocol.readAll(TBinaryProtocol.java:429)<br/> at org.apache.thrift.protocol.TBinaryProtocol.readI32(TBinaryProtocol.java:318)<br/> at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:219)<br/> at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:77)<br/> at org.apache.cassandra.thrift.Cassandra$Client.recv_login(Cassandra.java:582)<br/> at org.apache.cassandra.thrift.Cassandra$Client.login(Cassandra.java:569)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:135)<br/> ... 6 more</p>
</comment>
<comment id="15144766" author="cornelf@cakesolutions.net" created="Fri, 12 Feb 2016 16:12:32 +0000">
<p><a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html?scroll=reference_ds_qfg_n1r_1k__thrift_framed_transport_size_in_mb" class="external-link" rel="nofollow">https://docs.datastax.com/en/cassandra/2.1/cassandra/configuration/configCassandra_yaml_r.html?scroll=reference_ds_qfg_n1r_1k__thrift_framed_transport_size_in_mb</a> 15728640=15MB (default)<br/> bump that thrift_framed_transport_size_in_mb up on the cassandra.yaml although ~336MB is a bit too much.<br/> Also have a look at <a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCStress_t.html" class="external-link" rel="nofollow">https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCStress_t.html</a></p>
</comment>
<comment id="15157043" author="cornelf@cakesolutions.net" created="Mon, 22 Feb 2016 14:24:13 +0000">
<p>Also, `-transport` must be specified when the cluster is client-to-node ssl encrypted <a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCStress_t.html" class="external-link" rel="nofollow">https://docs.datastax.com/en/cassandra/2.1/cassandra/tools/toolsCStress_t.html</a></p>
</comment>
<comment id="15157229" author="vara" created="Mon, 22 Feb 2016 16:27:03 +0000">
<p>Hi Cornel,<br/> I have increased "thrift_framed_transport_size_in_mb" size from 15MB to 337MB in all cassandra nodes and restarted cassandra but i am seeing the same exception. I have alos passed the transport option but no luuck</p> <p>cassandra-stress write n=100000 -rate threads\&gt;=5 threads\&lt;=9 -mode thrift user='vara.bonthu' password='mypassword' -log file=~/vara_write_100kfile.log -transport truststore=/etc/ssl/jks/truststore.jks truststore-password='xxxxxxxxxxxxxxxxx'</p> <p>Excpetion log:<br/> ---------------------<br/> Exception in thread "main" java.lang.RuntimeException: org.apache.thrift.transport.TTransportException: Frame size (352518912) larger than max length (15728640)!<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:144)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:110)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesThrift(SettingsSchema.java:111)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:59)<br/> at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:205)<br/> at org.apache.cassandra.stress.StressAction.run(StressAction.java:55)<br/> at org.apache.cassandra.stress.Stress.main(Stress.java:109)<br/> Caused by: org.apache.thrift.transport.TTransportException: Frame size (352518912) larger than max length (15728640)!</p>
</comment>
<comment id="15157366" author="cornelf@cakesolutions.net" created="Mon, 22 Feb 2016 17:41:41 +0000">
<p>Add also: <br/> factory=org.apache.cassandra.thrift.SSLTransportFactory</p> <p>More on the -transport options here:<br/> <a href="https://github.com/apache/cassandra/blob/cassandra-2.1/tools/stress/src/org/apache/cassandra/stress/settings/SettingsTransport.java#L116" class="external-link" rel="nofollow">https://github.com/apache/cassandra/blob/cassandra-2.1/tools/stress/src/org/apache/cassandra/stress/settings/SettingsTransport.java#L116</a></p>
</comment>
<comment id="15158748" author="vara" created="Tue, 23 Feb 2016 11:30:29 +0000">
<p>I have tried that but i get the authentication error this time. I am able to login to CQLSH with my credentials without any issues(cqlsh --ssl -u "vara.bonthu" -p 'xxxxxxxxxx').</p> <p>/usr/bin/cassandra-stress write n=100000 -mode thrift user="vara.bonthu" password='xxxxxx' -log file=~/vara_write_100kfile.log -transport factory=org.apache.cassandra.thrift.SSLTransportFactory truststore=/etc/ssl/jks/truststore.jks truststore-password='xxxx'</p> <p>Exception in thread "main" java.lang.RuntimeException: AuthenticationException(why:Username and/or password are incorrect)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:144)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:110)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpacesThrift(SettingsSchema.java:111)<br/> at org.apache.cassandra.stress.settings.SettingsSchema.createKeySpaces(SettingsSchema.java:59)<br/> at org.apache.cassandra.stress.settings.StressSettings.maybeCreateKeyspaces(StressSettings.java:205)<br/> at org.apache.cassandra.stress.StressAction.run(StressAction.java:55)<br/> at org.apache.cassandra.stress.Stress.main(Stress.java:109)<br/> Caused by: AuthenticationException(why:Username and/or password are incorrect)<br/> at org.apache.cassandra.thrift.Cassandra$login_result$login_resultStandardScheme.read(Cassandra.java:8334)<br/> at org.apache.cassandra.thrift.Cassandra$login_result$login_resultStandardScheme.read(Cassandra.java:8320)<br/> at org.apache.cassandra.thrift.Cassandra$login_result.read(Cassandra.java:8262)<br/> at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:86)<br/> at org.apache.cassandra.thrift.Cassandra$Client.recv_login(Cassandra.java:582)<br/> at org.apache.cassandra.thrift.Cassandra$Client.login(Cassandra.java:569)<br/> at org.apache.cassandra.stress.settings.StressSettings.getRawThriftClient(StressSettings.java:135)<br/> ... 6 more</p> <p>I have also tried running in native mode<br/> ------------------------------------------------------</p> <p>cassandra-stress write n=100000 -mode native cql3 -schema keyspace="keyspace1" -log file=~/vara_write_100kfile.log -transport factory=org.apache.cassandra.thrift.SSLTransportFactory truststore=/etc/ssl/jks/truststore.jks truststore-password='xxxxx'</p> <p>Unable to create stress keyspace: You have not logged in</p> <p>Exception in thread "Thread-259" Exception in thread "Thread-246" Exception in thread "Thread-257" java.lang.RuntimeException: java.io.IOException: Error creating the initializing the SSL Context<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:198)<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:171)<br/> at org.apache.cassandra.stress.StressAction$Consumer.run(StressAction.java:285)<br/> Caused by: java.io.IOException: Error creating the initializing the SSL Context<br/> at org.apache.cassandra.security.SSLFactory.createSSLContext(SSLFactory.java:147)<br/> at org.apache.cassandra.stress.util.JavaDriverClient.connect(JavaDriverClient.java:102)<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:189)<br/> ... 2 more<br/> Caused by: java.io.FileNotFoundException: conf/.keystore (No such file or directory)<br/> at java.io.FileInputStream.open0(Native Method)<br/> at java.io.FileInputStream.open(FileInputStream.java:195)<br/> at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:138)<br/> at java.io.FileInputStream.&lt;init&gt;(FileInputStream.java:93)<br/> at org.apache.cassandra.security.SSLFactory.createSSLContext(SSLFactory.java:122)<br/> ... 4 more<br/> Exception in thread "Thread-228" java.lang.RuntimeException: java.io.IOException: Error creating the initializing the SSL Context<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:198)<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:171)<br/> at org.apache.cassandra.stress.StressAction$Consumer.run(StressAction.java:285)<br/> Caused by: java.io.IOException: Error creating the initializing the SSL Context<br/> at org.apache.cassandra.security.SSLFactory.createSSLContext(SSLFactory.java:147)<br/> at org.apache.cassandra.stress.util.JavaDriverClient.connect(JavaDriverClient.java:102)<br/> at org.apache.cassandra.stress.settings.StressSettings.getJavaDriverClient(StressSettings.java:189</p>
</comment>
<comment id="15158755" author="cornelf@cakesolutions.net" created="Tue, 23 Feb 2016 11:39:48 +0000">
<p>Remove any quotes from user="vara.bonthu" password='xxxxxx'</p>
</comment>
<comment id="15158895" author="vara" created="Tue, 23 Feb 2016 13:50:45 +0000">
<p>It worked fine this time Cornel. Thanks for resolving the issue. </p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 6 Oct 2015 15:11:23 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2mlr3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10173] Compaction isn't cleaning out tombstones between hint deliveries
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10173
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>3 node cluster, 100M writes. Same scenario as 10172:</p> <p>Test Start: 00:00:00<br/> Node 1 Killed: 00:05:48<br/> Node 2 Killed: 00:13:33<br/> Node 1 Started: 00:24:20<br/> Node 2 Started: 00:32:23<br/> Test Done: 00:38:33</p> <p>Node 1 hints replay finished: 00:56:16<br/> Node 2 hints replay finished: 01:00:16<br/> Node 3 hints replay finished: 02:08:00</p> <p>Log attached. Note the tombstone_failure_threshold errors.</p>
</description>
<environment/>
<key id="12858498">CASSANDRA-10173</key>
<summary>
Compaction isn't cleaning out tombstones between hint deliveries
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jbellis">Jonathan Ellis</reporter>
<labels></labels>
<created>Tue, 25 Aug 2015 02:56:54 +0000</created>
<updated>Wed, 28 Oct 2015 16:11:38 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14710485" author="jbellis" created="Tue, 25 Aug 2015 02:57:53 +0000">
<p>(<a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aboudreault" class="user-hover" rel="aboudreault">Alan Boudreault</a> ran this test for me. For the record, 3.0 is looking very good: <a href="http://riptano.github.io/cassandra_performance/graph_v5/graph.html?stats=cassandra-2.2-vs-3.0-100M-writes-hints.log&amp;metric=op_rate&amp;operation=1_write&amp;smoothing=1&amp;show_aggregates=true&amp;xmin=0&amp;xmax=2527.91&amp;ymin=0&amp;ymax=97650.3" class="external-link" rel="nofollow">http://riptano.github.io/cassandra_performance/graph_v5/graph.html?stats=cassandra-2.2-vs-3.0-100M-writes-hints.log&amp;metric=op_rate&amp;operation=1_write&amp;smoothing=1&amp;show_aggregates=true&amp;xmin=0&amp;xmax=2527.91&amp;ymin=0&amp;ymax=97650.3</a>)</p>
</comment>
<comment id="14711103" author="iamaleksey" created="Tue, 25 Aug 2015 11:34:21 +0000">
<p>Full disclosure: I haven't looked at the logs at all just yet, this is merely my guess at this point.</p> <p>I'm reasonably confident that auto-compaction is actually disabled there. However, we can only forcefully major-compact the sstables that aren't already compacting. And there are two different events that might trigger hints replay in pre-3.0 C*: one is the scheduled replay (allthethings) every 10 minutes, the other one is a node coming up. And the latter would also trigger a major compaction before starting replay, but only for the sstables that aren't already compacting.</p> <p>Because of this overlap it's not guaranteed that a pre-replay compaction would clean out all the tombstones. If this is what is indeed happening, one workaround would be to bound <tt>max_hints_delivery_threads</tt> to 1 (the default in the .yaml is 2).</p> <p>3.0 should be looking good, obviously, for more reasons than just lack of compaction. Not directly related to the issue, but replay triggering in 3.0 is also simpler - we just do it every 10 seconds, because it's cheap, and don't listen to node up events at all.</p>
</comment>
<comment id="14711107" author="iamaleksey" created="Tue, 25 Aug 2015 11:36:30 +0000">
<p>FWIW the default in <tt>Config.java</tt> <b>is</b> actually 1, but it is 2 in the .yaml. I'm not sure why, but 1 is probably a better default overall, so the .yaml should be corrected.</p>
</comment>
<comment id="14711230" author="iamaleksey" created="Tue, 25 Aug 2015 13:11:45 +0000">
<p>And a proper fix would be to limit those compactions to one at a time, if that is indeed the cause.</p>
</comment>
</comments>
<attachments>
<attachment id="12752134" name="system (3).log" size="536690" author="jbellis" created="Tue, 25 Aug 2015 02:56:54 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 25 Aug 2015 11:34:21 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2jbjb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10143] Apparent counter overcount during certain network partitions
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10143
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>This issue is reproducible in this <a href="https://github.com/riptano/jepsen/blob/f45f5320db608d48de2c02c871aecc4910f4d963/cassandra/test/cassandra/counter_test.clj#L16" class="external-link" rel="nofollow">Jepsen Test</a>.</p> <p>The test starts a five-node cluster and issues increments by one against a single counter. It then checks that the counter is in the range <span class="error">&#91;OKed increments, OKed increments + Write Timeouts&#93;</span> at each read. Increments are issued at CL.ONE and reads at CL.ALL. Throughout the test, network failures are induced that create halved network partitions. A halved network partition splits the cluster into three connected nodes and two connected nodes, randomly.</p> <p>This test started failing; bisects showed that it was actually a test change that caused this failure. When the network partitions are induced in a cycle of 15s healthy/45s partitioned or 20s healthy/45s partitioned, the test failes. When network partitions are induced in a cycle of 15s healthy/60s partitioned, 20s healthy/45s partitioned, or 20s healthy/60s partitioned, the test passes.</p> <p>There is nothing unusual in the logs of the nodes for the failed tests. The results are very reproducible.</p> <p>One noticeable trend is that more reads seem to get serviced during the failed tests.</p> <p>Most testing has been done in 2.1.8 - the same issue appears to be present in 2.2/3.0/trunk, but I haven't spent as much time reproducing.</p> <p>Ideas?</p>
</description>
<environment/>
<key id="12857608">CASSANDRA-10143</key>
<summary>
Apparent counter overcount during certain network partitions
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="iamaleksey">Aleksey Yeschenko</assignee>
<reporter username="jkni">Joel Knighton</reporter>
<labels></labels>
<created>Thu, 20 Aug 2015 18:05:19 +0000</created>
<updated>Tue, 8 Dec 2015 20:46:32 +0000</updated>
<fixVersion>3.0.x</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14706849" author="iamaleksey" created="Fri, 21 Aug 2015 15:17:28 +0000">
<p>No ideas, don't see how this can be possible. Will have a look at code/test once 3.0 is out.</p>
</comment>
<comment id="14729988" author="jkni" created="Thu, 3 Sep 2015 23:01:02 +0000">
<p>Looks like we've got some external reproduction here: <a href="http://datastrophic.io/evaluating-cassandra-2-1-counters-consistency/" class="external-link" rel="nofollow">Cassandra 2.1 Counters: Testing Consistency During nodes Failures</a></p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 21 Aug 2015 15:17:28 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j653:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10142] Protocol v1 and v2 don't deal with frozen type correctly
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10142
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When trying to connect with the Python driver to a cluster running trunk, the connection fails with a <tt>NoHostAvailable</tt> exception if the protocol version is set to 1 or 2.</p> <p>The attached script reproduces the error and demonstrates that the connection works if the protocol version is 3 or 4. </p>
</description>
<environment/>
<key id="12857586">CASSANDRA-10142</key>
<summary>
Protocol v1 and v2 don't deal with frozen type correctly
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels>
<label>client-impacting</label>
</labels>
<created>Thu, 20 Aug 2015 16:34:43 +0000</created>
<updated>Fri, 30 Oct 2015 16:46:00 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<component>CQL</component>
<due/>
<votes>0</votes>
<watches>8</watches>
<comments>
<comment id="14705630" author="bdeggleston" created="Thu, 20 Aug 2015 19:43:37 +0000">
<p>The problem appeared in commit {{db782362aaf25214a94c393b20cdbade829c5291}, as part of <a href="https://issues.apache.org/jira/browse/CASSANDRA-6717" title="Modernize schema tables" class="issue-link" data-issue-key="CASSANDRA-6717"><del>CASSANDRA-6717</del></a>. Although from what I've been able to tell so far, it's just exposing a problem with the C* protocol frozen type protocol serialization implementation, which is encoding the frozen map length as a 4 bytes int,instead of the 2 expected by versions 1&amp;2</p>
</comment>
<comment id="14705646" author="thobbs" created="Thu, 20 Aug 2015 19:52:14 +0000">
<p>The driver should be forcing protocol_version to 3 or higher when decoding the contents of FrozenType data: <a href="https://github.com/datastax/python-driver/blob/master/cassandra/cqltypes.py#L979-L991" class="external-link" rel="nofollow">https://github.com/datastax/python-driver/blob/master/cassandra/cqltypes.py#L979-L991</a>. It already does something similar for tuples, UDTs, and nested collections: <a href="https://github.com/datastax/python-driver/blob/master/cassandra/cqltypes.py#L788" class="external-link" rel="nofollow">https://github.com/datastax/python-driver/blob/master/cassandra/cqltypes.py#L788</a>.</p> <p>cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=aholmber" class="user-hover" rel="aholmber">Adam Holmberg</a></p>
</comment>
<comment id="14705697" author="aholmber" created="Thu, 20 Aug 2015 20:27:00 +0000">
<p>Blake's comment is accurate. It was not exposed before because there were no frozen types in the metadata read at startup.</p> <p>Thanks. <a href="https://datastax-oss.atlassian.net/browse/PYTHON-384" class="external-link" rel="nofollow">https://datastax-oss.atlassian.net/browse/PYTHON-384</a></p>
</comment>
<comment id="14705706" author="iamaleksey" created="Thu, 20 Aug 2015 20:31:51 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=bdeggleston" class="user-hover" rel="bdeggleston">Blake Eggleston</a> thanks for finding the reason. This needs to be fixed in the driver, for 2.1 and 2.2 C* users. However, for 3.0, after some discussion, we decided to consider removing support for v1 and v2 protocols (see <a href="https://issues.apache.org/jira/browse/CASSANDRA-10146" title="Deprecate v1 and v2 protocol in 2.2, drop support in 3.0" class="issue-link" data-issue-key="CASSANDRA-10146"><del>CASSANDRA-10146</del></a>), so marking this issue as Won't Fix, unless someone objects to that decision.</p>
</comment>
<comment id="14707469" author="aholmber" created="Fri, 21 Aug 2015 21:09:04 +0000">
<p>I got a chance to look into this a little more. <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=thobbs" class="user-hover" rel="thobbs">Tyler Hobbs</a> I'm not sure this is something the driver should handle. We do not deserialize via FrozenType in results &#8211; this is a results message coming back with a top-level ListType mis-encoded for the protocol version in use. I think the server should either indicate FrozenType in the results metadata (in which case we can use the strategy you mention), or encode the un-nested collection for the protocol version in use.</p> <p>Thoughts?</p>
</comment>
<comment id="14709472" author="slebresne" created="Mon, 24 Aug 2015 15:40:01 +0000">
<p>I agree with what's above: we should pretend it's a list if it's not properly encoded as a list for the version of the protocol in use. If we do decide to go with <a href="https://issues.apache.org/jira/browse/CASSANDRA-10146" title="Deprecate v1 and v2 protocol in 2.2, drop support in 3.0" class="issue-link" data-issue-key="CASSANDRA-10146"><del>CASSANDRA-10146</del></a>, then it's not a problem for 3.0, but that is still something to fix in prior versions. And agreed also on the solutions, we can either:</p> <ul> <li>send frozen types always as a custom type</li> <li>or simply make sure we use 2 bytes for the size</li> </ul> <p>A priori I have a preference for the 2nd option (unless of course there is a complication I'm not thinking of) since that will provide a better experience to users (even though in practice users should use protocol v3 if they are going to use frozen types).</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="12310051">
<name>Supercedes</name>
<inwardlinks description="is superceded by">
<issuelink>
<issuekey id="12857635">CASSANDRA-10146</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12751524" name="repro.sh" size="370" author="mambocab" created="Thu, 20 Aug 2015 16:34:43 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 20 Aug 2015 19:43:37 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j60f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10389] Repair session exception Validation failed
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10389
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I'm running a repair on a ring of nodes, that was recently extented from 3 to 13 nodes. The extension was done two days ago, the repair was attempted yesterday.</p> <blockquote> <p><span class="error">&#91;2015-09-22 11:55:55,266&#93;</span> Starting repair command #9, repairing keyspace perspectiv with repair options (parallelism: parallel, primary range: false, incremental: true, job threads: 1, ColumnFamilies: [], dataCenters: [], hosts: [], # of ranges: 517)<br/> <span class="error">&#91;2015-09-22 11:55:58,043&#93;</span> Repair session 1f7c50c0-6110-11e5-b992-9f13fa8664c8 for range (-5927186132136652665,-5917344746039874798] failed with error <a href="#1f7c50c0-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #1f7c50c0-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>] Validation failed in cblade1.XXX/XXX (progress: 0%)</p></blockquote> <p>BTW, I am ignoring the LEAK errors for now, that's outside of the scope of the main issue:</p> <blockquote> <p>ERROR <span class="error">&#91;Reference-Reaper:1&#93;</span> 2015-09-22 11:58:27,843 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@4d25ad8f) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@896826067:/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-73-big was not released before the reference was garbage collected</p></blockquote> <p>I scrubbed the sstable with failed validation on cblade1 with nodetool scrub perspectiv stock_increment_agg:</p> <blockquote> <p>INFO <span class="error">&#91;CompactionExecutor:1704&#93;</span> 2015-09-22 12:05:31,615 OutputHandler.java:42 - Scrubbing BigTableReader(path='/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-83-big-Data.db') (345466609 bytes)<br/> INFO <span class="error">&#91;CompactionExecutor:1703&#93;</span> 2015-09-22 12:05:31,615 OutputHandler.java:42 - Scrubbing BigTableReader(path='/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-82-big-Data.db') (60496378 bytes)<br/> ERROR <span class="error">&#91;Reference-Reaper:1&#93;</span> 2015-09-22 12:05:31,676 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@4ca8951e) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@114161559:/var/lib/cassandra/data/perspectiv/receipt_agg_total-76abb0625de711e59f6e0b7d98a25b6e/la-48-big was not released before the reference was garbage collected<br/> ERROR <span class="error">&#91;Reference-Reaper:1&#93;</span> 2015-09-22 12:05:31,676 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@eeb6383) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@1612685364:/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-83-big was not released before the reference was garbage collected<br/> ERROR <span class="error">&#91;Reference-Reaper:1&#93;</span> 2015-09-22 12:05:31,676 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@1de90543) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@2058626950:/var/lib/cassandra/data/perspectiv/receipt_agg_total-76abb0625de711e59f6e0b7d98a25b6e/la-49-big was not released before the reference was garbage collected<br/> ERROR <span class="error">&#91;Reference-Reaper:1&#93;</span> 2015-09-22 12:05:31,676 Ref.java:187 - LEAK DETECTED: a reference (org.apache.cassandra.utils.concurrent.Ref$State@15616385) to class org.apache.cassandra.io.sstable.format.SSTableReader$InstanceTidier@1386628428:/var/lib/cassandra/data/perspectiv/receipt_agg_total-76abb0625de711e59f6e0b7d98a25b6e/la-47-big was not released before the reference was garbage collected<br/> INFO <span class="error">&#91;CompactionExecutor:1703&#93;</span> 2015-09-22 12:05:35,098 OutputHandler.java:42 - Scrub of BigTableReader(path='/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-82-big-Data.db') complete: 51397 rows in new sstable and 0 empty (tombstoned) rows dropped<br/> INFO <span class="error">&#91;CompactionExecutor:1704&#93;</span> 2015-09-22 12:05:47,605 OutputHandler.java:42 - Scrub of BigTableReader(path='/var/lib/cassandra/data/perspectiv/stock_increment_agg-840cad405de711e5b9929f13fa8664c8/la-83-big-Data.db') complete: 292600 rows in new sstable and 0 empty (tombstoned) rows dropped</p></blockquote> <p>Now, after scrubbing, another repair was attempted, it did finish, but with lots of errors from other nodes:</p> <blockquote> <p><span class="error">&#91;2015-09-22 12:01:18,020&#93;</span> Repair session db476b51-6110-11e5-b992-9f13fa8664c8 for range (5019296454787813261,5021512586040808168] failed with error <a href="#db476b51-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (5019296454787813261,5021512586040808168">repair #db476b51-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (5019296454787813261,5021512586040808168</a>] Validation failed in /10.YYY (progress: 91%)<br/> <span class="error">&#91;2015-09-22 12:01:18,079&#93;</span> Repair session db482ea1-6110-11e5-b992-9f13fa8664c8 for range (-3660233266780784242,-3638577078894365342] failed with error <a href="#db482ea1-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-3660233266780784242,-3638577078894365342">repair #db482ea1-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-3660233266780784242,-3638577078894365342</a>] Validation failed in /10.XXX (progress: 92%)<br/> <span class="error">&#91;2015-09-22 12:01:18,276&#93;</span> Repair session db4a0361-6110-11e5-b992-9f13fa8664c8 for range (9158857758535272856,9167427882441871745] failed with error <a href="#db4a0361-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (9158857758535272856,9167427882441871745">repair #db4a0361-6110-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (9158857758535272856,9167427882441871745</a>] Validation failed in /10.YYY (progress: 95%)</p></blockquote> <p>After scrubbing stock_increment_agg on all nodes, just to be sure, the repair still failed, this time with the following exception:</p> <blockquote> <p>INFO <span class="error">&#91;Repair#16:50&#93;</span> 2015-09-22 12:08:47,471 RepairJob.java:181 - <a href="#ea123bf3-6111-11e5-b992-9f13fa8664c8">repair #ea123bf3-6111-11e5-b992-9f13fa8664c8</a> Requesting merkle trees for stock_increment_agg (to <span class="error">&#91;/10.60.77.202, cblade1.XXX/XXX&#93;</span>)<br/> ERROR <span class="error">&#91;RepairJobTask:1&#93;</span> 2015-09-22 12:08:47,471 RepairSession.java:290 - <a href="#ea123bf0-6111-11e5-b992-9f13fa8664c8">repair #ea123bf0-6111-11e5-b992-9f13fa8664c8</a> Session completed with the following error<br/> org.apache.cassandra.exceptions.RepairException: <a href="#ea123bf0-6111-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (355657753119264326,366309649129068298">repair #ea123bf0-6111-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (355657753119264326,366309649129068298</a>] Validation failed in cblade1.<br/> at org.apache.cassandra.repair.ValidationTask.treeReceived(ValidationTask.java:64) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:183) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:399) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:158) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span></p></blockquote>
</description>
<environment>
<p>Debian 8, Java 1.8.0_60, Cassandra 2.2.1 (datastax compilation)</p>
</environment>
<key id="12895735">CASSANDRA-10389</key>
<summary>Repair session exception Validation failed</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jedrzej.sieracki">Jędrzej Sieracki</reporter>
<labels></labels>
<created>Wed, 23 Sep 2015 10:05:25 +0000</created>
<updated>Wed, 17 Feb 2016 21:04:41 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>1</votes>
<watches>8</watches>
<comments>
<comment id="14904474" author="yukim" created="Wed, 23 Sep 2015 13:07:31 +0000">
<p>What kind of error do you see in replica nodes (in cblade1 or other nodes that failed to validate)?</p>
</comment>
<comment id="14906018" author="jedrzej.sieracki" created="Thu, 24 Sep 2015 08:37:00 +0000">
<p>After checking the logs more thoroughly, the issue seems to be "Cannot start multiple repair sessions over the same sstables".</p> <p>The interesting log portions from repair session run on cblade1:</p> <blockquote> <p>INFO <span class="error">&#91;Repair#24:1&#93;</span> 2015-09-24 09:58:37,480 RepairJob.java:107 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> requesting merkle trees for stock_increment_agg (to <span class="error">&#91;/cblade10, cblade1&#93;</span>)<br/> INFO <span class="error">&#91;Repair#24:1&#93;</span> 2015-09-24 09:58:37,480 RepairJob.java:181 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> Requesting merkle trees for stock_increment_agg (to <span class="error">&#91;/cblade10, cblade1&#93;</span>)<br/> ERROR <span class="error">&#91;ValidationExecutor:28&#93;</span> 2015-09-24 09:58:37,481 CompactionManager.java:1070 - Cannot start multiple repair sessions over the same sstables<br/> ERROR <span class="error">&#91;ValidationExecutor:28&#93;</span> 2015-09-24 09:58:37,481 Validator.java:246 - Failed creating a merkle tree for <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>], /cblade1(see log for details)<br/> INFO <span class="error">&#91;AntiEntropyStage:1&#93;</span> 2015-09-24 09:58:37,481 RepairSession.java:181 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> Received merkle tree for stock_increment_agg from /cblade1<br/> ERROR <span class="error">&#91;ValidationExecutor:28&#93;</span> 2015-09-24 09:58:37,481 CassandraDaemon.java:183 - Exception in thread Thread<span class="error">&#91;ValidationExecutor:28,1,main&#93;</span><br/> java.lang.RuntimeException: Cannot start multiple repair sessions over the same sstables<br/> at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1071) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager.access$700(CompactionManager.java:94) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager$10.call(CompactionManager.java:669) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> WARN <span class="error">&#91;RepairJobTask:1&#93;</span> 2015-09-24 09:58:37,481 RepairJob.java:162 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> stock_increment_agg sync failed<br/> ERROR <span class="error">&#91;RepairJobTask:2&#93;</span> 2015-09-24 09:58:37,482 CassandraDaemon.java:183 - Exception in thread Thread<span class="error">&#91;RepairJobTask:2,5,RMI Runtime&#93;</span><br/> org.apache.cassandra.exceptions.RepairException: <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>] Validation failed in cblade1.dforcom.localdomain/cblade1<br/> at org.apache.cassandra.repair.ValidationTask.treeReceived(ValidationTask.java:64) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:183) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:399) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:158) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> INFO <span class="error">&#91;Repair#24:2&#93;</span> 2015-09-24 09:58:37,482 RepairJob.java:107 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> requesting merkle trees for receipt_agg_total (to <span class="error">&#91;/cblade10, cblade1.dforcom.localdomain/cblade1&#93;</span>)<br/> ERROR <span class="error">&#91;Repair#24:1&#93;</span> 2015-09-24 09:58:37,482 CassandraDaemon.java:183 - Exception in thread Thread<span class="error">&#91;Repair#24:1,5,RMI Runtime&#93;</span><br/> com.google.common.util.concurrent.UncheckedExecutionException: org.apache.cassandra.exceptions.RepairException: <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>] Validation failed in cblade1.dforcom.localdomain/cblade1<br/> at com.google.common.util.concurrent.Futures.wrapAndThrowUnchecked(Futures.java:1387) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.util.concurrent.Futures.getUnchecked(Futures.java:1373) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at org.apache.cassandra.repair.RepairJob.run(RepairJob.java:169) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> Caused by: org.apache.cassandra.exceptions.RepairException: <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>] Validation failed in cblade1.dforcom.localdomain/cblade1<br/> at org.apache.cassandra.repair.ValidationTask.treeReceived(ValidationTask.java:64) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:183) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:399) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:158) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> ... 3 common frames omitted<br/> INFO <span class="error">&#91;Repair#24:2&#93;</span> 2015-09-24 09:58:37,482 RepairJob.java:181 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> Requesting merkle trees for receipt_agg_total (to <span class="error">&#91;/cblade10, cblade1.dforcom.localdomain/cblade1&#93;</span>)<br/> INFO <span class="error">&#91;AntiEntropyStage:1&#93;</span> 2015-09-24 09:58:37,482 RepairSession.java:181 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> Received merkle tree for stock_increment_agg from /cblade10<br/> ERROR <span class="error">&#91;RepairJobTask:1&#93;</span> 2015-09-24 09:58:37,482 RepairSession.java:290 - <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8">repair #0fc98340-6292-11e5-b992-9f13fa8664c8</a> Session completed with the following error<br/> org.apache.cassandra.exceptions.RepairException: <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>] Validation failed in cblade1.dforcom.localdomain/cblade1<br/> at org.apache.cassandra.repair.ValidationTask.treeReceived(ValidationTask.java:64) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:183) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:399) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:158) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:66) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span></p></blockquote> <p>..and at that moment on cblade10:</p> <blockquote> <p>ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,481 CompactionManager.java:1070 - Cannot start multiple repair sessions over the same sstables<br/> ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,481 Validator.java:246 - Failed creating a merkle tree for <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/stock_increment_agg, (-5927186132136652665,-5917344746039874798</a>], /cblade1 (see log for details)<br/> ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,482 CassandraDaemon.java:183 - Exception in thread Thread<span class="error">&#91;ValidationExecutor:21,1,main&#93;</span><br/> java.lang.RuntimeException: Cannot start multiple repair sessions over the same sstables<br/> at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1071) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager.access$700(CompactionManager.java:94) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager$10.call(CompactionManager.java:669) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,483 CompactionManager.java:1070 - Cannot start multiple repair sessions over the same sstables<br/> ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,483 Validator.java:246 - Failed creating a merkle tree for <a href="#0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/receipt_agg_total, (-5927186132136652665,-5917344746039874798">repair #0fc98340-6292-11e5-b992-9f13fa8664c8 on perspectiv/receipt_agg_total, (-5927186132136652665,-5917344746039874798</a>], /cblade1 (see log for details)<br/> ERROR <span class="error">&#91;ValidationExecutor:21&#93;</span> 2015-09-24 09:58:37,483 CassandraDaemon.java:183 - Exception in thread Thread<span class="error">&#91;ValidationExecutor:21,1,main&#93;</span><br/> java.lang.RuntimeException: Cannot start multiple repair sessions over the same sstables<br/> at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1071) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager.access$700(CompactionManager.java:94) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager$10.call(CompactionManager.java:669) ~<span class="error">&#91;apache-cassandra-2.2.1.jar:2.2.1&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span></p></blockquote>
</comment>
<comment id="15103940" author="depend" created="Sun, 17 Jan 2016 21:55:15 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jedrzej.sieracki" class="user-hover" rel="jedrzej.sieracki">Jędrzej Sieracki</a> not sure if you still have this problem. But have you tried to restart all the C* instances?</p>
</comment>
<comment id="15108643" author="jeffggardner@gmail.com" created="Wed, 20 Jan 2016 14:52:50 +0000">
<p>We are also experiencing this issue in 2.2.3; and yes we have restarted all nodes.</p> <p>Our config:</p> <p>Cassandra 2.2.3<br/> AWS west-2 and east-1 regions with 6 nodes per region <span class="error">&#91;2/AZ&#93;</span></p>
</comment>
<comment id="15108758" author="jeffggardner@gmail.com" created="Wed, 20 Jan 2016 15:43:22 +0000">
<p>this is becoming a significant problem in our production environment... can this be escalated or is there a known work around?</p>
</comment>
<comment id="15108763" author="slebresne" created="Wed, 20 Jan 2016 15:48:15 +0000">
<blockquote><p>is there a known work around?</p></blockquote> <p>yes, stop starting multiple competing repair simultaneously.</p>
</comment>
<comment id="15151180" author="luxifer" created="Wed, 17 Feb 2016 21:04:41 +0000">
<p>I think we're seeing this issue as well. Running Cassandra 2.2.5. Haven't tried restarting all nodes but will do that now.</p> <p>We're running incremental repairs (now default, eh?) and while testing this before we put that into production we already found that repairing a whole keyspace will create a massive amount of open filehandles / "anti-compacted" sstables even though the repair will still only work one CF at a time. This caused some problems so we're now running repairs one CF at a time and on only one node at a time.</p> <p>We did not have this issue in our testing but seing it in production now, nevertheless. What's interesting is that the node, on which the repair runs, at some point suddenly thrashes its heap (i.e. full heap usage, 65%-85% GC!!!) while at the same time produces huge amounts of tiny, concurrent reads, leading to really bad read latency from disk and a lot of I/O wait.</p> <p>The bad thing is: This (Cassandra) node becomes so unresponsive that it significantly impacts the performance of the whole cluster (a total of 9 machines, rf 5 / quorum for most reads/writes, rf 2 / one for less important bulk data). So neither the java driver nor the other nodes, when being coordinator, manage to just leave this node alone for a while. As soon as I disable gossip on this node, the rest of the cluster is fine again.</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a>: I applaud you for your very useful comment.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 23 Sep 2015 13:07:31 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2lg8n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333059</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10391] sstableloader fails with client SSL enabled with non-standard keystore/truststore location
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10391
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>If client SSL is enabled, sstableloader is unable to access the keystore and truststore if they are not in the expected locations. I reproduce this issue providing <tt>-f /path/to/cassandra.yaml</tt> as well as manually using the <tt>-ks</tt> flag with the proper path to the keystore.</p> <p>For example:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>client_encryption_options: enabled: true keystore: /var/tmp/.keystore </pre> </div></div> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre># sstableloader -d 172.31.2.240,172.31.2.241 -f /etc/dse/cassandra/cassandra.yaml Keyspace1/Standard1/ Could not retrieve endpoint ranges: java.io.FileNotFoundException: /usr/share/dse/conf/.keystore Run with --debug to get full stack trace or --help to get help. # # sstableloader -d 172.31.2.240,172.31.2.241 -ks /var/tmp/.keystore Keyspace1/Standard1/ Could not retrieve endpoint ranges: java.io.FileNotFoundException: /usr/share/dse/conf/.keystore Run with --debug to get full stack trace or --help to get help. # </pre> </div></div> <p>The full stack is:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre># sstableloader -d 172.31.2.240,172.31.2.241 -f /etc/dse/cassandra/cassandra.yaml --debug Keyspace1/Standard1/ Could not retrieve endpoint ranges: java.io.FileNotFoundException: /usr/share/dse/conf/.keystore java.lang.RuntimeException: Could not retrieve endpoint ranges: at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:283) at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:144) at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95) Caused by: java.io.FileNotFoundException: /usr/share/dse/conf/.keystore at com.datastax.bdp.transport.client.TClientSocketFactory.getSSLSocket(TClientSocketFactory.java:128) at com.datastax.bdp.transport.client.TClientSocketFactory.openSocket(TClientSocketFactory.java:114) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:186) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:120) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:111) at org.apache.cassandra.tools.BulkLoader$ExternalClient.createThriftClient(BulkLoader.java:302) at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:254) ... 2 more root@ip-172-31-2-240:/tmp/foo# </pre> </div></div> <p>.</p> <p>If I copy the keystore to the expected location, I get the same error with the truststore.</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre># sstableloader -d 172.31.2.240,172.31.2.241 -f /etc/dse/cassandra/cassandra.yaml --debug Keyspace1/Standard1/ Could not retrieve endpoint ranges: java.io.FileNotFoundException: /usr/share/dse/conf/.truststore java.lang.RuntimeException: Could not retrieve endpoint ranges: at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:283) at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:144) at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95) Caused by: java.io.FileNotFoundException: /usr/share/dse/conf/.truststore at com.datastax.bdp.transport.client.TClientSocketFactory.getSSLSocket(TClientSocketFactory.java:130) at com.datastax.bdp.transport.client.TClientSocketFactory.openSocket(TClientSocketFactory.java:114) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:186) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:120) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:111) at org.apache.cassandra.tools.BulkLoader$ExternalClient.createThriftClient(BulkLoader.java:302) at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:254) ... 2 more # </pre> </div></div> <p>If I copy the truststore, it finds them both, but then fails to open them due to what I assume is a password error, even those it's present in the cassandra.yaml.</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre># sstableloader -d 172.31.2.240,172.31.2.241 -f /etc/dse/cassandra/cassandra.yaml --debug Keyspace1/Standard1/ Could not retrieve endpoint ranges: java.io.IOException: Failed to open transport to: 172.31.2.240:9160 java.lang.RuntimeException: Could not retrieve endpoint ranges: at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:283) at org.apache.cassandra.io.sstable.SSTableLoader.stream(SSTableLoader.java:144) at org.apache.cassandra.tools.BulkLoader.main(BulkLoader.java:95) Caused by: java.io.IOException: Failed to open transport to: 172.31.2.240:9160 at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:137) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:111) at org.apache.cassandra.tools.BulkLoader$ExternalClient.createThriftClient(BulkLoader.java:302) at org.apache.cassandra.tools.BulkLoader$ExternalClient.init(BulkLoader.java:254) ... 2 more Caused by: org.apache.thrift.transport.TTransportException: Error creating the transport at org.apache.thrift.transport.TSSLTransportFactory.createSSLContext(TSSLTransportFactory.java:201) at org.apache.thrift.transport.TSSLTransportFactory.getClientSocket(TSSLTransportFactory.java:165) at com.datastax.bdp.transport.client.TClientSocketFactory.getSSLSocket(TClientSocketFactory.java:136) at com.datastax.bdp.transport.client.TClientSocketFactory.openSocket(TClientSocketFactory.java:114) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:186) at com.datastax.bdp.transport.client.TDseClientTransportFactory.openTransport(TDseClientTransportFactory.java:120) ... 5 more Caused by: java.io.IOException: Keystore was tampered with, or password was incorrect at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:772) at sun.security.provider.JavaKeyStore$JKS.engineLoad(JavaKeyStore.java:55) at java.security.KeyStore.load(KeyStore.java:1445) at org.apache.thrift.transport.TSSLTransportFactory.createSSLContext(TSSLTransportFactory.java:179) ... 10 more Caused by: java.security.UnrecoverableKeyException: Password verification failed at sun.security.provider.JavaKeyStore.engineLoad(JavaKeyStore.java:770) ... 13 more </pre> </div></div> <p>If I specify the password on the command line, I get the same error.</p>
</description>
<environment>
<p><span class="error">&#91;cqlsh 4.1.1 | Cassandra 2.0.14.425 | DSE 4.6.6 | CQL spec 3.1.1 | Thrift protocol 19.39.0&#93;</span></p> <p><span class="error">&#91;cqlsh 5.0.1 | Cassandra 2.1.8.689 | DSE 4.7.3 | CQL spec 3.2.0 | Native protocol v3&#93;</span></p>
</environment>
<key id="12895819">CASSANDRA-10391</key>
<summary>
sstableloader fails with client SSL enabled with non-standard keystore/truststore location
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="nutbunnies">Andrew Hust</assignee>
<reporter username="jmoses">Jon Moses</reporter>
<labels></labels>
<created>Wed, 23 Sep 2015 15:53:50 +0000</created>
<updated>Tue, 17 Nov 2015 21:13:29 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="15009517" author="suiterdev" created="Tue, 17 Nov 2015 21:13:29 +0000">
<p>If you are using sstableloader in a secure environment with SSL, you need to pass the TrustFactory option, -tf, along with the truststore and password, or truststore, keystore, and passwords. See <a href="http://docs.datastax.com/en/datastax_enterprise/4.5/datastax_enterprise/tools/toolsSStblLd.html?scroll=toolsSStblLd__secSstblldrNde" class="external-link" rel="nofollow">http://docs.datastax.com/en/datastax_enterprise/4.5/datastax_enterprise/tools/toolsSStblLd.html?scroll=toolsSStblLd__secSstblldrNde</a> for details.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 17 Nov 2015 21:13:29 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2lgrb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12329670</customfieldvalue>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-10194] Deadlock on startup</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10194
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Possible deadlock on startup. Seen on 2.1.5 and 2.1.7. Thread dump attached. </p>
</description>
<environment/>
<key id="12858944">CASSANDRA-10194</key>
<summary>Deadlock on startup</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jjirsa">Jeff Jirsa</reporter>
<labels></labels>
<created>Wed, 26 Aug 2015 10:34:37 +0000</created>
<updated>Fri, 18 Sep 2015 20:49:42 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14712932" author="jjirsa" created="Wed, 26 Aug 2015 10:51:17 +0000">
<p>Discussed this quickly with <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict" class="user-hover" rel="benedict">Benedict</a> early this morning in IRC. Hopefully he can share his 2 cents while it's fresh.</p>
</comment>
<comment id="14712940" author="benedict" created="Wed, 26 Aug 2015 11:06:43 +0000">
<p>Attaching a cleaned up version of the thread dump.</p> <p>I cannot say exactly why the following is happening, but I can say that it is:</p> <ul> <li>An sstablereader is being released; during release it persists its read meter, and this is a durable write that requires commit log space</li> <li>The commit log segment manager is not allocating one, and is awaiting work. I <em>assume</em> this means reserve segments are not yet enabled, i.e. it is too early in startup to perform a durable write. However, I cannot see <tt>CassandraDaemon</tt> anywhere in the log, so it's possible there is some other reason they cannot be allocated</li> <li>An sstable for the same keyspace is being flushed, and this</li> </ul> <p>Full system logs, and perhaps a heap dump, would aid greatly in pinning down the cause, however we should really make ourselves at least robust to this deadlock by, for instance, throwing an exception if we attempt to write a durable mutation while the commit log is disabled.</p> <p>It's also possible this is another manifestation of the Linux FUTEX_WAIT bug. If you could rule out your system being affected by this, it would help a great deal.</p>
</comment>
<comment id="14735391" author="jjirsa" created="Tue, 8 Sep 2015 18:53:19 +0000">
<p>As far as I can tell, my CPU is one of the haswell chips that would have issues, but my ubuntu 1404 kernel should be patched (3.19 series from 2015, and ubuntu patches went up in 2014). I'm not going to be able to provide a heap dump. I may be able to provide sanitized logs. </p>
</comment>
<comment id="14876374" author="jjirsa" created="Fri, 18 Sep 2015 20:49:42 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=benedict" class="user-hover" rel="benedict">Benedict</a> in the absence of full logs (which I may be able to upload sanitized, but won't be for some time), is there anything else that can help narrow this down? It's seen, typically, on machines with tens of thousands of sstables (lots of vnodes + dtcs). Can I search for anything in the log short of uploading the entire log for you?<br/> CassandraDaemon lines? </p>
</comment>
</comments>
<attachments>
<attachment id="12752444" name="aggregated thread dump" size="27344" author="benedict" created="Wed, 26 Aug 2015 11:06:43 +0000"/>
<attachment id="12752439" name="cassandra-thread" size="113790" author="jjirsa" created="Wed, 26 Aug 2015 10:34:37 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 26 Aug 2015 11:06:43 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2je93:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332753</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10111] reconnecting snitch can bypass cluster name check
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10111
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Setup:</p> <ul> <li>Two clusters: A &amp; B</li> <li>Both are two DC cluster</li> <li>Both use GossipingPropertyFileSnitch with different listen_address/broadcast_address</li> </ul> <p>A new node was added to cluster A with a broadcast_address of an existing node in cluster B (due to an out of data DNS entry). Cluster B added all of the nodes from cluster A, somehow bypassing the cluster name mismatch check for this nodes. The first reference to cluster A nodes in cluster B logs is when then were added:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> INFO [GossipStage:1] 2015-08-17 15:08:33,858 Gossiper.java (line 983) Node /8.37.70.168 is now part of the cluster </pre> </div></div> <p>Cluster B nodes then tried to gossip to cluster A nodes, but cluster A kept them out with 'ClusterName mismatch'. Cluster B however tried to send to send reads/writes to cluster A and general mayhem ensued.</p> <p>Obviously this is a Bad (TM) config that Should Not Be Done. However, since the consequence of crazy merged clusters are really bad (the reason there is the name mismatch check in the first place) I think the hole is reasonable to plug. I'm not sure exactly what the code path is that skips the check in GossipDigestSynVerbHandler.</p>
</description>
<environment/>
<key id="12856760">CASSANDRA-10111</key>
<summary>reconnecting snitch can bypass cluster name check</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="jkni">Joel Knighton</assignee>
<reporter username="cburroughs">Chris Burroughs</reporter>
<labels>
<label>gossip</label>
<label>messaging-service-bump-required</label>
</labels>
<created>Mon, 17 Aug 2015 22:18:43 +0000</created>
<updated>Mon, 21 Dec 2015 21:24:44 +0000</updated>
<fixVersion>3.x</fixVersion>
<component>Distributed Metadata</component>
<due/>
<votes>0</votes>
<watches>7</watches>
<comments>
<comment id="14711923" author="philipthompson" created="Tue, 25 Aug 2015 20:31:09 +0000">
<p>What Cassandra version did this happen on? For both clusters, A and B, if you could.</p>
</comment>
<comment id="14711939" author="cburroughs" created="Tue, 25 Aug 2015 20:40:23 +0000"><p>They both were on 2.0.15 at the time</p></comment>
<comment id="14875887" author="mambocab" created="Fri, 18 Sep 2015 16:26:15 +0000">
<p>cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania" class="user-hover" rel="Stefania">Stefania</a> <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brandon.williams" class="user-hover" rel="brandon.williams">Brandon Williams</a> &#8211; May I asign this to you, or can you recommend someone I can assign this to?</p>
</comment>
<comment id="14877217" author="stefania" created="Sat, 19 Sep 2015 17:18:55 +0000">
<p>I'll take it but I have a few critical tickets that have higher priority.</p>
</comment>
<comment id="15004289" author="jkni" created="Fri, 13 Nov 2015 16:59:01 +0000">
<p>This can occur because we only check for cluster name mismatches in the <tt>GossipDigestSynVerbHandler</tt>. In the original design of Cassandra, this was sufficient, since we always replied to the <tt>listen_address</tt>.</p> <p>Since we now reply to the <tt>broadcast_address</tt>, the <tt>GossipDigestAckVerbHandler</tt> and the <tt>GossipDigestAck2VerbHandler</tt> also need to check <tt>clusterId</tt> for mismatches. <tt>GossipDigestAck</tt> and <tt>GossipDigestAck2</tt> don't contain <tt>clusterId</tt> currently, so we need to bump the <tt>MessagingService</tt> version to accommodate the addition of this field.</p> <p>The reason this metadata contamination is unidirectional is as follows:<br/> 1. New node sends <tt>GossipDigestSyn</tt> asking for all info.<br/> 2. Node from cluster A replies to cluster B node with shared broadcast address, adding info for all nodes from cluster A and asking for no info.<br/> 3. Cluster B node doesn't share cluster B data since it hasn't been requested.</p> <p>All subsequent direct gossiping between the two clusters is blocked by the <tt>GossipDigestSynVerbHandler</tt>.</p> <p>I have a working fix for this; we need to decide when a <tt>MessagingService</tt> bump will occur.</p> <p>Thanks for the report!</p>
</comment>
<comment id="15055463" author="jkni" created="Mon, 14 Dec 2015 06:00:33 +0000">
<p>I've fixed this issue by adding the cluster name in the ack/ack2 messages. We need it in both messages because incorrect broadcast addresses can result in arbitrary chaining between clusters in the manner described in the above comment. I've accommodated this in the handlers and ensured they continue to work with lower MessagingService versions so that there is a clean upgrade path. Unit tests for the Syn/Ack/Ack2 verb handlers have also been included.</p> <p>The part of this patch in which I'm least confident is accommodating the MessagingService version increase throughout the rest of the code. I've verified this as best as I can, but many of the areas in which I had to accommodate the change are new to me.</p> <p>CI is clean relative to upstream. A dtest reproducing the issue is available <a href="https://github.com/jkni/cassandra-dtest/tree/10111" class="external-link" rel="nofollow">here</a>.</p> <table class='confluenceTable'><tbody> <tr> <th class='confluenceTh'>branch</th> <th class='confluenceTh'>testall</th> <th class='confluenceTh'>dtest</th> </tr> <tr> <td class='confluenceTd'><a href="https://github.com/jkni/cassandra/tree/10111-trunk" class="external-link" rel="nofollow">10111-trunk</a></td> <td class='confluenceTd'><a href="http://cassci.datastax.com/view/Dev/view/jkni/job/jkni-10111-trunk-testall" class="external-link" rel="nofollow">testall</a></td> <td class='confluenceTd'><a href="http://cassci.datastax.com/view/Dev/view/jkni/job/jkni-10111-trunk-dtest" class="external-link" rel="nofollow">dtest</a></td> </tr> </tbody></table>
</comment>
<comment id="15067055" author="pauloricardomg" created="Mon, 21 Dec 2015 21:00:23 +0000">
<p>Code and approach looks good but it seems we can only bump the messaging service version in the next major, or 4.0.</p> <p>Alternatives are to wait until then, or maybe do some workaround before, like adding a new gossip field <tt>CLUSTER_ID</tt> to <tt>ApplicationState</tt> and ignore any <tt>GossipDigestAck</tt> or <tt>GossipDigestAck2</tt> messages containing states from other cluster ids.</p> <p>Since this is quite an unlikely (and unfortunate) situation I'd be more in favor of waiting for the messaging bump (since we've waited until here) instead of polluting gossip with more fields.</p>
</comment>
<comment id="15067072" author="jkni" created="Mon, 21 Dec 2015 21:18:41 +0000">
<p>Sounds good - my original understanding was that this would be okay, but it sounds like the messaging service version change strategy is still unclear.</p> <p>I think the best option is to wait until the next messaging service change. As you mentioned, this is an unlikely situation that has a solution in the form of forcing removal of the entries from gossip using nodetool.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 25 Aug 2015 20:31:09 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j107:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12329873</customfieldvalue>
<customfieldvalue>12333872</customfieldvalue>
<customfieldvalue>12333871</customfieldvalue>
<customfieldvalue>12334152</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>pauloricardomg</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10084] Very slow performance streaming a large query from a single CF
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10084
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We have a relatively simple column family that we use to track event data from different providers. We have been utilizing it for some time. Here is what it looks like: </p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> CREATE TABLE data.stories_by_text ( ref_id timeuuid, second_type text, second_value text, object_type text, field_name text, value text, story_id timeuuid, data map&lt;text, text&gt;, PRIMARY KEY ((ref_id, second_type, second_value, object_type, field_name), value, story_id) ) WITH CLUSTERING ORDER BY (value ASC, story_id ASC) AND bloom_filter_fp_chance = 0.01 AND caching = '{<span class="code-quote">"keys"</span>:<span class="code-quote">"ALL"</span>, <span class="code-quote">"rows_per_partition"</span>:<span class="code-quote">"NONE"</span>}' AND comment = 'Searchable fields and actions in a story are indexed by ref id which corresponds to a brand, app, app instance, or user.' AND compaction = {'min_threshold': '4', 'cold_reads_to_omit': '0.0', 'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE'; </pre> </div></div> <p>We will, on a daily basis pull a query of the complete data for a given index, it will look like this: </p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> select * from stories_by_text where ref_id = f0124740-2f5a-11e5-a113-03cdf3f3c6dc and second_type = 'Day' and second_value = '20150812' and object_type = 'booshaka:user' and field_name = 'hashedEmail'; </pre> </div></div> <p>In the past, we have been able to pull millions of records out of the CF in a few seconds. We recently added the data column so that we could filter on event data and provide more detailed analysis of activity for our reports. The data map, declared with 'data map&lt;text, text&gt;' is very small; only 2 or 3 name/value pairs.</p> <p>Since we have added this column, our streaming query performance has gone straight to hell. I just ran the above query and it took 46 minutes to read 86K rows and then it timed out.</p> <p>I am uncertain what other data you need to see in order to diagnose this. We are using STCS and are considering a change to Leveled Compaction. The table is repaired nightly and the updates, which are at a very fast clip will only impact the partition key for today, while the queries are for previous days only. </p> <p>To my knowledge these queries no longer finish ever. They time out, even though I put a 60 second timeout on the read for the cluster. I can watch it pause for 30 to 50 seconds many times during the stream. </p> <p>Again, this only started happening when we added the data column.</p> <p>Please let me know what else you need for this. It is having a very big impact on our system.</p>
</description>
<environment>
<p>Cassandra 2.1.8<br/> 12GB EC2 instance<br/> 12 node cluster<br/> 32 concurrent reads<br/> 32 concurrent writes<br/> 6GB heap space</p>
</environment>
<key id="12856318">CASSANDRA-10084</key>
<summary>
Very slow performance streaming a large query from a single CF
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="thebrenthaines">Brent Haines</reporter>
<labels>
<label>triaged</label>
</labels>
<created>Sat, 15 Aug 2015 00:44:59 +0000</created>
<updated>Wed, 2 Sep 2015 16:11:43 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14699194" author="benedict" created="Mon, 17 Aug 2015 08:39:31 +0000">
<p>I'm sorry to say this most likely isn't a "bug". Because of how collections are implemented, they introduce more work when comparing <em>every</em> cell, and this is a known limitation. In 3.0 this problem should be resolved, but until then you should expect performance to degrade when introducing collections to a table.</p> <p>It is possible we can mitigate this somewhat, but no guarantees, and I'm not sure we can spare much time to address it given the ramp up to 3.0 release.</p>
</comment>
<comment id="14699211" author="benedict" created="Mon, 17 Aug 2015 08:48:06 +0000">
<p>If you want to attach a profile of your instance while it's serving one of these requests, it may at least help rule out some unrelated inefficiency to the one I am discussing, and help direct any work we do have time for.</p>
</comment>
<comment id="14699680" author="thebrenthaines" created="Mon, 17 Aug 2015 15:25:42 +0000">
<p>FWIW, changing to LCS helped quite a lot. Before that, the query stream would halt periodically, sometimes long enough for the query to time out. Now things are quite a bit more reliable, but still slow. </p> <p>I don't have enough knowledge about how the collections are stored to understand why this degradation is so severe. In case it's interesting to you, I'll add the detail that the performance hit happens for all queries, with or without the data column in it (selecting all other columns but that one doesn't change anything), and older queries for records that predate the addition of the column are also slow. </p> <p>I wouldn't want to derail your current efforts on 3.0. It would be enough to just confirm that the map column is a likely candidate for a 10x slowdown for streaming queries. The map column is data we filter on post query. We could format a JSON string for a text column and drop the map column. Given the volume of data that we process, this would be a semi-permanent hack though; I doubt if we would ever convert it back to a collection given the cost of migration. Still, it isn't a horrible approach.</p> <p>I can add the profile later today too, in case I am running into something else. </p>
</comment>
<comment id="14699690" author="benedict" created="Mon, 17 Aug 2015 15:32:26 +0000">
<p>There is only one problem, which is that once you have a collection column, you cannot get rid of the change to behaviour by removing it. You would need to rollback the entire cluster state, including your schema tables. This could be extremely painful, I realise, and I'm sorry I don't have better news.</p> <p>The fact that LCS mitigates the problem is another data point in favour of this being the culprit, but if you can get me the profile it would give us much more information either way. I'll then see if I can find some way to mitigate this for you.</p>
</comment>
<comment id="14699716" author="thebrenthaines" created="Mon, 17 Aug 2015 15:49:25 +0000">
<p>Ah. I was afraid of that. We'd probably create a new table with the desired format, direct our processing to the new table and write a storm topology to migrate data over. A whole new column family should work, right? </p> <p>I'll try to capture the profile today. This is on a large cluster, but if I set the fetch size up high I should be able to keep the query on a single box long enough to capture data.</p> <p>Appreciate the help. If we can mitigate this to a reasonable point, would upgrading to 3.0 fix this? It would be favorable to keep things the way they are, muddle through it and then upgrade when the time comes (how soon is that?) and live happily ever after. <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14699733" author="benedict" created="Mon, 17 Aug 2015 16:00:47 +0000">
<blockquote><p>A whole new column family should work, right?</p></blockquote> <p>Yes, absolutely.</p> <blockquote><p>would upgrading to 3.0 fix this?</p></blockquote> <p>I would be very surprised if it didn't. I won't promise, as there are a lot of unknowns, but given my assumptions about the problem, and the changes to 3.0: yes.</p> <blockquote><p>how soon is that?</p></blockquote> <p>Not long, but I'd rather not give you our targets in case we slip <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14705971" author="thebrenthaines" created="Thu, 20 Aug 2015 23:27:10 +0000">
<p>I did a lot of tuning with prefetching, threads per client, and added multithreading to our query collator. Performance has improved a lot, but it doesn't come close to what we had before we added the collection to the table. </p> <p>Right now, I have discovered a query for a specific index value that is particularly slow, 3 minutes for 10,000 records (there are 650,000 records). </p> <p>When I discovered this index, it was halting after providing only a about 1% of the data and did not produce any kind of error or exception. I did a repair on one of the nodes for that partition key and it seems to be working, but is very slow now. I have attached stack dumps for every node involved in the query while the query was running, though I am not certain which one is doing work at any given time. </p> <p>Stupid question - is there a quick way to see what nodes own the key for a specific query? I turn trace on and run the query a bunch of times to get all three. </p> <p>Please see the attached profiles for the 3 nodes. </p> <p>Also FYI - We run an incremental repair nightly. They usually finish, but sometimes, in the morning, nodes report <b>much</b> more storage than they actually own. They all own about 60 to 90GB, but after repair some nodes will say they own 2+ TB! Restarting reveals that they are way behind on compaction and take about 2 hours to clear that up. If I try a nodetool compactionstats before restarting, it will hang until timeout. </p> <p>Final question, is upgrading to 2.2 a safe bet for some of these issues? Specifically the halting of compaction during repair? </p>
</comment>
<comment id="14705974" author="thebrenthaines" created="Thu, 20 Aug 2015 23:28:00 +0000">
<p>stack dumps for 3 nodes that are processing the slow streaming query.</p>
</comment>
</comments>
<attachments>
<attachment id="12750633" name="cassandra.yaml" size="35770" author="thebrenthaines" created="Sat, 15 Aug 2015 00:44:59 +0000"/>
<attachment id="12751616" name="node1.txt" size="155961" author="thebrenthaines" created="Thu, 20 Aug 2015 23:28:00 +0000"/>
<attachment id="12751617" name="node2.txt" size="172927" author="thebrenthaines" created="Thu, 20 Aug 2015 23:28:00 +0000"/>
<attachment id="12751618" name="node3.txt" size="168578" author="thebrenthaines" created="Thu, 20 Aug 2015 23:28:00 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>4.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 17 Aug 2015 08:39:31 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2iydz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10965] Shadowable tombstones can continue to shadow view results when timestamps match
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10965
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I've attached a script which reproduces the issue. The first time we insert with <tt>TIMESTAMP 2</tt>, we are inserting a new row which has the same timestamp as the previous shadow tombstone, and it continues to be shadowed by that tombstone because we shadow values with the same timestamp.</p>
</description>
<environment/>
<key id="12927067">CASSANDRA-10965</key>
<summary>
Shadowable tombstones can continue to shadow view results when timestamps match
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="carlyeks">Carl Yeksigian</assignee>
<reporter username="carlyeks">Carl Yeksigian</reporter>
<labels></labels>
<created>Mon, 4 Jan 2016 20:08:42 +0000</created>
<updated>Mon, 25 Jan 2016 22:26:33 +0000</updated>
<fixVersion>3.0.x</fixVersion>
<component>Local Write-Read Paths</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="15090159" author="firstprayer" created="Fri, 8 Jan 2016 23:16:15 +0000">
<p>I ran the script, and here is the output:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cqlsh:mykeyspace&gt; SELECT c, k, val FROM base; SELECT c, k, val FROM mv_reuse; c | k | val ---+---+----- 0 | 1 | 1 (1 rows) c | k | val ---+---+----- 0 | 1 | 1 (1 rows) cqlsh:mykeyspace&gt; UPDATE base USING TIMESTAMP 1 SET c = 1 WHERE k = 1; cqlsh:mykeyspace&gt; SELECT c, k, val FROM base; SELECT c, k, val FROM mv_reuse; c | k | val ---+---+----- 1 | 1 | 1 (1 rows) c | k | val ---+---+----- (0 rows) </pre> </div></div> <p>So the problem is: after the update using the same timestamp, the row is not shown when query from the materialized view?</p>
</comment>
<comment id="15092479" author="carlyeks" created="Mon, 11 Jan 2016 18:57:16 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=firstprayer" class="user-hover" rel="firstprayer">Taiyuan Zhang</a>: Yes, that's the issue here; while we get a value from the base, we have hidden it in the view because of the tombstones that we generated for the previous value.</p>
</comment>
<comment id="15093440" author="firstprayer" created="Tue, 12 Jan 2016 07:07:23 +0000">
<p>Got it. Are you currently working on this? If not, I'm interested in digging into this.</p>
</comment>
<comment id="15096502" author="carlyeks" created="Wed, 13 Jan 2016 16:40:49 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=firstprayer" class="user-hover" rel="firstprayer">Taiyuan Zhang</a>: I haven't started working on this, but it is a pretty high priority bug, so we'd like to get this in with the 3.3 bug fix release, which will happen in early February, so this will have to be fixed sometime in the next 2-3 weeks. Does that timeline make sense for you?</p>
</comment>
<comment id="15097388" author="firstprayer" created="Thu, 14 Jan 2016 01:04:04 +0000">
<p>I haven't started looking into this so I don't know how complicated the problem is, but the time seems to fit into my calendar. I'll look into this in recent 1 or 2 days to better understand the problem and give a better estimation.</p>
</comment>
<comment id="15116196" author="carlyeks" created="Mon, 25 Jan 2016 22:26:33 +0000">
<p>When we resolve 2 cells with conflicting timestamps for the base table, we use the value to determine which cell wins. However, the view has no information about this conflict or the resolution.</p> <p>Adding another field to the deletion would solve this; it would indicate whether the tombstone should shadow a value with the same time since a resolution in the same time resolved the values, or whether it should only apply to values which are before the tombstone, thus a tie with the tombstone would result in the value being used, not the tombstone.</p> <p>Pushed a <a href="https://github.com/carlyeks/cassandra/tree/ticket/10965/3.0" class="external-link" rel="nofollow">branch</a> which includes this change as a "replacement" flag.</p>
</comment>
</comments>
<attachments>
<attachment id="12780378" name="shadow-ts.cql" size="907" author="carlyeks" created="Mon, 4 Jan 2016 20:08:42 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 8 Jan 2016 23:16:15 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qrqf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>slebresne</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10968] When taking snapshot, manifest.json contains incorrect or no files when column family has secondary indexes
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10968
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Noticed indeterminate behaviour when taking snapshot on column families that has secondary indexes setup. The created manifest.json created when doing snapshot, sometimes contains no file names at all and sometimes some file names. <br/> I don't know if this post is related but that was the only thing I could find:<br/> <a href="http://www.mail-archive.com/user%40cassandra.apache.org/msg42019.html" class="external-link" rel="nofollow">http://www.mail-archive.com/user%40cassandra.apache.org/msg42019.html</a></p>
</description>
<environment/>
<key id="12927301">CASSANDRA-10968</key>
<summary>
When taking snapshot, manifest.json contains incorrect or no files when column family has secondary indexes
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="Fredderf">Fred A</reporter>
<labels>
<label>lhf</label>
</labels>
<created>Tue, 5 Jan 2016 15:36:20 +0000</created>
<updated>Fri, 8 Jan 2016 16:43:51 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qt6f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333872</customfieldvalue>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10952] NullPointerException in Gossiper.getHostId
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10952
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We added some nodes into our cluster, for some of them, when they finish bootstrap, they are not shown in the `nodetool status` of other nodes.</p> <p>I checked the logs and found this:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> 2015-12-29_05:06:23.89461 ERROR 05:06:23 Exception in thread <span class="code-object">Thread</span>[GossipStage:9,5,main] 2015-12-29_05:06:23.89463 java.lang.NullPointerException: <span class="code-keyword">null</span> 2015-12-29_05:06:23.89463 at org.apache.cassandra.gms.Gossiper.getHostId(Gossiper.java:811) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89464 at org.apache.cassandra.service.StorageService.handleStateNormal(StorageService.java:1664) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89464 at org.apache.cassandra.service.StorageService.onChange(StorageService.java:1485) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89464 at org.apache.cassandra.gms.Gossiper.doOnChangeNotifications(Gossiper.java:1156) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89465 at org.apache.cassandra.gms.Gossiper.applyNewStates(Gossiper.java:1138) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89465 at org.apache.cassandra.gms.Gossiper.applyStateLocally(Gossiper.java:1095) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89466 at org.apache.cassandra.gms.GossipDigestAckVerbHandler.doVerb(GossipDigestAckVerbHandler.java:58) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89466 at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:62) ~[apache-cassandra-2.1.8+git20151215.c8ed2ab16.jar:2.1.8+git20151215.c8ed2ab16] 2015-12-29_05:06:23.89469 at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_45] 2015-12-29_05:06:23.89469 at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_45] 2015-12-29_05:06:23.89469 at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:744) ~[na:1.7.0_45] </pre> </div></div> <p>This looks different than <a href="https://issues.apache.org/jira/browse/CASSANDRA-10089" title="NullPointerException in Gossip handleStateNormal" class="issue-link" data-issue-key="CASSANDRA-10089"><del>CASSANDRA-10089</del></a>, so I create a new jira.</p>
</description>
<environment/>
<key id="12924735">CASSANDRA-10952</key>
<summary>NullPointerException in Gossiper.getHostId</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="jkni">Joel Knighton</assignee>
<reporter username="dikanggu">Dikang Gu</reporter>
<labels></labels>
<created>Tue, 29 Dec 2015 20:06:16 +0000</created>
<updated>Fri, 8 Jan 2016 23:22:21 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15090148" author="jkni" created="Fri, 8 Jan 2016 23:10:01 +0000">
<p>You are correct - this looks to be a different issue than <a href="https://issues.apache.org/jira/browse/CASSANDRA-10089" title="NullPointerException in Gossip handleStateNormal" class="issue-link" data-issue-key="CASSANDRA-10089"><del>CASSANDRA-10089</del></a>. I'm not immediately able to find the problem.</p> <p>A few more pieces of information would be helpful:<br/> 1. Can you provide full logs from both a node that was already in the cluster and a missing bootstrapped node?<br/> 2. Is the bootstrapped node missing from all nodes in the cluster or just some?<br/> 3. What does nodetool status on a missing bootstrapped node report?</p> <p>Thanks.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 8 Jan 2016 23:10:01 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qdqv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10945] rebuild fail ,received file doesn't exist?
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10945
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>we rebuild dc1 from dc1.</p> <p>Rebuild file have received completely.<br/> Rebuild 41cf1460-aade-11e5-8a0c-e7d99dc4b078<br/> /172.16.0.100<br/> Receiving 16 files, 514112829261 bytes total. Already received 16 files, 514112829261 bytes total</p> <p> /172.16.0.101<br/> Receiving 12 files, 620055599407 bytes total. Already received 12 files, 620055599407 bytes total</p> <p>========================<br/> But rebuild log didn't show streamsession end.</p> <p>We found the following errors:</p> <p>ERROR <span class="error">&#91;StreamReceiveTask:4&#93;</span> 2015-12-27 10:56:13,133 CassandraDaemon.java:227 - Exception in thread Thread<span class="error">&#91;StreamReceiveTask:4,5,RMI Runtime&#93;</span><br/> java.lang.AssertionError: null<br/> at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:159) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.util.FileUtils.renameWithConfirm(FileUtils.java:154) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:558) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.rename(SSTableWriter.java:546) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.close(SSTableWriter.java:520) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.finish(SSTableWriter.java:453) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:445) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.io.sstable.SSTableWriter.closeAndOpenReader(SSTableWriter.java:440) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at org.apache.cassandra.streaming.StreamReceiveTask$OnCompletionRunnable.run(StreamReceiveTask.java:128) ~<span class="error">&#91;apache-cassandra-2.1.10.jar:2.1.10&#93;</span><br/> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~<span class="error">&#91;na:1.7.0_80&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~<span class="error">&#91;na:1.7.0_80&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~<span class="error">&#91;na:1.7.0_80&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) <span class="error">&#91;na:1.7.0_80&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.7.0_80&#93;</span></p> <p>It is seems that just received file doesn't existed.How is that happened?<br/> Some other thread change or remove that file?</p> <p>And streamsession doesn't end up normally even exception is also a problem I think.</p>
</description>
<environment>
<p>Cassandra 2.1.0<br/> java version "1.7.0_80"</p>
</environment>
<key id="12924471">CASSANDRA-10945</key>
<summary>rebuild fail ,received file doesn't exist?</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="wateray">wateray</reporter>
<labels></labels>
<created>Mon, 28 Dec 2015 08:38:54 +0000</created>
<updated>Fri, 8 Jan 2016 16:25:59 +0000</updated>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15089450" author="iamaleksey" created="Fri, 8 Jan 2016 16:25:51 +0000"><p>Are you running Windows by any chance?</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 8 Jan 2016 16:25:51 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2qc47:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10928] SSTableExportTest.testExportColumnsWithMetadata randomly fails
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10928
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The SSTableExportTest.testExportColumnsWithMetadata test will randomly fail (bogusly). Currently, the string check used won’t work if the JSON generated happened to order the elements in the array differently.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> assertEquals( <span class="code-quote">"unexpected serialization format <span class="code-keyword">for</span> topLevelDeletion"</span>, <span class="code-quote">"{\"</span>markedForDeleteAt\<span class="code-quote">":0,\"</span>localDeletionTime\<span class="code-quote">":0}"</span>, serializedDeletionInfo.toJSONString()); </pre> </div></div> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[junit] Testcase: testExportColumnsWithMetadata(org.apache.cassandra.tools.SSTableExportTest):	FAILED [junit] unexpected serialization format for topLevelDeletion expected:&lt;{"[markedForDeleteAt":0,"localDeletionTime]":0}&gt; but was:&lt;{"[localDeletionTime":0,"markedForDeleteAt]":0}&gt; [junit] junit.framework.AssertionFailedError: unexpected serialization format for topLevelDeletion expected:&lt;{"[markedForDeleteAt":0,"localDeletionTime]":0}&gt; but was:&lt;{"[localDeletionTime":0,"markedForDeleteAt]":0}&gt; [junit] at org.apache.cassandra.tools.SSTableExportTest.testExportColumnsWithMetadata(SSTableExportTest.java:299) [junit] </pre> </div></div>
</description>
<environment/>
<key id="12923888">CASSANDRA-10928</key>
<summary>
SSTableExportTest.testExportColumnsWithMetadata randomly fails
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="kohlisankalp">sankalp kohli</assignee>
<reporter username="mkjellman">Michael Kjellman</reporter>
<labels></labels>
<created>Wed, 23 Dec 2015 01:16:28 +0000</created>
<updated>Mon, 25 Jan 2016 22:05:57 +0000</updated>
<fixVersion>2.1.12</fixVersion>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="15069094" author="aweisberg" created="Wed, 23 Dec 2015 03:38:32 +0000">
<p>Maybe I botched setting the fix version. My bad.</p>
</comment>
<comment id="15081418" author="brandon.williams" created="Mon, 4 Jan 2016 17:32:37 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=philipthompson" class="user-hover" rel="philipthompson">Philip Thompson</a> is cassci seeing this?</p>
</comment>
<comment id="15081427" author="philipthompson" created="Mon, 4 Jan 2016 17:34:29 +0000"><p>Not anytime in the last 50 builds on 2.1.</p></comment>
<comment id="15092879" author="kohlisankalp" created="Mon, 11 Jan 2016 22:54:34 +0000"><p>This affects 2.1 only</p></comment>
<comment id="15095647" author="kohlisankalp" created="Wed, 13 Jan 2016 05:41:21 +0000">
<p>cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=brandon.williams" class="user-hover" rel="brandon.williams">Brandon Williams</a> Can you please review this?</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12786352">CASSANDRA-9065</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12781670" name="CASSANDRA_10928_2.1.diff" size="1322" author="kohlisankalp" created="Mon, 11 Jan 2016 22:54:05 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 23 Dec 2015 03:38:32 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2q8l3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333872</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>jasobrown</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12333872</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-10906] List index out of range</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10906
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Using COPY FROM command to import a .csv file with a header row and '|' delimited you get an error back "List index out of range"</p>
</description>
<environment><p>java version "1.8.0_66", 64-bit</p></environment>
<key id="12923139">CASSANDRA-10906</key>
<summary>List index out of range</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="scott.chaffee@gmail.com">Scott Chaffee</reporter>
<labels></labels>
<created>Fri, 18 Dec 2015 21:22:05 +0000</created>
<updated>Mon, 21 Dec 2015 16:27:21 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15066654" author="mambocab" created="Mon, 21 Dec 2015 16:26:21 +0000">
<p>Thank you for the report. Could you please include steps to reproduce? In particular, it'd be helpful to have the CREATE TABLE statement and the COPY FROM statement you use so we don't have to reverse-engineer them from your included CSV.</p>
</comment>
</comments>
<attachments>
<attachment id="12778592" name="Schedule.csv" size="1058" author="scott.chaffee@gmail.com" created="Fri, 18 Dec 2015 21:22:05 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 21 Dec 2015 16:26:21 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2q3yv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10874] running stress with compaction strategy and replication factor fails on read after write
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10874
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When running a read stress after write stress with a compaction strategy and replication factor matching the node count will fail with an exception. </p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> Operation x0 on key(s) [38343433384b34364c30]: Data returned was not validated </pre> </div></div> <p>Example run:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ccm create stress -v git:cassandra-3.0 -n 3 -s ccm node1 stress write n=10M -rate threads=300 -schema replication\(factor=3\) compaction\(strategy=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy\) ccm node1 nodetool flush ccm node1 nodetool compactionstats # check until quiet ccm node1 stress read n=10M -rate threads=300 </pre> </div></div> <ul class="alternate" type="square"> <li>This will fail with/out vnodes but will occasionally pass without vnodes.</li> <li>Changing the read phase to be CL=QUORUM will make it pass.</li> <li>Removing the replication factor on write will make it pass.</li> <li>Happens on all compaction strategies</li> </ul> <p>So with that in mind I attempted to add a repair after the write phase. This leads to 1 of 2 outcomes.</p> <p>1: a repair that has a greater than 100% completion, usually stalls after a bit, but have seen it get to &gt;400% progress:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> id compaction type keyspace table completed total unit progress 2d5344c0-9dc8-11e5-9d5f-4fdec8d76c27 Validation keyspace1 standard1 94722609949 44035292145 bytes 215.11% </pre> </div></div> <p>2: a repair that has a greatly inflated completed/total value, it will crunch for a bit then lockup:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> id compaction type keyspace table completed total unit progress 8c4cf7f0-a34a-11e5-a321-777be88c58ae Validation keyspace1 standard1 0 874811100900 bytes 0.00% ❯ du -sh ~/.ccm/stress/node1/ 2.4G ~/.ccm/stress/node1/ ❯ du -sh ~/.ccm/stress 7.1G ~/.ccm/stress </pre> </div></div> <p>This has been reproduced on cassandra-3.0 and cassandra-2.1 both locally and using cstar_perf (links below). <br/> A big twist is that cassandra-2.2 will pass the majority of the time. It will complete successfully without the repair 8 out of 10 runs. This can be seen in the cstar_perf links below.</p> <p>cstar_perf runs:<br/> <a href="http://cstar.datastax.com/tests/id/c8fa27a4-a205-11e5-8fbc-0256e416528f" class="external-link" rel="nofollow">http://cstar.datastax.com/tests/id/c8fa27a4-a205-11e5-8fbc-0256e416528f</a><br/> <a href="http://cstar.datastax.com/tests/id/a254c572-a2ce-11e5-a8b9-0256e416528f" class="external-link" rel="nofollow">http://cstar.datastax.com/tests/id/a254c572-a2ce-11e5-a8b9-0256e416528f</a></p>
</description>
<environment/>
<key id="12922133">CASSANDRA-10874</key>
<summary>
running stress with compaction strategy and replication factor fails on read after write
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="nutbunnies">Andrew Hust</reporter>
<labels></labels>
<created>Tue, 15 Dec 2015 20:46:22 +0000</created>
<updated>Thu, 17 Dec 2015 01:33:54 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15061292" author="pauloricardomg" created="Thu, 17 Dec 2015 01:33:54 +0000">
<p>afaik the default stress consistency is ONE for writes and reads, so since you're writing with 300 threads, it's expected that some mutations will be dropped due to overload and some ONE reads will fail, since dropped mutations were not yet hinted (only after 10 minutes). that's why the problem doesn't work without replication or with read CL = quorum.</p> <p>are repairs completing and do stress reads work after it? if so, I suspect those might only be reporting/presentation errors.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 17 Dec 2015 01:33:54 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pxrj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332167</customfieldvalue>
<customfieldvalue>12332360</customfieldvalue>
<customfieldvalue>12332541</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10868] Skip supercolumns upgrade tests on jdk8
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10868
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The tests in the <tt>upgrade_supercolumns_test</tt> dtest module fail when we test on JDK8 because they attempt to upgrade from 2.0, which will not compile on JDK8:</p> <p><a href="http://cassci.datastax.com/job/cassandra-2.1_dtest_jdk8/160/testReport/upgrade_supercolumns_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.1_dtest_jdk8/160/testReport/upgrade_supercolumns_test/</a></p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rhatch" class="user-hover" rel="rhatch">Russ Hatch</a> As we look at how we want to run upgrade tests in the future, we should consider this. In the meantime, I think the best way to deal with this might be to add something to the exclude files in <tt>conf/</tt>. That sound reasonable, or is there a better way to do this?</p>
</description>
<environment/>
<key id="12921808">CASSANDRA-10868</key>
<summary>Skip supercolumns upgrade tests on jdk8</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mambocab">Jim Witschey</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels></labels>
<created>Mon, 14 Dec 2015 22:49:16 +0000</created>
<updated>Wed, 20 Jan 2016 21:38:46 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15108932" author="philipthompson" created="Wed, 20 Jan 2016 17:05:38 +0000">
<p>If we don't compile the 2.0 version, and just use the binaries, those should run on jdk8 just fine.</p>
</comment>
<comment id="15108943" author="mambocab" created="Wed, 20 Jan 2016 17:09:29 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rhatch" class="user-hover" rel="rhatch">Russ Hatch</a> does Philip's proposal make sense? I just want to make sure we aren't missing something obvious.</p>
</comment>
<comment id="15109028" author="rhatch" created="Wed, 20 Jan 2016 17:49:45 +0000">
<p>I'm not certain what guarantees can be made about the binaries running on jdk8, but seems reasonable to me if that's not a problem. Alternatively I guess we could to jdk switching similar to how it's done in upgrade_through_versions_test.py if the first approach doesn't pan out. Not sure how implementing this will look, but we should take care to not let binaries be used as the upgraded-to (only uprgaded-from) version, unless we're specifically looking to vet those binaries.</p>
</comment>
<comment id="15109488" author="mambocab" created="Wed, 20 Jan 2016 21:38:46 +0000">
<p>This should be addressed by this dtest PR: <a href="https://github.com/riptano/cassandra-dtest/pull/756" class="external-link" rel="nofollow">https://github.com/riptano/cassandra-dtest/pull/756</a></p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 20 Jan 2016 17:05:38 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pvrj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10864] Dropped mutations high until cluster restart
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10864
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Originally raised and investigated in <a href="https://www.mail-archive.com/user@cassandra.apache.org/msg44586.html" class="external-link" rel="nofollow">https://www.mail-archive.com/user@cassandra.apache.org/msg44586.html</a></p> <p>Cause is still unclear, but a rolling restart has on two occasions since been performed to cope with dropped mutations and timed-out reads.</p> <p>Pattern is indicative of some kind of code quality issue possibly involving locking operations. Stack flame graphs do not show a clear difference between restarts.</p>
</description>
<environment/>
<key id="12921774">CASSANDRA-10864</key>
<summary>Dropped mutations high until cluster restart</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="autocracy">Jeff Ferland</reporter>
<labels></labels>
<created>Mon, 14 Dec 2015 21:28:22 +0000</created>
<updated>Mon, 21 Dec 2015 16:48:18 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15066688" author="mambocab" created="Mon, 21 Dec 2015 16:48:18 +0000">
<p>Here:</p> <p><a href="https://www.mail-archive.com/user%40cassandra.apache.org/msg44644.html" class="external-link" rel="nofollow">https://www.mail-archive.com/user%40cassandra.apache.org/msg44644.html</a></p> <p>you mentioned that you were going to look at commitlog behavior. Did you get any new information from that? And were you able to watch <tt>ttop</tt> at all, as described here:</p> <p><a href="https://www.mail-archive.com/user%40cassandra.apache.org/msg44589.html" class="external-link" rel="nofollow">https://www.mail-archive.com/user%40cassandra.apache.org/msg44589.html</a></p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> This seems to be related to, or at least effecting, repair. Could you have a look at the email thread and see if you can tell what the issue is?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 21 Dec 2015 16:48:18 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pvjz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333770</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-10825] OverloadedException is untested</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10825
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>If you grep test/src and cassandra-dtest you will find that the string OverloadedException doesn't appear anywhere.</p> <p>In <a href="https://issues.apache.org/jira/browse/CASSANDRA-10477" title="java.lang.AssertionError in StorageProxy.submitHint" class="issue-link" data-issue-key="CASSANDRA-10477"><del>CASSANDRA-10477</del></a> it was found that there were cases where Paxos should back-pressure and throw OverloadedException but didn't.</p> <p>If OverloadedException is used for functional purposes then we should test that it is thrown under expected conditions. If there are behaviors driven by catching or tracking OverloadedException we should test those as well.</p>
</description>
<environment/>
<key id="12919752">CASSANDRA-10825</key>
<summary>OverloadedException is untested</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="aweisberg">Ariel Weisberg</reporter>
<labels></labels>
<created>Mon, 7 Dec 2015 16:20:02 +0000</created>
<updated>Mon, 7 Dec 2015 16:20:44 +0000</updated>
<component>Local Write-Read Paths</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<issuelinks>
<issuelinktype id="12310060">
<name>Container</name>
<inwardlinks description="Is contained by">
<issuelink>
<issuekey id="12783402">CASSANDRA-9012</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pjlz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10826] frozen<> added to non-frozen UDF/UDA argument types in schema metadata
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10826
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The function "avg_state" is created with a non-frozen tuple argument <tt>state</tt> and return type. It should be non-frozen because it's modified by the code in the body of the UDF.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> CREATE KEYSPACE examples WITH replication = { 'class': 'SimpleStrategy', 'replication_factor': '3' }; CREATE FUNCTION examples.avg_state(state tuple&lt;<span class="code-object">int</span>, bigint&gt;, val <span class="code-object">int</span>) CALLED ON NULL INPUT RETURNS tuple&lt;<span class="code-object">int</span>, bigint&gt; LANGUAGE java AS '<span class="code-keyword">if</span> (val != <span class="code-keyword">null</span>) { state.setInt(0, state.getInt(0) + 1); state.setLong(1, state.getLong(1) + val.intValue()); } <span class="code-keyword">return</span> state;' </pre> </div></div> <p>However, the schema metadata has the both the <tt>state</tt> argument and the return type incorrectly defined as <tt>frozen&lt;&gt;</tt>:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cqlsh&gt; SELECT argument_types, return_type FROM system_schema.functions WHERE keyspace_name = 'examples' AND function_name = 'avg_state'; argument_types | return_type ---------------------------------------+---------------------------- ['frozen&lt;tuple&lt;<span class="code-object">int</span>, bigint&gt;&gt;', '<span class="code-object">int</span>'] | frozen&lt;tuple&lt;<span class="code-object">int</span>, bigint&gt;&gt; </pre> </div></div>
</description>
<environment/>
<key id="12919763">CASSANDRA-10826</key>
<summary>
frozen<> added to non-frozen UDF/UDA argument types in schema metadata
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="snazy">Robert Stupp</assignee>
<reporter username="mpenick">Michael Penick</reporter>
<labels>
<label>client-impacting</label>
</labels>
<created>Mon, 7 Dec 2015 16:50:29 +0000</created>
<updated>Tue, 5 Jan 2016 21:12:27 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15045236" author="mpenick" created="Mon, 7 Dec 2015 17:00:03 +0000">
<p>I might have misunderstood the meaning of <tt>frozen&lt;&gt;</tt>, as it doesn't mean <tt>const</tt> or <tt>final</tt>. I think it means that it's an atomic piece of data that updated altogether. Regardless, it's still confusing that it's added implicitly to argument and return types of the above UDF.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pjof:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333891</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10821] OOM Killer terminates Cassandra when Compactions use too much memory then won't restart
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10821
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We were writing to the DB from EC2 instances in us-east-1 at a rate of about 3000 per second, replication us-east:2 us-west:2, LeveledCompaction and DeflateCompressor.</p> <p>After about 48 hours some nodes had over 800 pending compactions and a few of them started getting killed for Linux OOM. Priam attempts to restart the nodes, but they fail because of corrupted saved_cahce files.</p> <p>Loading has finished, and the cluster is mostly idle, but 6 of the nodes were killed again last night by OOM.</p> <p>This is the log message where the node won't restart:</p> <p>ERROR <span class="error">&#91;main&#93;</span> 2015-12-05 13:59:13,754 CassandraDaemon.java:635 - Detected unreadable sstables /media/ephemeral0/cassandra/saved_caches/KeyCache-ca.db, please check NEWS.txt and ensure that you have upgraded through all required intermediate versions, running upgradesstables</p> <p>This is the dmesg where the node is terminated:</p> <p><span class="error">&#91;360803.234422&#93;</span> Out of memory: Kill process 10809 (java) score 949 or sacrifice child<br/> <span class="error">&#91;360803.237544&#93;</span> Killed process 10809 (java) total-vm:438484092kB, anon-rss:29228012kB, file-rss:107576kB</p> <p>This is what Compaction Stats look like currently:</p> <p>pending tasks: 1096<br/> id compaction type keyspace table completed total unit progress<br/> 93eb3200-9b58-11e5-b9f1-ffef1041ec45 Compaction overlordpreprod document 8670748796 839129219651 bytes 1.03%<br/> Compaction system hints 30 1921326518 bytes 0.00%<br/> Active compaction remaining time : 27h33m47s</p> <p>Only 6 of the 32 nodes have compactions pending, and all on the order of 1000.</p>
</description>
<environment>
<p>EC2 32 x i2.xlarge split between us-east-1a,c and us-west 2a,b</p> <p>Linux 4.1.10-17.31.amzn1.x86_64 #1 SMP Sat Oct 24 01:31:37 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux</p> <p>Java(TM) SE Runtime Environment (build 1.8.0_65-b17)<br/> Java HotSpot(TM) 64-Bit Server VM (build 25.65-b01, mixed mode)</p> <p>Cassandra version: 2.2.3</p>
</environment>
<key id="12919449">CASSANDRA-10821</key>
<summary>
OOM Killer terminates Cassandra when Compactions use too much memory then won't restart
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tbartold">Thom Bartold</reporter>
<labels></labels>
<created>Sat, 5 Dec 2015 14:44:15 +0000</created>
<updated>Thu, 17 Dec 2015 23:15:42 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="15044839" author="tbartold" created="Mon, 7 Dec 2015 12:19:41 +0000">
<p>After restarting again yesterday, one of 6 nodes has started compacting regularly and is down to a few hundred pending. The other 5 are still working on the same one.</p> <p>e.g. The node mentioned above appears to still be working on the same compaction, but with a different id.</p> <p>pending tasks: 1095<br/> id compaction type keyspace table completed total unit progress<br/> 70583ff0-9cba-11e5-8c41-ffef1041ec45 Compaction overlordpreprod document 323082945806 839129219651 bytes 38.50%<br/> Active compaction remaining time : n/a</p>
</comment>
<comment id="15063055" author="carlyeks" created="Thu, 17 Dec 2015 23:15:42 +0000">
<p>The restart issue you are having is caused by thinking that a cache is an SSTable.This is probably caused by <tt>saved_cache_directory</tt> being a subdirectory of one of the <tt>data_file_directories</tt>. I've created <a href="https://issues.apache.org/jira/browse/CASSANDRA-10902" title="Skip saved cache directory when checking SSTables at startup" class="issue-link" data-issue-key="CASSANDRA-10902"><del>CASSANDRA-10902</del></a> to track that issue.</p> <p>That doesn't explain the OOM, though.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 17 Dec 2015 23:15:42 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2phr3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12333745</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10812] CompactionInterruptedException related to secondary index build during rolling upgrade
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10812
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I'm not certain if this is a problem or not, but during upgrade tests we're observing the following exception:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>INFO [RMI TCP Connection(4)-127.0.0.1] 2015-12-02 09:07:11,067 Keyspace.java:600 - adding secondary index table cf.vals to operation DEBUG [CompactionExecutor:2] 2015-12-02 09:07:11,071 CompactionTask.java:146 - Compacting (be950fe0-990e-11e5-9474-ff4e6f1f6740) [/tmp/dtest-yLzF8G/test/node1/data/upgrade/cf-6a7d8130990e11e5ac03ff4e6f1f6740/upgrade-cf-ka-1-Data.db:level=0, ] INFO [CompactionExecutor:1] 2015-12-02 09:07:11,083 CompactionManager.java:1436 - Compaction interrupted: Secondary index build@6a7d8130-990e-11e5-ac03-ff4e6f1f6740(upgrade, cf, 221970/1166280)bytes ERROR [SecondaryIndexManagement:1] 2015-12-02 09:07:11,096 CassandraDaemon.java:195 - Exception in thread Thread[SecondaryIndexManagement:1,5,main] java.lang.RuntimeException: java.util.concurrent.ExecutionException: org.apache.cassandra.db.compaction.CompactionInterruptedException: Compaction interrupted: Secondary index build@6a7d8130-990e-11e5-ac03-ff4e6f1f6740(upgrade, cf, 221970/1 166280)bytes at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:368) ~[main/:na] at org.apache.cassandra.index.internal.CassandraIndex.buildBlocking(CassandraIndex.java:671) ~[main/:na] at org.apache.cassandra.index.internal.CassandraIndex.lambda$getBuildIndexTask$214(CassandraIndex.java:641) ~[main/:na] at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_66] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_66] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66] at java.lang.Thread.run(Thread.java:745) [na:1.8.0_66] Caused by: java.util.concurrent.ExecutionException: org.apache.cassandra.db.compaction.CompactionInterruptedException: Compaction interrupted: Secondary index build@6a7d8130-990e-11e5-ac03-ff4e6f1f6740(upgrade, cf, 221970/1166280)bytes at java.util.concurrent.FutureTask.report(FutureTask.java:122) ~[na:1.8.0_66] at java.util.concurrent.FutureTask.get(FutureTask.java:192) ~[na:1.8.0_66] at org.apache.cassandra.utils.FBUtilities.waitOnFuture(FBUtilities.java:364) ~[main/:na] ... 6 common frames omitted Caused by: org.apache.cassandra.db.compaction.CompactionInterruptedException: Compaction interrupted: Secondary index build@6a7d8130-990e-11e5-ac03-ff4e6f1f6740(upgrade, cf, 221970/1166280)bytes at org.apache.cassandra.index.SecondaryIndexBuilder.build(SecondaryIndexBuilder.java:67) ~[main/:na] at org.apache.cassandra.db.compaction.CompactionManager$11.run(CompactionManager.java:1269) ~[main/:na] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_66] ... 4 common frames omitted </pre> </div></div> <p>These tests are typically writing and reading data continuously and restarting nodes (so perhaps this is a routine exception under those circumstances?).</p>
</description>
<environment/>
<key id="12918078">CASSANDRA-10812</key>
<summary>
CompactionInterruptedException related to secondary index build during rolling upgrade
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rhatch">Russ Hatch</reporter>
<labels></labels>
<created>Thu, 3 Dec 2015 18:13:08 +0000</created>
<updated>Fri, 4 Dec 2015 16:38:03 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="15038233" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000">
<p>attaching logs from all nodes.</p> <p>node1_debug.log has the exception.</p>
</comment>
<comment id="15038240" author="rhatch" created="Thu, 3 Dec 2015 18:15:27 +0000">
<p>Logs are also showing the same exception as reported in <a href="https://issues.apache.org/jira/browse/CASSANDRA-10122" title="AssertionError after upgrade to 3.0" class="issue-link" data-issue-key="CASSANDRA-10122"><del>CASSANDRA-10122</del></a> so perhaps these are related.</p>
</comment>
</comments>
<attachments>
<attachment id="12775600" name="node1.log" size="122685" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000"/>
<attachment id="12775601" name="node1_debug.log" size="389523" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000"/>
<attachment id="12775602" name="node2.log" size="115108" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000"/>
<attachment id="12775603" name="node2_debug.log" size="226621" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000"/>
<attachment id="12775604" name="node3.log" size="59960" author="rhatch" created="Thu, 3 Dec 2015 18:14:36 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>5.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2p9an:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333891</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10801] Unexplained inconsistent data with Cassandra 2.1
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10801
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We are experiencing weird behavior which we cannot explain.</p> <p>We have a CF, with RF=3, and we are writing and reading data to it with consistency level of ONE.</p> <p>For some reason, we see inconsistent results when querying for data.<br/> Even for rows that were written a day ago, we're seeing inconsistent results (1 replca has the data, the two others don't).</p> <p>Now, I would expect to see timeouts/dropped mutations, but all relevant counters are not advancing, and I would also expect hints to fix this inconsistency within minutes, but yet it doesn't.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cqlsh:testing&gt; SELECT WRITETIME(last_update),site_id, tree_id, individual_id, last_update FROM testcf WHERE site_id = 229673621 AND tree_id = 9 AND individual_id = 9032483; writetime(last_update) | site_id | tree_id | individual_id | last_update ------------------------+-----------+---------+---------------+------------- 1448988343028000 | 229673621 | 9 | 9032483 | 1380912397 (1 rows) cqlsh:testing&gt; SELECT WRITETIME(last_update),site_id, tree_id, individual_id, last_update FROM testcf WHERE site_id = 229673621 AND tree_id = 9 AND individual_id = 9032483; site_id | tree_id | individual_id | last_update -----------+---------+---------------+------------- (0 rows) cqlsh:testing&gt; SELECT dateof(now()) FROM system.local ; dateof(now()) -------------------------- 2015-12-02 14:48:44+0000 (1 rows) </pre> </div></div> <p>We are running with Cassandra 2.1.11 with Oracle Java 1.8.0_65-b17</p>
</description>
<environment/>
<key id="12917596">CASSANDRA-10801</key>
<summary>Unexplained inconsistent data with Cassandra 2.1</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="imriz">Imri Zvik</reporter>
<labels></labels>
<created>Wed, 2 Dec 2015 14:51:39 +0000</created>
<updated>Wed, 23 Dec 2015 08:53:04 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>5</votes>
<watches>11</watches>
<comments>
<comment id="15037942" author="philipthompson" created="Thu, 3 Dec 2015 15:34:41 +0000">
<p>Your consistency appears to match the CL you are querying with. I don't see the issue here.</p>
</comment>
<comment id="15037983" author="imriz" created="Thu, 3 Dec 2015 15:58:06 +0000">
<p>Please correct me if I am wrong, but to my understanding, even if I am writing with ONE, and my RF is 3, and at the time of the write 2 out of 3 replicas did not get the write, hints should be written and replayed within 10 minutes.<br/> So, assuming this row was written hours before the SELECT, all 3 replicas should already be up to date.</p>
</comment>
<comment id="15037995" author="philipthompson" created="Thu, 3 Dec 2015 16:04:05 +0000">
<p>Hints are only written if the coordinator believes the other nodes are down. It is entirely possible for the second and third writes not to be written, but no hints to be stored. If you need higher consistency, use something like CL QUORUM. Only repair guarantees all nodes are consistent.</p>
</comment>
<comment id="15038001" author="imriz" created="Thu, 3 Dec 2015 16:06:12 +0000">
<p>This is not what the docs at <a href="http://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_about_hh_c.html" class="external-link" rel="nofollow">http://docs.datastax.com/en/cassandra/2.1/cassandra/dml/dml_about_hh_c.html</a> says.</p> <blockquote> <p>During a write operation, when hinted handoff is enabled and consistency can be met, the coordinator stores a hint about dead replicas in the local system.hints table under either of these conditions:<br/> A replica node for the row is known to be down ahead of time.<br/> A replica node does not respond to the write request.</p></blockquote> <p>According to that, it will also write a hint upon a timeout.</p>
</comment>
<comment id="15038004" author="philipthompson" created="Thu, 3 Dec 2015 16:10:56 +0000">
<p>I'll re-open this then, to let someone else examine the behavior you're describing, to confirm if your inconsistency is a bug with hints.</p> <p>EDIT: I've looked into this, and I was wrong. Hints are written on timeouts as well as down nodes. Though I've been told this issue may still not be the fault of hints.</p>
</comment>
<comment id="15061757" author="maor.cohen" created="Thu, 17 Dec 2015 09:08:16 +0000">
<p>Tracing result of 3 query executions. First and last queries returned one row as expected (seems to be found by key cache). Second returned nothing.</p> <p>See tracing.log</p>
</comment>
<comment id="15061762" author="maor.cohen" created="Thu, 17 Dec 2015 09:13:07 +0000">
<p>Updated trace log. Last query shows read repair. From that point, row should always return.<br/> It's also worth mentioning that we read in QUORUM consistency.</p>
</comment>
<comment id="15062199" author="pauloricardomg" created="Thu, 17 Dec 2015 15:36:31 +0000">
<p>A funny thing is that on case 2 coordinator (10.84.30.222) sends a read message to 10.84.30.236 on instant 24.718, and that message is received on instant 24.716, so a few ms before the message was sent.</p> <p>How is data being written to the cluster? Individually or in batches? Are there multiple updates to the same key? Are there any data deletions? Are nodes clocks synchronized? What's the delay between data write and read? What is the gc_grace_seconds of the testcf table? Are there any ERROR or WARN in the logs?</p> <p>No specific suspicion, just general questions to see if we can infer something. Some more specific reproduction steps would be nice too.</p>
</comment>
<comment id="15062242" author="maor.cohen" created="Thu, 17 Dec 2015 16:05:38 +0000">
<p>Thanks Paulo.</p> <p>I'll try to answer you questions:</p> <ul> <li>We tried writing in batches and using individual updates. Problem appeared in both methods.</li> <li>We don't update existing rows (using "update" query), instead we run another "insert" query that overwrites the row.</li> <li>We have very few deletions. Less than 1% of queries.</li> <li>Reading in production env is done using range query, although as you can see in the example it happens also with simple queries.</li> <li>In the attached example the data was written 4 days before the read (write consistency level was "ALL" in the write time).</li> <li>gc_grace_seconds = 864000</li> <li>No special errors or warnings in the log file. There are some dropped mutations but that's all.</li> <li>Clock is synchronized on all servers</li> </ul> <p>I wish I had a way to reproduce this. This seems to be quite random. I hope the information I added can give you a lead.</p> <p>Let me know if there is more information I can add.</p>
</comment>
<comment id="15066261" author="maor.cohen" created="Mon, 21 Dec 2015 09:59:02 +0000">
<p>One more important fact that might help to understand the problem:<br/> We dropped and recreated that table with the same name and also truncated it several times. The dropped table contained data - meaning it wasn't empty when we recreated or truncated it.</p> <p>I understand that there were bugs in earlier versions related to dropping and recreating a table with the same name but they should be solved in this version.</p>
</comment>
<comment id="15066371" author="maor.cohen" created="Mon, 21 Dec 2015 11:57:15 +0000">
<p>Another example (trace2.log):</p> <p>Rows that was loaded on Dec 17 (4 days before the read attempt). Executed CQL with consistency level ONE:</p> <p>1. First query returned no rows. Logs shows that it doesn't send read request to other nodes.<br/> 2. Second query also didn't return rows. Read request sent to other nodes. Inconsistency found by read repair.<br/> 3. Last query returned the row.</p> <p>I don't understand why the first query didn't send request to other nodes while the last one did. Can someone explain this?</p>
</comment>
<comment id="15066391" author="pauloricardomg" created="Mon, 21 Dec 2015 12:22:31 +0000">
<blockquote><p>I don't understand why the first query didn't send request to other nodes while the last one did.</p></blockquote> <p>Reads are only sent to the amount of nodes necessary to satisfy consistency, so if you read at <tt>ONE</tt> the query is only sent to 1 node. If read repair is triggered, the query is sent to more nodes.</p> <p>Are you sure your writes were at <tt>ALL</tt> consistency? The first report by some other person says the write was at <tt>ONE</tt>. Because if you had dropped mutations then some of your <tt>ALL</tt> writes have failed, and those might be causing inconsistencies. </p> <p>Unfortunately it's not possible to identify what may be causing this with the info you provided so you should try to provide more specific reproduction steps. As a workaround, you may try to recreate the table with a different name and see if the problem persists.</p>
</comment>
<comment id="15066461" author="maor.cohen" created="Mon, 21 Dec 2015 13:52:11 +0000">
<p>We started with write ONE and read ONE.<br/> Then we changed write ONE and read ALL, write ALL and read ONE but records were still missing.<br/> Currently the setting is read and write in QUORUM consistency.</p> <p>Reloading to table with different name is an option but we want to try other things before going in this direction.</p>
</comment>
<comment id="15069397" author="maor.cohen" created="Wed, 23 Dec 2015 08:53:04 +0000">
<p>We upgraded the Cassandra nodes from 2.1.11 to 2.1.12 and the java driver from 2.1.5 to 2.1.9 two days ago. Since then the total inconsistencies (missing rows that are actually exist) is dropping. Take a look at the screenshot "missing_rows".</p> <p>We are still monitoring but things are looking good. I would be happy to get a clue about what made this improvement.</p>
</comment>
</comments>
<attachments>
<attachment id="12779219" name="missing_rows.png" size="50668" author="maor.cohen" created="Wed, 23 Dec 2015 08:53:04 +0000"/>
<attachment id="12778816" name="trace2.log" size="33066" author="maor.cohen" created="Mon, 21 Dec 2015 11:57:15 +0000"/>
<attachment id="12778222" name="tracing.log" size="41802" author="maor.cohen" created="Thu, 17 Dec 2015 09:13:07 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 3 Dec 2015 15:34:41 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2p6br:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333770</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10787] OutOfMemoryError after few hours from node restart
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10787
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Cassandra Cluster was operating flawessly for around 3 months. Lately I've got a critical problem with it - after few hours of running clients are disconnected permanently (that may be Datastax C# Driver problem, though), however few more hours later (with smaller load), on all 2 nodes there is thrown an exception (details in files):</p> <blockquote><p>java.lang.OutOfMemoryError: Java heap space</p></blockquote> <p>Cases description:</p> <p> Case 2 (heavy load):</p> <ul class="alternate" type="square"> <li>2015-11-26 16:09:40,834 Restarted all nodes in cassandra cluster</li> <li>2015-11-26 17:03:46,774 First client disconnected permanently</li> <li>2015-11-26 22:17:02,327 Node shutdown</li> </ul> <p>	Case 3 (unknown load, different node):</p> <ul class="alternate" type="square"> <li>2015-11-26 02:19:49,585 Node shutdown (visible only in systemlog, I don't know why not in debug log)</li> </ul> <p>	Case 4 (low load):</p> <ul class="alternate" type="square"> <li>2015-11-27 13:00:24,994 Node restart</li> <li>2015-11-27 22:26:56,131 Node shutdown</li> </ul> <p>Is that a software issue or I am using too weak Amazon instances? If so, how can the required amount of memory be calculated?</p>
</description>
<environment>
<p>Amazon DataStax Auto-Clustering AMI 2.6.3-1404-pv<br/> on 2x m1.large instances (2 vCPU, 64-bit, 7.5GB RAM, Raid0 2x420GB Disk)<br/> <span class="error">&#91;cqlsh 5.0.1 | Cassandra 2.2.3 | CQL spec 3.3.1 | Native protocol v4&#93;</span><br/> RF=3</p>
</environment>
<key id="12916940">CASSANDRA-10787</key>
<summary>OutOfMemoryError after few hours from node restart</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="piotrwest">Piotr Westfalewicz</reporter>
<labels></labels>
<created>Mon, 30 Nov 2015 12:00:17 +0000</created>
<updated>Thu, 17 Dec 2015 09:40:06 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15032219" author="mshuler" created="Mon, 30 Nov 2015 18:30:41 +0000">
<p>m1.large instances are pretty small for Cassandra. In general, I would guess that when starting out, your cluster was not as busy as it is now, and you are seeing some limitations of the server size at this point.</p> <p>I only looked very quickly at a couple of you logs and I spotted a few pending mutations and a good number of pending compactions being repeated in the metrics logging. I don't think (please, correct me if I'm wrong) that m1.large offers any SSD drives, so compactions piling up, along with slow I/O to get those operations completed, is going to result in over taxing a limited instance like the m1.large.</p>
</comment>
<comment id="15032587" author="piotrwest" created="Mon, 30 Nov 2015 22:11:25 +0000">
<p>Thank you <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mshuler" class="user-hover" rel="mshuler">Michael Shuler</a> . Yes, on one node there was max. ~30 compactions, on the other node there is only one massive compaction. Do you know how to estimate if the cluster is coping fine with the load before it crashes? Getting exceptions at client side and seeing OutOfMemoryError is far too late.</p> <p>My choice was based on <a href="http://www.datastax.com/dev/blog/ec2-series-doc" class="external-link" rel="nofollow">http://www.datastax.com/dev/blog/ec2-series-doc</a> (though "low-end production usage" is vague definition).</p>
</comment>
<comment id="15034465" author="philipthompson" created="Tue, 1 Dec 2015 19:50:12 +0000">
<p>As noted by Michael, this may be underprovisioning and not a memory leak, but thank you for attaching the logs so we can triage.</p>
</comment>
<comment id="15061795" author="piotrwest" created="Thu, 17 Dec 2015 09:38:45 +0000">
<p>Hey guys,</p> <p>Here is the continuation of the story:<br/> 0. Taking your advice, I've decided to create more powerful cluster<br/> 1. I've created a new cluster, on 2x m1.xlarge instances (4 vCPU, 64-bit, 15GB RAM, Raid0 4x420GB HDD Disk), and changed RF to 2<br/> 2. Took the snapshot of the data (keyspace.table=logs.group) on one of the old nodes<br/> 3. scp between old node and the new node. From snapshot to the cassandra/data/kayspace/tablename folder<br/> 4. Loaded the data without restarting the server - by nodetool refresh<br/> 5. Triggered nodetool repair</p> <p>After few hours - the server went down. I've attached the logs. This is the case 5 files. Maybe that's because of the size of sstables? In my case one of them was around 50GB.</p> <p>I've also migrated the rest of the data (not "big" logs.group, but another tables from 500M to 5GB) the same way and the server was working fine and the data was accessible.</p>
</comment>
</comments>
<attachments>
<attachment id="12774810" name="case2_debuglog_head.txt" size="708145" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774811" name="case2_debuglog_tail.txt" size="567833" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774812" name="case2_systemlog.txt" size="18323933" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774806" name="case3_debuglog_tail.txt" size="3378221" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774807" name="case3_systemlog_tail.txt" size="2123609" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774808" name="case4_debuglog_tail.txt" size="21784" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12774809" name="case4_systemlog.txt" size="14075418" author="piotrwest" created="Mon, 30 Nov 2015 12:00:17 +0000"/>
<attachment id="12778226" name="case5_debuglog.txt" size="6634013" author="piotrwest" created="Thu, 17 Dec 2015 09:38:45 +0000"/>
<attachment id="12778227" name="case5_systemlog.txt" size="11224468" author="piotrwest" created="Thu, 17 Dec 2015 09:38:45 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>9.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 30 Nov 2015 18:30:41 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2p29z:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333745</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10770] Warning TIOStreamTransport.java:112 - Error closing output stream.
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10770
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Hi, In our cluster cassandra of 6 nodes we are having many times the next warning</p> <p>WARN <span class="error">&#91;Thrift:2477&#93;</span> 2015-11-25 10:06:33,795 TIOStreamTransport.java:112 - Error closing output stream.<br/> java.net.SocketException: Socket closed<br/> at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:116) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.net.SocketOutputStream.write(SocketOutputStream.java:153) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.io.BufferedOutputStream.flushBuffer(BufferedOutputStream.java:82) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.io.BufferedOutputStream.flush(BufferedOutputStream.java:140) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.io.FilterOutputStream.close(FilterOutputStream.java:158) ~<span class="error">&#91;na:1.8.0_60&#93;</span><br/> at org.apache.thrift.transport.TIOStreamTransport.close(TIOStreamTransport.java:110) ~<span class="error">&#91;libthrift-0.9.2.jar:0.9.2&#93;</span><br/> at org.apache.cassandra.thrift.TCustomSocket.close(TCustomSocket.java:197) <span class="error">&#91;apache-cassandra-2.1.11.jar:2.1.11&#93;</span><br/> at org.apache.thrift.transport.TFramedTransport.close(TFramedTransport.java:89) <span class="error">&#91;libthrift-0.9.2.jar:0.9.2&#93;</span><br/> at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run(CustomTThreadPoolServer.java:231) <span class="error">&#91;apache-cassandra-2.1.11.jar:2.1.11&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_60&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_60&#93;</span></p> <p>We are not able to know why cassandra is closing a socket that was close before. This is hapening mostly when cassandra is having high load of writes.</p> <p>Is it that a bug?</p>
</description>
<environment><p>Cassandra 2.1.11, ubuntu 12.04</p></environment>
<key id="12916103">CASSANDRA-10770</key>
<summary>
Warning TIOStreamTransport.java:112 - Error closing output stream.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="carlo_4002">jean carlo rivera ura</reporter>
<labels>
<label>stress-mode</label>
<label>thrift</label>
</labels>
<created>Wed, 25 Nov 2015 10:04:00 +0000</created>
<updated>Tue, 5 Jan 2016 21:00:16 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15043263" author="carlo_4002" created="Sat, 5 Dec 2015 11:52:55 +0000">
<p>We realized that this WARN happens when we are making some bench using cassandra stress.</p> <p>And we got also several hint handoff</p>
</comment>
<comment id="15083772" author="snazy" created="Tue, 5 Jan 2016 21:00:01 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=carlo_4002" class="user-hover" rel="carlo_4002">jean carlo rivera ura</a> it seems you're just overloading the cluster and your clients disconnect and C* is then unable to send the response back (thus the "Socket closed" in a "socketWrite" method). Hinted handoffs can occur too, if you put too much load on your cluster. I don't think this is a bug.</p>
</comment>
</comments>
<attachments>
<attachment id="12774308" name="warning-thrift.txt" size="1399" author="carlo_4002" created="Wed, 25 Nov 2015 10:04:00 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 5 Jan 2016 21:00:01 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ox47:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>ahmed.eljami</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10769] "received out of order wrt DecoratedKey" after scrub
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10769
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>After running scrub and cleanup on all nodes in single data center I'm getting:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [ValidationExecutor:103] 2015-11-25 06:28:21,530 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]], /10.210.3.221 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:103] 2015-11-25 06:28:21,531 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:103,1,main] java.lang.AssertionError: row DecoratedKey(-5867787467868737053, 00093237363331303631320000040000808800) received out of order wrt DecoratedKey(-5865937851627253360, 00093331323031373733320000040000c3c700) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1010) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:622) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div> <p>What I did is to run repair on other node:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> time nodetool repair --in-local-dc </pre> </div></div> <p>Corresponding log on the node where repair has been started:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [AntiEntropySessions:414] 2015-11-25 06:28:21,533 RepairSession.java:303 - [repair #89fa2b70-933d-11e5-b036-75bb514ae072] session completed with the following error org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] INFO [AntiEntropySessions:415] 2015-11-25 06:28:21,533 RepairSession.java:260 - [repair #b9458fa0-933d-11e5-b036-75bb514ae072] <span class="code-keyword">new</span> session: will sync /10.210.3.221, /10.210.3.118, /10.210.3.117 on range (7119703141488009983,7129744584776466802] <span class="code-keyword">for</span> sync.[device_token, entity2, user_stats, user_device, user_quota, user_store, user_device_progress, entity_by_id2] ERROR [AntiEntropySessions:414] 2015-11-25 06:28:21,533 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[AntiEntropySessions:414,5,RMI <span class="code-object">Runtime</span>] java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div>
</description>
<environment><p>C* 2.1.11, Debian Wheezy</p></environment>
<key id="12916089">CASSANDRA-10769</key>
<summary>
"received out of order wrt DecoratedKey" after scrub
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mlowicki">mlowicki</reporter>
<labels></labels>
<created>Wed, 25 Nov 2015 09:12:40 +0000</created>
<updated>Wed, 10 Feb 2016 15:18:29 +0000</updated>
<due/>
<votes>1</votes>
<watches>3</watches>
<comments>
<comment id="15026472" author="mlowicki" created="Wed, 25 Nov 2015 09:17:56 +0000">
<p>Found this error on other node as well:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [ValidationExecutor:78] 2015-11-24 22:35:52,652 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #93837260-92fb-11e5-b036-75bb514ae072 on sync/entity2, (-6012485790753833422,-6009995015166063234]], /10.210.3.221 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:78] 2015-11-24 22:35:52,652 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:78,1,main] java.lang.AssertionError: row DecoratedKey(-6012437544863914154, 00093237363237353730320000040000c3c700) received out of order wrt DecoratedKey(-6009997709246787268, 00093237353833303430320000040000c3c700) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1010) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:622) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div>
</comment>
<comment id="15026585" author="mark curtis" created="Wed, 25 Nov 2015 10:37:37 +0000">
<p>I've been searching for this error too and I noticed that this pops up in <a href="https://issues.apache.org/jira/browse/CASSANDRA-9133" title="Getting validationexception while repairing nodes" class="issue-link" data-issue-key="CASSANDRA-9133"><del>CASSANDRA-9133</del></a> which is marked as a duplicate of <a href="https://issues.apache.org/jira/browse/CASSANDRA-9126" title="java.lang.RuntimeException: Last written key DecoratedKey &gt;= current key DecoratedKey" class="issue-link" data-issue-key="CASSANDRA-9126"><del>CASSANDRA-9126</del></a>. However the fix is marked as 2.1.x so not 100% sure it would be the same issue, but thought it might be worth mentioning</p>
</comment>
<comment id="15026601" author="mlowicki" created="Wed, 25 Nov 2015 10:50:10 +0000">
<p>Yeah, found <a href="https://issues.apache.org/jira/browse/CASSANDRA-9126" title="java.lang.RuntimeException: Last written key DecoratedKey &gt;= current key DecoratedKey" class="issue-link" data-issue-key="CASSANDRA-9126"><del>CASSANDRA-9126</del></a> as well but decided to file a separate ticket as scrub didn't helped in my case.</p>
</comment>
<comment id="15026651" author="mark curtis" created="Wed, 25 Nov 2015 11:35:49 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlowicki" class="user-hover" rel="mlowicki">mlowicki</a> Can I ask what errors your were hitting that preceded the need to run scrub?</p>
</comment>
<comment id="15026657" author="mlowicki" created="Wed, 25 Nov 2015 11:38:30 +0000">
<p>I'm struggling with <a href="https://issues.apache.org/jira/browse/CASSANDRA-9935" title="Repair fails with RuntimeException" class="issue-link" data-issue-key="CASSANDRA-9935">CASSANDRA-9935</a>.</p>
</comment>
<comment id="15028727" author="mlowicki" created="Thu, 26 Nov 2015 13:13:29 +0000">
<p>Another error from today (10.210.3.221 is node where I've started repair - still in progress):</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [ValidationExecutor:588] 2015-11-26 12:48:02,877 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]], /10.210.3.221 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:588] 2015-11-26 12:48:02,878 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:588,1,main] java.lang.AssertionError: row DecoratedKey(-2928866306571865615, 00093238373434343231320000040000b33100) received out of order wrt DecoratedKey(-2921918599167375595, 00093331343939363437320000040000c3c700) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1010) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:622) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] ERROR [AntiEntropySessions:1061] 2015-11-26 12:48:02,880 RepairSession.java:303 - [repair #72d57040-943b-11e5-b036-75bb514ae072] session completed with the following error org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] INFO [AntiEntropySessions:1062] 2015-11-26 12:48:02,880 RepairSession.java:260 - [repair #ee6d25e0-943b-11e5-b036-75bb514ae072] <span class="code-keyword">new</span> session: will sync /10.210.3.221, /10.210.3.224, /10.210.3.117 on range (-4713086263421125450,-4709745913912183602] <span class="code-keyword">for</span> sync.[device_token, entity2, user_stats, user_device, user_quota, user_store, user_device_progress, entity_by_id2] ERROR [AntiEntropySessions:1061] 2015-11-26 12:48:02,881 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[AntiEntropySessions:1061,5,RMI <span class="code-object">Runtime</span>] java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div>
</comment>
<comment id="15140965" author="jfgosselin" created="Wed, 10 Feb 2016 15:18:29 +0000">
<p>We are also seeing this issue in our multi datacenters cluster (3 DCs), C* 2.1.9 (and using LCS). We ran nodetool scrub on all the nodes but the error keeps coming back .</p> <p>How can we get into this state ?</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ERROR [ValidationExecutor:5884] 2016-02-03 09:27:41,703 Validator.java:245 - Failed creating a merkle tree for [repair #a8f3f040-ca58-11e5-9dda-130298de45de on keyspace1/xyz, (5126461213031423923,5128334161692376535]], /10.174.216.163 (see log for details) ERROR [ValidationExecutor:5884] 2016-02-03 09:27:41,704 CassandraDaemon.java:223 - Exception in thread Thread[ValidationExecutor:5884,1,main] java.lang.AssertionError: row DecoratedKey(5126475305931285312, 00103cee13c2c0ea38328138fcad86515eef0000250233636565313363322d633065612d333833322d383133382d6663616438363531356565660000105cc950f02b6239f0bf9af60ac7dd452400) received out of order wrt DecoratedKey(5128167525973821686, 00105fe2e7db8810387a9a2955a07ecfa7d30000250235666532653764622d383831302d333837612d396132392d353561303765636661376433000010f64b1c2b7d1c3ff893b70c24c5dbdc6b00) at org.apache.cassandra.repair.Validator.add(Validator.java:126) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1003) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:615) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] </pre> </div></div>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 25 Nov 2015 10:37:37 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ox13:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333770</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10759] nodetool upgradesstables does not always complete synchronously
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10759
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The "nodetool upgradesstables" command does not always complete synchronously. We notice that the command exits with an exit code 0, however, there are still files left behind on an older version that disappear later. </p>
</description>
<environment><p>Discovered on Apache Cassandra 2.1.8.689</p></environment>
<key id="12915460">CASSANDRA-10759</key>
<summary>
nodetool upgradesstables does not always complete synchronously
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jmonserrate">Jamie</reporter>
<labels></labels>
<created>Mon, 23 Nov 2015 18:01:48 +0000</created>
<updated>Wed, 25 Nov 2015 16:18:09 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15027022" author="joshuamckenzie" created="Wed, 25 Nov 2015 16:18:09 +0000">
<p>What's the environment (OS) you're running into this on?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 25 Nov 2015 16:18:09 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ot5b:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10756] Timeout failures in NativeTransportService.testConcurrentDestroys unit test
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10756
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>History of test on trunk <a href="http://cassci.datastax.com/job/trunk_testall/lastCompletedBuild/testReport/org.apache.cassandra.service/NativeTransportServiceTest/testConcurrentDestroys/history/" class="external-link" rel="nofollow">here</a>.</p> <p>I've seen these failures across 3.0/trunk for a while. I ran the test looping locally for a while and the timeout is fairly easy to reproduce. The timeout appears to be an indefinite hang and not a timing issue.</p> <p>When the timeout occurs, the following stack trace is at the end of the logs for the unit test.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [ForkJoinPool.commonPool-worker-1] 2015-11-22 21:30:53,635 Failed to submit a listener notification task. Event loop shut down? java.util.concurrent.RejectedExecutionException: event executor terminated at io.netty.util.concurrent.SingleThreadEventExecutor.reject(SingleThreadEventExecutor.java:745) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.SingleThreadEventExecutor.addTask(SingleThreadEventExecutor.java:322) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.SingleThreadEventExecutor.execute(SingleThreadEventExecutor.java:728) ~[netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.DefaultPromise.execute(DefaultPromise.java:671) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.DefaultPromise.notifyLateListener(DefaultPromise.java:641) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.util.concurrent.DefaultPromise.addListener(DefaultPromise.java:138) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:93) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.DefaultChannelPromise.addListener(DefaultChannelPromise.java:28) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.group.DefaultChannelGroupFuture.&lt;init&gt;(DefaultChannelGroupFuture.java:116) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.group.DefaultChannelGroup.close(DefaultChannelGroup.java:275) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.group.DefaultChannelGroup.close(DefaultChannelGroup.java:167) [netty-all-4.0.23.Final.jar:4.0.23.Final] at org.apache.cassandra.transport.Server$ConnectionTracker.closeAll(Server.java:277) [main/:na] at org.apache.cassandra.transport.Server.close(Server.java:180) [main/:na] at org.apache.cassandra.transport.Server.stop(Server.java:116) [main/:na] at java.util.Collections$SingletonSet.forEach(Collections.java:4767) ~[na:1.8.0_60] at org.apache.cassandra.service.NativeTransportService.stop(NativeTransportService.java:136) ~[main/:na] at org.apache.cassandra.service.NativeTransportService.destroy(NativeTransportService.java:144) ~[main/:na] at org.apache.cassandra.service.NativeTransportServiceTest.lambda$withService$102(NativeTransportServiceTest.java:201) ~[classes/:na] at java.util.stream.IntPipeline$3$1.accept(IntPipeline.java:233) ~[na:1.8.0_60] at java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:110) ~[na:1.8.0_60] at java.util.Spliterator$OfInt.forEachRemaining(Spliterator.java:693) ~[na:1.8.0_60] at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ~[na:1.8.0_60] at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ~[na:1.8.0_60] at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:747) ~[na:1.8.0_60] at java.util.stream.ReduceOps$ReduceTask.doLeaf(ReduceOps.java:721) ~[na:1.8.0_60] at java.util.stream.AbstractTask.compute(AbstractTask.java:316) ~[na:1.8.0_60] at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731) ~[na:1.8.0_60] at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289) ~[na:1.8.0_60] at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056) ~[na:1.8.0_60] at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692) ~[na:1.8.0_60] at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157) ~[na:1.8.0_60] </pre> </div></div>
</description>
<environment/>
<key id="12915225">CASSANDRA-10756</key>
<summary>
Timeout failures in NativeTransportService.testConcurrentDestroys unit test
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jkni">Joel Knighton</reporter>
<labels></labels>
<created>Mon, 23 Nov 2015 04:14:28 +0000</created>
<updated>Mon, 23 Nov 2015 15:13:23 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15022232" author="spodxx@gmail.com" created="Mon, 23 Nov 2015 15:12:47 +0000">
<p>It's a bit unfortunate that the netty promises will not yield an exception or any result at all in case the executor has already been shut down. </p> <p>Adding a simple guard to not execute destroy twice seems to prevent the issue to happen.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 23 Nov 2015 15:12:47 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2orp3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333891</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10751] "Pool is shutdown" error when running Hadoop jobs on Yarn
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10751
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Trying to execute an Hadoop job on Yarn, I get errors from Cassandra's internal code. It seems that connections are shutdown but we can't understand why ...<br/> Here is a subtract of the errors. I also add a file with the complete debug logs.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> 15/11/22 20:05:54 [main]: DEBUG core.RequestHandler: Error querying node006.internal.net/192.168.12.22:9042, trying next host (error is: com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown) Failed with exception java.io.IOException:java.io.IOException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried <span class="code-keyword">for</span> query failed (tried: node006.internal.net/192.168.12.22:9042 (com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown)) 15/11/22 20:05:54 [main]: ERROR CliDriver: Failed with exception java.io.IOException:java.io.IOException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried <span class="code-keyword">for</span> query failed (tried: node006.internal.net/192.168.12.22:9042 (com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown)) java.io.IOException: java.io.IOException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried <span class="code-keyword">for</span> query failed (tried: node006.internal.net/192.168.12.22:9042 (com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown)) at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:508) at org.apache.hadoop.hive.ql.exec.FetchOperator.pushRow(FetchOperator.java:415) at org.apache.hadoop.hive.ql.exec.FetchTask.fetch(FetchTask.java:140) at org.apache.hadoop.hive.ql.Driver.getResults(Driver.java:1672) at org.apache.hadoop.hive.cli.CliDriver.processLocalCmd(CliDriver.java:233) at org.apache.hadoop.hive.cli.CliDriver.processCmd(CliDriver.java:165) at org.apache.hadoop.hive.cli.CliDriver.processLine(CliDriver.java:376) at org.apache.hadoop.hive.cli.CliDriver.executeDriver(CliDriver.java:736) at org.apache.hadoop.hive.cli.CliDriver.run(CliDriver.java:681) at org.apache.hadoop.hive.cli.CliDriver.main(CliDriver.java:621) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:497) at org.apache.hadoop.util.RunJar.run(RunJar.java:221) at org.apache.hadoop.util.RunJar.main(RunJar.java:136) Caused by: java.io.IOException: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried <span class="code-keyword">for</span> query failed (tried: node006.internal.net/192.168.12.22:9042 (com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown)) at org.apache.hadoop.hive.cassandra.input.cql.HiveCqlInputFormat.getRecordReader(HiveCqlInputFormat.java:132) at org.apache.hadoop.hive.ql.exec.FetchOperator$FetchInputFormatSplit.getRecordReader(FetchOperator.java:674) at org.apache.hadoop.hive.ql.exec.FetchOperator.getRecordReader(FetchOperator.java:324) at org.apache.hadoop.hive.ql.exec.FetchOperator.getNextRow(FetchOperator.java:446) ... 15 more Caused by: com.datastax.driver.core.exceptions.NoHostAvailableException: All host(s) tried <span class="code-keyword">for</span> query failed (tried: node006.internal.net/192.168.12.22:9042 (com.datastax.driver.core.ConnectionException: [node006.internal.net/192.168.12.22:9042] Pool is shutdown)) at com.datastax.driver.core.exceptions.NoHostAvailableException.copy(NoHostAvailableException.java:84) at com.datastax.driver.core.DriverThrowables.propagateCause(DriverThrowables.java:37) at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:214) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:52) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:36) at org.apache.cassandra.hadoop.cql3.CqlRecordReader.fetchKeys(CqlRecordReader.java:578) at org.apache.cassandra.hadoop.cql3.CqlRecordReader.buildQuery(CqlRecordReader.java:526) at org.apache.cassandra.hadoop.cql3.CqlRecordReader.initialize(CqlRecordReader.java:148) </pre> </div></div>
</description>
<environment>
<p>Hadoop 2.7.1 (HDP 2.3.2)<br/> Cassandra 2.1.11</p>
</environment>
<key id="12915183">CASSANDRA-10751</key>
<summary>
"Pool is shutdown" error when running Hadoop jobs on Yarn
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="cscetbon">Cyril Scetbon</assignee>
<reporter username="cscetbon">Cyril Scetbon</reporter>
<labels></labels>
<created>Sun, 22 Nov 2015 19:19:25 +0000</created>
<updated>Fri, 27 Nov 2015 00:50:56 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15023401" author="cscetbon" created="Mon, 23 Nov 2015 23:55:22 +0000">
<p>Hey <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexliu68" class="user-hover" rel="alexliu68">Alex Liu</a>, I've assigned it to you as I know you're the one who can easily guess what happens. Don't hesitate to assign it to someone else if you think I'm wrong. Thanks</p>
</comment>
<comment id="15023480" author="alexliu68" created="Tue, 24 Nov 2015 00:37:00 +0000">
<p>The error indicates that C* node can't handle the load(Maybe there are too many splits). Do you try the latest C* 2.x or C*3.x?</p>
</comment>
<comment id="15023612" author="cscetbon" created="Tue, 24 Nov 2015 02:24:11 +0000">
<p>Cassandra 2.1.11. It was working fine with 2.0.12</p>
</comment>
<comment id="15024784" author="cscetbon" created="Tue, 24 Nov 2015 16:30:57 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexliu68" class="user-hover" rel="alexliu68">Alex Liu</a> The number of splits has not changed and is the same as with 2.0.12. The strange errors are :</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> 15/11/24 15:26:32 [cluster2-blocking-task-worker-1]: DEBUG core.HostConnectionPool: Creating <span class="code-keyword">new</span> connection on busy pool to /10.234.62.20:9042 15/11/24 15:26:32 [cluster2-blocking-task-worker-0]: DEBUG core.HostConnectionPool: Creating <span class="code-keyword">new</span> connection on busy pool to /10.234.62.20:9042 15/11/24 15:26:32 [cluster2-nio-worker-34]: DEBUG core.Connection: Connection[/10.234.62.20:9042-5, inFlight=0, closed=<span class="code-keyword">false</span>] Connection opened successfully 15/11/24 15:26:32 [cluster2-nio-worker-35]: DEBUG core.Connection: Connection[/10.234.62.20:9042-6, inFlight=0, closed=<span class="code-keyword">false</span>] Connection opened successfully 15/11/24 15:26:32 [cluster2-nio-worker-34]: DEBUG Host.STATES: [/10.234.62.20:9042] <span class="code-keyword">new</span> connection created, total = 1 15/11/24 15:26:32 [cluster2-nio-worker-35]: DEBUG Host.STATES: [/10.234.62.20:9042] <span class="code-keyword">new</span> connection created, total = 2 15/11/24 15:26:32 [cluster2-nio-worker-35]: DEBUG core.Connection: Connection[/10.234.62.20:9042-6, inFlight=0, closed=<span class="code-keyword">true</span>] closing connection 15/11/24 15:26:32 [cluster2-nio-worker-34]: DEBUG core.Connection: Connection[/10.234.62.20:9042-5, inFlight=0, closed=<span class="code-keyword">true</span>] closing connection 15/11/24 15:26:32 [cluster2-nio-worker-35]: DEBUG Host.STATES: [/10.234.62.20:9042] connection closed, remaining = 1 15/11/24 15:26:32 [cluster2-nio-worker-34]: DEBUG Host.STATES: [/10.234.62.20:9042] connection closed, remaining = 0 15/11/24 15:26:32 [cluster2-nio-worker-35]: DEBUG core.Connection: Connection[/10.234.62.20:9042-6, inFlight=0, closed=<span class="code-keyword">true</span>] has already terminated 15/11/24 15:26:32 [cluster2-nio-worker-34]: DEBUG core.Connection: Connection[/10.234.62.20:9042-5, inFlight=0, closed=<span class="code-keyword">true</span>] has already terminated 15/11/24 15:26:32 [cluster2-blocking-task-worker-0]: DEBUG Host.STATES: Defuncting Connection[/10.234.62.20:9042-6, inFlight=0, closed=<span class="code-keyword">true</span>] because: [/10.234.62.20:9042] Error <span class="code-keyword">while</span> setting keyspace </pre> </div></div> <p>I can see that the error "Error while setting keyspace" is displayed when there is a <b>ExecutionException</b>. It just weird that it happens so quickly ...</p>
</comment>
<comment id="15024873" author="alexliu68" created="Tue, 24 Nov 2015 17:12:35 +0000">
<p>Can you get the full stacktrace by changing the log level of Host.STATES to TRACE?</p>
</comment>
<comment id="15025776" author="cscetbon" created="Wed, 25 Nov 2015 00:12:37 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexliu68" class="user-hover" rel="alexliu68">Alex Liu</a>, so the issue is that CqlRecord calls cluster.connect using a <a href="https://github.com/apache/cassandra/blob/trunk/src/java/org/apache/cassandra/hadoop/cql3/CqlRecordReader.java#L138" class="external-link" rel="nofollow">quoted keyspace string</a> and that the java driver quotes it too when it accesses the keyspace using <a href="https://github.com/datastax/java-driver/blob/2.1.8/driver-core/src/main/java/com/datastax/driver/core/Connection.java#L477" class="external-link" rel="nofollow">CQL</a>. If I remove the first quote my job runs.</p>
</comment>
<comment id="15025825" author="alexliu68" created="Wed, 25 Nov 2015 00:34:45 +0000">
<p>Cool, can you check latest C* 2.2.* and C*3.x. If possible, submit a patch.</p>
</comment>
<comment id="15026002" author="cscetbon" created="Wed, 25 Nov 2015 02:10:14 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexliu68" class="user-hover" rel="alexliu68">Alex Liu</a> Here are the patches for each version</p>
</comment>
<comment id="15029330" author="cscetbon" created="Fri, 27 Nov 2015 00:50:56 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=alexliu68" class="user-hover" rel="alexliu68">Alex Liu</a> did you get any chance to have a look at it ?</p>
</comment>
</comments>
<attachments>
<attachment id="12774238" name="CASSANDRA-10751-2.2.patch" size="646" author="cscetbon" created="Wed, 25 Nov 2015 02:10:14 +0000"/>
<attachment id="12774237" name="CASSANDRA-10751-3.0.patch" size="646" author="cscetbon" created="Wed, 25 Nov 2015 02:10:14 +0000"/>
<attachment id="12773736" name="output.log" size="258464" author="cscetbon" created="Sun, 22 Nov 2015 19:19:25 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 24 Nov 2015 00:37:00 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2orfr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>alexliu68</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10370] upgrade_tests.cql_tests:TestCQL.static_columns_with_distinct_test fails in 2.1 nodes
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10370
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When running the dtest <tt>upgrade_tests.cql_tests:TestCQL.static_columns_with_distinct_test</tt> against 2x2.1 nodes, the test fails due to a row being returned multiple times. This isn't reproducible between 3.0 nodes, but is between 2.1&lt;-&gt;3.0 nodes, so it's safe to say it's not a 3.0 bug. To reproduce, run:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>UPGRADE_MODE=none nosetests upgrade_tests/cql_tests.py:TestCQL.static_columns_with_distinct_test</pre> </div></div> <p> with the environment variable <tt>OLD_CASSANDRA_DIR</tt> set to a repo with cassandra-2.1 checked out.</p>
</description>
<environment/>
<key id="12875714">CASSANDRA-10370</key>
<summary>
upgrade_tests.cql_tests:TestCQL.static_columns_with_distinct_test fails in 2.1 nodes
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="bdeggleston">Blake Eggleston</reporter>
<labels></labels>
<created>Thu, 17 Sep 2015 22:39:55 +0000</created>
<updated>Fri, 6 Nov 2015 22:54:28 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2kd3r:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332984</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-10327] Performance regression in 2.2</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10327
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Related to <a href="https://issues.apache.org/jira/browse/CASSANDRA-10326" title="Performance is worse in 3.0" class="issue-link" data-issue-key="CASSANDRA-10326"><del>CASSANDRA-10326</del></a>, one of the read-only workloads <em>appears</em> to show a regression in 2.2, however it is possible this is simply down to a different compaction result (this shouldn't be very likely given the use of LCS, though, and that we wait for compaction to acquiesce, and while the different is not consistent across both runs, it is consistently worse).</p> <p>The query is looking up the last item of a partition.</p> <p><a href="http://cstar.datastax.com/graph?stats=f0a17292-5a13-11e5-847a-42010af0688f&amp;metric=op_rate&amp;operation=3_user&amp;smoothing=1&amp;show_aggregates=true&amp;xmin=0&amp;xmax=155.43&amp;ymin=0&amp;ymax=13777.5" class="external-link" rel="nofollow">run1</a><br/> <a href="http://cstar.datastax.com/graph?stats=e25aaaa0-5a13-11e5-ae0d-42010af0688f&amp;metric=op_rate&amp;operation=3_user&amp;smoothing=1&amp;show_aggregates=true&amp;xmin=0&amp;xmax=74.36&amp;ymin=0&amp;ymax=34078" class="external-link" rel="nofollow">run2</a></p>
</description>
<environment/>
<key id="12863992">CASSANDRA-10327</key>
<summary>Performance regression in 2.2</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="benedict">Benedict</reporter>
<labels></labels>
<created>Mon, 14 Sep 2015 19:05:57 +0000</created>
<updated>Wed, 28 Oct 2015 16:11:54 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14744082" author="benedict" created="Mon, 14 Sep 2015 19:25:17 +0000">
<p>As <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tjake" class="user-hover" rel="tjake">T Jake Luciani</a> points out <a href="https://issues.apache.org/jira/browse/CASSANDRA-10326?focusedCommentId=14744064&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14744064" class="external-link" rel="nofollow">here</a>, it's entirely possible this is caused by 2.1 failing part way through the write load.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2k5nb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9936] node cannot join into cluster while handshaking with seed
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9936
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When a node tries to join in to a cluster by talking to the seed, I got the following error on system.log in the seed.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.AssertionError: -1010673279660824450 not found in at org.apache.cassandra.locator.TokenMetadata.getPredecessor(TokenMetadata.java:683) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.locator.TokenMetadata.getPrimaryRangesFor(TokenMetadata.java:627) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.SizeEstimatesRecorder.run(SizeEstimatesRecorder.java:68) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:118) ~[apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_51] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308) [na:1.8.0_51] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180) [na:1.8.0_51] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294) [na:1.8.0_51] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_51] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_51] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.8.0_51] </pre> </div></div> <p>seed's yaml:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> listen_address: 10.0.0.94 broadcast_address: 52.28.10.78 rpc_address: 0.0.0.0 broadcast_rpc_address: 52.28.10.78 seed_provider: - class_name: org.apache.cassandra.locator.SimpleSeedProvider parameters: - seeds: <span class="code-quote">"52.28.10.78"</span> </pre> </div></div> <p>node's yaml:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> listen_address: 10.0.0.95 broadcast_address: 52.28.59.43 rpc_address: 0.0.0.0 broadcast_rpc_address: 52.28.59.43 seed_provider: - class_name: org.apache.cassandra.locator.SimpleSeedProvider parameters: - seeds: <span class="code-quote">"52.28.10.78"</span> </pre> </div></div>
</description>
<environment/>
<key id="12850222">CASSANDRA-9936</key>
<summary>
node cannot join into cluster while handshaking with seed
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mulderbaba">Mert Caliskan</reporter>
<labels></labels>
<created>Thu, 30 Jul 2015 12:01:02 +0000</created>
<updated>Wed, 28 Oct 2015 16:11:48 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2i49b:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-9939] CASSANDRA-8819 Same Bug</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9939
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p><a href="https://issues.apache.org/jira/browse/CASSANDRA-8819" title="LOCAL_QUORUM writes returns wrong message" class="issue-link" data-issue-key="CASSANDRA-8819"><del>CASSANDRA-8819</del></a> was not actually included in the 2.0.13 release per release notes and the problem still exist. Moving a token generates errors still. </p> <p>com.datastax.driver.core.exceptions.WriteTimeoutException: Cassandra timeout during write query at consistency LOCAL_QUORUM (3 replica were required but only 2 acknowledged the write)"</p>
</description>
<environment/>
<key id="12850316">CASSANDRA-9939</key>
<summary>CASSANDRA-8819 Same Bug</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="ascii4">Tom Lewis</reporter>
<labels></labels>
<created>Thu, 30 Jul 2015 17:40:03 +0000</created>
<updated>Wed, 2 Sep 2015 13:52:02 +0000</updated>
<due/>
<votes>2</votes>
<watches>2</watches>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12775794">CASSANDRA-8819</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2i4u7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10291] Bootstrap hangs on adding new node
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10291
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Adding new node in heavy loaded environment freeze bootstrap. No errors are reported in log files. Some of other other nodes throws "String didn't validate" error, but I;m not sure that this is related. <br/> After restarting node it start bootstrap again and hangs after some time . </p> <p>nodetool netstats shows : <br/> /data/XXX/XXXX/tmp-la-1184-big-Data.db 5126078789/18345924701 bytes(27%) received from idx:0/192.168.220.16<br/> /data/XXX/XXXX/tmp-la-1233-big-Data.db 7213706459/18600941671 bytes(38%) received from idx:0/192.168.220.22<br/> /data/XXX/XXXX/tmp-la-1599-big-Data.db 8492408759/17572043398 bytes(48%) received from idx:0/192.168.220.12<br/> /data/XXX/XXXX/tmp-la-2066-big-Data.db 15773981555/18508127610 bytes(85%) received from idx:0/192.168.220.18<br/> /data/XXX/XXXX/tmp-la-211-big-Data.db 8274231066/17172754085 bytes(48%) received from idx:0/192.168.220.20</p> <p>but listing files on local FS shows "No such file or directory"</p> <p>This happens only if there is significant amount of data. I have 1.5 TB per node on 13 node cluster, we use STCS compaction strategy and flat network topology . </p>
</description>
<environment>
<p>Debian 7 64 bit<br/> HotSpot JDK 1.7.0_79<br/> Cassandra-2.2.1 via apt-get <br/> 1x Intel Quad-Core Xeon E3-1230 / 16GB / 4x1TB SATA / 3x1TB RAID0 data drive </p>
</environment>
<key id="12862689">CASSANDRA-10291</key>
<summary>Bootstrap hangs on adding new node</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="sadoyan">Ara Sadoyan</reporter>
<labels></labels>
<created>Wed, 9 Sep 2015 07:44:01 +0000</created>
<updated>Thu, 12 Nov 2015 17:22:38 +0000</updated>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>6</watches>
<comments>
<comment id="14739252" author="mshuler" created="Thu, 10 Sep 2015 18:07:56 +0000">
<p>(dropped a bunch of extra jira fields)</p> <p>Looking at the log, it appears to me that you may be suffering from network issues where the streaming fails. Have you made any configuration adjustments or discussed this with people on the mailing list or irc? Recovering from a bootstrap failure usually means just bootstrap again. Since you have a pretty large amount of data on an already-loaded cluster with questionable network interruption, you might get better help and ideas from other users on the mailing list or irc - not sure if this is exactly a bug.</p>
</comment>
<comment id="14739722" author="sadoyan" created="Thu, 10 Sep 2015 22:16:55 +0000">
<p>This cluster is running for almost a year and there were no problems in 2.1 .<br/> Problem appeared after I have upgraded to 2.2. Today I did bootstrap again and failed same way, but there was nothing in logs.<br/> Regarding network. These servers are directly connected to gbit switch .<br/> I have lowered down stream speed so commulative traffic to bootstrapping node was about 700 mbit, just to ensure that I do not have bandwidth problem. So i guess this is a bug. </p>
</comment>
<comment id="14739790" author="mshuler" created="Thu, 10 Sep 2015 22:53:35 +0000">
<p>I'm slightly confused on the versions we're talking about. Your log shows apache-cassandra-2.2.0.jar - this JIRA indicates your env is 2.2.1 and you indicated reproduced in 2.2.1. What version is your cluster running?</p>
</comment>
<comment id="14740572" author="sadoyan" created="Fri, 11 Sep 2015 11:00:57 +0000"><p>Full system log during node bootstrap </p></comment>
<comment id="14740582" author="sadoyan" created="Fri, 11 Sep 2015 11:08:02 +0000"><p>Nodetool output and Stack trace: </p></comment>
<comment id="14740585" author="sadoyan" created="Fri, 11 Sep 2015 11:09:30 +0000">
<p>ok I have cleared all logs and did bootstrap of Cassandra node. Attached full system.log during last bootstrap. <br/> To have full picture I have also attached nodetool netstats and one hanged stream's stack trace. <br/> Stack trace is for only one stream, but all other hanged ones are almost the same. <br/> There were no traffic and working streams when I was collecting date. </p>
</comment>
<comment id="14740956" author="sadoyan" created="Fri, 11 Sep 2015 15:08:38 +0000">
<p>Have just tried to upgrade to java8, no success. <br/> Also very strange thing is going on during bootstrap </p> <p>nodetool netstats on boostrapping node shows that stream is stalled and destination file does not exists, but source continues to send stream and shows progress. </p> <p>cassa15 14:59:00 ~ # nodetool netstats | grep 192.168.220.19 (Destination Node)<br/> /192.168.220.19<br/> /opt/cassandra/storage/data/REPLACED/html_2015_07-be0b6c300f5311e59d7f27679cc9890d/tmp-la-6-big-Data.db 1278964766/10319377771 bytes(12%) received from idx:0/192.168.220.19</p> <p>cassa15 14:59:13 ~ # ls /opt/cassandra/storage/data/REPLACED/html_2015_07-be0b6c300f5311e59d7f27679cc9890d/tmp-la-6-big-Data.db<br/> ls: cannot access /opt/cassandra/storage/data/REPLACED/html_2015_07-be0b6c300f5311e59d7f27679cc9890d/tmp-la-6-big-Data.db: No such file or directory</p> <p>cassa15 14:59:06 ~ # nodetool -h 192.168.220.19 netstats <br/> Mode: NORMAL<br/> Bootstrap 6e3f57f0-5893-11e5-bf5a-5f8e66db7dc7<br/> /192.168.220.27<br/> Sending 461 files, 146529071898 bytes total. Already sent 0 files, 7905965086 bytes total<br/> /opt/cassandra/storage/data/REPLACED/html_2015_07-be0b6c300f5311e59d7f27679cc9890d/la-3919-big-Data.db 7905965086/10319377771 bytes(76%) sent to idx:0/192.168.220.27</p> <p>after 10 minutes : </p> <p>Absolutely same picture at bootstrapping node, but stuff is changed in source node. </p> <p>cassa15 15:03:18 ~ # nodetool -h 192.168.220.19 netstats <br/> Mode: NORMAL<br/> Bootstrap 6e3f57f0-5893-11e5-bf5a-5f8e66db7dc7<br/> /192.168.220.27<br/> Sending 461 files, 146529071898 bytes total. Already sent 0 files, 9994641455 bytes total<br/> /opt/cassandra/storage/data//REPLACED/html_2015_07-be0b6c300f5311e59d7f27679cc9890d/la-3919-big-Data.db 9994641455/10319377771 bytes(96%) sent to idx:0/192.168.220.27<br/> Read Repair Statistics:<br/> Attempted: 48576<br/> Mismatch (Blocking): 0<br/> Mismatch (Background): 69<br/> Pool Name Active Pending Completed<br/> Large messages n/a 0 545698<br/> Small messages n/a 0 10507575<br/> Gossip messages n/a 0 811646</p> <p>Any idea ? </p>
</comment>
<comment id="14741064" author="mshuler" created="Fri, 11 Sep 2015 16:19:29 +0000">
<p>Thanks for the extra info. This log shows C* 2.2.1 - are <b>all</b> nodes in the cluster running 2.2.1? I'm just trying to rule out the obvious.</p>
</comment>
<comment id="14741351" author="sadoyan" created="Fri, 11 Sep 2015 18:46:46 +0000"><p>Yes Michael, all nodes are C* 2.2.1 . </p></comment>
<comment id="14790598" author="mambocab" created="Wed, 16 Sep 2015 15:57:16 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> Do you have any idea why this might happen? and do you know who might be an appropriate assignee?</p>
</comment>
<comment id="14791031" author="yukim" created="Wed, 16 Sep 2015 19:58:10 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=sadoyan" class="user-hover" rel="sadoyan">Ara Sadoyan</a> do you still have system.log from the nodes /192.168.220.22 and /192.168.220.17 around the same time as attached system.log?</p>
</comment>
<comment id="14802724" author="sadoyan" created="Thu, 17 Sep 2015 10:28:19 +0000"><p>Cluster logs during bootstrap </p></comment>
<comment id="14802725" author="sadoyan" created="Thu, 17 Sep 2015 10:28:24 +0000">
<p>I do not have that systems logs but I have reproduced problem. Attachment logs_netstats.tar.gz contains system logs from all cluster nodes during bootstrap of 192.168.220.27 . <br/> java.io.IOException: Broken pipe exception at the end of logs appeared only after I have stopped 192.168.220.27 with bunch of hanged streams </p>
</comment>
<comment id="14802730" author="sadoyan" created="Thu, 17 Sep 2015 10:34:09 +0000"><p>Logs</p></comment>
<comment id="14876191" author="yukim" created="Fri, 18 Sep 2015 19:22:51 +0000">
<p>Thanks for the logs.<br/> Stream with /192.168.220.16 and /192.168.220.17 are having trouble.<br/> Can you run <tt>nodetool scrub</tt> on those two to see if any corruption in SSTables?</p>
</comment>
<comment id="14876299" author="sadoyan" created="Fri, 18 Sep 2015 20:18:24 +0000">
<p>Streams that you are referring to were the only ones which were detected as failed and successfully restreamed . if you look at 192.168.220.27 netstat logs in attachment you will see that at the time that bootstrap was fully hanged up there were no streams from 192.168.220.17 and I can ensure that 16 was able to restream that particular stream. I was watching netstats during all bootstrap and noticed that failed streams were closed. Beside I did nodetool upgradesstables on all nodes without any errors before last bootstrap.</p>
</comment>
<comment id="14953280" author="mambocab" created="Mon, 12 Oct 2015 16:26:04 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> Any thoughts on the logs, given that information?</p>
</comment>
<comment id="14953376" author="yukim" created="Mon, 12 Oct 2015 17:03:43 +0000">
<p>Unfortunately not so much.</p> <p>All I got were:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> WARN [STREAM-IN-/192.168.220.17] 2015-09-17 08:27:32,189 StreamSession.java:644 - [Stream #a5f6b030-5d07-11e5-b554-5f8e66db7dc7] Retrying <span class="code-keyword">for</span> following errorjava.lang.AssertionError: <span class="code-keyword">null</span> at org.apache.cassandra.streaming.compress.CompressedInputStream.read(CompressedInputStream.java:96) ~[apache-cassandra-2.2.1.jar:2.2.1] at java.io.InputStream.read(InputStream.java:179) ~[na:1.7.0_80] at java.io.InputStream.skip(InputStream.java:222) ~[na:1.7.0_80] at org.apache.cassandra.streaming.StreamReader.drain(StreamReader.java:137) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.compress.CompressedStreamReader.read(CompressedStreamReader.java:106) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:49) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:38) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:56) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:261) [apache-cassandra-2.2.1.jar:2.2.1] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div> <p>and</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> WARN [STREAM-IN-/192.168.220.16] 2015-09-17 09:40:42,378 StreamSession.java:644 - [Stream #a5f6b030-5d07-11e5-b554-5f8e66db7dc7] Retrying <span class="code-keyword">for</span> following errororg.apache.cassandra.serializers.MarshalException: <span class="code-object">String</span> didn't validate. at org.apache.cassandra.serializers.UTF8Serializer.validate(UTF8Serializer.java:35) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.marshal.AbstractType.getString(AbstractType.java:91) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.cql3.ColumnIdentifier.&lt;init&gt;(ColumnIdentifier.java:58) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.composites.SimpleSparseCellNameType.fromByteBuffer(SimpleSparseCellNameType.java:83) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.composites.AbstractCType$Serializer.deserialize(AbstractCType.java:381) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.composites.AbstractCType$Serializer.deserialize(AbstractCType.java:365) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.RangeTombstone$Serializer.deserializeBody(RangeTombstone.java:357) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.OnDiskAtom$Serializer.deserializeFromSSTable(OnDiskAtom.java:84) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:52) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.db.AbstractCell$1.computeNext(AbstractCell.java:46) ~[apache-cassandra-2.2.1.jar:2.2.1] at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143) ~[guava-16.0.jar:na] at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138) ~[guava-16.0.jar:na] at org.apache.cassandra.io.sstable.format.big.BigTableWriter.appendFromStream(BigTableWriter.java:243) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.StreamReader.writeRow(StreamReader.java:162) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.compress.CompressedStreamReader.read(CompressedStreamReader.java:95) ~[apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:49) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:38) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:56) [apache-cassandra-2.2.1.jar:2.2.1] at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:261) [apache-cassandra-2.2.1.jar:2.2.1] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div> <p>so I wonder if there were SSTable corruption on those nodes.<br/> Though "(/192.168.220.)16 was able to restream that particular stream." so 17 was only problematic at that moment.</p>
</comment>
<comment id="14953764" author="sadoyan" created="Mon, 12 Oct 2015 21:25:59 +0000">
<p>Guys the real problem is not logged.<br/> These particular streams were restreamed, but actaul hanged streams were never been logged. These streams were just hanged silently.<br/> Please do not concentrate on these two streams. <br/> AFAIK upgradesstables should show corrupted sstables , but when I did that it passe smoothly on all nodes.<br/> Soon I will upgrade cluster to 2.2.2 and try to reproduce issue.</p>
</comment>
<comment id="14987992" author="sadoyan" created="Tue, 3 Nov 2015 19:57:24 +0000">
<p><br/> After scrubbing all keyspaces I have reproduced it on version 2.2.3</p>
</comment>
</comments>
<attachments>
<attachment id="12757006" name="logs_netstats.tar.gz" size="165017" author="sadoyan" created="Thu, 17 Sep 2015 10:34:09 +0000"/>
<attachment id="12755382" name="nodetool.txt" size="4415" author="sadoyan" created="Fri, 11 Sep 2015 11:08:02 +0000"/>
<attachment id="12755380" name="system.log" size="881067" author="sadoyan" created="Fri, 11 Sep 2015 11:00:57 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 10 Sep 2015 18:07:56 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311020" key="com.atlassian.jira.plugin.system.customfieldtypes:url">
<customfieldname>External issue URL</customfieldname>
<customfieldvalues>
<customfieldvalue>
<![CDATA[
http://stackoverflow.com/questions/32404913/cassandra-staled-bootstrap
]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2jxpj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333059</customfieldvalue>
<customfieldvalue>12333745</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332983</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10287] nodetool rebuild does not work with join_ring=false
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10287
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I'm setting up a new data center as described in <a href="http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_add_dc_to_cluster_t.html" class="external-link" rel="nofollow">http://docs.datastax.com/en/cassandra/2.0/cassandra/operations/ops_add_dc_to_cluster_t.html</a>, with one change: I'm starting the new node with join_ring=false, because I want to prevent reads to be routed to the new node.</p> <p>When starting nodetool rebuild as described in 7b, the command immediately returns. In the log file, I can see a message that states the the streaming is started. Then nothing happens, not even after a few hours of waiting.</p>
</description>
<environment/>
<key id="12862537">CASSANDRA-10287</key>
<summary>
nodetool rebuild does not work with join_ring=false
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tomvandenberge">Tom van den Berge</reporter>
<labels></labels>
<created>Tue, 8 Sep 2015 20:04:32 +0000</created>
<updated>Thu, 17 Sep 2015 19:42:48 +0000</updated>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14739263" author="mshuler" created="Thu, 10 Sep 2015 18:15:05 +0000">
<p>What version of Cassandra are you using? Possibly <a href="https://issues.apache.org/jira/browse/CASSANDRA-6961" title="nodes should go into hibernate when join_ring is false" class="issue-link" data-issue-key="CASSANDRA-6961"><del>CASSANDRA-6961</del></a> which was fixVer 2.0.7</p>
</comment>
<comment id="14740431" author="tomvandenberge" created="Fri, 11 Sep 2015 08:55:30 +0000"><p>Cassandra 2.1.6.</p></comment>
<comment id="14804338" author="mambocab" created="Thu, 17 Sep 2015 19:42:48 +0000">
<p>cc'ing <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> &#8211; do you know what might be causing this?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 10 Sep 2015 18:15:05 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2jwsf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10303] streaming for 'nodetool rebuild' fails after adding a datacenter
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10303
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>we add another datacenter.<br/> use nodetool rebuild DC1<br/> stream from some node of old datacenter always hang up with these exception:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-1472] 2015-09-10 19:24:53,091 CassandraDaemon.java:223 - Exception in thread <span class="code-object">Thread</span>[<span class="code-object">Thread</span>-1472,5,RMI <span class="code-object">Runtime</span>] java.lang.RuntimeException: java.io.IOException: Connection timed out at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[apache-cassandra-2.1.8.jar:2.1.8] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) ~[na:1.7.0_60] Caused by: java.io.IOException: Connection timed out at sun.nio.ch.FileDispatcherImpl.read0(Native Method) ~[na:1.7.0_60] at sun.nio.ch.SocketDispatcher.read(SocketDispatcher.java:39) ~[na:1.7.0_60] at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223) ~[na:1.7.0_60] at sun.nio.ch.IOUtil.read(IOUtil.java:197) ~[na:1.7.0_60] at sun.nio.ch.SocketChannelImpl.read(SocketChannelImpl.java:379) ~[na:1.7.0_60] at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:59) ~[na:1.7.0_60] at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109) ~[na:1.7.0_60] at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103) ~[na:1.7.0_60] at org.apache.cassandra.streaming.compress.CompressedInputStream$Reader.runMayThrow(CompressedInputStream.java:172) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~[apache-cassandra-2.1.8.jar:2.1.8] ... 1 common frames omitted </pre> </div></div> <p>i must restart node to stop current rebuild, and rebuild agagin and again to success....</p>
</description>
<environment><p>jdk1.7<br/> cassandra 2.1.8</p></environment>
<key id="12863292">CASSANDRA-10303</key>
<summary>
streaming for 'nodetool rebuild' fails after adding a datacenter
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="zhaoyan">zhaoyan</reporter>
<labels></labels>
<created>Fri, 11 Sep 2015 06:02:38 +0000</created>
<updated>Thu, 3 Dec 2015 03:51:40 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14740258" author="zhaoyan" created="Fri, 11 Sep 2015 06:08:04 +0000">
<p>These happen after we set <br/> “sysctl -w net.ipv4.tcp_keepalive_time=60 net.ipv4.tcp_keepalive_probes=3 net.ipv4.tcp_keepalive_intvl=10”</p> <p>if not set this，there is another error:<br/> ERROR <span class="error">&#91;RMI TCP Connection(19)-xxxxxxx&#93;</span> 2015-09-01 00:02:36,714 StorageService.java:1058 - Error while rebuilding node<br/> org.apache.cassandra.streaming.StreamException: Stream failed<br/> at org.apache.cassandra.streaming.management.StreamEventJMXNotifier.onFailure(StreamEventJMXNotifier.java:85) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at com.google.common.util.concurrent.Futures$4.run(Futures.java:1172) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202) ~<span class="error">&#91;guava-16.0.jar:na&#93;</span><br/> at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:208) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:184) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:412) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.StreamSession.sessionFailed(StreamSession.java:617) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.StreamSession.messageReceived(StreamSession.java:472) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:256) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> ERROR <span class="error">&#91;STREAM-OUT-/xxxxxxxxxx&#93;</span> 2015-09-01 00:02:36,714 StreamSession.java:502 - <a href="#04cd8620-4fd3-11e5-8d26-33ebdae8f95a">Stream #04cd8620-4fd3-11e5-8d26-33ebdae8f95a</a> Streaming error occurred<br/> java.io.IOException: Broken pipe<br/> at sun.nio.ch.FileDispatcherImpl.write0(Native Method) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> at sun.nio.ch.SocketDispatcher.write(SocketDispatcher.java:47) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:93) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> at sun.nio.ch.IOUtil.write(IOUtil.java:65) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> at sun.nio.ch.SocketChannelImpl.write(SocketChannelImpl.java:487) ~<span class="error">&#91;na:1.7.0_60&#93;</span><br/> at org.apache.cassandra.io.util.DataOutputStreamAndChannel.write(DataOutputStreamAndChannel.java:48) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.messages.StreamMessage.serialize(StreamMessage.java:44) ~<span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.sendMessage(ConnectionHandler.java:351) <span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at org.apache.cassandra.streaming.ConnectionHandler$OutgoingMessageHandler.run(ConnectionHandler.java:331) <span class="error">&#91;apache-cassandra-2.1.8.jar:2.1.8&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.7.0_60&#93;</span></p>
</comment>
<comment id="14744225" author="mambocab" created="Mon, 14 Sep 2015 20:41:33 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhaoyan" class="user-hover" rel="zhaoyan">zhaoyan</a> I'm unable to reproduce locally with <a href="https://github.com/pcmanus/ccm/" class="external-link" rel="nofollow">ccm</a>. Have you been able to reproduce this with a fresh cluster?</p> <p>In the failure you described in your comment, after changing configurations with <tt>sysctl</tt>, were you able to get the rebuild to succeed by running it again?</p>
</comment>
<comment id="14744864" author="zhaoyan" created="Tue, 15 Sep 2015 05:39:08 +0000">
<p>I restart and rebuild agagin and agagin ....<br/> rebuild one node success after many try times;</p>
</comment>
<comment id="14744867" author="zhaoyan" created="Tue, 15 Sep 2015 05:40:45 +0000">
<p>my data is very big. one node is 1T data <br/> I have six nodes in one cluster</p>
</comment>
<comment id="14744870" author="zhaoyan" created="Tue, 15 Sep 2015 05:43:49 +0000">
<p>I am sorry, I has no environment to reproduce this with a fresh cluster.</p>
</comment>
<comment id="14790586" author="mambocab" created="Wed, 16 Sep 2015 15:51:35 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> Do you have any insight on this, and may I assign this to you?</p>
</comment>
<comment id="14790597" author="yukim" created="Wed, 16 Sep 2015 15:57:02 +0000">
<p>Maybe check network and firewall?<br/> Broken pipe / connection timeout is from OS' network layer I guess.</p>
</comment>
<comment id="14790613" author="mambocab" created="Wed, 16 Sep 2015 16:03:01 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=zhaoyan" class="user-hover" rel="zhaoyan">zhaoyan</a> Do you think networking problems could have caused these issues?</p>
</comment>
<comment id="14805175" author="zhaoyan" created="Fri, 18 Sep 2015 08:05:14 +0000">
<p>we used vpn and firewall.</p> <p>but cassandra not try?<br/> if ( java.io.IOException: Connection timed out )</p> { try again? } <p>how long the timeout?</p> <p>any setting can be set?</p>
</comment>
<comment id="14935324" author="darkslice" created="Tue, 29 Sep 2015 15:23:34 +0000">
<p>I've seen similar problems in 2.1.6 on a single DC</p> <p>For example we have 100 keyspaces with 5 CF in each over 4 Cassandra nodes. - No data in any. (all data had a TTL of 10 seconds)<br/> I tried to add another node to the system and after 2 hours 13 min in i get...</p> <p>ERROR 12:25:19 <a href="#c7b822a0-6692-11e5-94b5-e758b0554964">Stream #c7b822a0-6692-11e5-94b5-e758b0554964</a> Streaming error occurred<br/> java.io.IOException: Connection timed out</p> <p>I'm now 5 hours into trying to add in a 5th node in a Cassandra cluster with no data.</p> <p>We are running in AWS so its unlikely to be network issues</p>
</comment>
<comment id="14936476" author="zhaoyan" created="Wed, 30 Sep 2015 07:18:01 +0000">
<p>I'm sorry to reply you so late.</p> <p>I think networking might be one of the reasons.</p> <p>Data disaster recovery between the two city, network is generally not very good.</p> <p>I'm so upset now.</p>
</comment>
<comment id="14936935" author="mambocab" created="Wed, 30 Sep 2015 14:51:34 +0000">
<p>A couple questions &#8211; </p> <ul class="alternate" type="square"> <li>Are your nodes in the same region?</li> <li>Did you use <tt>nodetool rebuild</tt> or not? Just checking to see how your situation compares to that in the original report.</li> </ul>
</comment>
<comment id="15037199" author="wateray" created="Thu, 3 Dec 2015 03:44:55 +0000">
<p>The node which execute rebuild, when it read stream throws java.io.IOException: Connection timed out.,<br/> It will hang up, because of this exception does not been caughted. The StreamSession didn't know the exception, it cann't end up.</p> <p>The latest release version 2.1.11,2.2.3 3.0 don't fix this bug. The develop trunk has fixed this bug.<br/> CompressedInputStream.java </p> <p><b>with bug version</b></p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">while</span> (bufferRead &lt; readLength) { <span class="code-object">int</span> r = source.read(compressedWithCRC, bufferRead, readLength - bufferRead); <span class="code-keyword">if</span> (r &lt; 0) { dataBuffer.put(POISON_PILL); <span class="code-keyword">return</span>; <span class="code-comment">// <span class="code-keyword">throw</span> exception where we consume dataBuffer </span> } bufferRead += r; } </pre> </div></div> <p><b>fixed version</b></p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">protected</span> void runMayThrow() <span class="code-keyword">throws</span> Exception { .............. <span class="code-keyword">while</span> (bufferRead &lt; readLength) { <span class="code-object">int</span> r; <span class="code-keyword">try</span> { r = source.read(compressedWithCRC, bufferRead, readLength - bufferRead); <span class="code-keyword">if</span> (r &lt; 0) { dataBuffer.put(POISON_PILL); <span class="code-keyword">return</span>; <span class="code-comment">// <span class="code-keyword">throw</span> exception where we consume dataBuffer </span> } } <span class="code-keyword">catch</span> (IOException e) { dataBuffer.put(POISON_PILL); <span class="code-keyword">throw</span> e; } bufferRead += r; } dataBuffer.put(compressedWithCRC); } .......} </pre> </div></div>
</comment>
<comment id="15037202" author="yukim" created="Thu, 3 Dec 2015 03:51:40 +0000">
<p>This is fixed in <a href="https://issues.apache.org/jira/browse/CASSANDRA-10012" title="Deadlock when session streaming is retried after exception" class="issue-link" data-issue-key="CASSANDRA-10012"><del>CASSANDRA-10012</del></a> including soon to be released 2.1.12.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 14 Sep 2015 20:41:33 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2k1cf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9935] Repair fails with RuntimeException
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9935
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We had problems with slow repair in 2.1.7 (<a href="https://issues.apache.org/jira/browse/CASSANDRA-9702" title="Repair running really slow" class="issue-link" data-issue-key="CASSANDRA-9702">CASSANDRA-9702</a>) but after upgrade to 2.1.8 it started to work faster but now it fails with:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ... [2015-07-29 20:44:03,956] Repair session 23a811b0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-5474076923322749342,-5468600594078911162] finished [2015-07-29 20:44:03,957] Repair session 336f8740-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-8631877858109464676,-8624040066373718932] finished [2015-07-29 20:44:03,957] Repair session 4ccd8430-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-5372806541854279315,-5369354119480076785] finished [2015-07-29 20:44:03,957] Repair session 59f129f0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (8166489034383821955,8168408930184216281] finished [2015-07-29 20:44:03,957] Repair session 6ae7a9a0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (6084602890817326921,6088328703025510057] finished [2015-07-29 20:44:03,957] Repair session 8938e4a0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-781874602493000830,-781745173070807746] finished [2015-07-29 20:44:03,957] Repair command #4 finished error: nodetool failed, check server logs -- StackTrace -- java.lang.RuntimeException: nodetool failed, check server logs at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:290) at org.apache.cassandra.tools.NodeTool.main(NodeTool.java:202) </pre> </div></div> <p>After running:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> nodetool repair --partitioner-range --parallel --in-local-dc sync </pre> </div></div> <p>Last records in logs regarding repair are:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 09ff9e40-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-7695808664784761779,-7693529816291585568] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 17d8d860-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (8063716953988492222,8065203836608925992] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 23a811b0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-5474076923322749342,-5468600594078911162] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,956 StorageService.java:2952 - Repair session 336f8740-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-8631877858109464676,-8624040066373718932] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 4ccd8430-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-5372806541854279315,-5369354119480076785] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 59f129f0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (8166489034383821955,8168408930184216281] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 6ae7a9a0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (6084602890817326921,6088328703025510057] finished INFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,957 StorageService.java:2952 - Repair session 8938e4a0-3632-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-781874602493000830,-781745173070807746] finished </pre> </div></div> <p>but a bit above I see (at least two times in attached log):</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,853 StorageService.java:2959 - Repair session 1b07ea50-3608-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (5765414319217852786,5781018794516851576] failed with error org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2950) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]] Validation failed in /10.195.15.162 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:62) ~[apache-cassandra-2.1.8.jar:2.1.8] ... 3 common frames omittedINFO [<span class="code-object">Thread</span>-173887] 2015-07-29 20:44:03,854 StorageService.java:2952 - Repair session 846d9300-3608-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-6705935 742755245856,-6704072966568763453] finished </pre> </div></div>
</description>
<environment><p>C* 2.1.8, Debian Wheezy</p></environment>
<key id="12850184">CASSANDRA-9935</key>
<summary>Repair fails with RuntimeException</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="yukim">Yuki Morishita</assignee>
<reporter username="mlowicki">mlowicki</reporter>
<labels></labels>
<created>Thu, 30 Jul 2015 07:43:44 +0000</created>
<updated>Fri, 19 Feb 2016 20:06:33 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>2</votes>
<watches>7</watches>
<comments>
<comment id="14647877" author="yukim" created="Thu, 30 Jul 2015 16:13:28 +0000"><p>Do you see ERROR in /10.195.15.162?</p></comment>
<comment id="14647925" author="mlowicki" created="Thu, 30 Jul 2015 16:50:22 +0000">
<p>&gt; ping db1.sync.lati.osa<br/> PING a10-05-07.lati.osa (10.195.15.162): 56 data bytes</p> <p>So you've log attached to this ticket.</p>
</comment>
<comment id="14647948" author="yukim" created="Thu, 30 Jul 2015 17:02:25 +0000">
<p>Ok, I looked at the attached log, but I think the log missed ERROR that I'm looking for.<br/> Can you still get the log from the time before attached log?<br/> You have validation error in /10.195.15.176 also so looking at that node too may be helpful.</p>
</comment>
<comment id="14647968" author="mlowicki" created="Thu, 30 Jul 2015 17:14:08 +0000">
<p>Attached log from 10.195.15.176 (db5.sync.lati.osa).</p> <p>Older ones available on <a href="https://drive.google.com/file/d/0B_8mc_afWmd2Vnk4ZE5kS3J6OE0/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2Vnk4ZE5kS3J6OE0/view?usp=sharing</a> and <a href="https://drive.google.com/file/d/0B_8mc_afWmd2UElxUEZQUmtsaFk/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2UElxUEZQUmtsaFk/view?usp=sharing</a> (They are bigger than 10MB).</p>
</comment>
<comment id="14647981" author="mlowicki" created="Thu, 30 Jul 2015 17:20:21 +0000">
<p>More logs from db1.sync.lati.osa (10.195.15.162) available on <a href="https://drive.google.com/file/d/0B_8mc_afWmd2QVk2VVRTRVl1ZDQ/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2QVk2VVRTRVl1ZDQ/view?usp=sharing</a> and <a href="https://drive.google.com/file/d/0B_8mc_afWmd2MHREM2hzUlNjd0E/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2MHREM2hzUlNjd0E/view?usp=sharing</a>.</p>
</comment>
<comment id="14648082" author="yukim" created="Thu, 30 Jul 2015 18:28:22 +0000">
<div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> /10.195.15.162 ERROR [ValidationExecutor:210] 2015-07-29 15:43:11,407 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #1b07ea50-3608-11e5-a93e-4963524a8bde on sync/entity_by_id2, (5765414319217852786,5781018794516851576]], /10.195.15.162 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:210] 2015-07-29 15:43:11,407 CassandraDaemon.java:223 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:210,1,main] java.lang.AssertionError: row DecoratedKey(5765594635590376341, 00093238343336363131320000040000c3c700) received out of order wrt DecoratedKey(5780928708170690997, 00093233353634313435340000040000c3c700) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1011) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:623) ~[apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] /10.195.15.176 ERROR [ValidationExecutor:422] 2015-07-29 12:56:05,095 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #296789f0-35f1-11e5-a93e-4963524a8bde on sync/entity2, (6044856108640048843,6045004223660784737]], /10.195.15.162 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:422] 2015-07-29 12:56:05,096 CassandraDaemon.java:223 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:422,1,main] java.lang.AssertionError: row DecoratedKey(6044863856301870146, 00093239323237333032320000040000ba8100) received out of order wrt DecoratedKey(6044997179498328855, 000932393231393536313200000400025b9a00) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1011) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.8.jar:2.1.8] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:623) ~[apache-cassandra-2.1.8.jar:2.1.8] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div> <p>There is <a href="https://issues.apache.org/jira/browse/CASSANDRA-9126" title="java.lang.RuntimeException: Last written key DecoratedKey &gt;= current key DecoratedKey" class="issue-link" data-issue-key="CASSANDRA-9126"><del>CASSANDRA-9126</del></a>, and if you are using leveled compaction strategy on those table, out of order might come from <a href="https://issues.apache.org/jira/browse/CASSANDRA-8211" title="Overlapping sstables in L1+" class="issue-link" data-issue-key="CASSANDRA-8211"><del>CASSANDRA-8211</del></a>.<br/> Can you run scrub on those nodes?</p>
</comment>
<comment id="14648101" author="mlowicki" created="Thu, 30 Jul 2015 18:37:36 +0000">
<p>Should I run <tt>nodetool scrub sync</tt> on db1.sync.lati.osa and db5.sync.lati.osa or on all nodes inside this data center?</p>
</comment>
<comment id="14648122" author="yukim" created="Thu, 30 Jul 2015 18:48:06 +0000"><p>just on those two nodes is fine for now.</p></comment>
<comment id="14648760" author="mlowicki" created="Fri, 31 Jul 2015 05:09:40 +0000">
<p><tt>nodetool scrub sync</tt> finished on db1.sync.lati.osa and db5.sync.lati.osa. Just launched repair but it can take up to 10-12 hours before it crashes. Will keep you updated.</p>
</comment>
<comment id="14649575" author="mlowicki" created="Fri, 31 Jul 2015 18:09:19 +0000">
<p>Failed with the same error after ~13 hours:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [2015-07-31 16:57:43,909] Repair command #5 finished error: nodetool failed, check server logs -- StackTrace -- java.lang.RuntimeException: nodetool failed, check server logs at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:290) at org.apache.cassandra.tools.NodeTool.main(NodeTool.java:202) </pre> </div></div> <p>Log file - <a href="https://drive.google.com/file/d/0B_8mc_afWmd2OV96RDZBclRNSFE/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2OV96RDZBclRNSFE/view?usp=sharing</a>.</p> <p>Tried yesterday to run repair in another DC but got the same error.</p>
</comment>
<comment id="14652638" author="mlowicki" created="Mon, 3 Aug 2015 22:05:18 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> ping.</p>
</comment>
<comment id="14652648" author="yukim" created="Mon, 3 Aug 2015 22:17:33 +0000">
<p>Your log indicates validation error in /10.195.15.163 and /10.195.15.167.<br/> If errors in those nodes are the same as above, then you need to run scrub on those also.<br/> Are you using leveled compaciton strategy?</p>
</comment>
<comment id="14652680" author="mlowicki" created="Mon, 3 Aug 2015 22:29:56 +0000">
<p>Yes, I'm using LCS. I'll run scrub on these nodes and then repair. Will let you know about the result.</p>
</comment>
<comment id="14654169" author="mlowicki" created="Tue, 4 Aug 2015 19:05:21 +0000">
<p>Just finished running <tt>nodetool scrub</tt> on all nodes in single DC (took ~12 hours) and started repair.</p>
</comment>
<comment id="14654970" author="mlowicki" created="Wed, 5 Aug 2015 07:53:26 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> the same error after ~12 hours:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [2015-08-05 06:35:07,340] Repair session 18f8c020-3b3c-11e5-a93e-4963524a8bde <span class="code-keyword">for</span> range (-781874602493000830,-781745173070807746] finished[2015-08-05 06:35:07,340] Repair command #6 finished error: nodetool failed, check server logs-- StackTrace -- java.lang.RuntimeException: nodetool failed, check server logs at org.apache.cassandra.tools.NodeTool$NodeToolCmd.run(NodeTool.java:290) at org.apache.cassandra.tools.NodeTool.main(NodeTool.java:202) </pre> </div></div> <p>Logs from db1.sync.lati.osa (10.195.15.162) - <a href="https://drive.google.com/file/d/0B_8mc_afWmd2LWcxRWRPWTFnMlk/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2LWcxRWRPWTFnMlk/view?usp=sharing</a> <br/> Logs from db4.sync.lati.osa (10.195.15.167) - <a href="https://drive.google.com/file/d/0B_8mc_afWmd2ejVnR24tVm5OZUk/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2ejVnR24tVm5OZUk/view?usp=sharing</a></p>
</comment>
<comment id="14658865" author="yukim" created="Wed, 5 Aug 2015 20:35:55 +0000">
<p>Thanks.<br/> Hmm, do you still have logs when running nodetool scrub?<br/> Did it detect out of order rows in any SSTable?</p>
</comment>
<comment id="14658878" author="mlowicki" created="Wed, 5 Aug 2015 20:40:47 +0000">
<p>It didn't print anything to the console on all nodes. I can grep through system.log or attach logs from each box if this helps?</p>
</comment>
<comment id="14659666" author="mlowicki" created="Thu, 6 Aug 2015 08:12:25 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> I've launched repair in 2nd DC to get more logs from repair - <a href="https://gist.github.com/mlowicki/43e3074f46f12737577e" class="external-link" rel="nofollow">https://gist.github.com/mlowicki/43e3074f46f12737577e</a>.</p> <p>I've found two exceptions:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [2015-08-06 03:03:33,231] Repair session d4f0d420-3baa-11e5-9ec3-75bb514ae072 <span class="code-keyword">for</span> range (-1449999620433819156,-1424504876804571443] failed with error org.apache.cassandra.exceptions.RepairException: [repair #d4f0d420-3baa-11e5-9ec3-75bb514ae072 on sync/entity2, (-1449999620433819156,-1424504876804571443]] Validation failed in /10.210.3.162 </pre> </div></div> <p>and</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [2015-08-06 03:03:33,239] Repair session 967ca730-3bb1-11e5-9ec3-75bb514ae072 <span class="code-keyword">for</span> range (3125697280560263437,3131751716701120659] failed with error org.apache.cassa ndra.exceptions.RepairException: [repair #967ca730-3bb1-11e5-9ec3-75bb514ae072 on sync/entity_by_id2, (3125697280560263437,3131751716701120659]] Validation failed in /10.210.3.221 </pre> </div></div> <p>10.210.3.162 = db6.sync.ams.osa<br/> 10.210.3.221 = db1.sync.ams.osa</p> <p>Repair was started on db1.sync.ams.osa.</p> <p>I see no errors on db6.sync.ams.osa in system.log starting from 2015-08-06 00:24:16,322 to 2015-08-06 08:04:58,283 (no "ERROR" string there).</p> <p>On db1.sync.ams.osa I've found two errors - <a href="https://gist.github.com/mlowicki/3bf39f9f9ad0d4e202e5" class="external-link" rel="nofollow">https://gist.github.com/mlowicki/3bf39f9f9ad0d4e202e5</a>.</p> <p>I've launched <tt>nodetool scrub</tt> on db6.sync.ams.osa and will send logs when finish.</p>
</comment>
<comment id="14660075" author="mlowicki" created="Thu, 6 Aug 2015 14:21:05 +0000">
<p>Logs from db6.sync.ams.osa where scrub was started - <a href="https://drive.google.com/file/d/0B_8mc_afWmd2NjZXZGJRRnI4TzA/view?usp=sharing" class="external-link" rel="nofollow">https://drive.google.com/file/d/0B_8mc_afWmd2NjZXZGJRRnI4TzA/view?usp=sharing</a></p>
</comment>
<comment id="14681935" author="mlowicki" created="Tue, 11 Aug 2015 15:21:39 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> any updates?</p>
</comment>
<comment id="14731416" author="mlowicki" created="Fri, 4 Sep 2015 21:03:39 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> I've launched repair for all keyspaces <tt>nodetool repair --in-local-dc --parallel</tt>. #1 was for "OpsCenter", #2 for sync which is mentioned above in this thread, #3 for system_traces. Part of the output in <a href="https://cpaste.org/plvyleda5" class="external-link" rel="nofollow">https://cpaste.org/plvyleda5</a>. Interesting it says:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> [2015-09-04 18:07:55,588] Repair command #2 finished </pre> </div></div> <p>Maybe the problem with assertion error is while outputting results as repair for sync keyspace always fails after similar time period?</p>
</comment>
<comment id="14731492" author="yukim" created="Fri, 4 Sep 2015 21:52:18 +0000">
<p>So your repair finally succeeded?</p> <blockquote><p>Maybe the problem with assertion error is while outputting results as repair for sync keyspace always fails after similar time period?</p></blockquote> <p>That assertion error happens when creating Merkle Tree from group of SSTables.<br/> It can be from unordered SSTable that happened sometime before, or LCS bug that used to allow overlapping within the level (<a href="https://issues.apache.org/jira/browse/CASSANDRA-8211" title="Overlapping sstables in L1+" class="issue-link" data-issue-key="CASSANDRA-8211"><del>CASSANDRA-8211</del></a>).<br/> The former can be checked with <tt>scrub</tt>, but the log you attached before did not show unordered SSTable.<br/> The latter may be fixed by restarting the node.</p>
</comment>
<comment id="14731811" author="mlowicki" created="Sat, 5 Sep 2015 05:27:40 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> how can I detect that repair succeeded?</p> <p>We've restarted all nodes couple of days ago so it didn't helped.</p>
</comment>
<comment id="15025314" author="mlowicki" created="Tue, 24 Nov 2015 20:36:31 +0000">
<p>Launched repair and got the same exception after couple of days but grepped through logs and found:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-7155] 2015-11-24 17:38:24,895 StorageService.java:2999 - Repair session 3c9f7d40-8e19-11e5-bda4-0d9c8928349f <span class="code-keyword">for</span> range (-1741218705797202342,-1741060704162047213] failed with error java.io.IOException: Failed during snapshot creation. java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: Failed during snapshot creation. at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: java.io.IOException: Failed during snapshot creation. at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: java.io.IOException: Failed during snapshot creation. at org.apache.cassandra.repair.RepairSession.failedSnapshot(RepairSession.java:344) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairJob$2.onFailure(RepairJob.java:146) ~[apache-cassandra-2.1.11.jar:2.1.11] at com.google.common.util.concurrent.Futures$4.run(Futures.java:1172) ~[guava-16.0.jar:na] ... 3 common frames omitted </pre> </div></div> <p>Additionally:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-7155] 2015-11-24 17:38:24,907 StorageService.java:2999 - Repair session b55b4930-8e73-11e5-bda4-0d9c8928349f <span class="code-keyword">for</span> range (5801873202797297113,5802832998541920530] failed with error org.apache.cassandra.exceptions.RepairException: [repair #b55b4930-8e73-11e5-bda4-0d9c8928349f on sync/entity2, (5801873202797297113,5802832998541920530]] Validation failed in /10.195.15.167 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #b55b4930-8e73-11e5-bda4-0d9c8928349f on sync/entity2, (5801873202797297113,5802832998541920530]] Validation failed in /10.195.15.167 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #b55b4930-8e73-11e5-bda4-0d9c8928349f on sync/entity2, (5801873202797297113,5802832998541920530]] Validation failed in /10.195.15.167 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #b55b4930-8e73-11e5-bda4-0d9c8928349f on sync/entity2, (5801873202797297113,5802832998541920530]] Validation failed in /10.195.15.167 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <p>10.195.15.167 is the one where I've started repair...</p>
</comment>
<comment id="15025417" author="yukim" created="Tue, 24 Nov 2015 21:13:55 +0000">
<p>Those two have different repair session ID.<br/> Can you grep logs on other replica with those ID and see if there are ERROR log?</p>
</comment>
<comment id="15025432" author="mlowicki" created="Tue, 24 Nov 2015 21:19:08 +0000">
<p>Didn't found these session IDs on other nodes:</p> <ul> <li><a href="https://www.dropbox.com/s/qtx5rzmqzl9zj47/Screenshot%202015-11-24%2022.22.03.png?dl=0" class="external-link" rel="nofollow">https://www.dropbox.com/s/qtx5rzmqzl9zj47/Screenshot%202015-11-24%2022.22.03.png?dl=0</a></li> <li><a href="https://www.dropbox.com/s/o7k0cfhscd1au50/Screenshot%202015-11-24%2022.22.19.png?dl=0" class="external-link" rel="nofollow">https://www.dropbox.com/s/o7k0cfhscd1au50/Screenshot%202015-11-24%2022.22.19.png?dl=0</a></li> </ul>
</comment>
<comment id="15025455" author="yukim" created="Tue, 24 Nov 2015 21:30:37 +0000">
<p>Is there a chance that older contains those?</p>
</comment>
<comment id="15025516" author="mlowicki" created="Tue, 24 Nov 2015 21:58:17 +0000">
<p>Nothing found. Checked system.log.1.zip from /var/log/cassandra on each box but only on db8.lati (where repair started) found those session IDs.</p>
</comment>
<comment id="15030436" author="mlowicki" created="Sat, 28 Nov 2015 08:59:37 +0000">
<p>Tried to run repair once again after online scrub and cleanup on all nodes. Failed with the same error. This is what I've found in logs:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [ValidationExecutor:1089] 2015-11-28 04:33:15,865 Validator.java:245 - Failed creating a merkle tree <span class="code-keyword">for</span> [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]], /10.210.3.221 (see log <span class="code-keyword">for</span> details) ERROR [ValidationExecutor:1089] 2015-11-28 04:33:15,866 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[ValidationExecutor:1089,1,main] java.lang.AssertionError: row DecoratedKey(-6842806631972123001, 00093238333134323933320000040000c3c700) received out of order wrt DecoratedKey(-6841074726771668561, 00093231363735323034340000040000c3c700) at org.apache.cassandra.repair.Validator.add(Validator.java:127) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1010) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:622) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] ERROR [AntiEntropySessions:1957] 2015-11-28 04:33:15,868 RepairSession.java:303 - [repair #0f9c5530-9589-11e5-b036-75bb514ae072] session completed with the following error org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [AntiEntropySessions:1957] 2015-11-28 04:33:15,869 CassandraDaemon.java:227 - Exception in thread <span class="code-object">Thread</span>[AntiEntropySessions:1957,5,RMI <span class="code-object">Runtime</span>] java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,350 StorageService.java:2999 - Repair session 93837260-92fb-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-6012485790753833422,-6009995015166063234] failed with error org.apache.cassandra.exceptions.RepairException: [repair #93837260-92fb-11e5-b036-75bb514ae072 on sync/entity2, (-6012485790753833422,-6009995015166063234]] Validation failed in /10.210.3.118 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #93837260-92fb-11e5-b036-75bb514ae072 on sync/entity2, (-6012485790753833422,-6009995015166063234]] Validation failed in /10.210.3.118 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #93837260-92fb-11e5-b036-75bb514ae072 on sync/entity2, (-6012485790753833422,-6009995015166063234]] Validation failed in /10.210.3.118 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #93837260-92fb-11e5-b036-75bb514ae072 on sync/entity2, (-6012485790753833422,-6009995015166063234]] Validation failed in /10.210.3.118 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,404 StorageService.java:2999 - Repair session 89fa2b70-933d-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-5867793819051725444,-5865919628027816979] failed with error org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #89fa2b70-933d-11e5-b036-75bb514ae072 on sync/entity_by_id2, (-5867793819051725444,-5865919628027816979]] Validation failed in /10.210.3.117 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,446 StorageService.java:2999 - Repair session 3ff36a20-9372-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (8066543735336862962,8074446636728465478] failed with error java.io.IOException: Endpoint /10.210.3.230 died java.util.concurrent.ExecutionException: java.lang.RuntimeException: java.io.IOException: Endpoint /10.210.3.230 died at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: java.io.IOException: Endpoint /10.210.3.230 died at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: java.io.IOException: Endpoint /10.210.3.230 died at org.apache.cassandra.repair.RepairSession.failedNode(RepairSession.java:351) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairSession.convict(RepairSession.java:386) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.gms.FailureDetector.interpret(FailureDetector.java:276) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.gms.Gossiper.doStatusCheck(Gossiper.java:758) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.gms.Gossiper.access$800(Gossiper.java:66) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.gms.Gossiper$GossipTask.run(Gossiper.java:180) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.concurrent.DebuggableScheduledThreadPoolExecutor$UncomplainingRunnable.run(DebuggableScheduledThreadPoolExecutor.java:118) ~[apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:304) [na:1.7.0_80] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:178) ~[na:1.7.0_80] at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293) ~[na:1.7.0_80] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,555 StorageService.java:2999 - Repair session 72d57040-943b-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-2928915626059257529,-2921716383005026147] failed with error org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #72d57040-943b-11e5-b036-75bb514ae072 on sync/entity2, (-2928915626059257529,-2921716383005026147]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,687 StorageService.java:2999 - Repair session e9f771a0-94fe-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-2890799998431679809,-2889623741271856504] failed with error org.apache.cassandra.exceptions.RepairException: [repair #e9f771a0-94fe-11e5-b036-75bb514ae072 on sync/entity2, (-2890799998431679809,-2889623741271856504]] Validation failed in /10.210.3.221 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #e9f771a0-94fe-11e5-b036-75bb514ae072 on sync/entity2, (-2890799998431679809,-2889623741271856504]] Validation failed in /10.210.3.221 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #e9f771a0-94fe-11e5-b036-75bb514ae072 on sync/entity2, (-2890799998431679809,-2889623741271856504]] Validation failed in /10.210.3.221 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #e9f771a0-94fe-11e5-b036-75bb514ae072 on sync/entity2, (-2890799998431679809,-2889623741271856504]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,766 StorageService.java:2999 - Repair session 0f9c5530-9589-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-6842825601551036942,-6841068234348096268] failed with error org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_80] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_80] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2990) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.7.0_80] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.11.jar:2.1.11] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_80] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_80] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_80] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #0f9c5530-9589-11e5-b036-75bb514ae072 on sync/entity2, (-6842825601551036942,-6841068234348096268]] Validation failed in /10.210.3.221 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.11.jar:2.1.11] ... 3 common frames omitted </pre> </div></div> <p>Repair failed between 08:00 and 08:40.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ERROR [<span class="code-object">Thread</span>-6628] 2015-11-28 08:17:03,446 StorageService.java:2999 - Repair session 3ff36a20-9372-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (8066543735336862962,8074446636728465478] failed with error java.io.IOException: Endpoint /10.210.3.230 died </pre> </div></div> <p>Is interesting but I haven't found more about it in logs (Attached logs from box where I've started repair - 10.210.3.221 and 10.210.3.230).</p> <p>If started repair for one of failed ranges then it works fine:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> root@db1:~# time nodetool repair --in-local-dc -st -2890799998431679809 -et -2889623741271856504 sync entity2 [2015-11-28 08:36:41,736] Starting repair command #5, repairing 1 ranges <span class="code-keyword">for</span> keyspace sync (parallelism=SEQUENTIAL, full=<span class="code-keyword">true</span>) [2015-11-28 08:37:48,286] Repair session 26483200-95ab-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (-2890799998431679809,-2889623741271856504] finished [2015-11-28 08:37:48,286] Repair command #5 finished real 1m8.393s user 0m2.620s sys 0m0.184s </pre> </div></div>
</comment>
<comment id="15030439" author="mlowicki" created="Sat, 28 Nov 2015 09:05:56 +0000">
<p>Also If I run repair for range where got this "Endpoint X died" it works fine:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> root@db1:~# time nodetool repair --in-local-dc -st 8066543735336862962 -et 8074446636728465478 [2015-11-28 08:55:19,048] Nothing to repair <span class="code-keyword">for</span> keyspace 'system' [2015-11-28 08:55:19,069] Starting repair command #6, repairing 1 ranges <span class="code-keyword">for</span> keyspace OpsCenter (parallelism=SEQUENTIAL, full=<span class="code-keyword">true</span>) [2015-11-28 08:55:19,176] Repair command #6 finished [2015-11-28 08:55:19,188] Starting repair command #7, repairing 1 ranges <span class="code-keyword">for</span> keyspace sync (parallelism=SEQUENTIAL, full=<span class="code-keyword">true</span>) [2015-11-28 09:03:49,529] Repair session c054ec60-95ad-11e5-b036-75bb514ae072 <span class="code-keyword">for</span> range (8066543735336862962,8074446636728465478] finished [2015-11-28 09:03:49,529] Repair command #7 finished [2015-11-28 09:03:49,544] Starting repair command #8, repairing 1 ranges <span class="code-keyword">for</span> keyspace system_traces (parallelism=SEQUENTIAL, full=<span class="code-keyword">true</span>) [2015-11-28 09:03:49,562] Repair command #8 finished real 8m32.356s user 0m2.784s sys 0m0.224s </pre> </div></div>
</comment>
<comment id="15031827" author="mlowicki" created="Mon, 30 Nov 2015 14:25:54 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a>: any chance this is related to network issues? During the weekend I've monitored it carefully and repair failed at the same time I see drop in number of requests sent to C* cluster in this datacenter. I've decided to run repair for smaller tables where it takes 1-4 hours to complete and it happened once (launched on 6 nodes) also when such drop appears.</p> <p>Tried 2nd time and now it works (and I don't see any anomalies in metrics).</p>
</comment>
<comment id="15134437" author="jfgosselin" created="Fri, 5 Feb 2016 16:45:49 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> We are also seeing this issue in our multi datacenters cluster (3 DCs), C* 2.1.9 (and using LCS). We ran nodetool scrub on all the nodes but the error keeps coming back . </p> <p>We did have some network glitch, as <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mlowicki" class="user-hover" rel="mlowicki">mlowicki</a> was saying, can it be related to network issues ? </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ERROR [ValidationExecutor:5884] 2016-02-03 09:27:41,703 Validator.java:245 - Failed creating a merkle tree for [repair #a8f3f040-ca58-11e5-9dda-130298de45de on keyspace1/xyz, (5126461213031423923,5128334161692376535]], /10.174.216.163 (see log for details) ERROR [ValidationExecutor:5884] 2016-02-03 09:27:41,704 CassandraDaemon.java:223 - Exception in thread Thread[ValidationExecutor:5884,1,main] java.lang.AssertionError: row DecoratedKey(5126475305931285312, 00103cee13c2c0ea38328138fcad86515eef0000250233636565313363322d633065612d333833322d383133382d6663616438363531356565660000105cc950f02b6239f0bf9af60ac7dd452400) received out of order wrt DecoratedKey(5128167525973821686, 00105fe2e7db8810387a9a2955a07ecfa7d30000250235666532653764622d383831302d333837612d396132392d353561303765636661376433000010f64b1c2b7d1c3ff893b70c24c5dbdc6b00) at org.apache.cassandra.repair.Validator.add(Validator.java:126) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1003) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:615) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] </pre> </div></div>
</comment>
<comment id="15141000" author="yukim" created="Wed, 10 Feb 2016 15:30:12 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jfgosselin" class="user-hover" rel="jfgosselin">Jean-Francois Gosselin</a><br/> If LCS is the cause of out of order, you will see WARN message like following on start up or scrub:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>At level x, /data/foo/bar/xxx.db [xxxx, xxxx] overlaps /data/foo/bar/yyy.db [yyyy, yyyy]. ... </pre> </div></div> <p>Can you confirm if this is the case?</p>
</comment>
<comment id="15141245" author="jfgosselin" created="Wed, 10 Feb 2016 17:26:42 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> The WARN message should be in the C* log or on the stdout of nodetool ?</p>
</comment>
<comment id="15141274" author="yukim" created="Wed, 10 Feb 2016 17:39:54 +0000"><p>It is in C* log.</p></comment>
<comment id="15141341" author="jfgosselin" created="Wed, 10 Feb 2016 18:09:44 +0000">
<p>No, we haven't seen this WARN. The only thing we haven't tried is a node restart (based on you comment above " ... The latter may be fixed by restarting the node." ) . Although I'm not sure it will fix the problem since we've used C* 2.1.9 from the beginning.</p>
</comment>
<comment id="15143270" author="jfgosselin" created="Thu, 11 Feb 2016 18:58:53 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> Yesterday we ran nodetool scrub on all the nodes and restarted the nodes. No luck we're still getting "received out of order wrt DecoratedKey" . Any suggestions for the next step ?</p>
</comment>
<comment id="15143307" author="jfgosselin" created="Thu, 11 Feb 2016 19:18:22 +0000">
<p>Here's a new one with no clear message from the exception :</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>INFO [AntiEntropyStage:1] 2016-02-11 17:21:20,947 RepairSession.java:171 - [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b] Received merkle tree for bar from /10.53.10.30 ERROR [AntiEntropySessions:28] 2016-02-11 17:21:21,033 RepairSession.java:303 - [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b] session completed with the following error org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] ERROR [AntiEntropySessions:28] 2016-02-11 17:21:21,034 CassandraDaemon.java:223 - Exception in thread Thread[AntiEntropySessions:28,5,RMI Runtime] java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_65] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] Caused by: org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.9.jar:2.1.9] ... 3 common frames omitted ERROR [Thread-20728] 2016-02-11 17:21:21,034 StorageService.java:2966 - Repair session d78e02b0-d0e3-11e5-a04a-4ffa10ef584b for range (-5525881226490706160,-5525442713957813067] failed with error org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 java.util.concurrent.ExecutionException: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at java.util.concurrent.FutureTask.report(FutureTask.java:122) [na:1.7.0_65] at java.util.concurrent.FutureTask.get(FutureTask.java:188) [na:1.7.0_65] at org.apache.cassandra.service.StorageService$4.runMayThrow(StorageService.java:2957) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) [apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_65] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] Caused by: java.lang.RuntimeException: org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at com.google.common.base.Throwables.propagate(Throwables.java:160) ~[guava-16.0.jar:na] at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:32) [apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_65] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) ~[na:1.7.0_65] ... 1 common frames omitted Caused by: org.apache.cassandra.exceptions.RepairException: [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]] Validation failed in /172.16.63.39 at org.apache.cassandra.repair.RepairSession.validationComplete(RepairSession.java:166) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.service.ActiveRepairService.handleMessage(ActiveRepairService.java:406) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.repair.RepairMessageVerbHandler.doVerb(RepairMessageVerbHandler.java:134) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:64) ~[apache-cassandra-2.1.9.jar:2.1.9] ... 3 common frames omitted INFO [STREAM-IN-/10.53.10.29] 2016-02-11 17:21:21,056 StreamResultFuture.java:180 - [Stream #dccd16d2-d0e3-11e5-a04a-4ffa10ef584b] Session with /10.53.10.29 is complete INFO [STREAM-IN-/10.53.10.29] 2016-02-11 17:21:21,056 StreamResultFuture.java:212 - [Stream #dccd16d2-d0e3-11e5-a04a-4ffa10ef584b] All sessions completed </pre> </div></div>
</comment>
<comment id="15143323" author="yukim" created="Thu, 11 Feb 2016 19:30:44 +0000"><p>What is the error in /172.16.63.39?</p></comment>
<comment id="15143400" author="jfgosselin" created="Thu, 11 Feb 2016 20:01:59 +0000">
<p>Ok from 172.16.63.39, same error "received out of order wrt DecoratedKey" :</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ERROR [ValidationExecutor:118] 2016-02-11 17:21:27,512 Validator.java:245 - Failed creating a merkle tree for [repair #d78e02b0-d0e3-11e5-a04a-4ffa10ef584b on foo/bar, (-5525881226490706160,-5525442713957813067]], /10.174.216.158 (see log for details) ERROR [ValidationExecutor:118] 2016-02-11 17:21:27,516 CassandraDaemon.java:223 - Exception in thread Thread[ValidationExecutor:118,1,main] java.lang.AssertionError: row DecoratedKey(-5525725068665570338, 0010e3a74bf82717394598e2b7421c89382e0000250265336137346266382d323731372d333934352d393865322d623734323163383933383265000010f64b1c2b7d1c3ff893b70c24c5dbdc6b00) received out of order wrt DecoratedKey(-5525444669477674618, 0010581499f0b99337e1bf468611fd0233e40000250235383134393966302d623939332d333765312d626634362d383631316664303233336534000010f64b1c2b7d1c3ff893b70c24c5dbdc6b00) at org.apache.cassandra.repair.Validator.add(Validator.java:126) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.doValidationCompaction(CompactionManager.java:1003) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager.access$600(CompactionManager.java:94) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager$9.call(CompactionManager.java:615) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_65] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_65] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_65] </pre> </div></div>
</comment>
<comment id="15145336" author="jfgosselin" created="Fri, 12 Feb 2016 21:27:51 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> What's the next step to troubleshoot this issue ? Any specific log we could enable at DEBUG ?</p>
</comment>
<comment id="15154700" author="yukim" created="Fri, 19 Feb 2016 19:16:58 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jfgosselin" class="user-hover" rel="jfgosselin">Jean-Francois Gosselin</a> Just want to check, how are you running repair?<br/> What repair options are you using?<br/> Have you run incremental repair?</p>
</comment>
<comment id="15154789" author="jfgosselin" created="Fri, 19 Feb 2016 20:06:33 +0000">
<p>We are doing range repair with <a href="https://github.com/spotify/cassandra-reaper" class="external-link" rel="nofollow">https://github.com/spotify/cassandra-reaper</a> . We don't use incremental repair . We also see the issue with : nodetool repair -pr</p>
</comment>
</comments>
<attachments>
<attachment id="12747940" name="db1.sync.lati.osa.cassandra.log" size="9245169" author="mlowicki" created="Thu, 30 Jul 2015 07:43:44 +0000"/>
<attachment id="12748031" name="db5.sync.lati.osa.cassandra.log" size="3883298" author="mlowicki" created="Thu, 30 Jul 2015 17:14:08 +0000"/>
<attachment id="12774702" name="system.log.10.210.3.117" size="13490013" author="mlowicki" created="Sat, 28 Nov 2015 08:59:31 +0000"/>
<attachment id="12774700" name="system.log.10.210.3.221" size="19935112" author="mlowicki" created="Sat, 28 Nov 2015 08:53:19 +0000"/>
<attachment id="12774701" name="system.log.10.210.3.230" size="14600943" author="mlowicki" created="Sat, 28 Nov 2015 08:53:19 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>5.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 30 Jul 2015 16:13:28 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2i40v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9753] LOCAL_QUORUM reads can block cross-DC if there is a digest mismatch
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9753
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When there is a digest mismatch during the initial read, a data read request is sent to all replicas involved in the initial read. This can be more than the initial blockFor if read repair was done and if speculative retry kicked in. E.g. for RF 3 in two DCs, the number of reads could be 4: 2 for LOCAL_QUORUM, 1 for read repair and 1 for speculative read if one replica was slow. If there is then a digest mismatch, Cassandra will issue the data read to all 4 and set blockFor=4. Now the read query is blocked on cross-DC latency. The digest mismatch read blockFor should be capped at RF for the local DC when using CL.LOCAL_*.</p> <p>You can reproduce this behaviour by creating a keyspace with NetworkTopologyStrategy, RF 3 per DC, dc_local_read_repair=1.0 and ALWAYS for speculative read. If you force a digest mismatch (e.g. by deleting a replicas SSTables and restarting) you can see in tracing that it is blocking for 4 responses.</p>
</description>
<environment/>
<key id="12843312">CASSANDRA-9753</key>
<summary>
LOCAL_QUORUM reads can block cross-DC if there is a digest mismatch
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rlow">Richard Low</reporter>
<labels></labels>
<created>Tue, 7 Jul 2015 21:27:02 +0000</created>
<updated>Thu, 12 Nov 2015 17:42:51 +0000</updated>
<due/>
<votes>2</votes>
<watches>12</watches>
<comments>
<comment id="14642031" author="pauloricardomg" created="Sun, 26 Jul 2015 17:13:53 +0000">
<p>What is the <tt>read_repair_chance</tt> (<b>NOT</b> <tt>dc_local_read_repair</tt>) ? If &gt; 0, then maybe that's a duplicate of <a href="https://issues.apache.org/jira/browse/CASSANDRA-8479" class="external-link" rel="nofollow">8479</a>, because currently the <tt>read_repair_chance</tt> is orthogonal to consistency level and may cross DC boundaries even if CL is LOCAL_*. You may be interested in the discussion of <a href="https://issues.apache.org/jira/browse/CASSANDRA-6887" class="external-link" rel="nofollow">CASSANDRA-6887</a> to change that behavior.</p>
</comment>
<comment id="14642264" author="kohlisankalp" created="Mon, 27 Jul 2015 05:08:17 +0000">
<p>I think this is a little different. In <a href="https://issues.apache.org/jira/browse/CASSANDRA-6887" title="LOCAL_ONE read repair only does local repair, in spite of global digest queries" class="issue-link" data-issue-key="CASSANDRA-6887">CASSANDRA-6887</a>, they are discussing about global read repair chance vs CL of LOCAL*. In this, even when we are using dc_local_read_repair and a LOCAL consistency level, it is still blocking. The reason is that speculative retry is getting mixed here. </p>
</comment>
<comment id="14642825" author="rlow" created="Mon, 27 Jul 2015 15:00:56 +0000">
<p>I agree with Sankalp. This is with read_repair_chance = 0.</p>
</comment>
<comment id="14642835" author="pauloricardomg" created="Mon, 27 Jul 2015 15:09:22 +0000">
<p>Agreed, thanks for the clarification. Then I guess that's the problem mentioned by <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey" class="user-hover" rel="iamaleksey">Aleksey Yeschenko</a> and confirmed by <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a> in that thread.</p> <blockquote><p>1. LOCAL_* requests will potentially use a replica from another DC for an eager retry</p></blockquote>
</comment>
<comment id="14642881" author="rlow" created="Mon, 27 Jul 2015 15:36:27 +0000">
<p>Using a remote replica for an eager retry is fine, but blocking on it for a later digest mismatch read is not.</p>
</comment>
<comment id="14642883" author="rlow" created="Mon, 27 Jul 2015 15:37:36 +0000">
<p>Actually I take that back. It's not fine, since it could violate local DC consistency. So fixing by avoiding any reads to remote DCs for eager retries would fix this too.</p>
</comment>
<comment id="14737396" author="tomvandenberge" created="Wed, 9 Sep 2015 18:49:38 +0000">
<p>I was setting up a new DC, and noticed that other DCs were sending read queries to this DC, even though clients did not connect to the new DC, and all queries were using LOCAL_* consistency. This bug proved to be the cause of this problem.</p> <p>I was able to work around it by disabling speculative_retry on all tables:<br/> alter table &lt;table&gt; with speculative_retry='NONE';</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12702346">CASSANDRA-6887</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sun, 26 Jul 2015 17:13:53 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gyjj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12327942</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9822] Debian/Ubuntu init script status says that Cassandra is not running when it actually is
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9822
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The reason: The current CMD_PATT regex can't match very long command lines.</p> <p>If a lot of Java options are used (thus causing the command line for Cassandra to be very long) the value of /proc/PID/cmdline is truncated before the phrase "CassandraDaemon" (at exactly 4096 characters) so the regex "cassandra.+CassandraDaemon" fails to match.</p>
</description>
<environment><p>Any Ubuntu/Debian system</p></environment>
<key id="12845332">CASSANDRA-9822</key>
<summary>
Debian/Ubuntu init script status says that Cassandra is not running when it actually is
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="eherot">Eric Herot</reporter>
<labels></labels>
<created>Wed, 15 Jul 2015 17:45:11 +0000</created>
<updated>Thu, 19 Nov 2015 15:46:34 +0000</updated>
<component>Packaging</component>
<due/>
<votes>1</votes>
<watches>5</watches>
<comments>
<comment id="14628463" author="jbellis" created="Wed, 15 Jul 2015 18:03:20 +0000">
<p>/cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mshuler" class="user-hover" rel="mshuler">Michael Shuler</a></p>
</comment>
<comment id="14628522" author="mshuler" created="Wed, 15 Jul 2015 18:40:44 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=eherot" class="user-hover" rel="eherot">Eric Herot</a> what version of Cassandra is this? I recall a long process line classpath env fix along the way at some point, but I'm not sure which version/branch.</p>
</comment>
<comment id="14628584" author="eherot" created="Wed, 15 Jul 2015 19:30:22 +0000">
<p>The basic code in question still seemed to be there in the 2.1 and 2.2 master branches on git.apache.com, although if there is a more esoteric fix somewhere else in the init script I may not have noticed it. We are observing the problem in 2.1.8 on Ubuntu 14.04.2 LTS.</p>
</comment>
<comment id="14643883" author="dallinb" created="Tue, 28 Jul 2015 05:47:23 +0000">
<p>We experienced the problem with both 2.1 and 2.2 (package installs) on Ubuntu 12.04 and 14.04. As a temporary workaround, changed the search string from "cassandra.+CassandraDaemon" to simply "cassandra" and the service status command worked as expected.</p>
</comment>
<comment id="14645693" author="timw" created="Wed, 29 Jul 2015 08:28:12 +0000">
<p>The 4096 is the value of <tt>PAGE_SIZE</tt> (<tt>getconf PAGE_SIZE</tt> to check), which is the limit of the command line reported in <tt>/proc/&lt;pid&gt;/cmdline</tt>. <br/> Changing PAGE_SIZE requires a kernel recompile, so the method of checking the Cassandra process will probably need tweaking.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 15 Jul 2015 18:03:20 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2hamn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9766] Bootstrap outgoing streaming speeds are much slower than during repair
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9766
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have a cluster in Amazon cloud , its described in detail in the attachment. What I've noticed is that we during bootstrap we never go above 12MB/sec transmission speeds and also those speeds flat line almost like we're hitting some sort of a limit ( this remains true for other tests that I've ran) however during the repair we see much higher,variable sending rates. I've provided network charts in the attachment as well . Is there an explanation for this? Is something wrong with my configuration, or is it a possible bug?</p>
</description>
<environment>
<p>Cassandra 2.1.2. more details in the pdf attached </p>
</environment>
<key id="12843761">CASSANDRA-9766</key>
<summary>
Bootstrap outgoing streaming speeds are much slower than during repair
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="4x31">Alexei K</reporter>
<labels></labels>
<created>Thu, 9 Jul 2015 05:13:34 +0000</created>
<updated>Tue, 16 Feb 2016 21:27:32 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>0</votes>
<watches>6</watches>
<comments>
<comment id="14630097" author="yukim" created="Thu, 16 Jul 2015 18:06:53 +0000">
<p>Are you using vnodes?<br/> Do you use secondary indexes heavily?</p>
</comment>
<comment id="14630690" author="4x31" created="Fri, 17 Jul 2015 02:51:32 +0000">
<p>Hi Yuki,<br/> Yes we are using vnodes, and no we don't use Cassandra indexes at all.</p>
</comment>
<comment id="14903459" author="yukim" created="Tue, 22 Sep 2015 21:21:59 +0000">
<p>Sorry for late update.<br/> I think I found the bottle neck.</p> <p>To make sure:</p> <p>Are you using SSTable compression?<br/> What is the range of SSTable size?<br/> How large is your partition?</p> <p>When reading compressed data from network, receiving node buffers upto 1024 compressed chunks(compression chunk size is default 64kb), and putting into buffer can be blocked until read from buffer, decompress, calculate / update various stats and write received partition to SSTable files.<br/> (Block can happen here: <a href="https://github.com/apache/cassandra/blob/cassandra-2.1/src/java/org/apache/cassandra/streaming/compress/CompressedInputStream.java#L180" class="external-link" rel="nofollow">https://github.com/apache/cassandra/blob/cassandra-2.1/src/java/org/apache/cassandra/streaming/compress/CompressedInputStream.java#L180</a>)</p> <p>One possible solution is to change hardcoded buffer length to tunable using yaml or system property.</p>
</comment>
<comment id="14939129" author="jbellis" created="Thu, 1 Oct 2015 01:02:23 +0000">
<p>Is that actually a different path for bootstrap than repair, or do you think the reported behavior is inaccurate?</p>
</comment>
<comment id="14939147" author="yukim" created="Thu, 1 Oct 2015 01:33:55 +0000">
<p>Both does the same for compressed SSTables.<br/> Bootstrap can send whole SSTable which is much larger than receiving buffer, while repair sends only part of SSTable that is different.</p>
</comment>
<comment id="15149229" author="urandom" created="Tue, 16 Feb 2016 20:12:59 +0000">
<p>I'm seeing something similar here; I get an eerily consistent 4.5MB/s <em>per stream</em>, (much less than the stream throughput limit, and the capability of the network). We have large partitions, large SSTables, and a mixture of 256k and 512k chunk lengths.</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yukim" class="user-hover" rel="yukim">Yuki Morishita</a> what would be the best test of this, would <a href="https://gist.github.com/eevans/81f02849eab7634871c9" class="external-link" rel="nofollow">https://gist.github.com/eevans/81f02849eab7634871c9</a> do?</p>
</comment>
<comment id="15149333" author="urandom" created="Tue, 16 Feb 2016 21:27:32 +0000">
<p>So if I'm understanding this correctly (and I'm probably not), increasing the receiving buffer would get more of the data over the wire before blocking on the read from buffer, decompression, etc (up to however much the buffer was increased by). Is that right? If so, that wouldn't really help much; That would seem to imply that processing the compressed data is the bottleneck, and that the blocking is (rightfully) applying back-pressure to the network-side.</p>
</comment>
</comments>
<attachments>
<attachment id="12744409" name="problem.pdf" size="831215" author="4x31" created="Thu, 9 Jul 2015 05:13:34 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 16 Jul 2015 18:06:53 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2h19b:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12328841</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-9702] Repair running really slow</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9702
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>We're using 2.1.x since the very beginning and we always had problem with failing or slow repair. In one data center we aren't able to finish repair for many weeks (partially because <a href="https://issues.apache.org/jira/browse/CASSANDRA-9681" title="Memtable heap size grows and many long GC pauses are triggered" class="issue-link" data-issue-key="CASSANDRA-9681"><del>CASSANDRA-9681</del></a> as we needed to reboot nodes periodically).</p> <p>I've launched it today morning (12 hours now) and monitor using <a href="https://github.com/spotify/cassandra-opstools/blob/master/bin/spcassandra-repairstats" class="external-link" rel="nofollow">https://github.com/spotify/cassandra-opstools/blob/master/bin/spcassandra-repairstats</a>. For the first hour it progressed to 9.43% but then it took ~10 hours to reach 9.44%. I see very rarely logs related to repair (each 15-20 minutes but sometimes nothing new for 1 hour).</p> <p>Repair launched with:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> nodetool repair --partitioner-range --parallel --in-local-dc {keyspace} </pre> </div></div> <p>Attached log file from today.</p> <p>We've ~4.1TB of data in 12 nodes with RF set to 3 (2 DC with 6 nodes each).</p>
</description>
<environment><p>C* 2.1.7, Debian Wheezy</p></environment>
<key id="12842100">CASSANDRA-9702</key>
<summary>Repair running really slow</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mlowicki">mlowicki</reporter>
<labels></labels>
<created>Wed, 1 Jul 2015 20:36:48 +0000</created>
<updated>Fri, 30 Oct 2015 16:56:21 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<component>Streaming and Messaging</component>
<due/>
<votes>2</votes>
<watches>5</watches>
<comments>
<comment id="14611607" author="mlowicki" created="Thu, 2 Jul 2015 07:32:36 +0000">
<p>After another ~12 hours it progressed to 10.21%. 6 hours later it's 10.52%.</p>
</comment>
<comment id="14654981" author="mlowicki" created="Wed, 5 Aug 2015 08:01:41 +0000">
<p>After upgrade to 2.1.8 we're seeing <a href="https://issues.apache.org/jira/browse/CASSANDRA-9935" title="Repair fails with RuntimeException" class="issue-link" data-issue-key="CASSANDRA-9935">CASSANDRA-9935</a> instead.</p>
</comment>
</comments>
<attachments>
<attachment id="12743146" name="db1.system.log" size="8827728" author="mlowicki" created="Wed, 1 Jul 2015 20:36:48 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gr8f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332753</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9842] Inconsistent behavior for '= null' conditions on static columns
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9842
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Both inserting a row (in a non-existent partition) and updating a static column in the same LWT fails. Creating the partition before performing the LWT works.</p> <h3><a name="TableDefinition"></a>Table Definition</h3> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> create table txtable(pcol bigint, ccol bigint, scol bigint <span class="code-keyword">static</span>, ncol text, primary key((pcol), ccol)); </pre> </div></div> <h3><a name="InsertingrowinnonexistentpartitionandupdatingstaticcolumninoneLWT"></a>Inserting row in non-existent partition and updating static column in one LWT</h3> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> begin batch insert into txtable (pcol, ccol, ncol) values (1, 1, 'A'); update txtable set scol = 1 where pcol = 1 <span class="code-keyword">if</span> scol = <span class="code-keyword">null</span>; apply batch; [applied] ----------- False </pre> </div></div> <h3><a name="CreatingpartitionbeforeLWT"></a>Creating partition before LWT</h3> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> insert into txtable (pcol, scol) values (1, <span class="code-keyword">null</span>) <span class="code-keyword">if</span> not exists; begin batch insert into txtable (pcol, ccol, ncol) values (1, 1, 'A'); update txtable set scol = 1 where pcol = 1 <span class="code-keyword">if</span> scol = <span class="code-keyword">null</span>; apply batch; [applied] ----------- True </pre> </div></div>
</description>
<environment><p>cassandra-2.1.8 on Ubuntu 15.04</p></environment>
<key id="12846049">CASSANDRA-9842</key>
<summary>
Inconsistent behavior for '= null' conditions on static columns
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="blerer">Benjamin Lerer</assignee>
<reporter username="tuxychandru">Chandra Sekar</reporter>
<labels></labels>
<created>Sat, 18 Jul 2015 03:39:20 +0000</created>
<updated>Mon, 21 Dec 2015 17:17:04 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.0.x</fixVersion>
<fixVersion>3.x</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14632246" author="jbellis" created="Sat, 18 Jul 2015 03:44:39 +0000">
<p>Cassandra's behavior is correct, the partition not existing is not the same as existing with null value.</p>
</comment>
<comment id="14632247" author="tuxychandru" created="Sat, 18 Jul 2015 03:47:10 +0000">
<p>Yes, but in the first example, the "if" clause does say "if scol = null" and yet the batch fails.</p>
</comment>
<comment id="14632248" author="jbellis" created="Sat, 18 Jul 2015 03:48:56 +0000">
<p>The LWT clause is evaluated before the rest of the batch. Statement order doesn't matter.</p>
</comment>
<comment id="14632507" author="tuxychandru" created="Sat, 18 Jul 2015 16:33:03 +0000">
<p><b>Deleting</b> the <b>non-existent</b> partition before performing the above batch also works! Is that intended behavior too?</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> delete from txtable where pcol = 1; begin batch insert into txtable (pcol, ccol, ncol) values (1, 1, 'A'); update txtable set scol = 1 where pcol = 1 <span class="code-keyword">if</span> scol = <span class="code-keyword">null</span>; apply batch; [applied] ----------- True </pre> </div></div>
</comment>
<comment id="14633818" author="tuxychandru" created="Mon, 20 Jul 2015 16:47:49 +0000">
<p>The behaviour seen in <a href="https://issues.apache.org/jira/browse/CASSANDRA-9842?focusedCommentId=14632507&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14632507" class="external-link" rel="nofollow">my comment</a>, contradicts the expected behaviour described in <a href="https://issues.apache.org/jira/browse/CASSANDRA-9842?focusedCommentId=14632248&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14632248" class="external-link" rel="nofollow">Jonathan's comment</a>.</p>
</comment>
<comment id="15066724" author="slebresne" created="Mon, 21 Dec 2015 17:16:04 +0000">
<p>You're right, there is an inconsistency there.</p> <p>To sum it up, the problem is that if we update a static column <tt>sc</tt> with a <tt>IF sc == null</tt> condition, whether or not the condition is applied changes simply by the virtue of deleting a (already non existing) partition. That is, if a partition <tt>p</tt> doesn't pre-exist,</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>UPDATE t SET scol = 0 WHERE p = 0 IF scol = null </pre> </div></div> <p>is not applied, but</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>DELETE FROM t WHERE p = 0; UPDATE t SET scol = 0 WHERE p = 0 IF scol = null </pre> </div></div> <p>doesn't apply, even though the initial deletion should be a no-op for all intent and purposes.</p> <p>The question could then be which of those answer is the right one. And that's probably the first response: we do want to make a difference between a partition that exists but has no value for a specific static column and one that doesn't exist at all. We do make that difference in <tt>SELECT</tt> in particular so it would be inconsistent not to do it. I will note however that on 3.0, the result of those 2 examples is actually consistent, but it returns <tt>true</tt> in both case (while, as I argue before we kind of want to return <tt>false</tt> in both cases) and changing that will require a bit of special casing in the condition handling code.</p> <p>Lastly, I'll note that this problem is quite different from the initial problem for which the ticket was raised so I'll update the title to reflect that (as noted by Jonathan, the behavior in the ticket description is actually correct).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 18 Jul 2015 03:44:39 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2hewn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9783] 2.1-offheap compaction dtests fail
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9783
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>All compaction dtests fail because the generated files are too large (assertion failure). See <a href="http://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/117/testReport/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.1_offheap_dtest/117/testReport/</a><br/> The tests work fine in non-offheap configuration.</p>
</description>
<environment/>
<key id="12844456">CASSANDRA-9783</key>
<summary>2.1-offheap compaction dtests fail</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="snazy">Robert Stupp</reporter>
<labels></labels>
<created>Sun, 12 Jul 2015 16:44:45 +0000</created>
<updated>Sun, 12 Jul 2015 16:44:45 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2h5gf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9805] nodetool status causes garbage to be accrued
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9805
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>As part of monitoring our Cassandra clusters (generally 2-6 nodes) we were running `nodetool status` regularly (~ every 5 minutes). On Cassandra 1.2.12 this worked fine and had negligible effect on the Cassandra database service.</p> <p>Having upgraded to Cassandra 2.0.14, we've found that, over time, the tenured memory space slowly fills with `RMIConnectionImpl` objects (and some other associated objects) until we start running into memory pressure and triggering proactive and then STW GC (which obviously impact performance of the cluster). It seems that these objects are kept around long enough to get promoted to tenured from Eden and then don't get considered for collection (due to internal reference cycles?).</p> <p>Very easy to reproduce, just call `nodetool status` in a loop and watch the memory usage climb to capacity then drop to empty after STW. No need to be accessing the DB keys at all.</p>
</description>
<environment>
<p>Ubuntu 14.04 64-bit<br/> Cassandra 2.0.14<br/> Java 1.7.0 OpenJDK</p>
</environment>
<key id="12845020">CASSANDRA-9805</key>
<summary>nodetool status causes garbage to be accrued</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="boss_mc">Andy Caldwell</reporter>
<labels></labels>
<created>Tue, 14 Jul 2015 17:14:38 +0000</created>
<updated>Wed, 27 Jan 2016 14:45:56 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14626729" author="jbellis" created="Tue, 14 Jul 2015 17:34:03 +0000"><p>Are you sure it's STW and not just CMS?</p></comment>
<comment id="14626735" author="boss_mc" created="Tue, 14 Jul 2015 17:37:42 +0000">
<p>Not 100% sure, I was monitoring the memory usage and I saw a steadily climbing sawtooth (caused I assume by Eden collections) until the sawtooth hit the top of the heap space, at which point it flattened out for a bit (Cassandra's logs started talking about running low on Heap space and CPU usage climbed dramatically) and then, a little while later, the memory usage dropped to basically nothing (the DB was empty for this test), so I'm guessing it's one then the other?</p>
</comment>
<comment id="14709534" author="jbellis" created="Mon, 24 Aug 2015 16:15:01 +0000">
<p>That's an old gen collection but not necessarily STW. Status should generate pretty consistent allocations which CMS should be able to clean out.</p>
</comment>
<comment id="14999895" author="boss_mc" created="Wed, 11 Nov 2015 03:39:14 +0000">
<p>Further investigation (see the discussion in <a href="https://github.com/Metaswitch/clearwater-cassandra/issues/42" class="external-link" rel="nofollow">https://github.com/Metaswitch/clearwater-cassandra/issues/42</a>) suggests you are correct, and this is a CMS collection. Unfortunately, CMS is not very concurrent on a single-core machine (since the GC thread takes over a core during CMS and there's no other core to handle service load until the GC completes) so the GC is basically an outage. As I previously mentioned, in 1.2.12 we didn't see the steadily climbing memory usage, we only see it in 2.0 or 2.1 installs. This is making monitoring our Cassandra deployment more difficult as we can't afford to use nodetool.</p> <p>According to <a href="https://wiki.apache.org/cassandra/CassandraHardware" class="external-link" rel="nofollow">https://wiki.apache.org/cassandra/CassandraHardware</a>, you recommend running Cassandra on large machines (8-cores is your "sweet spot" for hardware) which would side step this problem mostly but you also recommend running on large EC2 instances which have only 2 cores (<a href="https://aws.amazon.com/ec2/instance-types/" class="external-link" rel="nofollow">https://aws.amazon.com/ec2/instance-types/</a>) and so will halve in capacity during a CMS. Do you have any advice on running Cassandra on machines with limited cores such that we can avoid/mitigate the costs of the garbage collector?</p>
</comment>
<comment id="15118207" author="yukim" created="Tue, 26 Jan 2016 22:38:24 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=boss_mc" class="user-hover" rel="boss_mc">Andy Caldwell</a> Are you using vnodes? (Fresh 2.0 cluster uses 256 vnodes per node by default, while 1.2 does not.)</p> <p><a href="https://issues.apache.org/jira/browse/CASSANDRA-7238" title="Nodetool Status performance is much slower with VNodes On" class="issue-link" data-issue-key="CASSANDRA-7238"><del>CASSANDRA-7238</del></a> will solve performance of <tt>nodetool status</tt>. Unfortunately, patch is for 2.1+.</p>
</comment>
<comment id="15119328" author="boss_mc" created="Wed, 27 Jan 2016 14:45:56 +0000">
<p>Yes, we are, we're using the default number. When we upgraded we migrated our deployments over to vnodes, and all new deployments have used vnodes too.</p> <p>The linked fix does sound related, once that patch lands we'll give the new build a go and see if the issue has been resolved.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 14 Jul 2015 17:34:03 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2h8t3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11270] sstablerepairedset loads CLASSPATH improperly (RHEL)
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11270
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When I try to run sstablerepairedset I get the following:<br/> Error: Could not find or load main class org.apache.cassandra.tools.SSTableRepairedAtSetter</p> <p>The tool seems to assume jar files are in <tt>`dirname $0`/../../lib/*.jar</tt> but the tool is in <tt>/usr/bin/</tt> so assembling the CLASSPATH appears to be the failure.</p>
</description>
<environment><p>Centos 6.7, Cassandra 2.2.5</p></environment>
<key id="12945126">CASSANDRA-11270</key>
<summary>
sstablerepairedset loads CLASSPATH improperly (RHEL)
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="dankinder">Dan Kinder</reporter>
<labels></labels>
<created>Sat, 27 Feb 2016 00:29:08 +0000</created>
<updated>Sat, 27 Feb 2016 00:29:08 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2tusv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12334272</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11272] NullPointerException (NPE) during bootstrap startup in StorageService.java
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11272
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>After bootstrapping fails due to stream closed error, the following error results:</p> <p>Feb 27, 2016 8:06:38 PM com.google.common.util.concurrent.ExecutionList executeListener<br/> SEVERE: RuntimeException while executing runnable com.google.common.util.concurrent.Futures$6@3d61813b with executor INSTANCE<br/> java.lang.NullPointerException<br/> at org.apache.cassandra.service.StorageService$2.onFailure(StorageService.java:1284)<br/> at com.google.common.util.concurrent.Futures$6.run(Futures.java:1310)<br/> at com.google.common.util.concurrent.MoreExecutors$DirectExecutor.execute(MoreExecutors.java:457)<br/> at com.google.common.util.concurrent.ExecutionList.executeListener(ExecutionList.java:156)<br/> at com.google.common.util.concurrent.ExecutionList.execute(ExecutionList.java:145)<br/> at com.google.common.util.concurrent.AbstractFuture.setException(AbstractFuture.java:202)<br/> at org.apache.cassandra.streaming.StreamResultFuture.maybeComplete(StreamResultFuture.java:210)<br/> at org.apache.cassandra.streaming.StreamResultFuture.handleSessionComplete(StreamResultFuture.java:186)<br/> at org.apache.cassandra.streaming.StreamSession.closeSession(StreamSession.java:430)<br/> at org.apache.cassandra.streaming.StreamSession.onError(StreamSession.java:525)<br/> at org.apache.cassandra.streaming.StreamSession.doRetry(StreamSession.java:645)<br/> at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:70)<br/> at org.apache.cassandra.streaming.messages.IncomingFileMessage$1.deserialize(IncomingFileMessage.java:39)<br/> at org.apache.cassandra.streaming.messages.StreamMessage.deserialize(StreamMessage.java:59)<br/> at org.apache.cassandra.streaming.ConnectionHandler$IncomingMessageHandler.run(ConnectionHandler.java:261)<br/> at java.lang.Thread.run(Thread.java:745)</p>
</description>
<environment><p>debian jesse up to date</p></environment>
<key id="12945230">CASSANDRA-11272</key>
<summary>
NullPointerException (NPE) during bootstrap startup in StorageService.java
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="longtimer">Jason Kania</reporter>
<labels></labels>
<created>Sun, 28 Feb 2016 01:10:46 +0000</created>
<updated>Sun, 28 Feb 2016 01:11:10 +0000</updated>
<component>Lifecycle</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2tvfz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11195] static_columns_paging_test upgrade dtest flapping
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11195
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>On some upgrade paths, <tt>static_columns_paging_test</tt> is flapping:</p> <p><a href="http://cassci.datastax.com/job/upgrade_tests-all/9/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_HEAD_UpTo_Trunk/static_columns_paging_test/history/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/9/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_HEAD_UpTo_Trunk/static_columns_paging_test/history/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/8/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_UpTo_Trunk/static_columns_paging_test/history/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/8/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_UpTo_Trunk/static_columns_paging_test/history/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/8/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_UpTo_3_3_HEAD/static_columns_paging_test/history" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/8/testReport/upgrade_tests.paging_test/TestPagingDataNodes2RF1_2_2_UpTo_3_3_HEAD/static_columns_paging_test/history</a></p> <p>The failures indicate there is missing data. I have not reproduced the failure locally. I've only seen the failures on 2-node clusters with RF=1, not on the 3-node runs with RF=3.</p>
</description>
<environment/>
<key id="12940628">CASSANDRA-11195</key>
<summary>static_columns_paging_test upgrade dtest flapping</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="cassandra-te">DS Test Eng</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Fri, 19 Feb 2016 20:19:49 +0000</created>
<updated>Fri, 19 Feb 2016 20:19:49 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t31j:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11196] tuple_notation_test upgrade tests flaps
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11196
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p><tt>tuple_notation_test</tt> in the <tt>upgrade_tests.cql_tests</tt> module flaps on a number of different upgrade paths. Here are some of the tests that flap:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> upgrade_tests/cql_tests.py:TestCQLNodes2RF1_2_1_UpTo_2_2_HEAD.tuple_notation_test upgrade_tests/cql_tests.py:TestCQLNodes2RF1_2_1_UpTo_2_2_HEAD.tuple_notation_test upgrade_tests/cql_tests.py:TestCQLNodes3RF3_2_1_UpTo_2_2_HEAD.tuple_notation_test upgrade_tests/cql_tests.py:TestCQLNodes3RF3_2_1_UpTo_2_2_HEAD.tuple_notation_test upgrade_tests/cql_tests.py:TestCQLNodes3RF3_2_2_HEAD_UpTo_Trunk.tuple_notation_test upgrade_tests/cql_tests.py:TestCQLNodes3RF3_2_2_HEAD_UpTo_Trunk.tuple_notation_test </pre> </div></div> <p>Here's an example failure:</p> <p><a href="http://cassci.datastax.com/job/upgrade_tests-all/9/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_2_1_UpTo_2_2_HEAD/tuple_notation_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/9/testReport/upgrade_tests.cql_tests/TestCQLNodes2RF1_2_1_UpTo_2_2_HEAD/tuple_notation_test/</a></p> <p>All the failures I've seen fail with this error:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> &lt;ErrorMessage code=0000 [Server error] message=<span class="code-quote">"java.lang.IndexOutOfBoundsException"</span>&gt; </pre> </div></div>
</description>
<environment/>
<key id="12940637">CASSANDRA-11196</key>
<summary>tuple_notation_test upgrade tests flaps</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="blerer">Benjamin Lerer</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Fri, 19 Feb 2016 20:36:46 +0000</created>
<updated>Mon, 22 Feb 2016 10:02:09 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15156712" author="slebresne" created="Mon, 22 Feb 2016 10:02:09 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mambocab" class="user-hover" rel="mambocab">Jim Witschey</a> Is there still no way to get the server logs from a failed job? Being able to would likely make this trivial (without it we'll need to reproduce locally so we get a proper server side trace) and would have been tremendously useful a lot of times.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 22 Feb 2016 10:02:09 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t33j:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11152] SOURCE command in CQLSH 3.2 requires that "use keyspace" is in the cql file that you are sourcing
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11152
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>a difference in behaviour between SOURCE command in CQLSH 3.1 and 3.2. <br/> In CQLSH 3.1 SOURCE will NOT require "use keyspace" in the cql file that you execute: the "keyspace" directive in the qlshrc file will work and the cql file will be executed.</p> <p>In CQLSH 3.2.1, SOURCE command requires that "use keyspace" is in the cql file that you are sourcing, otherwise it throws this error:<br/> "No keyspace has been specified. USE a keyspace, or explicitly specify keyspace.tablename". <br/> The "keyspace" directive in cqlshrc is overridden by source command.</p> <p>steps to reproduce:<br/> create a file called select.cql in your home directory:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>echo "CONSISTENCY ONE;" &gt; select.cql echo "select * from tab;" &gt;&gt; select.cql </pre> </div></div> <p>in cqlsh:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>create KEYSPACE kspace WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}; create TABLE tab ( id int primary key); insert into tab (id) VALUES ( 1); </pre> </div></div> <p>Add this to cqlsgrc:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[authentication] keyspace = kspace </pre> </div></div> <p>Then exit cqlsh and rerun cqlsh using the cqlshrc just modified.<br/> Note that you are in keyspace "kspace".<br/> execute:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>source 'select.cql' </pre> </div></div> <p>this will have different behaviour in CQLSH 3.2 and 3.1</p>
</description>
<environment><p>CQLSH 3.2.1</p></environment>
<key id="12938255">CASSANDRA-11152</key>
<summary>
SOURCE command in CQLSH 3.2 requires that "use keyspace" is in the cql file that you are sourcing
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="fanimali">Francesco Animali</reporter>
<labels></labels>
<created>Wed, 10 Feb 2016 17:44:33 +0000</created>
<updated>Fri, 12 Feb 2016 13:50:02 +0000</updated>
<component>CQL</component>
<due/>
<votes>1</votes>
<watches>3</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sofz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333872</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11185] cqlsh_copy_tests.py:CqlshCopyTest.test_round_trip_with_sub_second_precision is failing
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11185
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>$ PRINT_DEBUG=true nosetests -vs cqlsh_tests/cqlsh_copy_tests.py:CqlshCopyTest.test_round_trip_with_sub_second_precision test_round_trip_with_sub_second_precision (cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest) ... cluster ccm directory: /tmp/dtest-bLMOLy Custom init_config not found. Setting defaults. Done setting configuration options: { 'initial_token': None, 'num_tokens': '256', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} Importing from csv file: /tmp/tmphRouGd (EE) Exporting to csv file: /tmp/tmph_HaMQ FAIL (EE) removing ccm cluster test at: /tmp/dtest-bLMOLy clearing ssl stores from [/tmp/dtest-bLMOLy] directory ====================================================================== FAIL: test_round_trip_with_sub_second_precision (cqlsh_tests.cqlsh_copy_tests.CqlshCopyTest) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/mshuler/git/cassandra-dtest/tools.py", line 253, in wrapped f(obj) File "/home/mshuler/git/cassandra-dtest/cqlsh_tests/cqlsh_copy_tests.py", line 1778, in test_round_trip_with_sub_second_precision csv_results) AssertionError: Element counts were not equal: First has 1, Second has 0: ['2', '1943-06-19 11:21:01.123000+0000'] First has 1, Second has 0: ['3', '1943-06-19 11:21:01.124000+0000'] First has 0, Second has 1: ['2', '1943-06-19 11:21:01.000000+0000'] First has 0, Second has 1: ['3', '1943-06-19 11:21:01.000000+0000'] -------------------- &gt;&gt; begin captured logging &lt;&lt; -------------------- dtest: DEBUG: cluster ccm directory: /tmp/dtest-bLMOLy dtest: DEBUG: Custom init_config not found. Setting defaults. dtest: DEBUG: Done setting configuration options: { 'initial_token': None, 'num_tokens': '256', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} dtest: DEBUG: Importing from csv file: /tmp/tmphRouGd dtest: DEBUG: Exporting to csv file: /tmp/tmph_HaMQ --------------------- &gt;&gt; end captured logging &lt;&lt; --------------------- ---------------------------------------------------------------------- Ran 1 test in 12.880s FAILED (failures=1) </pre> </div></div> <p><a href="http://cassci.datastax.com/job/trunk_dtest/1006/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_with_sub_second_precision/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/trunk_dtest/1006/testReport/cqlsh_tests.cqlsh_copy_tests/CqlshCopyTest/test_round_trip_with_sub_second_precision/</a></p> <p>Job changes:<br/> Commit 128d144c0d22238a9045cc697daf880452be974b by Josh McKenzie<br/> cqlsh: Add local timezone support to cqlsh<br/> patch by Stefan Podkowinski; reviewed by Paulo Motta for <a href="https://issues.apache.org/jira/browse/CASSANDRA-10397" title="Add local timezone support to cqlsh" class="issue-link" data-issue-key="CASSANDRA-10397"><del>CASSANDRA-10397</del></a></p>
</description>
<environment/>
<key id="12940224">CASSANDRA-11185</key>
<summary>
cqlsh_copy_tests.py:CqlshCopyTest.test_round_trip_with_sub_second_precision is failing
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mambocab">Jim Witschey</assignee>
<reporter username="mshuler">Michael Shuler</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Thu, 18 Feb 2016 18:12:55 +0000</created>
<updated>Fri, 19 Feb 2016 00:58:39 +0000</updated>
<fixVersion>3.x</fixVersion>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15152774" author="mshuler" created="Thu, 18 Feb 2016 18:23:22 +0000">
<p>Looks like the test assumptions need to account for the change in output.</p>
</comment>
<comment id="15153000" author="mambocab" created="Thu, 18 Feb 2016 20:11:11 +0000">
<p>See my comments on <a href="https://issues.apache.org/jira/browse/CASSANDRA-11184" title="cqlsh_tests.py:TestCqlsh.test_sub_second_precision is failing" class="issue-link" data-issue-key="CASSANDRA-11184">CASSANDRA-11184</a>:</p> <p><a href="https://issues.apache.org/jira/browse/CASSANDRA-11184?focusedCommentId=15152999&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15152999" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/CASSANDRA-11184?focusedCommentId=15152999&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15152999</a></p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania" class="user-hover" rel="Stefania">Stefania</a> <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=spodxx%40gmail.com" class="user-hover" rel="spodxx@gmail.com">Stefan Podkowinski</a> Any thoughts on these?</p>
</comment>
<comment id="15153463" author="stefania" created="Fri, 19 Feb 2016 00:58:39 +0000">
<p>Please see <a href="https://issues.apache.org/jira/browse/CASSANDRA-11184?focusedCommentId=15153462&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-15153462" class="external-link" rel="nofollow">comment</a> on <a href="https://issues.apache.org/jira/browse/CASSANDRA-11184" title="cqlsh_tests.py:TestCqlsh.test_sub_second_precision is failing" class="issue-link" data-issue-key="CASSANDRA-11184">CASSANDRA-11184</a>.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12940223">CASSANDRA-11184</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 18 Feb 2016 20:11:11 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t0jr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11184] cqlsh_tests.py:TestCqlsh.test_sub_second_precision is failing
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11184
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>$ PRINT_DEBUG=true nosetests -vs cqlsh_tests/cqlsh_tests.py:TestCqlsh.test_sub_second_precision test_sub_second_precision (cqlsh_tests.cqlsh_tests.TestCqlsh) ... cluster ccm directory: /tmp/dtest-h0TkA6 Custom init_config not found. Setting defaults. Done setting configuration options: { 'initial_token': None, 'num_tokens': '256', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} (EE) (EE) id | subid | value ----+---------------------------------+------- 1 | 1943-06-19 11:21:01.000000+0000 | abc (1 rows) FAIL removing ccm cluster test at: /tmp/dtest-h0TkA6 clearing ssl stores from [/tmp/dtest-h0TkA6] directory ====================================================================== FAIL: test_sub_second_precision (cqlsh_tests.cqlsh_tests.TestCqlsh) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/mshuler/git/cassandra-dtest/tools.py", line 253, in wrapped f(obj) File "/home/mshuler/git/cassandra-dtest/cqlsh_tests/cqlsh_tests.py", line 176, in test_sub_second_precision self.assertIn("1943-06-19 11:21:01.123000+0000", output) AssertionError: '1943-06-19 11:21:01.123000+0000' not found in '\n id | subid | value\n----+---------------------------------+-------\n 1 | 1943-06-19 11:21:01.000000+0000 | abc\n\n(1 rows)\n' -------------------- &gt;&gt; begin captured logging &lt;&lt; -------------------- dtest: DEBUG: cluster ccm directory: /tmp/dtest-h0TkA6 dtest: DEBUG: Custom init_config not found. Setting defaults. dtest: DEBUG: Done setting configuration options: { 'initial_token': None, 'num_tokens': '256', 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} dtest: DEBUG: id | subid | value ----+---------------------------------+------- 1 | 1943-06-19 11:21:01.000000+0000 | abc (1 rows) --------------------- &gt;&gt; end captured logging &lt;&lt; --------------------- ---------------------------------------------------------------------- Ran 1 test in 13.016s FAILED (failures=1) </pre> </div></div> <p><a href="http://cassci.datastax.com/job/trunk_dtest/1006/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_sub_second_precision/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/trunk_dtest/1006/testReport/cqlsh_tests.cqlsh_tests/TestCqlsh/test_sub_second_precision/</a></p> <p>Job changes:<br/> Commit 128d144c0d22238a9045cc697daf880452be974b by Josh McKenzie<br/> cqlsh: Add local timezone support to cqlsh<br/> patch by Stefan Podkowinski; reviewed by Paulo Motta for <a href="https://issues.apache.org/jira/browse/CASSANDRA-10397" title="Add local timezone support to cqlsh" class="issue-link" data-issue-key="CASSANDRA-10397"><del>CASSANDRA-10397</del></a></p>
</description>
<environment/>
<key id="12940223">CASSANDRA-11184</key>
<summary>
cqlsh_tests.py:TestCqlsh.test_sub_second_precision is failing
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mambocab">Jim Witschey</assignee>
<reporter username="mshuler">Michael Shuler</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Thu, 18 Feb 2016 18:09:21 +0000</created>
<updated>Fri, 19 Feb 2016 00:58:04 +0000</updated>
<fixVersion>3.x</fixVersion>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15152773" author="mshuler" created="Thu, 18 Feb 2016 18:23:17 +0000">
<p>Looks like the test assumptions need to account for the change in output.</p>
</comment>
<comment id="15152999" author="mambocab" created="Thu, 18 Feb 2016 20:10:20 +0000">
<p>It looks like I may not have reviewed <a href="https://github.com/riptano/cassandra-dtest/pull/773" class="external-link" rel="nofollow">dtest pr 773</a> properly &#8211; this test and the test described in <a href="https://issues.apache.org/jira/browse/CASSANDRA-11185" title="cqlsh_copy_tests.py:CqlshCopyTest.test_round_trip_with_sub_second_precision is failing" class="issue-link" data-issue-key="CASSANDRA-11185">CASSANDRA-11185</a> fails for me locally in the same way they fail on CassCI. Is there some configuration I'm missing <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=Stefania" class="user-hover" rel="Stefania">Stefania</a> <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=spodxx%40gmail.com" class="user-hover" rel="spodxx@gmail.com">Stefan Podkowinski</a>? I also do not see subsecond timestamps manually running cqlsh:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> cqlsh:ks&gt; TRUNCATE tab ... ; cqlsh:ks&gt; select * FROM tab ; id | subid ----+------- (0 rows) cqlsh:ks&gt; INSERT INTO tab (id, subid ) VALUES ( 2, '1943-06-19 11:21:01.123+0000'); cqlsh:ks&gt; select * FROM tab ; id | subid ----+--------------------------------- 2 | 1943-06-19 11:21:01.000000+0000 (1 rows) cqlsh:ks&gt; </pre> </div></div>
</comment>
<comment id="15153462" author="stefania" created="Fri, 19 Feb 2016 00:58:04 +0000">
<p>Thanks <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mambocab" class="user-hover" rel="mambocab">Jim Witschey</a>, it looks like microseconds were dropped when <a href="https://issues.apache.org/jira/browse/CASSANDRA-10397" title="Add local timezone support to cqlsh" class="issue-link" data-issue-key="CASSANDRA-10397"><del>CASSANDRA-10397</del></a> was merged into trunk. I've re-opened it, cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=pauloricardomg" class="user-hover" rel="pauloricardomg">Paulo Motta</a>.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12940224">CASSANDRA-11185</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 18 Feb 2016 20:10:20 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t0jj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11161] [offline] scrub can fail on zero byte components
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11161
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>/mnt/cassandra/data_05/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca$ sstablescrub -v system compaction_history ERROR 17:21:34 Exiting forcefully due to file system exception on startup, disk failure policy "stop" org.apache.cassandra.io.sstable.CorruptSSTableException: Corrupted: /mnt/cassandra/data_05/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca/system-compaction_history-ka-1936-CompressionInfo.db at org.apache.cassandra.io.compress.CompressionMetadata.&lt;init&gt;(CompressionMetadata.java:131) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.compress.CompressionMetadata.create(CompressionMetadata.java:85) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.util.CompressedSegmentedFile$Builder.metadata(CompressedSegmentedFile.java:79) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.util.CompressedPoolingSegmentedFile$Builder.complete(CompressedPoolingSegmentedFile.java:72) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.util.SegmentedFile$Builder.complete(SegmentedFile.java:169) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:741) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.sstable.SSTableReader.load(SSTableReader.java:692) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:480) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.sstable.SSTableReader.open(SSTableReader.java:376) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at org.apache.cassandra.io.sstable.SSTableReader$4.run(SSTableReader.java:523) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) [na:1.7.0_79] at java.util.concurrent.FutureTask.run(FutureTask.java:262) [na:1.7.0_79] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) [na:1.7.0_79] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_79] at java.lang.Thread.run(Thread.java:745) [na:1.7.0_79] Caused by: java.io.EOFException: null at java.io.DataInputStream.readUnsignedShort(DataInputStream.java:340) ~[na:1.7.0_79] at java.io.DataInputStream.readUTF(DataInputStream.java:589) ~[na:1.7.0_79] at java.io.DataInputStream.readUTF(DataInputStream.java:564) ~[na:1.7.0_79] at org.apache.cassandra.io.compress.CompressionMetadata.&lt;init&gt;(CompressionMetadata.java:106) ~[cassandra-all-2.1.12.1046.jar:2.1.12.1046] ... 14 common frames omitted cassandra@cass4-19-ussnn1:/mnt/cassandra/data_05/system/compaction_history-b4dbb7b4dc493fb5b3bfce6e434832ca$ $ ls -lah total 72K drwxr-xr-x 2 cassandra cassandra 4.0K Feb 11 15:33 . drwxr-xr-x 19 cassandra cassandra 4.0K Jul 2 2015 .. -rw-r--r-- 1 cassandra cassandra 0 Sep 4 17:36 system-compaction_history-ka-1936-CompressionInfo.db </pre> </div></div>
</description>
<environment/>
<key id="12938569">CASSANDRA-11161</key>
<summary>[offline] scrub can fail on zero byte components</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="brandon.williams">Brandon Williams</reporter>
<labels></labels>
<created>Thu, 11 Feb 2016 17:33:58 +0000</created>
<updated>Thu, 11 Feb 2016 17:33:58 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqdr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-11155] Scrub/Cleanup block snapshots</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11155
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have noticed that when running the cleanup or scrub process on Cassandra it prevents nodetool from taking a snapshot. The snapshot process essentially blocks until the scrub or cleanup is complete. I am not exactly sure if this is intended behavior. </p> <p>For the record, this observed behavior does not apply to repairs and major compactions.</p>
</description>
<environment><p>Linux Ubuntu hosts, Cassandra 2.1.12</p></environment>
<key id="12938412">CASSANDRA-11155</key>
<summary>Scrub/Cleanup block snapshots</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="victori">Victor Igumnov</reporter>
<labels></labels>
<created>Thu, 11 Feb 2016 02:37:27 +0000</created>
<updated>Thu, 11 Feb 2016 18:19:15 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15142159" author="brandon.williams" created="Thu, 11 Feb 2016 02:44:44 +0000">
<p>A thread dump of the main process while attempting to snap would be useful here.</p>
</comment>
<comment id="15143188" author="victori" created="Thu, 11 Feb 2016 18:19:15 +0000">
<p>Snapshot stalled while scrubbing thread dump.</p>
</comment>
</comments>
<attachments>
<attachment id="12787504" name="cass-scrub-threaddump.bz2" size="62024" author="victori" created="Thu, 11 Feb 2016 18:19:15 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 11 Feb 2016 02:44:44 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2spev:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332167</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332829</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11154] CassandraDaemon in Managed mode fails to be restartable
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11154
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Restarting the CassandraDeamon in managed mode fails to restart due to duplicate migration of already migrated keyspaces. </p> <p>To reproduce this, just do something like in this test class: <br/> <a href="https://github.com/ANierbeck/Karaf-Cassandra/blob/master/Karaf-Cassandra-Embedded/src/test/java/de/nierbeck/cassandra/embedded/TestEmbedded.java" class="external-link" rel="nofollow">https://github.com/ANierbeck/Karaf-Cassandra/blob/master/Karaf-Cassandra-Embedded/src/test/java/de/nierbeck/cassandra/embedded/TestEmbedded.java</a></p>
</description>
<environment/>
<key id="12938342">CASSANDRA-11154</key>
<summary>
CassandraDaemon in Managed mode fails to be restartable
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10002" iconUrl="https://issues.apache.org/jira/images/icons/statuses/document.png" description="A patch for this issue has been uploaded to JIRA by a contributor.">Patch Available</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="achim_nierbeck">Achim Nierbeck</reporter>
<labels></labels>
<created>Wed, 10 Feb 2016 21:29:19 +0000</created>
<updated>Wed, 17 Feb 2016 12:32:38 +0000</updated>
<fixVersion>3.x</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12787352" name="CASSANDRA-11154_patch.txt" size="3621" author="achim_nierbeck" created="Wed, 10 Feb 2016 21:38:16 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sozb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_10022" key="com.atlassian.jira.plugin.system.customfieldtypes:userpicker">
<customfieldname>Reviewer</customfieldname>
<customfieldvalues>
<customfieldvalue>iamaleksey</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12333891</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-11219] Some Paxos issues</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11219
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Two issues,<br/> 1. ‘Raw Paxos' without Single Leader may result in non-progress, though waiting and retry may solve part of the problem, but cannot be proven that it can make progress.<br/> 2. learning issue, mostRecentCommit may not sufficient for a learner to catch up, such as node A, B and C, C is down, while A and B done with two Commits, c1, and c2. now when C is up, only c2 could be learned by C, since update is based on row changes (according to my understanding), data may inconsistent due to this</p>
</description>
<environment/>
<key id="12941526">CASSANDRA-11219</key>
<summary>Some Paxos issues</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="andy.yx.chen@outlook.com">Andy Chen</reporter>
<labels></labels>
<created>Tue, 23 Feb 2016 20:06:02 +0000</created>
<updated>Tue, 23 Feb 2016 20:06:02 +0000</updated>
<component>Core</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t8kv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11163] Summaries are needlessly rebuilt when the BF FP ratio is changed
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11163
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>This is from trunk, but I also saw this happen on 2.0:</p> <p>Before:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>root@bw-1:/srv/cassandra# ls -ltr /var/lib/cassandra/data/keyspace1/standard1-071efdc0d11811e590c3413ee28a6c90/ total 221460 drwxr-xr-x 2 root root 4096 Feb 11 23:34 backups -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-6-big-TOC.txt -rw-r--r-- 1 root root 26518 Feb 11 23:50 ma-6-big-Summary.db -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-6-big-Statistics.db -rw-r--r-- 1 root root 2607705 Feb 11 23:50 ma-6-big-Index.db -rw-r--r-- 1 root root 192440 Feb 11 23:50 ma-6-big-Filter.db -rw-r--r-- 1 root root 10 Feb 11 23:50 ma-6-big-Digest.crc32 -rw-r--r-- 1 root root 35212125 Feb 11 23:50 ma-6-big-Data.db -rw-r--r-- 1 root root 2156 Feb 11 23:50 ma-6-big-CRC.db -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-7-big-TOC.txt -rw-r--r-- 1 root root 26518 Feb 11 23:50 ma-7-big-Summary.db -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-7-big-Statistics.db -rw-r--r-- 1 root root 2607614 Feb 11 23:50 ma-7-big-Index.db -rw-r--r-- 1 root root 192432 Feb 11 23:50 ma-7-big-Filter.db -rw-r--r-- 1 root root 9 Feb 11 23:50 ma-7-big-Digest.crc32 -rw-r--r-- 1 root root 35190400 Feb 11 23:50 ma-7-big-Data.db -rw-r--r-- 1 root root 2152 Feb 11 23:50 ma-7-big-CRC.db -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-5-big-TOC.txt -rw-r--r-- 1 root root 104178 Feb 11 23:50 ma-5-big-Summary.db -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-5-big-Statistics.db -rw-r--r-- 1 root root 10289077 Feb 11 23:50 ma-5-big-Index.db -rw-r--r-- 1 root root 757384 Feb 11 23:50 ma-5-big-Filter.db -rw-r--r-- 1 root root 9 Feb 11 23:50 ma-5-big-Digest.crc32 -rw-r--r-- 1 root root 139201355 Feb 11 23:50 ma-5-big-Data.db -rw-r--r-- 1 root root 8508 Feb 11 23:50 ma-5-big-CRC.db root@bw-1:/srv/cassandra# md5sum /var/lib/cassandra/data/keyspace1/standard1-071efdc0d11811e590c3413ee28a6c90/ma-5-big-Summary.db 5fca154fc790f7cfa37e8ad6d1c7552c </pre> </div></div> <p>BF ratio changed, node restarted:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>root@bw-1:/srv/cassandra# ls -ltr /var/lib/cassandra/data/keyspace1/standard1-071efdc0d11811e590c3413ee28a6c90/ total 242168 drwxr-xr-x 2 root root 4096 Feb 11 23:34 backups -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-6-big-TOC.txt -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-6-big-Statistics.db -rw-r--r-- 1 root root 2607705 Feb 11 23:50 ma-6-big-Index.db -rw-r--r-- 1 root root 192440 Feb 11 23:50 ma-6-big-Filter.db -rw-r--r-- 1 root root 10 Feb 11 23:50 ma-6-big-Digest.crc32 -rw-r--r-- 1 root root 35212125 Feb 11 23:50 ma-6-big-Data.db -rw-r--r-- 1 root root 2156 Feb 11 23:50 ma-6-big-CRC.db -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-7-big-TOC.txt -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-7-big-Statistics.db -rw-r--r-- 1 root root 2607614 Feb 11 23:50 ma-7-big-Index.db -rw-r--r-- 1 root root 192432 Feb 11 23:50 ma-7-big-Filter.db -rw-r--r-- 1 root root 9 Feb 11 23:50 ma-7-big-Digest.crc32 -rw-r--r-- 1 root root 35190400 Feb 11 23:50 ma-7-big-Data.db -rw-r--r-- 1 root root 2152 Feb 11 23:50 ma-7-big-CRC.db -rw-r--r-- 1 root root 80 Feb 11 23:50 ma-5-big-TOC.txt -rw-r--r-- 1 root root 10264 Feb 11 23:50 ma-5-big-Statistics.db -rw-r--r-- 1 root root 10289077 Feb 11 23:50 ma-5-big-Index.db -rw-r--r-- 1 root root 757384 Feb 11 23:50 ma-5-big-Filter.db -rw-r--r-- 1 root root 9 Feb 11 23:50 ma-5-big-Digest.crc32 -rw-r--r-- 1 root root 139201355 Feb 11 23:50 ma-5-big-Data.db -rw-r--r-- 1 root root 8508 Feb 11 23:50 ma-5-big-CRC.db -rw-r--r-- 1 root root 80 Feb 12 00:03 ma-8-big-TOC.txt -rw-r--r-- 1 root root 14902 Feb 12 00:03 ma-8-big-Summary.db -rw-r--r-- 1 root root 10264 Feb 12 00:03 ma-8-big-Statistics.db -rw-r--r-- 1 root root 1458631 Feb 12 00:03 ma-8-big-Index.db -rw-r--r-- 1 root root 10808 Feb 12 00:03 ma-8-big-Filter.db -rw-r--r-- 1 root root 10 Feb 12 00:03 ma-8-big-Digest.crc32 -rw-r--r-- 1 root root 19660275 Feb 12 00:03 ma-8-big-Data.db -rw-r--r-- 1 root root 1204 Feb 12 00:03 ma-8-big-CRC.db -rw-r--r-- 1 root root 26518 Feb 12 00:04 ma-7-big-Summary.db -rw-r--r-- 1 root root 26518 Feb 12 00:04 ma-6-big-Summary.db -rw-r--r-- 1 root root 104178 Feb 12 00:04 ma-5-big-Summary.db root@bw-1:/srv/cassandra# md5sum /var/lib/cassandra/data/keyspace1/standard1-071efdc0d11811e590c3413ee28a6c90/ma-5-big-Summary.db 5fca154fc790f7cfa37e8ad6d1c7552c </pre> </div></div> <p>This hurts startup time and appears to do nothing useful whatsoever.</p>
</description>
<environment/>
<key id="12938653">CASSANDRA-11163</key>
<summary>
Summaries are needlessly rebuilt when the BF FP ratio is changed
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="brandon.williams">Brandon Williams</reporter>
<labels></labels>
<created>Fri, 12 Feb 2016 00:08:41 +0000</created>
<updated>Fri, 12 Feb 2016 00:58:08 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.0.x</fixVersion>
<component>Core</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15143811" author="jjirsa" created="Fri, 12 Feb 2016 00:58:08 +0000">
<p>Also, the bloom filter is rebuilt on load(), but the rebuild (corrected) filter isn't persisted to disk (could make the argument that rebuilding the BF is right, but if you're going to take the time to do that, should also persist it to disk in the same way index summary is persisted).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 12 Feb 2016 00:58:08 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqw7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[CASSANDRA-11201] Compaction memory fault in 3.0.3</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11201
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I have been encountering the following errors periodically on the system:</p> <p>ERROR <span class="error">&#91;CompactionExecutor:6&#93;</span> 2016-02-20 16:54:09,069 CassandraDaemon.java:195 - Exception in thread Thread<span class="error">&#91;CompactionExecutor:6,1,main&#93;</span><br/> java.lang.InternalError: a fault occurred in a recent unsafe memory access operation in compiled Java code<br/> at org.apache.cassandra.utils.ByteBufferUtil.readShortLength(ByteBufferUtil.java:366) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.ByteBufferUtil.readWithShortLength(ByteBufferUtil.java:376) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.io.sstable.format.big.BigTableScanner.seekToCurrentRangeStart(BigTableScanner.java:175) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.io.sstable.format.big.BigTableScanner.access$200(BigTableScanner.java:51) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:280) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.io.sstable.format.big.BigTableScanner$KeyScanningIterator.computeNext(BigTableScanner.java:260) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.io.sstable.format.big.BigTableScanner.hasNext(BigTableScanner.java:240) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:369) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.MergeIterator$ManyToOne.advance(MergeIterator.java:189) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.MergeIterator$ManyToOne.computeNext(MergeIterator.java:158) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.AbstractIterator.hasNext(AbstractIterator.java:47) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.partitions.UnfilteredPartitionIterators$2.hasNext(UnfilteredPartitionIterators.java:150) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.transform.BasePartitions.hasNext(BasePartitions.java:72) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionIterator.hasNext(CompactionIterator.java:226) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionTask.runMayThrow(CompactionTask.java:177) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.utils.WrappedRunnable.run(WrappedRunnable.java:28) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionTask.executeInternal(CompactionTask.java:78) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.compaction.AbstractCompactionTask.execute(AbstractCompactionTask.java:60) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:263) ~<span class="error">&#91;apache-cassandra-3.0.3.jar:3.0.3&#93;</span><br/> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~<span class="error">&#91;na:1.8.0_65&#93;</span><br/> at java.util.concurrent.FutureTask.run(FutureTask.java:266) ~<span class="error">&#91;na:1.8.0_65&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~<span class="error">&#91;na:1.8.0_65&#93;</span><br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) <span class="error">&#91;na:1.8.0_65&#93;</span><br/> at java.lang.Thread.run(Thread.java:745) <span class="error">&#91;na:1.8.0_65&#93;</span></p> <p>This problem persisted after several reboots and even when most other applications on the system were terminated to provide more memory availability.</p> <p>The problem also occurs when running 'nodetool compact'.</p>
</description>
<environment>
<p>debian jesse latest release, updated Feb. 20th</p>
</environment>
<key id="12940832">CASSANDRA-11201</key>
<summary>Compaction memory fault in 3.0.3</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="longtimer">Jason Kania</reporter>
<labels></labels>
<created>Sat, 20 Feb 2016 23:50:18 +0000</created>
<updated>Mon, 22 Feb 2016 13:29:55 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15156661" author="slebresne" created="Mon, 22 Feb 2016 09:15:08 +0000">
<p>The <tt>java.lang.InternalError</tt> might suggest a JVM bug. Could you share your JVM version in particular? Also, are you using any non-default option?</p>
</comment>
<comment id="15156916" author="longtimer" created="Mon, 22 Feb 2016 13:29:55 +0000">
<p>I have tried on Oracle JDK version 65 and the latest 74 version.</p> <p>root@marble:/usr/local/bin/# java -version<br/> java version "1.8.0_74"<br/> Java(TM) SE Runtime Environment (build 1.8.0_74-b02)<br/> Java HotSpot(TM) 64-Bit Server VM (build 25.74-b02, mixed mode)</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 22 Feb 2016 09:15:08 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t4av:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11174] org.apache.cassandra.metrics:type=Streaming,name=ActiveOutboundStreams is always zero
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11174
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p><tt>org.apache.cassandra.metrics:type=Streaming,name=TotalIncomingBytes</tt> and <tt>org.apache.cassandra.metrics:type=Streaming,name=TotalOutgoingBytes</tt> work fine but <tt>org.apache.cassandra.metrics:type=Streaming,name=ActiveOutboundStreams</tt> is always 0.</p>
</description>
<environment><p>C* 2.1.12, Debian Wheezy</p></environment>
<key id="12939764">CASSANDRA-11174</key>
<summary>
org.apache.cassandra.metrics:type=Streaming,name=ActiveOutboundStreams is always zero
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mlowicki">mlowicki</reporter>
<labels></labels>
<created>Wed, 17 Feb 2016 09:59:08 +0000</created>
<updated>Mon, 22 Feb 2016 20:47:42 +0000</updated>
<component>Observability</component>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12788213" name="streams.png" size="62131" author="mlowicki" created="Wed, 17 Feb 2016 09:59:08 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sxpr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11127] index_summary_upgrade_test.py is failing
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11127
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>index_summary_upgrade_test.py is failing on the cassandra-3.0 branch, when run without vnodes. The exception I'm seeing on cassci is different than locally. The cassci failure is <a href="http://cassci.datastax.com/job/cassandra-3.0_novnode_dtest/157/testReport/index_summary_upgrade_test/TestUpgradeIndexSummary/test_upgrade_index_summary/" class="external-link" rel="nofollow">here</a>.</p> <p>Locally I see the following:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> 'ERROR [SSTableBatchOpen:2] 2016-02-05 15:29:04,304 CassandraDaemon.java:195 - Exception in thread <span class="code-object">Thread</span>[SSTableBatchOpen:2,5,main]\njava.lang.AssertionError: Illegal bounds [4..8); size: 4\n\tat org.apache.cassandra.io.util.Memory.checkBounds(Memory.java:339) ~[main/:na]\n\tat org.apache.cassandra.io.util.Memory.getInt(Memory.java:292) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.IndexSummary.getPositionInSummary(IndexSummary.java:146) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.IndexSummary.getKey(IndexSummary.java:151) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.validateSummarySamplingLevel(SSTableReader.java:928) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:748) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.load(SSTableReader.java:705) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:491) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader.open(SSTableReader.java:374) ~[main/:na]\n\tat org.apache.cassandra.io.sstable.format.SSTableReader$4.run(SSTableReader.java:533) ~[main/:na]\n\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) ~[na:1.8.0_66]\n\tat java.util.concurrent.FutureTask.run(FutureTask.java:266) ~[na:1.8.0_66]\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) ~[na:1.8.0_66]\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_66]\n\tat java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.8.0_66]'] </pre> </div></div> <p>Node log is attached.</p>
</description>
<environment/>
<key id="12937147">CASSANDRA-11127</key>
<summary>index_summary_upgrade_test.py is failing</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="philipthompson">Philip Thompson</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Fri, 5 Feb 2016 20:43:10 +0000</created>
<updated>Fri, 5 Feb 2016 20:43:18 +0000</updated>
<fixVersion>3.0.x</fixVersion>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12786554" name="node1_debug.log" size="197915" author="philipthompson" created="Fri, 5 Feb 2016 20:43:10 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2shu7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11126] select_distinct_with_deletions_test failing on non-vnode environments
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11126
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Looks like this was fixed in <a href="https://issues.apache.org/jira/browse/CASSANDRA-10762" title="select_distinct_with_deletions_test failing in mixed version cluster" class="issue-link" data-issue-key="CASSANDRA-10762"><del>CASSANDRA-10762</del></a>, but not for non-vnode environments:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> $ DISABLE_VNODES=yes KEEP_TEST_DIR=yes CASSANDRA_VERSION=git:cassandra-3.0 PRINT_DEBUG=<span class="code-keyword">true</span> nosetests -s -v upgrade_tests/cql_tests.py:TestCQLNodes2RF1.select_distinct_with_deletions_test select_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1) ... cluster ccm directory: /tmp/dtest-UXb0un http:<span class="code-comment">//git-wip-us.apache.org/repos/asf/cassandra.git git:cassandra-3.0 </span>Custom init_config not found. Setting defaults. Done setting configuration options: { 'num_tokens': None, 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} getting <span class="code-keyword">default</span> job version <span class="code-keyword">for</span> 3.0.3 UpgradePath(starting_version='binary:2.2.3', upgrade_version=None) starting from 2.2.3 upgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'} Querying upgraded node FAIL ====================================================================== FAIL: select_distinct_with_deletions_test (upgrade_tests.cql_tests.TestCQLNodes2RF1) ---------------------------------------------------------------------- Traceback (most recent call last): File <span class="code-quote">"/home/ryan/git/datastax/cassandra-dtest/upgrade_tests/cql_tests.py"</span>, line 3360, in select_distinct_with_deletions_test self.assertEqual(9, len(rows)) AssertionError: 9 != 8 -------------------- &gt;&gt; begin captured logging &lt;&lt; -------------------- dtest: DEBUG: cluster ccm directory: /tmp/dtest-UXb0un dtest: DEBUG: Custom init_config not found. Setting defaults. dtest: DEBUG: Done setting configuration options: { 'num_tokens': None, 'phi_convict_threshold': 5, 'range_request_timeout_in_ms': 10000, 'read_request_timeout_in_ms': 10000, 'request_timeout_in_ms': 10000, 'truncate_request_timeout_in_ms': 10000, 'write_request_timeout_in_ms': 10000} dtest: DEBUG: getting <span class="code-keyword">default</span> job version <span class="code-keyword">for</span> 3.0.3 dtest: DEBUG: UpgradePath(starting_version='binary:2.2.3', upgrade_version=None) dtest: DEBUG: starting from 2.2.3 dtest: DEBUG: upgrading to {'install_dir': '/home/ryan/.ccm/repository/gitCOLONcassandra-3.0'} dtest: DEBUG: Querying upgraded node --------------------- &gt;&gt; end captured logging &lt;&lt; --------------------- ---------------------------------------------------------------------- Ran 1 test in 56.022s FAILED (failures=1) </pre> </div></div>
</description>
<environment/>
<key id="12937142">CASSANDRA-11126</key>
<summary>
select_distinct_with_deletions_test failing on non-vnode environments
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="slebresne">Sylvain Lebresne</assignee>
<reporter username="enigmacurry">Ryan McGuire</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Fri, 5 Feb 2016 20:29:13 +0000</created>
<updated>Fri, 12 Feb 2016 11:26:21 +0000</updated>
<fixVersion>3.0.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15140640" author="slebresne" created="Wed, 10 Feb 2016 11:13:39 +0000">
<p>There seems to have been changes to the upgrade, so can someone tell me how I can ran this test between two local versions (that is, say I have a version of 2.1 checkouted in repository X and 3.0 checkouted in repository Y, how do I run from 2.1 to 3.0 using those locally checkouted versions)? I can't debug this properly otherwise. <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=enigmacurry" class="user-hover" rel="enigmacurry">Ryan McGuire</a><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rhatch" class="user-hover" rel="rhatch">Russ Hatch</a>?</p>
</comment>
<comment id="15141423" author="mambocab" created="Wed, 10 Feb 2016 18:42:23 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a> I'm afraid this isn't possible with <tt>ccm</tt> as it is. I'll file an issue about that; that's something we can improve on.</p> <p>The way I recommend you test two particular branches is to push them to GitHub and then use something like the code here:</p> <p><a href="https://github.com/mambocab/cassandra-dtest/commit/f1b747d7e9a0f5d792da9e13009b6a12293b10fe" class="external-link" rel="nofollow">https://github.com/mambocab/cassandra-dtest/commit/f1b747d7e9a0f5d792da9e13009b6a12293b10fe</a></p> <p>This will generate classes using your specified upgrade path. You can find the names of the generated tests by running</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> UPGRADE_TEST_RUN=<span class="code-keyword">true</span> CASSANDRA_VERSION=git:trunk nosetests 2&gt;&amp;1 -vv --collect-only | grep github_to_github </pre> </div></div> <p><tt>--collect-only</tt> makes <tt>nosetests</tt> just list the test names, rather than running the tests. <tt>github_to_github</tt> is a unique slug that gets added to class names when the upgrade path is specified in the commit I linked. <tt>UPGRADE_TEST_RUN</tt> makes the upgrade_tests runnable, and <tt>CASSANDRA_VERSION</tt> is necessary even if you don't end up using that version (this is an implementation mistake that we will fix).</p> <p>I recommend you use my <tt>nose-pasteable</tt> plugin (<tt>pip install nose-pasteable</tt>) and set <tt>NOSE_PASTEABLE=true</tt> in the command &#8211; this makes the names that <tt>nosetests</tt> generates useable as arguments to <tt>nosetests</tt> as described in the README: <a href="https://github.com/mambocab/nose-pasteable" class="external-link" rel="nofollow">https://github.com/mambocab/nose-pasteable</a></p>
</comment>
<comment id="15144466" author="slebresne" created="Fri, 12 Feb 2016 11:26:21 +0000">
<blockquote><p>I'm afraid this isn't possible with ccm as it is</p></blockquote> <p>Well, <tt>ccm</tt> certainly support running from a local directory so it ought to be possible. But I think I see what you mean, and I agree we can fix <tt>ccm</tt> so it's much easier to make this work transparently for this kind of test. We definitely should do that though.</p> <blockquote><p>The way I recommend you test two particular branches is to push them to GitHub</p></blockquote> <p>I'll do it this time, but that's seriously painful, as a typical way to debug such a problem involve multiple change/recompilation and having to commit and push every time adds significant annoyance and slowness to the process (if for no other reason than because I assume <tt>ccm</tt> will do a clean before recompiling every time which I can avoid most of the time locally).<br/> Anyway my main point being, when you work on this type of test framework, please keep in mind that having an easy way to test against a local checkout is pretty important for us, devs.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 10 Feb 2016 11:13:39 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sht3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12334361</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11138] cassandra-stress tool - clustering key values not distributed
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11138
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I am trying to get the stress tool to generate random values for three clustering keys. I am trying to simulate collecting events per user id (text, partition key). Events have a session type (text), event type (text), and creation time (timestamp) (clustering keys, in that order). For testing purposes I ended up with the following column spec:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>columnspec: - name: created_at cluster: uniform(10..10) - name: event_type size: uniform(5..10) population: uniform(1..30) cluster: uniform(1..30) - name: session_type size: fixed(5) population: uniform(1..4) cluster: uniform(1..4) - name: user_id size: fixed(15) population: uniform(1..1000000) - name: message size: uniform(10..100) population: uniform(1..100B) </pre> </div></div> <p>My expectation was that this would lead to anywhere between 10 and 1200 rows to be created per partition key. But it seems that exactly 10 rows are being created, with the <tt>created_at</tt> timestamp being the only variable that is assigned variable values (per partition key). The <tt>session_type</tt> and <tt>event_type</tt> variables are assigned fixed values. This is even the case if I set the cluster distribution to uniform(30..30) and uniform(4..4) respectively. With this setting I expected 1200 rows per partition key to be created, as announced when running the stress tool, but it is still 10.</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[rsteppac@centos bin]$ ./cassandra-stress user profile=../batch_too_large.yaml ops\(insert=1\) -log level=verbose file=~/centos_eventy_patient_session_event_timestamp_insert_only.log -node 10.211.55.8 … Created schema. Sleeping 1s for propagation. Generating batches with [1..1] partitions and [1..1] rows (of [1200..1200] total rows in the partitions) Improvement over 4 threadCount: 19% ... </pre> </div></div> <p>Sample of generated data:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>cqlsh&gt; select user_id, event_type, session_type, created_at from stresscql.batch_too_large LIMIT 30 ; user_id | event_type | session_type | created_at -----------------------------+------------------+--------------+-------------------------- %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 2012-10-19 08:14:11+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 2004-11-08 04:04:56+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 2002-10-15 00:39:23+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1999-08-31 19:56:30+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1999-04-02 20:46:26+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1990-10-08 03:27:17+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1984-03-31 23:30:34+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1975-11-16 02:41:28+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1970-04-07 07:23:48+0000 %\x7f\x03/.d29&lt;i\$u\x114 | Y ?\x1eR|\x13\t| | P+|u\x0b | 1970-03-08 23:23:04+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2015-10-12 17:48:51+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2010-10-28 06:21:13+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2005-06-28 03:34:41+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2005-01-29 05:26:21+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2003-03-27 01:31:24+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2002-03-29 14:22:43+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 2000-06-15 14:54:29+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 1998-03-08 13:31:54+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 1988-01-21 06:38:40+0000 N!\x0eUA7^r7d\x06J&lt;v&lt; | \x1bm/c/Th\x07U | E}P^k | 1975-08-03 21:16:47+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 2014-11-23 17:05:45+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 2012-02-23 23:20:54+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 2012-02-19 12:05:15+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 2005-10-17 04:22:45+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 2003-02-24 19:45:06+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 1996-12-18 06:18:31+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 1991-06-10 22:07:45+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 1983-05-05 12:29:09+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 1972-04-17 21:24:52+0000 oy\x1c0077H"i\x07\x13_%\x06 | | \nz@Qj\x1cB | E}P^k | 1971-05-09 23:00:02+0000 (30 rows) cqlsh&gt; </pre> </div></div> <p>If I remove the <tt>created_at</tt> clustering key, then the other two clustering keys are being assigned variable values per partition key.</p>
</description>
<environment><p>Cassandra 2.2.4, Centos 6.5, Java 8</p></environment>
<key id="12937790">CASSANDRA-11138</key>
<summary>
cassandra-stress tool - clustering key values not distributed
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="ralfsteppacher">Ralf Steppacher</reporter>
<labels>
<label>stress</label>
</labels>
<created>Tue, 9 Feb 2016 07:45:45 +0000</created>
<updated>Fri, 12 Feb 2016 16:10:17 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2slkn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11082] netty's level hadn't prevent OOM when receiver handle slow.
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11082
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>as we know, netty will OOM when received client is slow.</p> <p>due to if receiver can't handle response fast so that cassandra server can't flush data. it will cause channeloutbuffer with big size.</p> <p>we see the cassandra had configure write high/low water level, but I can't found any code to judge iswritable. so it will have possible OOM</p> <p>why cassandra hadn't handle this case?</p>
</description>
<environment/>
<key id="12934649">CASSANDRA-11082</key>
<summary>
netty's level hadn't prevent OOM when receiver handle slow.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="fujian1115">fujian</reporter>
<labels></labels>
<created>Thu, 28 Jan 2016 00:50:41 +0000</created>
<updated>Fri, 12 Feb 2016 01:37:21 +0000</updated>
<component>Streaming and Messaging</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15136805" author="slebresne" created="Mon, 8 Feb 2016 10:59:26 +0000">
<p>So you're saying that we don't have any back-pressure mechanism regarding client being too slow at receiving responses (and hence data to send accumulating server side)? Am I understanding that correctly?</p> <p>If so, I suppose that's true or at least I'm not aware of us doing anything special to prevent that. And it's a good question as to why we configure the high/low watermark given that we never check <tt>Channel.isWritable()</tt>: <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tjake" class="user-hover" rel="tjake">T Jake Luciani</a>, you introduced those configuration on <a href="https://issues.apache.org/jira/browse/CASSANDRA-6861" title="Optimise our Netty 4 integration" class="issue-link" data-issue-key="CASSANDRA-6861"><del>CASSANDRA-6861</del></a>?</p> <p>With that said, there isn't too much evidence so far that OOM due to clients being too slow to receive their responses is very common so lowering the priority.</p>
</comment>
<comment id="15136968" author="tjake" created="Mon, 8 Feb 2016 14:02:29 +0000">
<p>It's true, we should be checking isWritable() though I don't imagine we should condone/support many slow clients as a good use case for cassandra (it should be behind a firewall with local connections). </p> <p>The simplest place to put it is in our flushing logic. But what should we do drop the data on the floor? I imagine that would break the protocol so might be better to simply close the connection? wdyt <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a></p>
</comment>
<comment id="15138147" author="fujian1115" created="Tue, 9 Feb 2016 00:54:33 +0000">
<p>The case is corner but it can happen if I write one driver to send lots of requests without read any response.<br/> so it is one protect method to prevent similar cases though it is very hard to happen such as slow clients.<br/> In other words, it is best practice for safe system though it is low ratio to happen.</p> <p>there are three solutions for it:<br/> (1) just check isWritable() and if the value is false, drop the response. it is safe but it is rude.<br/> (2) just check isWritable() and if the value is false, close the channel. if use this solution, if the high water mark is set low it maybe be confused with big data response.<br/> (3) just check isWritable() and if the value is false, set AutoRead to false so that the client can slow down and can't send request at last.</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=tjake" class="user-hover" rel="tjake">T Jake Luciani</a> <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a> WDYT? And Can I apply one patch for the solution? 3ks.</p> <p>Jian</p>
</comment>
<comment id="15143809" author="fujian1115" created="Fri, 12 Feb 2016 00:57:19 +0000">
<p>I check the netty's code, only the message be sent can decrease the water mark, so if the message response is big such as &gt; 64M. we can't make one simple decision to set one low mark so that drop it. So it will involved more discussion.<br/> according to my understand. the datastax driver's: one message's max size is 256M, and cassadra is 2G. so it is hard to set the low/high water mark. I don't know is there any other limit can be used?</p> <p>so involved another question, if one response's column is 2G, how to avoid OOM when executing select before sent to network.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 8 Feb 2016 10:59:26 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2s2gf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11109] Cassandra process killed by OS due to out of memory issue
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11109
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>After we upgraded Cassandra from 2.1.12 to 2.2.4 on one of our nodes (A three nodes Cassandra cluster), we've been experiencing an og-going issue with cassandra process running with continuously increasing memory util killed by OOM. </p> <blockquote> <p>Feb 1 23:53:10 kernel: <span class="error">&#91;24135455.025185&#93;</span> <span class="error">&#91;19862&#93;</span> 494 19862 133728623 7379077 139068 0 0 java<br/> Feb 1 23:53:10 kernel: <span class="error">&#91;24135455.029678&#93;</span> Out of memory: Kill process 19862 (java) score 973 or sacrifice child<br/> Feb 1 23:53:10 kernel: <span class="error">&#91;24135455.035434&#93;</span> Killed process 19862 (java) total-vm:534918588kB, anon-rss:29413728kB, file-rss:102940kB</p></blockquote>
</description>
<environment>
<p>Operating System: <br/> Amazon Linux AMI release 2015.03<br/> Kernel \r on an \m</p> <p>Instance type: m3.2xlarge<br/> vCPUs: 8<br/> Memory: 30G<br/> Commitlog storage: 1 x 80 SSD Storage<br/> Data disks: EBS io1 300GB with 1000 IOPS</p>
</environment>
<key id="12936053">CASSANDRA-11109</key>
<summary>
Cassandra process killed by OS due to out of memory issue
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="lazyadmin">Tony Xu</reporter>
<labels></labels>
<created>Tue, 2 Feb 2016 18:46:05 +0000</created>
<updated>Wed, 24 Feb 2016 14:49:33 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15163116" author="lazyadmin" created="Wed, 24 Feb 2016 14:49:33 +0000"><p>Is anyone looking into this?</p></comment>
</comments>
<attachments>
<attachment id="12785817" name="cassandra-env.txt" size="14790" author="lazyadmin" created="Tue, 2 Feb 2016 18:46:05 +0000"/>
<attachment id="12785814" name="cassandra-system-log.txt" size="30515" author="lazyadmin" created="Tue, 2 Feb 2016 18:46:05 +0000"/>
<attachment id="12785815" name="cassandra.yaml" size="41650" author="lazyadmin" created="Tue, 2 Feb 2016 18:46:05 +0000"/>
<attachment id="12785816" name="system-messages.txt" size="11725" author="lazyadmin" created="Tue, 2 Feb 2016 18:46:05 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>4.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sb47:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11105] cassandra-stress tool - InvalidQueryException: Batch too large
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11105
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>I am using Cassandra 2.2.4 and I am struggling to get the cassandra-stress tool to work for my test scenario. I have followed the example on <a href="http://www.datastax.com/dev/blog/improved-cassandra-2-1-stress-tool-benchmark-any-schema" class="external-link" rel="nofollow">http://www.datastax.com/dev/blog/improved-cassandra-2-1-stress-tool-benchmark-any-schema</a> to create a yaml file describing my test (attached).</p> <p>I am collecting events per user id (text, partition key). Events have a session type (text), event type (text), and creation time (timestamp) (clustering keys, in that order). Plus some more attributes required for rendering the events in a UI. For testing purposes I ended up with the following column spec and insert distribution:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>columnspec: - name: created_at cluster: uniform(10..10000) - name: event_type size: uniform(5..10) population: uniform(1..30) cluster: uniform(1..30) - name: session_type size: fixed(5) population: uniform(1..4) cluster: uniform(1..4) - name: user_id size: fixed(15) population: uniform(1..1000000) - name: message size: uniform(10..100) population: uniform(1..100B) insert: partitions: fixed(1) batchtype: UNLOGGED select: fixed(1)/1200000 </pre> </div></div> <p>Running stress tool for just the insert prints </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Generating batches with [1..1] partitions and [0..1] rows (of [10..1200000] total rows in the partitions) </pre> </div></div> <p>and then immediately starts flooding me with <tt>com.datastax.driver.core.exceptions.InvalidQueryException: Batch too large</tt>. </p> <p>Why I should be exceeding the <tt>batch_size_fail_threshold_in_kb: 50</tt> in the <tt>cassandra.yaml</tt> I do not understand. My understanding is that the stress tool should generate one row per batch. The size of a single row should not exceed <tt>8+10*3+5*3+15*3+100*3 = 398 bytes</tt>. Assuming a worst case of all text characters being 3 byte unicode characters. </p> <p>This is how I start the attached user scenario:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[rsteppac@centos bin]$ ./cassandra-stress user profile=../batch_too_large.yaml ops\(insert=1\) -log level=verbose file=~/centos_event_by_patient_session_event_timestamp_insert_only.log -node 10.211.55.8 INFO 08:00:07 Did not find Netty's native epoll transport in the classpath, defaulting to NIO. INFO 08:00:08 Using data-center name 'datacenter1' for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor) INFO 08:00:08 New Cassandra host /10.211.55.8:9042 added Connected to cluster: Titan_DEV Datatacenter: datacenter1; Host: /10.211.55.8; Rack: rack1 Created schema. Sleeping 1s for propagation. Generating batches with [1..1] partitions and [0..1] rows (of [10..1200000] total rows in the partitions) com.datastax.driver.core.exceptions.InvalidQueryException: Batch too large at com.datastax.driver.core.exceptions.InvalidQueryException.copy(InvalidQueryException.java:35) at com.datastax.driver.core.DefaultResultSetFuture.extractCauseFromExecutionException(DefaultResultSetFuture.java:271) at com.datastax.driver.core.DefaultResultSetFuture.getUninterruptibly(DefaultResultSetFuture.java:185) at com.datastax.driver.core.AbstractSession.execute(AbstractSession.java:55) at org.apache.cassandra.stress.operations.userdefined.SchemaInsert$JavaDriverRun.run(SchemaInsert.java:87) at org.apache.cassandra.stress.Operation.timeWithRetry(Operation.java:159) at org.apache.cassandra.stress.operations.userdefined.SchemaInsert.run(SchemaInsert.java:119) at org.apache.cassandra.stress.StressAction$Consumer.run(StressAction.java:309) Caused by: com.datastax.driver.core.exceptions.InvalidQueryException: Batch too large at com.datastax.driver.core.Responses$Error.asException(Responses.java:125) at com.datastax.driver.core.DefaultResultSetFuture.onSet(DefaultResultSetFuture.java:120) at com.datastax.driver.core.RequestHandler.setFinalResult(RequestHandler.java:186) at com.datastax.driver.core.RequestHandler.access$2300(RequestHandler.java:45) at com.datastax.driver.core.RequestHandler$SpeculativeExecution.setFinalResult(RequestHandler.java:752) at com.datastax.driver.core.RequestHandler$SpeculativeExecution.onSet(RequestHandler.java:576) at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:1003) at com.datastax.driver.core.Connection$Dispatcher.channelRead0(Connection.java:925) at com.datastax.shaded.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at com.datastax.shaded.netty.handler.timeout.IdleStateHandler.channelRead(IdleStateHandler.java:254) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at com.datastax.shaded.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:103) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at com.datastax.shaded.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:242) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:339) at com.datastax.shaded.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:324) at com.datastax.shaded.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:847) at com.datastax.shaded.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131) at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:511) at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468) at com.datastax.shaded.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382) at com.datastax.shaded.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354) at com.datastax.shaded.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111) at java.lang.Thread.run(Thread.java:745) ... </pre> </div></div> <p>The C* log:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>INFO 08:00:04 Listening for thrift clients... WARN 08:00:07 Detected connection using native protocol version 2. Both version 1 and 2 of the native protocol are now deprecated and support will be removed in Cassandra 3.0. You are encouraged to upgrade to a client driver using version 3 of the native protocol ERROR 08:00:14 Batch of prepared statements for [stresscql.batch_too_large] is of size 58024, exceeding specified threshold of 51200 by 6824. (see batch_size_fail_threshold_in_kb) ERROR 08:00:15 Batch of prepared statements for [stresscql.batch_too_large] is of size 77985, exceeding specified threshold of 51200 by 26785. (see batch_size_fail_threshold_in_kb) ... </pre> </div></div>
</description>
<environment><p>Cassandra 2.2.4, Java 8, CentOS 6.5</p></environment>
<key id="12935888">CASSANDRA-11105</key>
<summary>
cassandra-stress tool - InvalidQueryException: Batch too large
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="ralfsteppacher">Ralf Steppacher</reporter>
<labels></labels>
<created>Tue, 2 Feb 2016 08:03:43 +0000</created>
<updated>Tue, 2 Feb 2016 17:35:10 +0000</updated>
<component>Tools</component>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="15128631" author="urandom" created="Tue, 2 Feb 2016 17:35:10 +0000">
<p>FWIW, I'm seeing the same thing (2.1.12), <a href="https://gist.github.com/eevans/1babf3fab9206951d7e6" class="external-link" rel="nofollow">yaml gist here</a>. When I run this config with <tt>n=1</tt>, I can see that 50 CQL rows are added, all with the same partition key, with two unique <tt>rev</tt> columns (25 each).</p>
</comment>
</comments>
<attachments>
<attachment id="12785737" name="batch_too_large.yaml" size="1424" author="ralfsteppacher" created="Tue, 2 Feb 2016 08:03:43 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 2 Feb 2016 17:35:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sa3j:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11091] Insufficient disk space in memtable flush should trigger disk fail policy
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11091
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>If there's insufficient disk space to flush, DiskAwareRunnable.getWriteDirectory throws and the flush fails. The commitlogs then grow indefinitely because the latch is never counted down.</p> <p>This should be an FSError so the disk fail policy is triggered. </p>
</description>
<environment/>
<key id="12934928">CASSANDRA-11091</key>
<summary>
Insufficient disk space in memtable flush should trigger disk fail policy
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rlow">Richard Low</reporter>
<labels></labels>
<created>Thu, 28 Jan 2016 21:51:00 +0000</created>
<updated>Fri, 29 Jan 2016 14:42:15 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="15123531" author="yukim" created="Fri, 29 Jan 2016 14:42:15 +0000">
<p>I think this is discussed in <a href="https://issues.apache.org/jira/browse/CASSANDRA-7275" title="Errors in FlushRunnable may leave threads hung" class="issue-link" data-issue-key="CASSANDRA-7275"><del>CASSANDRA-7275</del></a> and we are going to fix it in <a href="https://issues.apache.org/jira/browse/CASSANDRA-8496" title="Remove MemtablePostFlusher" class="issue-link" data-issue-key="CASSANDRA-8496">CASSANDRA-8496</a>.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 29 Jan 2016 14:42:15 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2s46f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332830</customfieldvalue>
<customfieldvalue>12333872</customfieldvalue>
<customfieldvalue>12333871</customfieldvalue>
<customfieldvalue>12334321</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12332830</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11162] upgrade tests failing with UDF configuration error
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11162
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Some of the upgrade dtests have a configuration error that causes them to fail when creating a UDF. The error message is</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> User-defined-functions are disabled in cassandra.yaml - set enable_user_defined_functions=<span class="code-keyword">true</span> to enable <span class="code-keyword">if</span> you are aware of the security risks </pre> </div></div> <p>Though it varies slightly between C* versions.</p> <p>Fixing this is probably a matter of setting this value in <tt>cassandra.yaml</tt> on certain upgrade paths.</p> <p>The tests failing can be found here:</p> <p><a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD/parallel_upgrade_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD/parallel_upgrade_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD/parallel_upgrade_with_internode_ssl_test/</a><br/> <a href="http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD/parallel_upgrade_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/upgrade_tests-all/2/testReport/upgrade_tests.upgrade_through_versions_test/ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD/parallel_upgrade_test/</a></p> <p>The tests' names are</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD.parallel_upgrade_with_internode_ssl_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_EndsAt_Trunk_HEAD.parallel_upgrade_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD.parallel_upgrade_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD.parallel_upgrade_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_RandomPartitioner_Skip_2_2_EndsAt_Trunk_HEAD.parallel_upgrade_with_internode_ssl_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_Skip_2_2_EndsAt_Trunk_HEAD.parallel_upgrade_with_internode_ssl_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD.parallel_upgrade_with_internode_ssl_test upgrade_tests.upgrade_through_versions_test.py:ProtoV3Upgrade_AllVersions_RandomPartitioner_EndsAt_Trunk_HEAD.parallel_upgrade_test </pre> </div></div>
</description>
<environment/>
<key id="12938636">CASSANDRA-11162</key>
<summary>upgrade tests failing with UDF configuration error</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Thu, 11 Feb 2016 22:39:24 +0000</created>
<updated>Thu, 11 Feb 2016 22:39:24 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqsf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11016] Fix flapping dtests with "unavailable" and "cannot achieve consistency" errors
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11016
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>A number of dtests flap when they run a query and get an unavailable exception or can't meet a particular CL. Examples include:</p> <p><a href="http://cassci.datastax.com/job/cassandra-2.2_dtest/470/testReport/replace_address_test/TestReplaceAddress/replace_first_boot_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.2_dtest/470/testReport/replace_address_test/TestReplaceAddress/replace_first_boot_test/</a></p> <p><a href="http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/488/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3/range_tombstones_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/view/cassandra-3.0/job/cassandra-3.0_dtest/488/testReport/upgrade_tests.cql_tests/TestCQLNodes3RF3/range_tombstones_test/</a></p> <p>This seems to be a different issue than <a href="https://issues.apache.org/jira/browse/CASSANDRA-10730" title="periodic timeout errors in dtest" class="issue-link" data-issue-key="CASSANDRA-10730"><del>CASSANDRA-10730</del></a> &#8211; bumping instance sizes to m3.2xl stopped that class of error, but bumping instance sizes to i2.4xl did not stop the errors described here.</p> <p>I'm probably the best person to tackle this, but won't get to it for a bit, so <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=philipthompson" class="user-hover" rel="philipthompson">Philip Thompson</a> might take it if he has time sooner.</p>
</description>
<environment/>
<key id="12930256">CASSANDRA-11016</key>
<summary>
Fix flapping dtests with "unavailable" and "cannot achieve consistency" errors
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels></labels>
<created>Thu, 14 Jan 2016 20:55:36 +0000</created>
<updated>Fri, 15 Jan 2016 16:02:28 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15101972" author="slebresne" created="Fri, 15 Jan 2016 16:02:28 +0000">
<p>I'll note that the truncate failures in the upgrade test are pretty easy to fix, see <a href="https://github.com/riptano/cassandra-dtest/pull/749" class="external-link" rel="nofollow">https://github.com/riptano/cassandra-dtest/pull/749</a> (I haven't checked this fix it tbh honest, but it's almost surely the problem).</p> <p>Haven't looked at the failure of replace_first_boot_test but from the error message that looks like a similar problem (the test not ensure a restart node has been detected by other ones when it should).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 15 Jan 2016 16:02:28 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2rbdz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11011] DateTieredCompactionStrategy not compacting sstables in 2.1.12
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11011
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The following CF is never compacting from day one</p> <p>CREATE TABLE globaldb."DynamicParameter" (<br/> dp_id bigint PRIMARY KEY,<br/> dp_advertiser_id int,<br/> dp_application_id int,<br/> dp_application_user_id bigint,<br/> dp_banner_id int,<br/> dp_campaign_id int,<br/> dp_click_timestamp timestamp,<br/> dp_country text,<br/> dp_custom_parameters text,<br/> dp_flags bigint,<br/> dp_ip int,<br/> dp_machine_id text,<br/> dp_string text<br/> ) WITH bloom_filter_fp_chance = 0.01<br/> AND caching = '</p> {"keys":"ALL", "rows_per_partition":"NONE"} <p>'<br/> AND comment = ''<br/> AND compaction = </p> {'max_sstable_age_days': '30', 'base_time_seconds': '3600', 'timestamp_resolution': 'MILLISECONDS', 'enabled': 'true', 'min_threshold': '2', 'class': 'org.apache.cassandra.db.compaction.DateTieredCompactionStrategy'} <p> AND compression = </p> {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} <p> AND dclocal_read_repair_chance = 0.2<br/> AND default_time_to_live = 10713600<br/> AND gc_grace_seconds = 1209600<br/> AND max_index_interval = 2048<br/> AND memtable_flush_period_in_ms = 0<br/> AND min_index_interval = 128<br/> AND read_repair_chance = 0.0<br/> AND speculative_retry = '99.0PERCENTILE';</p>
</description>
<environment><p>Ubuntu 14.04.3 LTS<br/> 2.1.12</p></environment>
<key id="12930060">CASSANDRA-11011</key>
<summary>
DateTieredCompactionStrategy not compacting sstables in 2.1.12
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="10222" iconUrl="https://issues.apache.org/jira/images/icons/statuses/generic.png" description="">Awaiting Feedback</status>
<statusCategory id="4" key="indeterminate" colorName="yellow"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="piavlo">Alexander Piavlo</reporter>
<labels>
<label>dtcs</label>
</labels>
<created>Thu, 14 Jan 2016 06:58:34 +0000</created>
<updated>Mon, 1 Feb 2016 23:37:15 +0000</updated>
<component>Compaction</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15097758" author="krummas" created="Thu, 14 Jan 2016 07:25:18 +0000">
<p>Is your timestamp_resolution really milliseconds? IE, do you do your inserts with "USING TIMESTAMP &lt;time_in_millis&gt;" ?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 14 Jan 2016 07:25:18 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ra6f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11008] Null Pointer Exception when upgrading from 2.1.12 to 3.0.2
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11008
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When upgrading a node from 2.1.12 to 3.0.2, I get a NPE during startup.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> INFO [main] 2016-01-13 19:25:52,566 LegacyHintsMigrator.java:88 - Migrating legacy hints to <span class="code-keyword">new</span> storage INFO [main] 2016-01-13 19:25:52,566 LegacyHintsMigrator.java:91 - Forcing a major compaction of system.hints table WARN [CompactionExecutor:2] 2016-01-13 19:26:05,372 BigTableWriter.java:171 - Writing large partition system/hints:4dbdaab0-f52d-46db-9367-b350567c89b8 (2548854721 bytes) INFO [main] 2016-01-13 19:26:05,528 LegacyHintsMigrator.java:95 - Writing legacy hints to the <span class="code-keyword">new</span> storage ERROR [main] 2016-01-13 19:26:08,777 CassandraDaemon.java:690 - Exception encountered during startup java.lang.NullPointerException: <span class="code-keyword">null</span> at org.apache.cassandra.serializers.Int32Serializer.deserialize(Int32Serializer.java:31) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.serializers.Int32Serializer.deserialize(Int32Serializer.java:25) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.db.marshal.AbstractType.compose(AbstractType.java:114) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.cql3.UntypedResultSet$Row.getInt(UntypedResultSet.java:287) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.convertLegacyHint(LegacyHintsMigrator.java:197) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.migrateLegacyHintsInternal(LegacyHintsMigrator.java:175) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.migrateLegacyHints(LegacyHintsMigrator.java:158) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.migrateLegacyHints(LegacyHintsMigrator.java:151) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.migrateLegacyHints(LegacyHintsMigrator.java:142) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.lambda$migrateLegacyHints$201(LegacyHintsMigrator.java:128) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator$$Lambda$140/892745204.accept(Unknown Source) ~[na:na] at java.lang.Iterable.forEach(Iterable.java:75) ~[na:1.8.0_45] at org.apache.cassandra.hints.LegacyHintsMigrator.migrateLegacyHints(LegacyHintsMigrator.java:128) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.hints.LegacyHintsMigrator.migrate(LegacyHintsMigrator.java:96) ~[apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.service.CassandraDaemon.setup(CassandraDaemon.java:294) [apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.service.CassandraDaemon.activate(CassandraDaemon.java:549) [apache-cassandra-3.0.2.jar:3.0.2] at org.apache.cassandra.service.CassandraDaemon.main(CassandraDaemon.java:677) [apache-cassandra-3.0.2.jar:3.0.2] INFO [main] 2016-01-13 19:29:10,940 YamlConfigurationLoader.java:92 - Loading settings from file:/etc/cassandra/cassandra.yaml </pre> </div></div>
</description>
<environment>
<p>Ubuntu 12.04.5 LTS (GNU/Linux 3.13.0-44-generic x86_64)</p>
</environment>
<key id="12930032">CASSANDRA-11008</key>
<summary>
Null Pointer Exception when upgrading from 2.1.12 to 3.0.2
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="nimi">Nimi Wariboko Jr.</reporter>
<labels></labels>
<created>Thu, 14 Jan 2016 03:36:16 +0000</created>
<updated>Tue, 9 Feb 2016 15:25:37 +0000</updated>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="15114695" author="nimi" created="Mon, 25 Jan 2016 03:21:22 +0000">
<p>Looks like when upgrading, a number of my system SSTables got corrupted. </p>
</comment>
<comment id="15138992" author="iamaleksey" created="Tue, 9 Feb 2016 14:34:06 +0000">
<p>Could be.</p> <p>It's throwing an NPE when trying to call <tt>row.getInt("ttl")</tt>, where <tt>ttl</tt> is coming from <tt>ttl(mutation) AS ttl</tt>. <tt>mutation</tt> column is definitely not null at this call site, so I'm a bit at a loss about how <tt>ttl(mutation)</tt> can be null here.</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=slebresne" class="user-hover" rel="slebresne">Sylvain Lebresne</a> am I missing something obvious here?</p>
</comment>
<comment id="15139015" author="slebresne" created="Tue, 9 Feb 2016 14:51:12 +0000">
<p>We actually return <tt>null</tt> for <tt>ttl(mutation)</tt> if there is no TTL (we maybe should return 0, and I think the main reason we don't is just that the code involved in setting the value don't differentiate between the fact that the column exist but has not TTL and the fact that the column itself is <tt>null</tt>; I suppose we could fix it, though I don't know if it's worth bothering) so maybe there was not TTL on that hint (not totally up to date as to whether that can happen but I believe a user could configure it that way at least?).</p>
</comment>
<comment id="15139024" author="iamaleksey" created="Tue, 9 Feb 2016 14:56:50 +0000">
<p>That's why I'm asking - to the best of my knowledge we've always ttl-d hinted mutations (at least in 1.2 and upwards).</p> <p>So I can't really explain this one I'm afraid.</p>
</comment>
<comment id="15139062" author="iamaleksey" created="Tue, 9 Feb 2016 15:25:29 +0000">
<p>Unassigning myself as I can't reproduce and have other things to work on.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 9 Feb 2016 14:34:06 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ra0f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12334321</customfieldvalue>
<customfieldvalue>12333260</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11078] upgrade_supercolumns_test dtests failing on 2.1
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11078
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>This tests in this module fail <a href="https://github.com/riptano/cassandra-dtest/blob/18647a3e167f127795e2fe63d73305dddf103716/upgrade_supercolumns_test.py#L213" class="external-link" rel="nofollow">here</a> and <a href="https://github.com/riptano/cassandra-dtest/blob/529cd71ad5ac4c2f28ccb5560ddc068f604c7b28/upgrade_supercolumns_test.py#L106" class="external-link" rel="nofollow">here</a> when a call to <tt>start</tt> with <tt>wait_other_notice=True</tt> times out. It happens consistently on the upgrade path from cassandra-2.1 to 2.2. I haven't seen clear evidence as to whether this is a test failure or a C* bug, so I'll mark it as a test error for the TE team to debug.</p> <p>I don't have a CassCI link for this failure - the changes to the tests haven't been merged yet.</p> <p>EDIT: changing the title of this ticket since there are multiple similar failures. The failing tests are</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> upgrade_supercolumns_test.py:TestSCUpgrade.upgrade_with_counters_test failing upgrade_supercolumns_test.py:TestSCUpgrade.upgrade_with_index_creation_test </pre> </div></div>
</description>
<environment/>
<key id="12934503">CASSANDRA-11078</key>
<summary>upgrade_supercolumns_test dtests failing on 2.1</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="philipthompson">Philip Thompson</assignee>
<reporter username="mambocab">Jim Witschey</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Wed, 27 Jan 2016 15:57:59 +0000</created>
<updated>Thu, 4 Feb 2016 20:58:07 +0000</updated>
<fixVersion>3.x</fixVersion>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15126689" author="enigmacurry" created="Mon, 1 Feb 2016 18:08:53 +0000">
<p>Here's a few runs from CassCI: </p> <ul class="alternate" type="square"> <li><a href="http://cassci.datastax.com/job/cassandra-2.1_dtest/414/testReport/upgrade_supercolumns_test/TestSCUpgrade/upgrade_with_counters_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.1_dtest/414/testReport/upgrade_supercolumns_test/TestSCUpgrade/upgrade_with_counters_test/</a></li> </ul> <ul class="alternate" type="square"> <li><a href="http://cassci.datastax.com/job/cassandra-2.1_dtest/414/testReport/upgrade_supercolumns_test/TestSCUpgrade/upgrade_with_index_creation_test/" class="external-link" rel="nofollow">http://cassci.datastax.com/job/cassandra-2.1_dtest/414/testReport/upgrade_supercolumns_test/TestSCUpgrade/upgrade_with_index_creation_test/</a></li> </ul>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 1 Feb 2016 18:08:53 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2s1jz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11044] query under certain partition key takes much more time than expected
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11044
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>In my cluster, all the nodes is under low workload, <br/> but query under certain partition key (we found one) takes much more time than expected. </p> <p>we write &amp; updates about 3 times per row in one day,<br/> reads are much more than writes.</p> <p>HARDWARD:<br/> 6*nodes(E5-2630, 1*ssd with 5GB data)</p> <p>TABLE DESCRIBE:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>CREATE TABLE album.user_updates ( user_id bigint, time_uuid bigint, key ascii, PRIMARY KEY (user_id, time_uuid) ) WITH CLUSTERING ORDER BY (time_uuid ASC) AND bloom_filter_fp_chance = 0.01 AND caching = '{"keys":"ALL", "rows_per_partition":"NONE"}' AND comment = '' AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy'} AND compression = {'sstable_compression': 'org.apache.cassandra.io.compress.LZ4Compressor'} AND dclocal_read_repair_chance = 0.1 AND default_time_to_live = 0 AND gc_grace_seconds = 864000 AND max_index_interval = 2048 AND memtable_flush_period_in_ms = 0 AND min_index_interval = 128 AND read_repair_chance = 0.0 AND speculative_retry = '99.0PERCENTILE'; </pre> </div></div> <p>QUERYs:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>select * from user_updates where user_id = 1432138730701829 limit 100; select count(1) from user_updates where user_id = 1432138730701829; </pre> </div></div> <p>RESULT: (takes about 3.5 minutes)</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> count ------- 1058 (1 rows) </pre> </div></div> <p>check attachments for the tracing log </p>
</description>
<environment/>
<key id="12932694">CASSANDRA-11044</key>
<summary>
query under certain partition key takes much more time than expected
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="xiaost">xiaost</reporter>
<labels></labels>
<created>Wed, 20 Jan 2016 12:35:59 +0000</created>
<updated>Mon, 8 Feb 2016 10:34:29 +0000</updated>
<component>Local Write-Read Paths</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15109430" author="iryndin" created="Wed, 20 Jan 2016 21:16:41 +0000">
<p>From log it looks like most time is spent while merging memtables and sstables. I see that after messages like <tt>Merging data from memtables and 3 sstables</tt> there is a big time gap before next message in log shows.</p>
</comment>
<comment id="15110251" author="xiaost" created="Thu, 21 Jan 2016 08:05:45 +0000">
<div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>"SharedPool-Worker-3" #371 daemon prio=5 os_prio=0 tid=0x00007fd3412ad000 nid=0x3bad runnable [0x00007fd21f687000] java.lang.Thread.State: RUNNABLE at org.apache.cassandra.db.RangeTombstoneList.insertFrom(RangeTombstoneList.java:649) at org.apache.cassandra.db.RangeTombstoneList.add(RangeTombstoneList.java:170) at org.apache.cassandra.db.RangeTombstoneList.add(RangeTombstoneList.java:142) at org.apache.cassandra.db.DeletionInfo.add(DeletionInfo.java:239) at org.apache.cassandra.db.ArrayBackedSortedColumns.delete(ArrayBackedSortedColumns.java:490) at org.apache.cassandra.db.ColumnFamily.addAtom(ColumnFamily.java:153) at org.apache.cassandra.db.filter.QueryFilter$2.getNext(QueryFilter.java:189) at org.apache.cassandra.db.filter.QueryFilter$2.hasNext(QueryFilter.java:161) at org.apache.cassandra.utils.MergeIterator$Candidate.advance(MergeIterator.java:146) at org.apache.cassandra.utils.MergeIterator$ManyToOne.&lt;init&gt;(MergeIterator.java:89) at org.apache.cassandra.utils.MergeIterator.get(MergeIterator.java:48) at org.apache.cassandra.db.filter.QueryFilter.collateColumns(QueryFilter.java:107) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:83) at org.apache.cassandra.db.filter.QueryFilter.collateOnDiskAtom(QueryFilter.java:70) at org.apache.cassandra.db.CollationController.collectAllData(CollationController.java:317) at org.apache.cassandra.db.CollationController.getTopLevelColumns(CollationController.java:61) at org.apache.cassandra.db.ColumnFamilyStore.getTopLevelColumns(ColumnFamilyStore.java:2011) at org.apache.cassandra.db.ColumnFamilyStore.getColumnFamily(ColumnFamilyStore.java:1815) at org.apache.cassandra.db.Keyspace.getRow(Keyspace.java:360) at org.apache.cassandra.db.SliceFromReadCommand.getRow(SliceFromReadCommand.java:85) at org.apache.cassandra.db.ReadVerbHandler.doVerb(ReadVerbHandler.java:38) at org.apache.cassandra.net.MessageDeliveryTask.run(MessageDeliveryTask.java:67) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$FutureTask.run(AbstractLocalAwareExecutorService.java:164) at org.apache.cassandra.concurrent.AbstractLocalAwareExecutorService$LocalSessionFutureTask.run(AbstractLocalAwareExecutorService.java:136) at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) at java.lang.Thread.run(Thread.java:745) </pre> </div></div> <p>here is the stack. I investigated into the code and found that <tt>gatherTombstones.getNext</tt> sometimes iters 9000+ times and takes 5s in <tt>returnCF.addAtom(atom)</tt></p> <p>I am trying to set <tt>gc_grace_seconds</tt> with a small value and compact and table.</p>
</comment>
<comment id="15112076" author="xiaost" created="Fri, 22 Jan 2016 08:01:35 +0000">
<p>seems duplicated of <a href="https://issues.apache.org/jira/browse/CASSANDRA-8546" title="RangeTombstoneList becoming bottleneck on tombstone heavy tasks" class="issue-link" data-issue-key="CASSANDRA-8546"><del>CASSANDRA-8546</del></a></p>
</comment>
<comment id="15136792" author="slebresne" created="Mon, 8 Feb 2016 10:34:29 +0000">
<p>If you see <tt>gatherTombstones.getNext</tt> iterating 9000+ times, then it definitively sounds like the partition is very tombstone heavy and that might just be the source of the problem. It might be related to <a href="https://issues.apache.org/jira/browse/CASSANDRA-8546" title="RangeTombstoneList becoming bottleneck on tombstone heavy tasks" class="issue-link" data-issue-key="CASSANDRA-8546"><del>CASSANDRA-8546</del></a> but I'm not sure because that ticket is mostly about inefficiencies in reverse queries and it doesn't seem that it's what you're doing and again, lots of iteration inside <tt>gatherTombstones.getNext</tt> simply suggest a huge amount of tombstones which is enough to explain the slowness.</p> <p>So the good question would be why you have a huge amount of tombstones in that partition. That could be due to the way your insert (you have a workload that simply insert too many tombstone), in which case you'd have to fix that. But one other issue that comes to mind is <a href="https://issues.apache.org/jira/browse/CASSANDRA-7953" title="RangeTombstones not merging during compaction" class="issue-link" data-issue-key="CASSANDRA-7953"><del>CASSANDRA-7953</del></a> which had the bad consequence of multiplying range tombstones, so that could be the underlying reason. Now you seem to be on 2.2.4 so <a href="https://issues.apache.org/jira/browse/CASSANDRA-7953" title="RangeTombstones not merging during compaction" class="issue-link" data-issue-key="CASSANDRA-7953"><del>CASSANDRA-7953</del></a> should be fixed, but there can still be lots of tombstones accumulated from before your upgrade that haven't been removed by compaction.</p> <p>Overall, trying to compact with a low <tt>gc_grace_seconds</tt> is definitively something to try and if you can report on the result of that experiment that would be appreciated.</p>
</comment>
</comments>
<attachments>
<attachment id="12783334" name="tracing.log" size="38053" author="xiaost" created="Wed, 20 Jan 2016 12:35:59 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 20 Jan 2016 21:16:41 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2rqfb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12333871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11063] Unable to compute ceiling for max when histogram overflowed
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11063
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>Issue <a href="https://issues.apache.org/jira/browse/CASSANDRA-8028" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/CASSANDRA-8028</a> seems related with error we are getting. But we are getting this with Cassandra 2.1.9 when autocompaction is running it keeps throwing following errors, we are unsure if its a bug or can be resolved, please suggest.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> WARN [CompactionExecutor:3] 2016-01-23 13:30:40,907 SSTableWriter.java:240 - Compacting large partition gccatlgsvcks/category_name_dedup:66611300 (138152195 bytes) ERROR [CompactionExecutor:1] 2016-01-23 13:30:50,267 CassandraDaemon.java:223 - Exception in thread <span class="code-object">Thread</span>[CompactionExecutor:1,1,main] java.lang.IllegalStateException: Unable to compute ceiling <span class="code-keyword">for</span> max when histogram overflowed at org.apache.cassandra.utils.EstimatedHistogram.mean(EstimatedHistogram.java:203) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.io.sstable.metadata.StatsMetadata.getEstimatedDroppableTombstoneRatio(StatsMetadata.java:98) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.io.sstable.SSTableReader.getEstimatedDroppableTombstoneRatio(SSTableReader.java:1987) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.AbstractCompactionStrategy.worthDroppingTombstones(AbstractCompactionStrategy.java:370) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.getNextBackgroundSSTables(SizeTieredCompactionStrategy.java:96) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy.getNextBackgroundTask(SizeTieredCompactionStrategy.java:179) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.WrappingCompactionStrategy.getNextBackgroundTask(WrappingCompactionStrategy.java:84) ~[apache-cassandra-2.1.9.jar:2.1.9] at org.apache.cassandra.db.compaction.CompactionManager$BackgroundCompactionCandidate.run(CompactionManager.java:230) ~[apache-cassandra-2.1.9.jar:2.1.9] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) ~[na:1.7.0_51] at java.util.concurrent.FutureTask.run(FutureTask.java:262) ~[na:1.7.0_51] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) ~[na:1.7.0_51] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) [na:1.7.0_51] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:744) [na:1.7.0_51] </pre> </div></div> <h3><a name="Additionalinfo%3A"></a>Additional info:</h3> <p><b>cfstats is running fine for that table...</b></p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ~ $ nodetool cfstats gccatlgsvcks.category_name_dedup Keyspace: gccatlgsvcks Read Count: 0 Read Latency: NaN ms. Write Count: 0 Write Latency: NaN ms. Pending Flushes: 0 Table: category_name_dedup SSTable count: 6 Space used (live): 836314727 Space used (total): 836314727 Space used by snapshots (total): 3621519 Off heap memory used (total): 6930368 SSTable Compression Ratio: 0.03725358753117693 <span class="code-object">Number</span> of keys (estimate): 3004 Memtable cell count: 0 Memtable data size: 0 Memtable off heap memory used: 0 Memtable <span class="code-keyword">switch</span> count: 0 Local read count: 0 Local read latency: NaN ms Local write count: 0 Local write latency: NaN ms Pending flushes: 0 Bloom filter <span class="code-keyword">false</span> positives: 0 Bloom filter <span class="code-keyword">false</span> ratio: 0.00000 Bloom filter space used: 5240 Bloom filter off heap memory used: 5192 Index summary off heap memory used: 1200 Compression metadata off heap memory used: 6923976 Compacted partition minimum bytes: 125 Compacted partition maximum bytes: 30753941057 Compacted partition mean bytes: 8352388 Average live cells per slice (last five minutes): 0.0 Maximum live cells per slice (last five minutes): 0.0 Average tombstones per slice (last five minutes): 0.0 Maximum tombstones per slice (last five minutes): 0.0 </pre> </div></div> <p><b>cfhistograms is also running fine...</b></p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ~ $ nodetool cfhistograms gccatlgsvcks category_name_dedup gccatlgsvcks/category_name_dedup histograms Percentile SSTables Write Latency Read Latency Partition Size Cell Count (micros) (micros) (bytes) 50% 0.00 0.00 0.00 1109 20 75% 0.00 0.00 0.00 2299 42 95% 0.00 0.00 0.00 11864 215 98% 0.00 0.00 0.00 35425 642 99% 0.00 0.00 0.00 51012 924 Min 0.00 0.00 0.00 125 4 Max 0.00 0.00 0.00 30753941057 268650950 </pre> </div></div>
</description>
<environment><p>Cassandra 2.1.9 on RHEL</p></environment>
<key id="12933593">CASSANDRA-11063</key>
<summary>
Unable to compute ceiling for max when histogram overflowed
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="nnishant">Navjyot Nishant</reporter>
<labels>
<label>Compaction</label>
<label>thread</label>
</labels>
<created>Sat, 23 Jan 2016 13:49:56 +0000</created>
<updated>Mon, 25 Jan 2016 17:51:30 +0000</updated>
<component>Compaction</component>
<due/>
<votes>1</votes>
<watches>5</watches>
<comments>
<comment id="15114280" author="nnishant" created="Sun, 24 Jan 2016 11:24:24 +0000">
<p><b>Update:</b></p> <p>We did executed major compaction against this table which got completed successfully and at this point there is no compaction running but This error is continuously getting logged in system.log. We tried bouncing the node which did not helped at all.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ~ $ nodetool compactionstats pending tasks: 0 </pre> </div></div>
</comment>
<comment id="15114984" author="krummas" created="Mon, 25 Jan 2016 09:56:23 +0000">
<p>we should note that you seem to have a 30GB partition: <tt>Compacted partition maximum bytes: 30753941057</tt> - we should ofc not fail like this anyway, but you might want to fix your data model</p>
</comment>
<comment id="15115648" author="nnishant" created="Mon, 25 Jan 2016 17:51:30 +0000">
<p>Thanks Marcus.. Yes we did identified this data modelling issue and wonking to fix this, but as you also mentioned this shouldn't fail like this anyways, do we have a workaround to fix this? Our system.log is full of this error.. Errors are unstoppable even when no compaction is running. At this point we just want to stop this spam.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 25 Jan 2016 09:56:23 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2rvy7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332984</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12327256</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11057] move_single_node_localhost_test is failing
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11057
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p><tt>pushed_notifications_test.TestPushedNotifications.move_single_node_localhost_test</tt> is failing across all tested versions. Example failure is <a href="http://cassci.datastax.com/job/cassandra-2.1_novnode_dtest/194/testReport/pushed_notifications_test/TestPushedNotifications/move_single_node_localhost_test/" class="external-link" rel="nofollow">here</a>. </p> <p>We need to debug this failure, as it is entirely likely it is a test issue and not a bug.</p>
</description>
<environment/>
<key id="12933105">CASSANDRA-11057</key>
<summary>move_single_node_localhost_test is failing</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="cassandra-te">DS Test Eng</assignee>
<reporter username="philipthompson">Philip Thompson</reporter>
<labels>
<label>dtest</label>
</labels>
<created>Thu, 21 Jan 2016 16:12:10 +0000</created>
<updated>Thu, 21 Jan 2016 16:42:23 +0000</updated>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2rsyn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11055] C*2.1 cqlsh DESCRIBE KEYSPACE ( or TABLE ) returns 'NoneType' object has no attribute 'replace'
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11055
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>C* 2.1 cqlsh DESCRIBE KEYSPACE ( or TABLE ) returns:</p> <p> 'NoneType' object has no attribute 'replace' </p> <p>for thrift CF's originally created in C* 1.2.</p> <p>Repro:</p> <p>1. Create cf in cassandra-cli on C* 1.2.x (1.2.9 was used here)</p> <p><span class="error">&#91;default@ks1&#93;</span> CREATE COLUMN FAMILY t1<br/> ...	WITH column_type='Standard'<br/> ...	AND comparator='CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type)'<br/> ...	AND default_validation_class='UTF8Type'<br/> ...	AND key_validation_class='UTF8Type'<br/> ...	AND read_repair_chance=0.1<br/> ...	AND dclocal_read_repair_chance=0.0<br/> ...	AND gc_grace=864000<br/> ...	AND min_compaction_threshold=4<br/> ...	AND max_compaction_threshold=32<br/> ...	AND replicate_on_write=true<br/> ...	AND compaction_strategy='LeveledCompactionStrategy' AND compaction_strategy_options=</p> {sstable_size_in_mb: 32} <p>...	AND caching='KEYS_ONLY'<br/> ...	AND compression_options=</p> {sstable_compression:SnappyCompressor, chunk_length_kb:64} <p>;</p> <p>qlsh&gt; describe keyspace ks1;</p> <p>CREATE KEYSPACE ks1 WITH replication = </p> { 'class': 'NetworkTopologyStrategy', 'datacenter1': '1' } <p>;</p> <p>USE ks1;</p> <p>CREATE TABLE t1 (<br/> key text,<br/> column1 text,<br/> column2 text,<br/> value text,<br/> PRIMARY KEY (key, column1, column2)<br/> ) WITH COMPACT STORAGE AND<br/> bloom_filter_fp_chance=0.100000 AND<br/> caching='KEYS_ONLY' AND<br/> comment='' AND<br/> dclocal_read_repair_chance=0.000000 AND<br/> gc_grace_seconds=864000 AND<br/> read_repair_chance=0.100000 AND<br/> replicate_on_write='true' AND<br/> populate_io_cache_on_flush='false' AND<br/> compaction=</p> {'sstable_size_in_mb': '32', 'class': 'LeveledCompactionStrategy'} <p> AND<br/> compression=</p> {'chunk_length_kb': '64', 'sstable_compression': 'SnappyCompressor'} <p>;</p> <p>cqlsh&gt; select keyspace_name, columnfamily_name,column_aliases,key_aliases from system.schema_columnfamilies where keyspace_name= 'ks1';</p> <p> keyspace_name | columnfamily_name | column_aliases | key_aliases<br/> --------------<del><ins></del>-----------------<del></ins></del>--------------<del>+</del>------------<br/> ks1 | t1 | [] | []</p> <p>2/ Upgrade -&gt; C* 2.0.9 -&gt; nodetool upgradesstables -a</p> <p>At this stage , DESCRIBE in cqlsh is working</p> <p>3/ Upgrade -&gt; C* 2.1.12 -&gt; nodetool upgradesstables -a</p> <p>DESCRIBE now fails:</p> <p>cqlsh&gt; describe table ks1.t1;<br/> 'NoneType' object has no attribute 'replace'</p> <p>cqlsh&gt; describe keyspace ks1;<br/> 'NoneType' object has no attribute 'replace'</p> <p>You can workaround by manually updating system.schema_columnfamilies</p> <p> UPDATE system.schema_columnfamilies SET column_aliases ='<span class="error">&#91;&quot;column1&quot;,&quot;column2&quot;&#93;</span>' WHERE keyspace_name = 'ks1' AND columnfamily_name = 't1';</p> <p>Once you exit and restart cqlsh, DESCRIBE is not working as per C* 1.2</p> <p>cqlsh&gt; describe keyspace ks1;</p> <p>CREATE KEYSPACE ks1 WITH replication = </p> {'class': 'NetworkTopologyStrategy', 'datacenter1': '1'} <p> AND durable_writes = true;</p> <p>CREATE TABLE ks1.t1 (<br/> key text,<br/> column1 text,<br/> column2 text,<br/> value text,<br/> PRIMARY KEY (key, column1, column2)<br/> ) WITH COMPACT STORAGE<br/> AND CLUSTERING ORDER BY (column1 ASC, column2 ASC)<br/> AND caching = '</p> {"keys":"ALL", "rows_per_partition":"NONE"} <p>'<br/> AND comment = ''<br/> AND compaction = </p> {'sstable_size_in_mb': '32', 'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'} <p> AND compression = </p> {'chunk_length_kb': '64', 'sstable_compression': 'org.apache.cassandra.io.compress.SnappyCompressor'} <p> AND dclocal_read_repair_chance = 0.0<br/> AND default_time_to_live = 0<br/> AND gc_grace_seconds = 864000<br/> AND max_index_interval = 2048<br/> AND memtable_flush_period_in_ms = 0<br/> AND min_index_interval = 128<br/> AND read_repair_chance = 0.1<br/> AND speculative_retry = '99.0PERCENTILE';</p>
</description>
<environment/>
<key id="12933073">CASSANDRA-11055</key>
<summary>
C*2.1 cqlsh DESCRIBE KEYSPACE ( or TABLE ) returns 'NoneType' object has no attribute 'replace'
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="sashley">Simon Ashley</reporter>
<labels>
<label>cqlsh</label>
</labels>
<created>Thu, 21 Jan 2016 13:56:49 +0000</created>
<updated>Wed, 3 Feb 2016 16:14:51 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<due/>
<votes>1</votes>
<watches>2</watches>
<comments>
<comment id="15130627" author="lazyadmin" created="Wed, 3 Feb 2016 16:14:51 +0000">
<p>We are experiencing the same issue here. Cassandra version 2.1.12, operating system is "Red Hat Enterprise Linux Server release 6.4 (Santiago)". </p> <blockquote> <p>cqlsh&gt; DESC SCHEMA;</p> <p>'NoneType' object has no attribute 'replace'</p></blockquote>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 3 Feb 2016 16:14:51 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2rsrj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12332167</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-11000] Mixing LWT and non-LWT operations can result in an LWT operation being acknowledged but not applied
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-11000
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>When mixing light-weight transaction (LWT, a.k.a. compare-and-set, conditional update) operations with regular operations, it can happen that an LWT operation is acknowledged (applied = True), even though the update has not been applied and a SELECT operation still returns the old data.</p> <p>For example, consider the following table:</p> <p>CREATE TABLE test (<br/> pk text,<br/> ck text,<br/> v text,<br/> PRIMARY KEY (pk, ck)<br/> );</p> <p>We start with an empty table and insert data using a regular (non-LWT) operation:</p> <p>INSERT INTO test (pk, ck, v) VALUES ('foo', 'bar', '123');</p> <p>A following SELECT statement returns the data as expected. Now we do a conditional update (LWT):</p> <p>UPDATE test SET v = '456' WHERE pk = 'foo' AND ck = 'bar' IF v = '123';</p> <p>As expected, the update is applied and a following SELECT statement shows the updated value.</p> <p>Now we do the same but use a time stamp that is slightly in the future (e.g. a few seconds) for the INSERT statement (obviously $time$ needs to be replaced by a time stamp that is slightly ahead of the system clock).</p> <p>INSERT INTO test (pk, ck, v) VALUES ('foo', 'bar', '123') USING TIMESTAMP $time$;</p> <p>Now, running the same UPDATE statement still report success (applied = True). However, a subsequent SELECT yields the old value ('123') instead of the updated value ('456'). Inspecting the time stamp of the value indicates that it has not been replaced (the value from the original INSERT is still in place).</p> <p>This behavior is exhibited in an single-node cluster running Cassandra 2.1.11, 2.2.4, and 3.0.1.</p> <p>Testing this for a multi-node cluster is a bit more tricky, so I only tested it with Cassandra 2.2.4. Here, I made one of the nodes lack behind in time for a few seconds (using libfaketime). I used a replication factor of three for the test keyspace. In this case, the behavior can be demonstrated even without using an explicitly specified time stamp. Running</p> <p>INSERT INTO test (pk, ck, v) VALUES ('foo', 'bar', '123');</p> <p>on a node with the regular clock followed by</p> <p>UPDATE test SET v = '456' WHERE pk = 'foo' AND ck = 'bar' IF v = '123';</p> <p>on the node lagging behind results in the UPDATE to report success, but the old value still being used.</p> <p>Interestingly, everything works as expected if using LWT operations consistently: When running</p> <p>UPDATE test SET v = '456' WHERE pk = 'foo' AND ck = 'bar' IF v = '123';<br/> UPDATE test SET v = '123' WHERE pk = 'foo' AND ck = 'bar' IF v = '456';</p> <p>in an alternating fashion on two nodes (one with a "normal" clock, one with the clock lagging behind), the updates are applied as expected. When checking the time stamps ("SELECT WRITETIME(v) FROM test;"), one can see that the time stamp is increased by just a single tick when the statement is executed on the node lagging behind.</p> <p>I think that this problem is strongly related to (or maybe even the same as) the one described in <a href="https://issues.apache.org/jira/browse/CASSANDRA-7801" title="A successful INSERT with CAS does not always store data in the DB after a DELETE" class="issue-link" data-issue-key="CASSANDRA-7801"><del>CASSANDRA-7801</del></a>, even though <a href="https://issues.apache.org/jira/browse/CASSANDRA-7801" title="A successful INSERT with CAS does not always store data in the DB after a DELETE" class="issue-link" data-issue-key="CASSANDRA-7801"><del>CASSANDRA-7801</del></a> was mainly concerned about a single-node cluster. However, the fact that this problem still exists in current versions of Cassandra makes me suspect that either it is a different problem or the original problem was not fixed completely with the patch from <a href="https://issues.apache.org/jira/browse/CASSANDRA-7801" title="A successful INSERT with CAS does not always store data in the DB after a DELETE" class="issue-link" data-issue-key="CASSANDRA-7801"><del>CASSANDRA-7801</del></a>.</p> <p>I found <a href="https://issues.apache.org/jira/browse/CASSANDRA-9655" title="Consider reverting CASSANDRA-7801" class="issue-link" data-issue-key="CASSANDRA-9655">CASSANDRA-9655</a> which suggest removing the changes introduced with <a href="https://issues.apache.org/jira/browse/CASSANDRA-7801" title="A successful INSERT with CAS does not always store data in the DB after a DELETE" class="issue-link" data-issue-key="CASSANDRA-7801"><del>CASSANDRA-7801</del></a> because they can be problematic under certain circumstances, but I am not sure whether this is the right place to discuss the issue I am experiencing. If you feel so, feel free to close this issue and update the description of <a href="https://issues.apache.org/jira/browse/CASSANDRA-9655" title="Consider reverting CASSANDRA-7801" class="issue-link" data-issue-key="CASSANDRA-9655">CASSANDRA-9655</a>.</p> <p>In my opinion, the best way to fix this problem would be ensuring that a write that is part of a LWT always uses a time stamp that is at least one tick greater than the time stamp of the existing data. As the existing data has to be read for checking the condition anyway, I do not think that this would cause an additional overhead. If this is not possible, I suggest to look into whether we can somehow detect such a situation and at least report failure (applied = False) on the LWT instead of reporting success.</p> <p>The latter solution would at least fix those cases where code checks the success of a LWT before performing any further actions (e.g. because the LWT is used to take some kind of lock). Currently, the code will assume that the operation was successful (and thus - staying in the example - it owns the lock), while other processes running in parallel will see a different state. It is my understanding that LWTs were designed to avoid exactly this situation, but at the moment the assumptions most users will make about LWTs do not always hold.</p> <p>Until this issue is solved, I suggest at least updating the CQL documentation and clearly stating that LWTs / conditional updates are not safe if data has been previously INSERTed / UPDATEd / DELETEd using non-LWT operations and there is a clock skew or time stamps that are in the future have been supplied explicitly. This should at least save some users from making wrong assumptions about LWTs and not realizing it until their application fails in an unsafe way.</p>
</description>
<environment>
<p>Cassandra 2.1, 2.2, and 3.0 on Linux and OS X.</p>
</environment>
<key id="12929299">CASSANDRA-11000</key>
<summary>
Mixing LWT and non-LWT operations can result in an LWT operation being acknowledged but not applied
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="smarsching">Sebastian Marsching</reporter>
<labels></labels>
<created>Mon, 11 Jan 2016 21:59:40 +0000</created>
<updated>Mon, 11 Jan 2016 21:59:40 +0000</updated>
<component>Coordination</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2r5hr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311421" key="com.atlassian.jira.plugin.system.customfieldtypes:multiversion">
<customfieldname>Reproduced In</customfieldname>
<customfieldvalues>
<customfieldvalue>12333871</customfieldvalue>
<customfieldvalue>12334152</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12333770</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10988] ClassCastException in SelectStatement
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10988
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>After we've upgraded our cluster to version 2.1.11, we started getting the bellow exceptions for some of our queries. Issue seems to be very similar to <a href="https://issues.apache.org/jira/browse/CASSANDRA-7284" title="ClassCastException in HintedHandoffManager.pagingFinished" class="issue-link" data-issue-key="CASSANDRA-7284"><del>CASSANDRA-7284</del></a>.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.ClassCastException: org.apache.cassandra.db.composites.Composites$EmptyComposite cannot be <span class="code-keyword">cast</span> to org.apache.cassandra.db.composites.CellName at org.apache.cassandra.db.composites.AbstractCellNameType.cellFromByteBuffer(AbstractCellNameType.java:188) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.composites.AbstractSimpleCellNameType.makeCellName(AbstractSimpleCellNameType.java:125) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.db.composites.AbstractCellNameType.makeCellName(AbstractCellNameType.java:254) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.makeExclusiveSliceBound(SelectStatement.java:1197) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.applySliceRestriction(SelectStatement.java:1205) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.processColumnFamily(SelectStatement.java:1283) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.process(SelectStatement.java:1250) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.processResults(SelectStatement.java:299) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:276) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:224) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.statements.SelectStatement.execute(SelectStatement.java:67) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.QueryProcessor.processStatement(QueryProcessor.java:238) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.cql3.QueryProcessor.processPrepared(QueryProcessor.java:493) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.transport.messages.ExecuteMessage.execute(ExecuteMessage.java:138) ~[apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:439) [apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.transport.Message$Dispatcher.channelRead0(Message.java:335) [apache-cassandra-2.1.11.jar:2.1.11] at io.netty.channel.SimpleChannelInboundHandler.channelRead(SimpleChannelInboundHandler.java:105) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:333) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext.access$700(AbstractChannelHandlerContext.java:32) [netty-all-4.0.23.Final.jar:4.0.23.Final] at io.netty.channel.AbstractChannelHandlerContext$8.run(AbstractChannelHandlerContext.java:324) [netty-all-4.0.23.Final.jar:4.0.23.Final] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_66] at org.apache.cassandra.concurrent.AbstractTracingAwareExecutorService$FutureTask.run(AbstractTracingAwareExecutorService.java:164) [apache-cassandra-2.1.11.jar:2.1.11] at org.apache.cassandra.concurrent.SEPWorker.run(SEPWorker.java:105) [apache-cassandra-2.1.11.jar:2.1.11] at java.lang.<span class="code-object">Thread</span>.run(<span class="code-object">Thread</span>.java:745) [na:1.8.0_66] </pre> </div></div>
</description>
<environment/>
<key id="12928641">CASSANDRA-10988</key>
<summary>ClassCastException in SelectStatement</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="RealVasko">Vassil Hristov</reporter>
<labels></labels>
<created>Fri, 8 Jan 2016 13:34:58 +0000</created>
<updated>Fri, 8 Jan 2016 13:34:58 +0000</updated>
<component>CQL</component>
<due/>
<votes>2</votes>
<watches>3</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2r1fr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10985] OOM during bulk read(slice query) operation
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10985
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>The thread java.lang.Thread @ 0x55000a4f0 Thrift:6 keeps local variables with total size 16,214,953,728 (98.23%) bytes.</p> <p>The memory is accumulated in one instance of "java.lang.Thread" loaded by "&lt;system class loader&gt;".<br/> The stacktrace of this Thread is available. See stacktrace.</p> <p>Keywords<br/> java.lang.Thread<br/> --------------------------------------------------------------------------------------<br/> Trace: </p> <p>Thrift:6<br/> at java.lang.OutOfMemoryError.&lt;init&gt;()V (OutOfMemoryError.java:48)<br/> at org.apache.cassandra.utils.ByteBufferUtil.read(Ljava/io/DataInput;I)Ljava/nio/ByteBuffer; (ByteBufferUtil.java:401)<br/> at org.apache.cassandra.utils.ByteBufferUtil.readWithVIntLength(Lorg/apache/cassandra/io/util/DataInputPlus;)Ljava/nio/ByteBuffer; (ByteBufferUtil.java:339)<br/> at org.apache.cassandra.db.marshal.AbstractType.readValue(Lorg/apache/cassandra/io/util/DataInputPlus;)Ljava/nio/ByteBuffer; (AbstractType.java:391)<br/> at org.apache.cassandra.db.rows.BufferCell$Serializer.deserialize(Lorg/apache/cassandra/io/util/DataInputPlus;Lorg/apache/cassandra/db/LivenessInfo;Lorg/apache/cassandra/config/ColumnDefinition;Lorg/apache/cassandra/db/SerializationHeader;Lorg/apache/cassandra/db/rows/SerializationHelper;)Lorg/apache/cassandra/db/rows/Cell; (BufferCell.java:298)<br/> at org.apache.cassandra.db.rows.UnfilteredSerializer.readSimpleColumn(Lorg/apache/cassandra/config/ColumnDefinition;Lorg/apache/cassandra/io/util/DataInputPlus;Lorg/apache/cassandra/db/SerializationHeader;Lorg/apache/cassandra/db/rows/SerializationHelper;Lorg/apache/cassandra/db/rows/Row$Builder;Lorg/apache/cassandra/db/LivenessInfo;)V (UnfilteredSerializer.java:453)<br/> at org.apache.cassandra.db.rows.UnfilteredSerializer.deserializeRowBody(Lorg/apache/cassandra/io/util/DataInputPlus;Lorg/apache/cassandra/db/SerializationHeader;Lorg/apache/cassandra/db/rows/SerializationHelper;IILorg/apache/cassandra/db/rows/Row$Builder;)Lorg/apache/cassandra/db/rows/Row; (UnfilteredSerializer.java:431)<br/> at org.apache.cassandra.db.rows.UnfilteredSerializer.deserialize(Lorg/apache/cassandra/io/util/DataInputPlus;Lorg/apache/cassandra/db/SerializationHeader;Lorg/apache/cassandra/db/rows/SerializationHelper;Lorg/apache/cassandra/db/rows/Row$Builder;)Lorg/apache/cassandra/db/rows/Unfiltered; (UnfilteredSerializer.java:360)<br/> at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext()Lorg/apache/cassandra/db/rows/Unfiltered; (UnfilteredRowIteratorSerializer.java:217)<br/> at org.apache.cassandra.db.rows.UnfilteredRowIteratorSerializer$1.computeNext()Ljava/lang/Object; (UnfilteredRowIteratorSerializer.java:210)<br/> at org.apache.cassandra.utils.AbstractIterator.hasNext()Z (AbstractIterator.java:47)<br/> at org.apache.cassandra.db.transform.BaseRows.hasNext()Z (BaseRows.java:108)<br/> at org.apache.cassandra.db.LegacyLayout$3.computeNext()Lorg/apache/cassandra/db/LegacyLayout$LegacyCell; (LegacyLayout.java:658)<br/> at org.apache.cassandra.db.LegacyLayout$3.computeNext()Ljava/lang/Object; (LegacyLayout.java:640)<br/> at org.apache.cassandra.utils.AbstractIterator.hasNext()Z (AbstractIterator.java:47)<br/> at org.apache.cassandra.thrift.CassandraServer.thriftifyColumns(Lorg/apache/cassandra/config/CFMetaData;Ljava/util/Iterator;)Ljava/util/List; (CassandraServer.java:112)<br/> at org.apache.cassandra.thrift.CassandraServer.thriftifyPartition(Lorg/apache/cassandra/db/rows/RowIterator;ZZI)Ljava/util/List; (CassandraServer.java:250)<br/> at org.apache.cassandra.thrift.CassandraServer.getSlice(Ljava/util/List;ZILorg/apache/cassandra/db/ConsistencyLevel;Lorg/apache/cassandra/service/ClientState;)Ljava/util/Map; (CassandraServer.java:270)<br/> at org.apache.cassandra.thrift.CassandraServer.multigetSliceInternal(Ljava/lang/String;Ljava/util/List;Lorg/apache/cassandra/thrift/ColumnParent;ILorg/apache/cassandra/thrift/SlicePredicate;Lorg/apache/cassandra/thrift/ConsistencyLevel;Lorg/apache/cassandra/service/ClientState;)Ljava/util/Map; (CassandraServer.java:566)<br/> at org.apache.cassandra.thrift.CassandraServer.multiget_slice(Ljava/util/List;Lorg/apache/cassandra/thrift/ColumnParent;Lorg/apache/cassandra/thrift/SlicePredicate;Lorg/apache/cassandra/thrift/ConsistencyLevel;)Ljava/util/Map; (CassandraServer.java:348)<br/> at org.apache.cassandra.thrift.Cassandra$Processor$multiget_slice.getResult(Lorg/apache/cassandra/thrift/Cassandra$Iface;Lorg/apache/cassandra/thrift/Cassandra$multiget_slice_args;)Lorg/apache/cassandra/thrift/Cassandra$multiget_slice_result; (Cassandra.java:3716)<br/> at org.apache.cassandra.thrift.Cassandra$Processor$multiget_slice.getResult(Ljava/lang/Object;Lorg/apache/thrift/TBase;)Lorg/apache/thrift/TBase; (Cassandra.java:3700)<br/> at org.apache.thrift.ProcessFunction.process(ILorg/apache/thrift/protocol/TProtocol;Lorg/apache/thrift/protocol/TProtocol;Ljava/lang/Object;)V (ProcessFunction.java:39)<br/> at org.apache.thrift.TBaseProcessor.process(Lorg/apache/thrift/protocol/TProtocol;Lorg/apache/thrift/protocol/TProtocol;)Z (TBaseProcessor.java:39)<br/> at org.apache.cassandra.thrift.CustomTThreadPoolServer$WorkerProcess.run()V (CustomTThreadPoolServer.java:204)<br/> at java.util.concurrent.ThreadPoolExecutor.runWorker(Ljava/util/concurrent/ThreadPoolExecutor$Worker;)V (ThreadPoolExecutor.java:1142)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run()V (ThreadPoolExecutor.java:617)<br/> at java.lang.Thread.run()V (Thread.java:745)</p> <p>------------------------------------------------------------------------------</p>
</description>
<environment>
<p>OS : Linux 6.5<br/> RAM : 126GB<br/> assign heap size: 8GB</p>
</environment>
<key id="12928590">CASSANDRA-10985</key>
<summary>OOM during bulk read(slice query) operation</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="sumit.thakur@rancoretech.com">sumit thakur</reporter>
<labels></labels>
<created>Fri, 8 Jan 2016 09:26:18 +0000</created>
<updated>Mon, 11 Jan 2016 03:55:27 +0000</updated>
<component>Observability</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15088957" author="sumit.thakur@rancoretech.com" created="Fri, 8 Jan 2016 09:27:42 +0000">
<p>Object / Stack Frame	java.lang.Thread @ 0x55000a4f0<br/> Name	Thrift:6<br/> Shallow Heap	120<br/> Retained Heap	16,214,953,728<br/> Context Class Loader sun.misc.Launcher$AppClassLoader @ 0x550000000<br/> Is Daemon	true</p> <p>Total: 6 entries</p>
</comment>
<comment id="15089236" author="slebresne" created="Fri, 8 Jan 2016 14:08:13 +0000">
<p>Can you tell us:</p> <ul> <li>whether this only happened once or if it's reproducible.</li> <li>what version of C* this is. This is clearly 3.X but a more precise version can't hurt.</li> <li>is that a brand new cluster (on 3.X), or an upgraded one.</li> <li>is there anything more you can tell us about the activity on the cluster when that happen? Is there node bootstrapping, some schema changes happening concurrently, a particularly high load, ....</li> </ul>
</comment>
<comment id="15090139" author="jkrupan" created="Fri, 8 Jan 2016 23:05:09 +0000">
<p>How big a slice are you trying to read? I'd recommend no more than 5K columns in a single request and issue multiple requests.</p> <p>Very large operations are an anti-pattern even if they do manage to sort of work.</p> <p>Was this working before for you and suddenly stopped working or was this the first time you tried a slice of this size?</p> <p>You're dealing with Thrift, so don't expect too much support.</p>
</comment>
<comment id="15091393" author="sumit.thakur@rancoretech.com" created="Mon, 11 Jan 2016 03:51:24 +0000">
<p>1. It is reproducible.<br/> 2. version 3.1<br/> 3. It is single node new cluster.<br/> 4. It happens while trying to read data using range slice (thrift client).</p> <p>where column size : 100kb<br/> no. of columns in each row = 3600<br/> no. of rows in column family = 24</p> <p>changes in yaml file :<br/> 1. thrift_framed_transport_size_in_mb = 1024 </p> <p>Please suggest better approach to handle this case.</p> <p>Thanks &amp; Regards<br/> Sumit </p>
</comment>
<comment id="15091396" author="sumit.thakur@rancoretech.com" created="Mon, 11 Jan 2016 03:55:27 +0000">
<p>It happens while trying to read data using range slice (thrift client).</p> <p>where column size : 100kb<br/> no. of columns in each row = 3600<br/> no. of rows in column family = 24</p> <p>changes in yaml file :<br/> 1. thrift_framed_transport_size_in_mb = 1024 </p> <p>Q.1) How much data(MB) can be read from cassandra using thrift <br/> client at a time?<br/> Q.2) How much data(MB) can be read from cassandra using native <br/> client at a time?</p> <p>Please suggest </p> <p>Thanks &amp; Regards<br/> Sumit Thakur</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 8 Jan 2016 14:08:13 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2r14f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-10982] Put gc.log in -Dcassandra.logdir location by default
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-10982
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p><a href="https://issues.apache.org/jira/browse/CASSANDRA-10140" title="Enable GC logging by default" class="issue-link" data-issue-key="CASSANDRA-10140"><del>CASSANDRA-10140</del></a> turned on gc.log by default, and set it's location to CASSANDRA_HOME/logs. It would be much better UX if when -Dcassandra.logdir was set, that it was used instead. This way users don't have to separately configure gc.log from the other log files.</p> <p>Additionally, I don't think 10140 made it to trunk, as grepping for `loggc` there shows me nothing in cassandra-env.sh as of 31f67c289.</p>
</description>
<environment/>
<key id="12928431">CASSANDRA-10982</key>
<summary>
Put gc.log in -Dcassandra.logdir location by default
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="philipthompson">Philip Thompson</reporter>
<labels></labels>
<created>Thu, 7 Jan 2016 20:22:08 +0000</created>
<updated>Fri, 8 Jan 2016 15:39:13 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<fixVersion>3.0.x</fixVersion>
<fixVersion>3.x</fixVersion>
<component>Configuration</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15088967" author="slebresne" created="Fri, 8 Jan 2016 09:38:46 +0000">
<blockquote><p>Additionally, I don't think 10140 made it to trunk</p></blockquote> <p>Something is wrong with my git fu but I don't know what. According to the git log, the patch from 3.0 <em>was</em> properly merged but the changes somehow weren't applied as if the merge was done with <tt>--strategy=ours</tt> even though I'm 100% sure the merge was not done with that option. This is not the only patch that I merge that had this problem in the last few days so if someone knows what I'm doing wrong and can enlighten me, that would be highly appreciated. I did fix this manually in the meantime.</p>
</comment>
<comment id="15089360" author="cnlwsu" created="Fri, 8 Jan 2016 15:39:13 +0000">
<p>Per conversation in irc. Not sure this ticket is possible since you cannot set the -Xloggc jvm option to a system property. We ultimately set cassandra.logdir to CASSANDRA_HOME/logs (except with deb patch) so this may be just unfortunate chicken and egg thing requiring a little duplication. </p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 8 Jan 2016 09:38:46 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2r053:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9530] SSTable corruption can trigger OOM
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9530
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>If a sstable is corrupted so that the length of a given is bogus, we'll still happily try to allocate a buffer of that bogus size to read the value, which can easily lead to an OOM.</p> <p>We should probably protect against this. In practice, a given value can be so big since it's limited by the protocol frame size in the first place. Maybe we could add a max_value_size_in_mb setting and we'd considered a sstable corrupted if it was containing a value bigger than that.</p> <p>I'll note that this ticket would be a good occasion to improve <tt>BlacklistingCompactionsTest</tt>. Typically, it currently generate empty values which makes it pretty much impossible to get the problem described here. And as described in <a href="https://issues.apache.org/jira/browse/CASSANDRA-9478" title="SSTables are not always properly marked suspected" class="issue-link" data-issue-key="CASSANDRA-9478"><del>CASSANDRA-9478</del></a>, it also doesn't test properly for thing like early opening of compaction results. We could try to randomize as much of the parameters of this test as possible to make it more likely to catch any type of corruption that could happen.</p>
</description>
<environment/>
<key id="12834581">CASSANDRA-9530</key>
<summary>SSTable corruption can trigger OOM</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="slebresne">Sylvain Lebresne</reporter>
<labels></labels>
<created>Tue, 2 Jun 2015 13:25:12 +0000</created>
<updated>Thu, 19 Nov 2015 16:05:51 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2figf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9434] If a node loses schema_columns SSTables it could delete all secondary indexes from the schema
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9434
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>It is possible that a single bad node can delete all secondary indexes if it restarts and cannot read its schema_columns SSTables. Here's a reproduction:</p> <ul> <li>Create a 2 node cluster (we saw it on 2.0.11)</li> <li>Create the schema:</li> </ul> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> create keyspace myks with replication = {'class':'SimpleStrategy', 'replication_factor':1}; use myks; create table mytable (a text, b text, c text, PRIMARY KEY (a, b) ); create index myindex on mytable(b); </pre> </div></div> <p>NB index must be on clustering column to repro</p> <ul> <li>Kill one node</li> <li>Wipe its commitlog and system/schema_columns sstables.</li> <li>Start it again</li> <li>Run on this node</li> </ul> <p>select index_name from system.schema_columns where keyspace_name = 'myks' and columnfamily_name = 'mytable' and column_name = 'b';</p> <p>and you'll see the index is null.</p> <ul> <li>Run 'describe schema' on the other node. Sometimes it will not show the index, but you might need to bounce for it to disappear.</li> </ul> <p>I think the culprit is SystemKeyspace.copyAllAliasesToColumnsProper.</p>
</description>
<environment/>
<key id="12831244">CASSANDRA-9434</key>
<summary>
If a node loses schema_columns SSTables it could delete all secondary indexes from the schema
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rlow">Richard Low</reporter>
<labels></labels>
<created>Wed, 20 May 2015 01:05:44 +0000</created>
<updated>Fri, 23 Oct 2015 14:33:53 +0000</updated>
<fixVersion>2.1.x</fixVersion>
<fixVersion>2.2.x</fixVersion>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14551601" author="rlow" created="Wed, 20 May 2015 01:12:14 +0000">
<p>cc <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=iamaleksey" class="user-hover" rel="iamaleksey">Aleksey Yeschenko</a></p>
</comment>
<comment id="14552251" author="iamaleksey" created="Wed, 20 May 2015 12:36:54 +0000">
<p>Fundamentally the issue is the loss of those sstables, and some of the ways we store schema. A lot will be addressed by <a href="https://issues.apache.org/jira/browse/CASSANDRA-6717" title="Modernize schema tables" class="issue-link" data-issue-key="CASSANDRA-6717"><del>CASSANDRA-6717</del></a> in 3.0.0.</p> <p>That said, I'll to look into minimizing the damage from this edge case on 2.0. This is no good.</p>
</comment>
<comment id="14700301" author="iamaleksey" created="Mon, 17 Aug 2015 22:00:29 +0000">
<p>So, the good news is that this issue will not happen in 2.1, 2.2, or 3.0. In those we assume that this migration had been performed in 2.0 already. Furthermore, in 3.0 the indexes are kept in a totally separate table from columns.</p> <p>The bad news is that 2.0 is EOL and that I don't know a solid heuristic for determining whether or not we have this data missing. It's possible for a pre-upgrade 2.0 node to have completely empty <tt>system.schema_columns</tt> (sans system tables' columns themselves) table if the system had no <tt>REGULAR</tt> columns defined on any of the tables.</p>
</comment>
<comment id="14700697" author="rlow" created="Tue, 18 Aug 2015 04:14:53 +0000">
<p>Thanks Aleksey. So it sounds like we should close this as behaves correctly?</p>
</comment>
<comment id="14701616" author="iamaleksey" created="Tue, 18 Aug 2015 17:10:55 +0000">
<p>'Correctly' is not the word I would use. Expected, I guess.</p> <p>I'll elaborate on what is going on. With CQL3 it became possible to give individual names to the components of the key validator and the comparator. Those names (aliases) were originally stored in <tt>system.schema_columnfamilies</tt> table, as JSON lists in columns <tt>key_aliases</tt> and <tt>column_aliases</tt>. Only <tt>REGULAR</tt> columns were stored in <tt>system.schema_columns</tt> table.</p> <p>Starting with 2.0 beta1 (<a href="https://issues.apache.org/jira/browse/CASSANDRA-5125" title="Support indexes on composite column components (clustered columns)" class="issue-link" data-issue-key="CASSANDRA-5125"><del>CASSANDRA-5125</del></a>) we keep all the 'aliases' in system.schema_columns together with the regular columns - for the newly-created tables. That was done specifically to allow secondary indexes on primary key columns.</p> <p><a href="https://issues.apache.org/jira/browse/CASSANDRA-6009" title="Migrate pre-2.0 key/value/column aliases to system.schema_columns" class="issue-link" data-issue-key="CASSANDRA-6009"><del>CASSANDRA-6009</del></a> (in 2.0.1) added a start-up migration step so that previously created tables (in 1.2 and before) too store their 'aliases' properly, in <tt>system.schema_columns</tt> (<tt>SystemKeyspace.copyAllAliasesToColumnsProper()</tt>). With sstables for columns absent, it just treated the tables as requiring a migration in your case, and so the new converted columns were created, and lacked any information about the indexes - since that was never stored in the aliases, and couldn't be. And those changes then propagated to the other nodes, and <tt>null</tt> s for <tt>index_info</tt>, <tt>index_options</tt>, and <tt>index_name</tt> won, given the same timestamp.</p> <p>This is a rare case (losing your columns sstables). This is properly fixed in 3.0, with Sam's latest commit of <a href="https://issues.apache.org/jira/browse/CASSANDRA-6717" title="Modernize schema tables" class="issue-link" data-issue-key="CASSANDRA-6717"><del>CASSANDRA-6717</del></a>, where the indexes are kept in a separate schema table.</p> <p>2.1 and 2.2 might still be affected, and I think we can actually guard against it in 2.0.2 and up, but the logic for 2.0 will be somewhat involved. 2.1 and 2.2, OTOH, pretty straightforward. Given that information, and 2.0 being EOL, do you object me only taking care of it in 2.1 and 2.2, if affected?</p>
</comment>
<comment id="14702418" author="rlow" created="Wed, 19 Aug 2015 04:13:23 +0000">
<p>Thanks for the explanation! With 2.0 EOL I don't think I can object much... I updated the fix versions.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 20 May 2015 12:36:54 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2eyrz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311420" key="com.atlassian.jira.plugin.system.customfieldtypes:version">
<customfieldname>Since Version</customfieldname>
<customfieldvalues>
<customfieldvalue>12327942</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[CASSANDRA-9418] Fix dtests on 2.2 branch on Windows
</title>
<link>
https://issues.apache.org/jira/browse/CASSANDRA-9418
</link>
<project id="12310865" key="CASSANDRA">Cassandra</project>
<description>
<p>There's a variety of infrastructural failures within dtest w/regards to windows that are causing tests to fail and those failures to cascade.</p> <p>Error: failure to delete commit log after a test / ccm cluster is stopped:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Traceback (most recent call last): File "C:\src\cassandra-dtest\dtest.py", line 452, in tearDown self._cleanup_cluster() File "C:\src\cassandra-dtest\dtest.py", line 172, in _cleanup_cluster self.cluster.remove() File "build\bdist.win-amd64\egg\ccmlib\cluster.py", line 212, in remove shutil.rmtree(self.get_path()) File "C:\Python27\lib\shutil.py", line 247, in rmtree rmtree(fullname, ignore_errors, onerror) File "C:\Python27\lib\shutil.py", line 247, in rmtree rmtree(fullname, ignore_errors, onerror) File "C:\Python27\lib\shutil.py", line 252, in rmtree onerror(os.remove, fullname, sys.exc_info()) File "C:\Python27\lib\shutil.py", line 250, in rmtree os.remove(fullname) WindowsError: [Error 5] Access is denied: 'c:\\temp\\dtest-4rxq2i\\test\\node1\\commitlogs\\CommitLog-5-1431969131917.log' </pre> </div></div> <p>Cascading error: implication is that tests aren't shutting down correctly and subsequent tests cannot start:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>06:00:20 ERROR: test_incr_decr_super_remove (thrift_tests.TestMutations) 06:00:20 ---------------------------------------------------------------------- 06:00:20 Traceback (most recent call last): 06:00:20 File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\thrift_tests.py", line 55, in setUp 06:00:20 cluster.start() 06:00:20 File "build\bdist.win-amd64\egg\ccmlib\cluster.py", line 249, in start 06:00:20 p = node.start(update_pid=False, jvm_args=jvm_args, profile_options=profile_options) 06:00:20 File "build\bdist.win-amd64\egg\ccmlib\node.py", line 457, in start 06:00:20 common.check_socket_available(itf) 06:00:20 File "build\bdist.win-amd64\egg\ccmlib\common.py", line 341, in check_socket_available 06:00:20 raise UnavailableSocketError("Inet address %s:%s is not available: %s" % (addr, port, msg)) 06:00:20 UnavailableSocketError: Inet address 127.0.0.1:9042 is not available: [Errno 10013] An attempt was made to access a socket in a way forbidden by its access permissions 06:00:20 -------------------- &gt;&gt; begin captured logging &lt;&lt; -------------------- 06:00:20 dtest: DEBUG: removing ccm cluster test at: d:\temp\dtest-a5iny5 06:00:20 dtest: DEBUG: cluster ccm directory: d:\temp\dtest-dalzcy 06:00:20 --------------------- &gt;&gt; end captured logging &lt;&lt; --------------------- </pre> </div></div> <p>I've also seen (and am debugging) an error where a node just fails to start via ccm.</p> <p>I'll update this ticket with PR's to dtest or other observations of interest.</p>
</description>
<environment/>
<key id="12830796">CASSANDRA-9418</key>
<summary>Fix dtests on 2.2 branch on Windows</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="JoshuaMcKenzie">Joshua McKenzie</assignee>
<reporter username="JoshuaMcKenzie">Joshua McKenzie</reporter>
<labels>
<label>Windows</label>
<label>docs-impacting</label>
</labels>
<created>Mon, 18 May 2015 19:11:24 +0000</created>
<updated>Fri, 13 Nov 2015 15:11:38 +0000</updated>
<fixVersion>2.2.x</fixVersion>
<component>Testing</component>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="14561704" author="joshuamckenzie" created="Wed, 27 May 2015 20:51:47 +0000">
<p>A simple ccm PR (<a href="https://github.com/pcmanus/ccm/pull/289" class="external-link" rel="nofollow">link</a>) and a dtest PR (<a href="https://github.com/riptano/cassandra-dtest/pull/299" class="external-link" rel="nofollow">link</a>) have knocked off 226 more failures and gotten us down to 338 failures from 564 (<a href="http://cassci.datastax.com/view/trunk/job/trunk_dtest_win32/271/" class="external-link" rel="nofollow">test run here</a>).</p> <p>In the logs there's a very high count of "Found running cassandra process with pid: 15776. Killing." from the dtest change to kill running cassandra processes during Tester.setUp(). The matching ccm PR was intended to give us something to correlate w/those failures to find out if there were specific tests that were hanging and address them, however this first test run gave us over 100 instances of hung tests that had to be killed. Hopefully there's a systemic infrastructural issue that we can address that will help with those errors.</p> <p>There's still a high number of errors indicating missing system.log, conf&#42;, or bin&#42; files; there's some environmental silliness occurring I haven't gotten any clarity on yet as it's CI specific. The PR for ccm didn't actually print to stderr so once I figure out why CI / nosetests is absorbing that output, I'll probably also put in some more debug information from ccm regarding starting and stopping clusters and point CI to that debug branch to get more information out of it.</p>
</comment>
<comment id="14571257" author="joshuamckenzie" created="Wed, 3 Jun 2015 16:07:38 +0000">
<p>After removing a windows-specific wrapper script and some windows-specific changes to both ccm and dtest:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>01:13:57 Ran 662 tests in 25177.644s 01:13:57 01:13:57 FAILED (SKIP=49, errors=46, failures=18) </pre> </div></div> <p>Moving on to addressing this class of errors next:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>01:13:57 ERROR: complex_data_types_test (json_test.FromJsonInsertTests) 01:13:57 ---------------------------------------------------------------------- 01:13:57 Traceback (most recent call last): 01:13:57 File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\json_test.py", line 1030, in complex_data_types_test 01:13:57 run_func_docstring(tester=self, test_func=self.complex_data_types_test) 01:13:57 File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\json_test.py", line 165, in run_func_docstring 01:13:57 raise RuntimeError("Doctest failed! Captured output:\n{}".format(test_output_capturer.content)) 01:13:57 RuntimeError: Doctest failed! Captured output: 01:13:57 ********************************************************************** 01:13:57 Line 70, in complex_data_types_test 01:13:57 Failed example: 01:13:57 cqlsh_print("SELECT key1, mylist from complex_types where key1 in ('row1', 'row2')") 01:13:57 Expected: 01:13:57 &lt;BLANKLINE&gt; 01:13:57 key1 | mylist 01:13:57 ------+----------------------------------- 01:13:57 row1 | ['five', 'six', 'seven', 'eight'] 01:13:57 row2 | ['five', 'six', 'seven', 'eight'] 01:13:57 &lt;BLANKLINE&gt; 01:13:57 (2 rows) 01:13:57 &lt;BLANKLINE&gt; 01:13:57 Got: 01:13:57 01:13:57 key1 | mylist 01:13:57 ------+----------------------------------- 01:13:57 row1 | ['five', 'six', 'seven', 'eight'] 01:13:57 row2 | ['five', 'six', 'seven', 'eight'] 01:13:57 01:13:57 (2 rows) 01:13:57 &lt;BLANKLINE&gt; </pre> </div></div> <p>Once errors are address, then failures, then finally performance. 7 hours for a full run is pretty painful, but there's certainly some opportunities for optimization on the windows startup scripts etc.</p>
</comment>
<comment id="14573406" author="joshuamckenzie" created="Thu, 4 Jun 2015 19:07:34 +0000">
<p>Issues w/json tests are two-fold:</p> <ol> <li>&lt;BLANKLINE&gt; comparisons are mismatched on Windows</li> <li>Default timestamp formatting is different on Windows.</li> </ol> <p>Re: #1: python coerces line-endings on all print or write calls to platform-specific endings, CRLF in Windows' case, which subsequently causes failures during the regex change and comparison in doctest.check_output as \s$ doesn't match the \s^M$ on Windows output. In order to resolve this, I've opened a dtest PR to convert CRLF to LF in cqlsh_print on Windows: <a href="https://github.com/riptano/cassandra-dtest/pull/312" class="external-link" rel="nofollow">PR</a></p> <p>Re: #2: It turns out there's a bug in the interaction between python's strftime and Windows clibs, specifically w/regards to %z in strftime (<a href="http://bugs.python.org/issue20010" class="external-link" rel="nofollow">bug report</a>) giving us a long string return on %z rather than the desired +/- vs. GMT. <a href="https://issues.apache.org/jira/browse/CASSANDRA-4746" title="cqlsh timestamp formatting is broken - displays wrong timezone info (at least on Ubuntu)" class="issue-link" data-issue-key="CASSANDRA-4746"><del>CASSANDRA-4746</del></a> dealt with a somewhat similar issue so I've piggybacked on that and attached a patch that will change the datetime formatter in cqlshlib to manually fix the TZ when on Windows and with a %z formatting flag.</p> <p>With the PR for dtest and the patch attached, all but 2 of the json tests are passing locally now.</p>
</comment>
<comment id="14575096" author="joshuamckenzie" created="Fri, 5 Jun 2015 19:51:33 +0000">
<p>Marked docs-impacting since the windows %z replacement at 2 char from end should likely be mentioned on our <a href="http://docs.datastax.com/en/cql/3.1/cql/cql_reference/cqlsh.html" class="external-link" rel="nofollow">cqlshrc documentation</a>.</p>
</comment>
<comment id="14575191" author="aweisberg" created="Fri, 5 Jun 2015 20:46:37 +0000">
<p>+1 for the patch attached to the ticket. We should document that on Windows with formats that end with %z we are going to nuke any non-<span class="error">&#91;numeric | punctuation&#93;</span> characters that come out with the formatted time.</p>
</comment>
<comment id="14575723" author="joshuamckenzie" created="Sat, 6 Jun 2015 13:46:38 +0000">
<p><a href="http://cassci.datastax.com/view/trunk/job/trunk_dtest_win32/307/#showFailuresLink" class="external-link" rel="nofollow">Down to 59 failures</a>.</p> <p>CqlshCopyTests are next in line:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[Errno 13] Permission denied: 'd:\\temp\\tmpyymlia' Stacktrace File "D:\Python27\lib\unittest\case.py", line 329, in run testMethod() File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\cqlsh_tests\cqlsh_copy_tests.py", line 591, in test_read_invalid_float self.data_validation_on_read_template(2.14, expect_invalid=True) File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\cqlsh_tests\cqlsh_copy_tests.py", line 564, in data_validation_on_read_template write_rows_to_csv(tempfile.name, data) File "D:\jenkins\workspace\trunk_dtest_win32\cassandra-dtest\cqlsh_tests\cqlsh_tools.py", line 59, in write_rows_to_csv with open(filename, 'w') as csvfile: "[Errno 13] Permission denied: 'd:\\\\temp\\\\tmpyymlia'\n-------------------- &gt;&gt; begin captured logging &lt;&lt; --------------------\ndtest: DEBUG: cluster ccm directory: d:\\temp\\dtest-9uh67e\n--------------------- &gt;&gt; end captured logging &lt;&lt; ---------------------" </pre> </div></div>
</comment>
<comment id="14639184" author="joshuamckenzie" created="Thu, 23 Jul 2015 17:26:29 +0000">
<p>Rebased and committed the %z json fixing patch to 2.2 and trunk - slipped through the cracks.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12850346">CASSANDRA-9942</issuekey>
</issuelink>
</outwardlinks>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12850345">CASSANDRA-9941</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12737658" name="9418_tz_formatting.txt" size="2361" author="JoshuaMcKenzie" created="Thu, 4 Jun 2015 19:09:58 +0000"/>
</attachments>
<subtasks>
<subtask id="12844861">CASSANDRA-9795</subtask>
<subtask id="12846943">CASSANDRA-9866</subtask>
<subtask id="12848381">CASSANDRA-9873</subtask>
<subtask id="12848945">CASSANDRA-9897</subtask>
<subtask id="12849393">CASSANDRA-9902</subtask>
<subtask id="12849404">CASSANDRA-9903</subtask>
<subtask id="12849406">CASSANDRA-9904</subtask>
<subtask id="12850737">CASSANDRA-9950</subtask>
<subtask id="12851486">CASSANDRA-9980</subtask>
<subtask id="12851491">CASSANDRA-9981</subtask>
<subtask id="12851492">CASSANDRA-9982</subtask>
<subtask id="12851500">CASSANDRA-9983</subtask>
<subtask id="12852289">CASSANDRA-9994</subtask>
<subtask id="12853887">CASSANDRA-10029</subtask>
<subtask id="12853921">CASSANDRA-10037</subtask>
<subtask id="12855409">CASSANDRA-10051</subtask>
<subtask id="12855734">CASSANDRA-10062</subtask>
<subtask id="12856203">CASSANDRA-10075</subtask>
<subtask id="12856205">CASSANDRA-10076</subtask>
<subtask id="12856207">CASSANDRA-10077</subtask>
<subtask id="12856209">CASSANDRA-10078</subtask>
<subtask id="12856960">CASSANDRA-10116</subtask>
<subtask id="12859686">CASSANDRA-10208</subtask>
<subtask id="12862457">CASSANDRA-10281</subtask>
</subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 5 Jun 2015 20:46:37 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ew1r:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
</rss>
</channel>