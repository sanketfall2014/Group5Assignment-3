<!--

RSS generated by JIRA (6.3.4#6332-sha1:51bc225ef474afe3128b2f66878477f322397b16) at Tue Mar 08 17:59:35 UTC 2016

It is possible to restrict the fields that are returned in this document by specifying the 'field' parameter in your request.
For example, to request only the issue key and summary add field=key&field=summary to the URL of your request.
For example:
https://issues.apache.org/jira/sr/jira.issueviews:searchrequest-xml/temp/SearchRequest.xml?jqlQuery=project+%3D+LUCENE+AND+resolution+%3D+Unresolved+AND+issuetype+%3D+Bug+ORDER+BY+priority+DESC&amp;tempMax=100&amp;field=key&amp;field=summary
-->
<!--
 If you wish to do custom client-side styling of RSS, uncomment this:
<?xml-stylesheet href="https://issues.apache.org/jira/styles/jiraxml2html.xsl" type="text/xsl"?>
-->
<rss version="0.92">
<channel>
<title>ASF JIRA</title>
<link>
https://issues.apache.org/jira/secure/IssueNavigator.jspa?reset=true&jqlQuery=project+%3D+LUCENE+AND+resolution+%3D+Unresolved+AND+issuetype+%3D+Bug+ORDER+BY+priority+DESC
</link>
<description>An XML representation of a search request</description>
<language>en-uk</language>
<issue start="0" end="100" total="470"/>
<build-info>
<version>6.3.4</version>
<build-number>6332</build-number>
<build-date>15-08-2014</build-date>
</build-info>
<item>
<title>
[LUCENE-6110] When call ' IndexWriter.getReader(IndexWriter) ' BLOCKED..
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6110</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>when the project start running (lt's a WebServer), First will build a IndexWriter object as single instance.<br/> then every got a request, the method will parse request,then build a IndexReader .the code seems like this.</p> <p>....<br/> indexReader = DirectoryReader.open(indexWriter, false);<br/> ...<br/> indexReader.close();<br/> return Data;</p> <p>the engine running, lt's okay. a fews days later, the Performance turnning down. use jstack shell command . got logs ,</p> <p>......<br/> "qtp463777123-1058" prio=10 tid=0x00007f716c1a2800 nid=0xb1e1 waiting for monitor entry <span class="error">&#91;0x00007f6ec0d35000&#93;</span><br/> java.lang.Thread.State: BLOCKED (on object monitor)<br/> at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:411)</p> <ul class="alternate" type="square"> <li>waiting to lock &lt;0x0000000752035af8&gt; (a java.lang.Object)<br/> at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:112)<br/> at </li> </ul> <p>lt's just BLOCKED.</p> <p>In File indexWriter.java</p> <p> DirectoryReader getReader(boolean applyAllDeletes) ... <br/> .....<br/> doBeforeFlush();<br/> boolean anySegmentFlushed = false;</p> <p> boolean success2 = false;<br/> try {<br/> synchronized (fullFlushLock) { // this line code will be blocked!!!! line code number 411<br/> .....</p>
</description>
<environment>
<p>Description:	CentOS release 6.5 (Final)<br/> Release:	6.5<br/> Codename:	Final</p>
</environment>
<key id="12761269">LUCENE-6110</key>
<summary>
When call ' IndexWriter.getReader(IndexWriter) ' BLOCKED..
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="micky.zf">micky.zf</reporter>
<labels>
<label>performance</label>
</labels>
<created>Fri, 12 Dec 2014 08:26:26 +0000</created>
<updated>Fri, 12 Dec 2014 08:39:25 +0000</updated>
<version>4.10</version>
<component>core/codecs</component>
<due/>
<votes>1</votes>
<watches>2</watches>
<timeoriginalestimate seconds="345600">96h</timeoriginalestimate>
<timeestimate seconds="345600">96h</timeestimate>
<comments>
<comment id="14243870" author="micky.zf" created="Fri, 12 Dec 2014 08:39:25 +0000">
<p>the method 'query' is what i used. and got blocked </p>
</comment>
</comments>
<attachments>
<attachment id="12686810" name="source.java" size="16477" author="micky.zf" created="Fri, 12 Dec 2014 08:39:25 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i23cu7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6572] Highlighter depends on analyzers-common
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6572</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This is a huge WTF, just for "LimitTokenOffsetFilter" which is only useful for highlighting.</p> <p>Adding all these intermodule dependencies makes things too hard to use.</p> <p>This is a 5.3 release blocker.</p>
</description>
<environment/>
<key id="12838134">LUCENE-6572</key>
<summary>Highlighter depends on analyzers-common</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Tue, 16 Jun 2015 11:26:06 +0000</created>
<updated>Thu, 18 Jun 2015 03:34:46 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14587892" author="rcmuir" created="Tue, 16 Jun 2015 11:26:42 +0000">
<p>I also don't understand why it depends on join. So messy</p>
</comment>
<comment id="14591180" author="dsmiley" created="Thu, 18 Jun 2015 03:34:46 +0000">
<p>Rob,<br/> I put LimitTokenOffsetFilter into analysis/common from the Highlighter because it didn't seem to fundamentally be about highlighting, and because there are other TokenFilters of the pattern LimitToken*Filter TokenFilters there.</p> <p>The highlighter module depends on some other modules, like "Join", because in short we don't yet have a Query visitor API.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 18 Jun 2015 03:34:46 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2g3jj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6247] artifacts are half a gigabyte</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6247</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This is a growing problem and now, its spun out of control.</p> <p>The latest release artifacts are half a gigabyte. sorry, I am against adding more retries to the smoke tester and continuing down the same path (<a href="https://issues.apache.org/jira/browse/LUCENE-6231" title="smokeTestRelease.py should retry failed downloads" class="issue-link" data-issue-key="LUCENE-6231">LUCENE-6231</a>).</p> <p>Instead I open this blocker issue to discuss fixing this. Whenever i tried to fix it before (e.g. removing zips), people complained at me "what are you trying to fix" and wouldn't let me minimize it in the slightest.</p> <p>Now the problem is clear, we have a blocker issue to discuss it.</p>
</description>
<environment/>
<key id="12775131">LUCENE-6247</key>
<summary>artifacts are half a gigabyte</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Sat, 14 Feb 2015 12:44:16 +0000</created>
<updated>Sun, 22 Feb 2015 07:37:12 +0000</updated>
<fixVersion>5.0</fixVersion>
<due/>
<votes>0</votes>
<watches>13</watches>
<comments>
<comment id="14321404" author="rcmuir" created="Sat, 14 Feb 2015 12:59:06 +0000">
<p>The first thing to fix is the embedded javadocs in the binary release.</p> <p>I love how the esoteric cases love to pop out from trying to do this: "but i dont have an internet connection, i'm on a secure network, blah blah". World's smallest violin is playing: you guys can run 'ant javadocs'. Very simple. Everyone else can read them online.</p> <p>I am going to repeat for the last time: We shouldnt include these tens of thousands of files in our binary releases when they just bloat them for all users, when most do not need it. </p>
</comment>
<comment id="14321419" author="rcmuir" created="Sat, 14 Feb 2015 13:54:18 +0000">
<p>Here are the calculations for current lucene branch_5x.<br/> Instead of a 144MB binary release, it could be 24MB.</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Current: 144,919,796 bytes -rw-rw-r-- 1 rmuir rmuir 67144315 Feb 14 08:38 lucene-5.1.0-SNAPSHOT.tgz -rw-rw-r-- 1 rmuir rmuir 77775481 Feb 14 08:38 lucene-5.1.0-SNAPSHOT.zip -Javadocs: 122,022,758 bytes (this means: don't include javadocs in the binary release. they are on the website, and users who need a local copy can build one with 'ant javadocs') -rw-rw-r-- 1 rmuir rmuir 60947629 Feb 14 08:42 lucene-5.1.0-SNAPSHOT.tgz -rw-rw-r-- 1 rmuir rmuir 61075129 Feb 14 08:42 lucene-5.1.0-SNAPSHOT.zip -Javadocs -3rdPartyJars: 48,935,497 bytes (this means: also don't include dependent third party jars. basic usage of lucene like running the demos does not require them. but several advanced modules have huge ones. Instead we could just clearly document what versions, for people not using a dependency manager) -rw-rw-r-- 1 rmuir rmuir 24405986 Feb 14 08:48 lucene-5.1.0-SNAPSHOT.tgz -rw-rw-r-- 1 rmuir rmuir 24529511 Feb 14 08:48 lucene-5.1.0-SNAPSHOT.zip -Javadocs -3rdPartyJars -Zip: 24,405,986 bytes (this means: also don't include the .zip. Its totally redundant. Welcome to 2015). -rw-rw-r-- 1 rmuir rmuir 24405986 Feb 14 08:48 lucene-5.1.0-SNAPSHOT.tgz </pre> </div></div>
</comment>
<comment id="14321430" author="steve_rowe" created="Sat, 14 Feb 2015 14:05:41 +0000">
<p>Setting an issue as a Blocker doesn't mean it holds up the release, Robert, as you are well aware.</p> <p>Even -1'ing a release vote doesn't hold up a release, unless you can get the majority of voters to agree with you.</p> <p>But you know this: you've been saying so for years.</p>
</comment>
<comment id="14321443" author="rcmuir" created="Sat, 14 Feb 2015 14:09:53 +0000">
<p>Nope, I'm just opening a blocker issue. If you don't agree this is a problem, then feel free to ignore it, create an RC, and call a VOTE on half a gigabyte anyway.</p> <p>But I am raising the issue and discussing the actual problem at hand here (not adding more retries and stuff like that to try to hack around it).</p>
</comment>
<comment id="14321561" author="ehatcher" created="Sat, 14 Feb 2015 17:08:21 +0000">
<p>(from <a href="https://issues.apache.org/jira/browse/LUCENE-6231" title="smokeTestRelease.py should retry failed downloads" class="issue-link" data-issue-key="LUCENE-6231">LUCENE-6231</a>)</p> <blockquote><p>2. fix for 5.1: we commit your patch and release 5.0, but we fix download size for 5.1. </p></blockquote> <p>I concur that download size is an issue and that it is worth fixing soon, but should not be a blocker for 5.0 at this stage.</p> <p>We all know that 5.1 will be right around the corner, so let's get 5.0 released.</p>
</comment>
<comment id="14321573" author="shalinmangar" created="Sat, 14 Feb 2015 17:24:54 +0000">
<p>I agree with you Robert. The download sizes have increased too much. For example, why should we ship Javadocs in Solr distributions? It may make sense to ship solrj javadocs only but no more.</p>
</comment>
<comment id="14321577" author="yseeley@gmail.com" created="Sat, 14 Feb 2015 17:30:31 +0000">
<blockquote><p>I am going to repeat for the last time: We shouldnt include these tens of thousands of files in our binary releases when they just bloat them for all users, when most do not need it.</p></blockquote> <p>+1 for removing javadoc from both lucene and solr (I've been onboard with that for years <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>As far as zip/tgz, I think Lucene as a developer library only needs one... but Solr as a product should keep the zip. My heliosearch download counts have the .zip outnumbering the .tgz... anyone know the counts for the ASF downloads?</p>
</comment>
<comment id="14321579" author="rcmuir" created="Sat, 14 Feb 2015 17:32:26 +0000">
<blockquote> <p>We all know that 5.1 will be right around the corner, so let's get 5.0 released.</p></blockquote> <p>I am completely +1 for this approach, but i have big concerns because there are quite a few file size issues open and no consensus anywhere. I honestly think it has gotten out of control, i DO NOT want to do anything risky or scary for 5.0, i DO NOT want to hold up the release, I just want us to agree there is a problem, and that we will fix this change this packaging in e.g. 5.1.</p> <p>As i mentioned, I do understand that solr underwent radical packaging changes for 5.0 already, so doing it again could cause confusion. If we must fix it for 5.0 due to those concerns, then that's ok too. But lets please not let it drop like all the other issues.</p>
</comment>
<comment id="14321580" author="rcmuir" created="Sat, 14 Feb 2015 17:33:52 +0000">
<blockquote> <p>As far as zip/tgz, I think Lucene as a developer library only needs one... but Solr as a product should keep the zip. My heliosearch download counts have the .zip outnumbering the .tgz... anyone know the counts for the ASF downloads?</p></blockquote> <p>I don't know this, but I want to point out one fact. Once the javadocs situation is fixed, the size of .tgz vs .zip is essentially the same (see my numbers above). I think thats because, once the javadocs thing is fixed, then zips/tgzs mostly contain already-compressed jars so it does not matter, its just a convenient packaging format.</p>
</comment>
<comment id="14321585" author="rjernst" created="Sat, 14 Feb 2015 17:37:37 +0000">
<p>I'm +1 to removing javadocs from binary release. I thought there was an issue for this from a while ago (after a release Robert did), but the closest I could find is the previous discussion on <a href="https://issues.apache.org/jira/browse/LUCENE-5589" title="release artifacts are too large." class="issue-link" data-issue-key="LUCENE-5589">LUCENE-5589</a>.</p>
</comment>
<comment id="14321624" author="anshumg" created="Sat, 14 Feb 2015 18:29:37 +0000">
<p>I'm +1 to removing javadocs from the binary release and making that and anything more that comes out, in 5.1.<br/> Let's decide on that and move forward?</p>
</comment>
<comment id="14321628" author="rcmuir" created="Sat, 14 Feb 2015 18:34:25 +0000">
<p>It would be good to get opinions on the other lucene changes here. Consensus on removing javadocs from the binary release is great, since its ~23MB we don't need, but the other proposed changes really get the size to something reasonable.</p> <p>For example once we remove the javadocs, .zip and .tar.gz are on par size-wise, so I propose to remove one of them. I do not care which one it is, but I don't think having both is really helpful for lucene. The third party jars are also very large, so we should discuss that too.</p> <p>NOTE: I didn't do experiments with solr, its an app so it has more complexities here. I am sure the packaging may need to be different there.</p>
</comment>
<comment id="14321663" author="noble.paul" created="Sat, 14 Feb 2015 19:26:44 +0000">
<p>+1 for removing javadocs. Users usually prefer to check it online</p> <p>What else are we going to remove to cut down the download size?</p>
</comment>
<comment id="14321697" author="rcmuir" created="Sat, 14 Feb 2015 20:40:58 +0000">
<p>My comment above shows several ways to do this significantly, please look thru it: <a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a></p> <p>Consensus on javadocs isn't enough here. We need to talk about these other things, sorry.</p>
</comment>
<comment id="14321711" author="mikemccand" created="Sat, 14 Feb 2015 21:21:18 +0000">
<p>+1 to remove javadocs from bin release.</p> <p>+1 to remove 3rd party JARs from lucene.</p> <p>+1 to build just .zip (not .tar.gz).</p>
</comment>
<comment id="14322061" author="jpountz" created="Sun, 15 Feb 2015 16:39:26 +0000">
<p>Same +1s as Michael, this sounds like a good trade-off to me.</p>
</comment>
<comment id="14322218" author="anshumg" created="Sun, 15 Feb 2015 22:33:15 +0000">
<p>I think it totally makes sense to do all of the above but in 5.1 instead of 5.0.</p>
</comment>
<comment id="14322235" author="janhoy" created="Sun, 15 Feb 2015 23:12:20 +0000"><p>+1 to Michael's suggestions - in 5.1</p></comment>
<comment id="14322844" author="arafalov" created="Mon, 16 Feb 2015 15:06:41 +0000">
<p>+1 on removing Javadocs in shipped version of both Solr and Lucene.</p> <p>Also, Solr ships with lucene-test library (and junit, ant, etc) in dist/test-framework. That's another 10Mb. I don't think anything in the binary distribution actually relies on it.</p>
</comment>
<comment id="14322958" author="rcmuir" created="Mon, 16 Feb 2015 16:32:53 +0000">
<p>Please, comment on all 3 of my suggestions listed here:</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a></p> <p>I don't know how many times i have to say it. The javadocs are only a small piece of what needs to be done here.</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a><br/> <a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a><br/> <a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a><br/> <a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a></p>
</comment>
<comment id="14322971" author="arafalov" created="Mon, 16 Feb 2015 16:41:18 +0000">
<p>Not everybody has an opinion on the other issues, I guess. I feel I know enough to vote on Javadoc issues, but on others, I don't understand the implications either way.</p> <p>But, rechecking that list, I think, for Solr, ..zip is better than .tgz for our target audience. Even if it is 2015. For Lucene, I don't know, maybe .tgz only is ok. But that would introduce inconsistencies between Lucene and Solr distributions.</p>
</comment>
<comment id="14322981" author="rcmuir" created="Mon, 16 Feb 2015 16:46:10 +0000">
<p>But that's the problem, nobody wants to make a decision, nobody has any guts to try to do anything here, and the release just gets bigger and bigger and bigger.</p> <p>Thats why there are no progress on other issues, thats why the release is half a gigabyte, and thats why I am raising hell. I'm the last hope of anything ever happening here, because I'm the only one that will break some eggs to get it done.</p> <p>Speak your mind now, if people whine about my proposals later, despite me making incredible amounts of noise to try to get comments about them, I can assure you that it will not be pretty.</p>
</comment>
<comment id="14322996" author="smolloy" created="Mon, 16 Feb 2015 16:56:41 +0000">
<p>+1 to everything in 5.1 (although zip may be easier for some than tgz, as long as there's only one)</p> <p>This said, maybe more people would vote on details if it was split in separate tickets. And if some part causes more waves, at least the rest could be tackled and be done with. I don't see javadocs and double-packaging as causing much waves (apart from potential long discussion around zip vs tgz), 3rd party libs might cause more. If you split the ticket, you can get all but 3rd party in quickly and at least make progress on reducing size. Not perfect, but on the right path...</p>
</comment>
<comment id="14323001" author="arafalov" created="Mon, 16 Feb 2015 17:00:48 +0000">
<p>Could we have a parent blocker and children for individual issues to discuss? My strong vote (if I had any) would be to dump Javadoc from 5.0 (yes, with a re-spin). Explaining it going away in 5.1 would be a lot more awkward. It's a clear issue with simple solution (just stop building/bundling). Nothing will break, because nothing relies on those Javadocs. I am already doing Javadocs online with search built-in ( <a href="http://www.solr-start.com/javadoc/solr-lucene/index.html" class="external-link" rel="nofollow">http://www.solr-start.com/javadoc/solr-lucene/index.html</a> ), so we know that the shipped Javadocs are not actually all that good or useful.</p> <p>Bundling as a zip/tgz-only is also easy to do (disable the task), but choosing which one to keep is harder and there might be downstream tasks that rely on a particular format's presence. But that should not hold up the Javadocs issue. So, maybe that should be for 5.1 with a warning/discussion on the dev list outside of JIRA.</p> <p>Other artifacts would probably take even more discussion. Target that for 5.1 or 5.2. I have absolutely zero opinions on those as I only use Lucene downloads to build the Javadocs. But I strongly agree on making things smaller. I suspect this discussion would also re-trigger the discussion on modularity/plugins. Both in relations to ElasticSearch implementation of plugins and with recent work on Solr towards plugins. Sparks could fly.</p>
</comment>
<comment id="14323008" author="rcmuir" created="Mon, 16 Feb 2015 17:03:29 +0000">
<p>For lucene, third party libs are an important component to the size though. They are more than 50% of it.</p> <p>I've tried splitting out this stuff before, it does not work (see <a href="https://issues.apache.org/jira/browse/LUCENE-5589" title="release artifacts are too large." class="issue-link" data-issue-key="LUCENE-5589">LUCENE-5589</a>)</p> <p>I think it is best to keep a coherent unified issue that attacks the size problem directly. I am not going to herd cats on 8 different issues like in the past.</p> <p>The issue is being brought to a head, right here, and I intend to fix it in 5.1. </p>
</comment>
<comment id="14323011" author="rcmuir" created="Mon, 16 Feb 2015 17:04:51 +0000">
<blockquote> <p>My strong vote (if I had any) would be to dump Javadoc from 5.0 (yes, with a re-spin). Explaining it going away in 5.1 would be a lot more awkward. </p></blockquote> <p>I don't want to downplay your argument here, don't get the wrong idea. But this is why i made this a blocker for 5.0 (i know, which pisses everyone off). If we need to fix things for 5.0, then we should do it. The issue should not be put off for 6.0</p>
</comment>
<comment id="14323030" author="arafalov" created="Mon, 16 Feb 2015 17:12:37 +0000">
<p>(meta-level comment)</p> <blockquote><p><a href="https://issues.apache.org/jira/browse/LUCENE-5589" title="release artifacts are too large." class="issue-link" data-issue-key="LUCENE-5589">LUCENE-5589</a></p></blockquote> <p>I see intermingling of the target audiences in these issues. There is issue that more affects developers (smoke test, repeated downloads of RCs, etc) and there are issues that affect final users and those downstream with the public release (tgz vs zip, Javadoc, etc).</p> <p>Both camps are in favor of smaller downloads I am sure, but not being explicit about it is what's muddling the discussion. For my target audience (users), any incremental improvement (decrease in size) would be good news as long as it does not break anything. Hence, that pushes Javadoc as the most important issue, even if it is not the maximum impact on size overall.</p>
</comment>
<comment id="14323041" author="rcmuir" created="Mon, 16 Feb 2015 17:21:02 +0000">
<p>Third party libraries are a far bigger component of the "user" download than the javadocs. See my sizes above.</p> <p>For lucene, these only apply to additional optional modules. Its not needed for example to run the demo or use lucene.<br/> We can have the build emit information to a .txt or whatever describing exactly which versions we have tested (for people not using a dependency manager to get these artifacts from maven).</p>
</comment>
<comment id="14323044" author="rcmuir" created="Mon, 16 Feb 2015 17:23:40 +0000">
<blockquote> <p>Both camps are in favor of smaller downloads I am sure, but not being explicit about it is what's muddling the discussion. </p></blockquote> <p>Who is not being explicit? I was explicit when i said what i wanted to do for lucene, its right here:</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-6247?focusedCommentId=14321419&amp;page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14321419</a></p> <p>I'm being explicit, thats not the problem. I think the problem is that you aren't listening.</p>
</comment>
<comment id="14323068" author="arafalov" created="Mon, 16 Feb 2015 17:49:43 +0000">
<blockquote><p>I'm being explicit, thats not the problem. I think the problem is that you aren't listening.</p></blockquote> <p>Are you really sure I am not listening!?! If I am not listening, then why my slides at the Solr Revolutions were bitching about Solr distribution size with charts and all? You think I wasted my precious presentation time on that because it was an easy issue to raise?</p> <p>There is a bad joke about Americans in a foreign country just repeating the questions (in English) louder when they are misunderstood. Similarly, I don't think using the same words again but in all caps (or with a blocker flag) is what will make a difference. You are being very explicit about <b>what you want</b> for Lucene. But when people come back and say that they disagree or only comment on a part of an issue, you are repeating exactly the same message just louder. I do not see you addressing different impacts on developers and final users. Impact is not just size, it's historical implications, 3rd party systems, etc. </p> <p>You asked for feedback, you got some, including some representing the issues you - as a hardcore developer - don't seem to care much about. You were unhappy that the feedback did not fully agree with your vision, so will now go ahead and do it <b>your way</b> anyway. Why did you bother asking then, apart from Grandstanding? </p> <p>The saddest thing is that people are mostly agreeing with you on this issue. Yet, the conversation is rapidly going in the direction where you will either abandon this with bitter complains or push things through in the way that only address your own concerns.</p>
</comment>
<comment id="14323077" author="rcmuir" created="Mon, 16 Feb 2015 17:54:56 +0000">
<blockquote> <p>But when people come back and say that they disagree or only comment on a part of an issue, you are repeating exactly the same message just louder. I do not see you addressing different impacts on developers and final users. Impact is not just size, it's historical implications, 3rd party systems, etc. </p></blockquote> <p>I haven't even begun to get loud. </p> <p>I proposed specific changes to lucene, with the size impacts of each. Maybe that is your confusion, that this is a LUCENE issue that I opened and is quite contained to that? I don't care about solr here, Someone else can lead the charge for solr honestly, it will not be me. sparks are not going to fly and I am not going to develop any plugin system to deal with its size issue.</p> <p>So please, lets just comment on the very specific proposal for lucene here and not discuss anything else irrelevant.</p>
</comment>
<comment id="14323088" author="rjernst" created="Mon, 16 Feb 2015 18:05:16 +0000">
<p>I've already given my +1 to removal of javadoc. Regarding the other two ideas:</p> <p>I am in favor of removing zip, and only leaving tgz. I did a quick survey of other apache projects. A number I looked at only released with tgz (hadoop, couchdb, cassandra, cordova). Others I looked at were the main httpd project, which released source as tgz but binary as zip, and Harmony which had both tgz and zip. Flex and Geronimo also released zip and labelled as "windows" and tgz and labelled it for mac and linux. IMO, if someone cannot handle extracting a tgz on windows, they can't handle running Solr.</p> <p>For removing dependencies, I'm in favor of this:</p> <blockquote><p>We can have the build emit information to a .txt or whatever describing exactly which versions we have tested (for people not using a dependency manager to get these artifacts from maven).</p></blockquote>
</comment>
<comment id="14323091" author="rcmuir" created="Mon, 16 Feb 2015 18:09:16 +0000">
<blockquote> <p> IMO, if someone cannot handle extracting a tgz on windows, they can't handle running Solr.</p></blockquote> <p>Lets keep the discussion contained to lucene here. Otherwise it will quickly blow out of scope and nothing will get done <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>Please note, we already release source code (and officially, thats the only thing we really release) as .tgz <b>only</b>. So it should be just fine to remove the binary .zip.</p>
</comment>
<comment id="14323176" author="markrmiller@gmail.com" created="Mon, 16 Feb 2015 19:43:19 +0000">
<blockquote><p>The saddest thing is that people are mostly agreeing with you on this issue. </p></blockquote> <p>That's usually the case. Pointing out what is happening on this issue won't solve anything unfortunately. This play has repeated 100 times by now.</p> <ul> <li>things have spiraled out of control!</li> <li>give me feedback or i will do what i want!</li> <li>your feedback sucks and your stupid, i will do what i want!</li> <li>your feedback sucks and your stupid, i will do what is obviously necessary and the only thing a sane person could think until you agree to all my points!</li> </ul> <p>repeat at random intervals</p>
</comment>
<comment id="14323332" author="janhoy" created="Mon, 16 Feb 2015 21:36:00 +0000">
<p>+1 for sub tasks, then they can go in different releases, and it is easier to track what needs to be done for each, and (most important) the discussion gets more focused and technical, not all this crazy fuzzy yelling about the end of the world being near if we don't do a b and c</p>
</comment>
<comment id="14324702" author="elyograg" created="Tue, 17 Feb 2015 19:11:20 +0000">
<p>My contribution:</p> <ul> <li>I agree with dropping zip and keeping .tgz or .tar.gz. That should cut the size roughly in half for developers. It won't impact a user's download time.</li> <li>The size of what a user must download is more important than what the developers must handle, but it's a separate issue.</li> <li>IMHO, those who cannot deal with a unix archive, regardless of OS, are probably not qualified to write Lucene code or admin Solr. <ul> <li>We can include some extraction instructions for Windows, which probably would start with installing 7zip or one of the non-free commercial offerings like Winzip or WinRar.</li> </ul> </li> </ul>
</comment>
<comment id="14324742" author="ehatcher" created="Tue, 17 Feb 2015 19:31:09 +0000">
<p>My $0.02 on the download format: .zip is what I always use, because it's pleasantly cross-platform and easy to inspect with `unzip -v`. I'm -0 on dropping .zip (not big enough of a deal to me either way, just a preference).</p>
</comment>
<comment id="14324760" author="elyograg" created="Tue, 17 Feb 2015 19:47:10 +0000">
<blockquote><p>I'm -0 on dropping .zip (not big enough of a deal to me either way, just a preference).</p></blockquote> <p>From what I understand, all text files included in the .zip artifacts are in Windows CR/LF format, which is wrong for every other platform. If we keep .zip, do we change that aspect of artifact creation? My bias would be to stick with the *NIX text format, but that will cause problems for less sophisticated Windows users who use the built in Notepad. Microsoft needs to correctly handle LF-only text files in Notepad.</p> <p>I don't really care too much about whether the supported archive is .zip or .tgz, but I do care about the text file format. I never run production on Windows, so I don't want CR in my text files. That's honestly my primary motivation for preferring tgz.</p>
</comment>
<comment id="14327074" author="rjernst" created="Thu, 19 Feb 2015 07:35:28 +0000">
<p>I have been working on some of the suggestions here for decreasing the artifacts sizes. I spun off separate issues as many suggested. Note that all of these are only for binary releases. Please comment there if you have opinions on those specific ideas:</p> <ul> <li><a href="https://issues.apache.org/jira/browse/LUCENE-6257" title="Remove javadocs from releases (except for publishing)" class="issue-link" data-issue-key="LUCENE-6257">LUCENE-6257</a> - Remove javadocs</li> <li><a href="https://issues.apache.org/jira/browse/LUCENE-6258" title="Cut binary releases down to a single format" class="issue-link" data-issue-key="LUCENE-6258">LUCENE-6258</a> - Remove zip or tgz</li> <li><a href="https://issues.apache.org/jira/browse/LUCENE-6259" title="Remove dependencies from binary releases" class="issue-link" data-issue-key="LUCENE-6259">LUCENE-6259</a> - Remove dependencies</li> </ul>
</comment>
<comment id="14327426" author="smolloy" created="Thu, 19 Feb 2015 13:56:35 +0000">
<blockquote><p>I spun off separate issues as many suggested.</p></blockquote> <p>Are those intended for both Lucene &amp; Solr? Should separate ones be entered for Solr as well? I think they should be aligned as much as possible.</p>
</comment>
<comment id="14327478" author="elyograg" created="Thu, 19 Feb 2015 14:20:07 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=smolloy" class="user-hover" rel="smolloy">Steve Molloy</a>, it has been my experience that issues affecting the build system for both Lucene and Solr are created in the LUCENE project. Sometimes this leads to omissions in the solr/CHANGES.txt file because a committer is focused on the LUCENE aspect of the issue and doesn't think about that file.</p> <p>To be <b>absolutely</b> sure we don't forget, documentation issues in SOLR, linked to the the relevant LUCENE issues, would be technically correct.</p>
</comment>
<comment id="14332071" author="janhoy" created="Sun, 22 Feb 2015 07:37:12 +0000">
<p>Found the existing JIRA where we discuss reducing the size of Solr (<a href="https://issues.apache.org/jira/browse/SOLR-6806" title="Reduce the size of the main Solr binary download" class="issue-link" data-issue-key="SOLR-6806">SOLR-6806</a>) which also links to <a href="https://issues.apache.org/jira/browse/SOLR-5103" title="Plugin Improvements" class="issue-link" data-issue-key="SOLR-5103">SOLR-5103</a> for a Solr plugin system. So for those interested, head over there and revive the discussion <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12758451">SOLR-6806</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 14 Feb 2015 14:05:41 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i25n1j:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5510] Docvalues need to be indexablefield (not storable)
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5510</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description/>
<environment/>
<key id="12699688">LUCENE-5510</key>
<summary>Docvalues need to be indexablefield (not storable)</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="1" iconUrl="https://issues.apache.org/jira/images/icons/priorities/blocker.png">Blocker</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="rcmuir">Robert Muir</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Sun, 9 Mar 2014 13:43:54 +0000</created>
<updated>Sun, 9 Mar 2014 13:43:54 +0000</updated>
<version>master</version>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>378035</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1t51r:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>378327</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6662] Resource Leaks</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6662</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Several resource leaks were identified. I am merging all resource leak issues and creating a single patch as suggested. </p>
</description>
<environment/>
<key id="12843012">LUCENE-6662</key>
<summary>Resource Leaks</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rmp91">Rishabh Patel</reporter>
<labels></labels>
<created>Mon, 6 Jul 2015 22:42:13 +0000</created>
<updated>Mon, 6 Jul 2015 23:29:23 +0000</updated>
<version>master</version>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<issuelinks>
<issuelinktype id="12310060">
<name>Container</name>
<outwardlinks description="contains">
<issuelink>
<issuekey id="12841005">LUCENE-6622</issuekey>
</issuelink>
<issuelink>
<issuekey id="12840632">LUCENE-6610</issuekey>
</issuelink>
<issuelink>
<issuekey id="12840683">LUCENE-6611</issuekey>
</issuelink>
<issuelink>
<issuekey id="12840729">LUCENE-6612</issuekey>
</issuelink>
<issuelink>
<issuekey id="12840980">LUCENE-6619</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12743834" name="LUCENE-6662.patch" size="14459" author="rmp91" created="Mon, 6 Jul 2015 23:19:33 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Flags</customfieldname>
<customfieldvalues>
<customfieldvalue key="10430">
<![CDATA[ Patch ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gwov:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5741] IndexWriter.tryDeleteDocument does not work
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5741</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I am using "fresh"a and opened reader. <br/> One segement and 3 documents in index.<br/> tryDeleteDocument always return false, i deep into your code, and see follow, that <br/> segmentInfos.indexOf(info)<br/> always return -1 because org.apache.lucene.index.SegmentInfoPerCommit doesnot have equals method, see screenshoot for more inforamtion <a href="http://postimg.org/image/jvtezvqnn/" class="external-link" rel="nofollow">http://postimg.org/image/jvtezvqnn/</a></p>
</description>
<environment/>
<key id="12718811">LUCENE-5741</key>
<summary>IndexWriter.tryDeleteDocument does not work</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mikemccand">Michael McCandless</assignee>
<reporter username="zhuravskiy.vs">Zhuravskiy Vitaliy</reporter>
<labels></labels>
<created>Fri, 6 Jun 2014 10:13:30 +0000</created>
<updated>Fri, 6 Jun 2014 14:40:54 +0000</updated>
<version>4.3</version>
<version>4.5</version>
<version>4.6</version>
<version>4.7</version>
<version>4.8</version>
<version>4.8.1</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14019733" author="zhuravskiy.vs" created="Fri, 6 Jun 2014 10:22:14 +0000">
<p>Same problem discussion here <a href="http://lucene.472066.n3.nabble.com/Unexpected-returning-false-from-IndexWriter-tryDeleteDocument-td4107633.html" class="external-link" rel="nofollow">http://lucene.472066.n3.nabble.com/Unexpected-returning-false-from-IndexWriter-tryDeleteDocument-td4107633.html</a></p>
</comment>
<comment id="14019759" author="mikemccand" created="Fri, 6 Jun 2014 11:07:38 +0000">
<p>Can you re-test with a newer version of Lucene?</p> <p>This may just be a dup of <a href="https://issues.apache.org/jira/browse/LUCENE-4986" title="NRT reader doesn&#39;t see changes after successful IW.tryDeleteDocument" class="issue-link" data-issue-key="LUCENE-4986"><del>LUCENE-4986</del></a> (fixed in 4.3.1 but it looks like you saw this issue in 4.3.0).</p>
</comment>
<comment id="14019879" author="zhuravskiy.vs" created="Fri, 6 Jun 2014 14:31:12 +0000">
<p>Hi, Michael, on 4.3.1 bug still present. Same situation on the 4.8.1 (<a href="http://postimg.org/image/zfb2ww6x5/" class="external-link" rel="nofollow">http://postimg.org/image/zfb2ww6x5/</a>).<br/> I wrote:<br/> "segmentInfos.indexOf(info)<br/> always return -1 because org.apache.lucene.index.SegmentInfos does not have equals method"</p> <p>Please read <a href="http://docs.oracle.com/javase/7/docs/api/java/util/List.html#indexOf(java.lang.Object" class="external-link" rel="nofollow">http://docs.oracle.com/javase/7/docs/api/java/util/List.html#indexOf(java.lang.Object</a>) , indexOf uses equals method of an object.<br/> On the screenshoot (<a href="http://postimg.org/image/jvtezvqnn/" class="external-link" rel="nofollow">http://postimg.org/image/jvtezvqnn/</a>) we have two instance of org.apache.lucene.index.SegmentInfoPerCommit (SegmentCommitInfo on 4.8.1), which has same values, but different for ArrayList, because has not overrided equals method (for example like in the SegmentInfo). Class must have overriden equals method, if you you want ArrayList.indexOf works (ArrayList.indexOf into org.apache.lucene.index.SegmentInfos#indexOf)</p> <p>Screenshoot of debuger on 4.8.1 with 4.3.1 index <a href="http://postimg.org/image/zfb2ww6x5/" class="external-link" rel="nofollow">http://postimg.org/image/zfb2ww6x5/</a></p> <p>I saw solr-lucene-core sources there uses hashmap instead list, and works. But in current source code class SegmentCommitInfo need to be equals method. </p>
</comment>
<comment id="14019882" author="mikemccand" created="Fri, 6 Jun 2014 14:40:54 +0000">
<p>The SegmentInfoPerCommit from the reader should be the very same instance as the one inside IndexWriter's SegmentInfos, and so the Object.equals impl (using ==) works here.</p> <p>So we need to figure out why in your case == returns false. Can you describe where the reader that you are passing in came from? It must be a near-real-time reader in order to work.</p> <p>Or can you make a small test case?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 6 Jun 2014 11:07:38 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>397010</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1wcm7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>397128</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-4787] The QueryScorer.getMaxWeight method is not found.
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-4787</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The following API documents refer to the QueryScorer.getMaxWeight method:<br/> <a href="http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/package-summary.html" class="external-link" rel="nofollow">http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/package-summary.html</a><br/> "The QueryScorer.getMaxWeight method is useful when passed to the GradientFormatter constructor to define the top score which is associated with the top color."<br/> <a href="http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/GradientFormatter.html" class="external-link" rel="nofollow">http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/GradientFormatter.html</a><br/> "See QueryScorer.getMaxWeight which can be used to calibrate scoring scale"</p> <p>However, the QueryScorer class does not declare a getMaxWeight method in lucene 4.1, according to its document:<br/> <a href="http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/QueryScorer.html" class="external-link" rel="nofollow">http://lucene.apache.org/core/4_1_0/highlighter/org/apache/lucene/search/highlight/QueryScorer.html</a></p> <p>Instead, the class declares a getMaxTermWeight method. Is that the correct method in the preceding two documents? If it is, please revise the two documents. </p>
</description>
<environment/>
<key id="12633242">LUCENE-4787</key>
<summary>The QueryScorer.getMaxWeight method is not found.</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="drzhonghao">Hao Zhong</reporter>
<labels></labels>
<created>Wed, 20 Feb 2013 18:13:18 +0000</created>
<updated>Sun, 29 Jun 2014 03:58:50 +0000</updated>
<version>4.1</version>
<component>modules/highlighter</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="13583184" author="erickerickson" created="Thu, 21 Feb 2013 13:30:10 +0000">
<p>It would be great if you could go ahead and create a patch for these, see: <a href="http://wiki.apache.org/solr/HowToContribute" class="external-link" rel="nofollow">http://wiki.apache.org/solr/HowToContribute</a>. Since you're right in the middle of seeing this, you're in a great position to go ahead and update the docs.</p>
</comment>
<comment id="14047050" author="mdodsworth@salesforce.com" created="Sun, 29 Jun 2014 03:58:50 +0000"><p>doc fixed in the attached patch.</p></comment>
</comments>
<attachments>
<attachment id="12653033" name="LUCENE-4787.patch" size="2554" author="mdodsworth@salesforce.com" created="Sun, 29 Jun 2014 00:29:32 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 21 Feb 2013 13:30:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>313738</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1i533:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>314083</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-4730] SmartChineseAnalyzer got wrong matched offset
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-4730</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>We found that SmartChineseAnalyzer got wrong matched offset with the following test code:</p> <p> public void testHighlight() throws Exception {<br/> String text = "My China "; <br/> String queryText = "China";<br/> StringBuilder builder = new StringBuilder("&lt;html&gt;");<br/> Analyzer analyzer = new SmartChineseAnalyzer(Version.LUCENE_40);<br/> //Analyzer analyzer = new StandardAnalyzer(Version.LUCENE_40);<br/> QueryParser parser = new QueryParser(Version.LUCENE_40, "text", analyzer);<br/> Query query = parser.parse(queryText);<br/> SimpleHTMLFormatter formatter = new SimpleHTMLFormatter("&lt;span style=\"background: yellow\"&gt;", "&lt;/span&gt;");<br/> TokenStream tokens = analyzer.tokenStream("text", new StringReader(text));<br/> QueryScorer scorer = new QueryScorer(query, "text");<br/> Highlighter highlighter = new Highlighter(formatter, scorer);<br/> highlighter.setTextFragmenter(new SimpleSpanFragmenter(scorer));<br/> String result = highlighter.getBestFragments(tokens, text, 10, "...");<br/> if (result.length() &lt; text.length()) </p> { result = text; } <p> builder.append("&lt;body&gt;");<br/> builder.append(result);<br/> builder.append("&lt;/body&gt;");<br/> builder.append("&lt;/html&gt;");<br/> System.out.println(builder.toString());<br/> }</p> <p>This method will generate a hilighted text, however, the highlight position is obviously wrong, and if we remove one space from the text, that is, change text from "My China " (ends with two spaces) to "My China " (ends with one space), it will generate a text with correct highlight. If we change the analyzer from SmartChineseAnalyzer to StandardAnalyzer, the highlight issue will disappear.</p>
</description>
<environment><p>JDK1.7 Linux/Windows</p></environment>
<key id="12629667">LUCENE-4730</key>
<summary>SmartChineseAnalyzer got wrong matched offset</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="cloudwave">Jinsong Hu</reporter>
<labels></labels>
<created>Tue, 29 Jan 2013 10:22:17 +0000</created>
<updated>Sun, 29 Jun 2014 15:39:08 +0000</updated>
<version>4.0</version>
<version>4.1</version>
<component>modules/analysis</component>
<due/>
<votes>1</votes>
<watches>4</watches>
<comments>
<comment id="14047046" author="mdodsworth@salesforce.com" created="Sun, 29 Jun 2014 03:47:09 +0000">
<p>This appears to be a symptom of <a href="https://issues.apache.org/jira/browse/LUCENE-4984" title="Fix ThaiWordFilter" class="issue-link" data-issue-key="LUCENE-4984"><del>LUCENE-4984</del></a> (fixed in 4.8).</p> <p>The following test fails:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-comment">// note Version.LUCENE_4_7 </span>assertAnalyzesTo(<span class="code-keyword">new</span> SmartChineseAnalyzer(Version.LUCENE_4_7, <span class="code-keyword">true</span>), <span class="code-quote">"My China "</span>, <span class="code-keyword">new</span> <span class="code-object">String</span>[] { <span class="code-quote">"my"</span>, <span class="code-quote">"china"</span>}, <span class="code-keyword">new</span> <span class="code-object">int</span>[] {0,3}, <span class="code-keyword">new</span> <span class="code-object">int</span>[] {2, 8}); </pre> </div></div> <p>whereas this passes:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-comment">// note Version.LUCENE_4_8 </span>assertAnalyzesTo(<span class="code-keyword">new</span> SmartChineseAnalyzer(Version.LUCENE_4_8, <span class="code-keyword">true</span>), <span class="code-quote">"My China "</span>, <span class="code-keyword">new</span> <span class="code-object">String</span>[] { <span class="code-quote">"my"</span>, <span class="code-quote">"china"</span>}, <span class="code-keyword">new</span> <span class="code-object">int</span>[] {0,3}, <span class="code-keyword">new</span> <span class="code-object">int</span>[] {2, 8}); </pre> </div></div> <p>I'll add a test to verify this double-whitespace case but otherwise, this can be closed out.</p>
</comment>
</comments>
<attachments>
<attachment id="12653040" name="LUCENE-4730.patch" size="2173" author="mdodsworth@salesforce.com" created="Sun, 29 Jun 2014 03:56:47 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sun, 29 Jun 2014 03:47:09 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>310163</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1hj13:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>310508</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-4200] ArrayIndexOutOfBoundsException in lucene.index.SegmentTermDocs.read
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-4200</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Sometimes one of my slave tomcat/solr instances stop working with following stacktrace (every request)<br/> If I restart tomcat everything work fine. </p> <p>Jul 6, 2012 11:30:04 AM org.apache.solr.common.SolrException log<br/> SEVERE: java.lang.ArrayIndexOutOfBoundsException: 12<br/> at org.apache.lucene.util.BitVector.get(BitVector.java:114)<br/> at org.apache.lucene.index.SegmentTermDocs.read(SegmentTermDocs.java:161)<br/> at org.apache.lucene.search.TermScorer.nextDoc(TermScorer.java:112)<br/> at org.apache.lucene.search.BooleanScorer2$SingleMatchScorer.nextDoc(BooleanScorer2.java:137)<br/> at org.apache.lucene.search.BooleanScorer2.score(BooleanScorer2.java:280)<br/> at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:581)<br/> at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:364)<br/> at org.apache.solr.search.SolrIndexSearcher.getDocSetNC(SolrIndexSearcher.java:863)<br/> at org.apache.solr.search.SolrIndexSearcher.getPositiveDocSet(SolrIndexSearcher.java:635)<br/> at org.apache.solr.search.SolrIndexSearcher.getProcessedFilter(SolrIndexSearcher.java:769)<br/> at org.apache.solr.search.SolrIndexSearcher.getDocListAndSetNC(SolrIndexSearcher.java:1341)<br/> at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1172)<br/> at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:375)<br/> at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:394)<br/> at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:186)<br/> at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:129)<br/> at org.apache.solr.core.SolrCore.execute(SolrCore.java:1376)<br/> at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:365)<br/> at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:260)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)<br/> at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)<br/> at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)<br/> at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)<br/> at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)<br/> at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)<br/> at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:298)<br/> at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859)<br/> at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:588)<br/> at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)<br/> at java.lang.Thread.run(Thread.java:636)</p>
</description>
<environment>
<p>java version "1.6.0_20"<br/> OpenJDK Runtime Environment (IcedTea6 1.9.13) (6b20-1.9.13-0ubuntu1~10.04.1)<br/> OpenJDK 64-Bit Server VM (build 19.0-b09, mixed mode)</p> <p>tomcat 6.0.24<br/> solr 3.6.0</p>
</environment>
<key id="12597719">LUCENE-4200</key>
<summary>
ArrayIndexOutOfBoundsException in lucene.index.SegmentTermDocs.read
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="petrovich">Serge Negodyuck</reporter>
<labels></labels>
<created>Fri, 6 Jul 2012 08:56:49 +0000</created>
<updated>Fri, 6 Jul 2012 08:56:49 +0000</updated>
<version>3.6</version>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>243765</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04frj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>23819</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3782] An incomplete fix for the NPE bugs in Directory.java
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3782</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The fix revision 499089 was aimed to remove an NPE bug (<a href="https://issues.apache.org/jira/browse/LUCENE-773" title="Deprecate &quot;create&quot; method in FSDirectory.getDirectory in favor of IndexWriter&#39;s &quot;create&quot;" class="issue-link" data-issue-key="LUCENE-773"><del>LUCENE-773</del></a>) on the value of "lockFactory " in the method "clearLock" of the file "/lucene/java/trunk/src/java/org/apache/lucene/store/Directory.java" , but it is incomplete. </p> <p>Since the value "lockFactory " could be null during the runtime execution, its value should also be null-checked before being dereferenced in other methods. </p> <p>The buggy code locations the same fix needs to be applied at are as bellows: </p> <p>Line 106 of the methods "doc()" , and "freq": </p> <p> public Lock makeLock(String name) </p> { [Line 106] return lockFactory.makeLock(name); }
</description>
<environment/>
<key id="12542526">LUCENE-3782</key>
<summary>
An incomplete fix for the NPE bugs in Directory.java
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="guangtai">Guangtai Liang</reporter>
<labels>
<label>incomplete_fix</label>
<label>missing_fixes</label>
</labels>
<created>Tue, 14 Feb 2012 13:10:42 +0000</created>
<updated>Tue, 14 Feb 2012 13:10:42 +0000</updated>
<version>3.0</version>
<component>core/store</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<timeoriginalestimate seconds="600">10m</timeoriginalestimate>
<timeestimate seconds="600">10m</timeestimate>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>227812</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ibz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24235</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3779] An incomplete fix for the NPE bugs in MultipleTermPositions.java
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3779</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The fix revision 219387 (Fix for NPE (bug #35626). Fix by Hans Hjelm, test case by Scotty Allen.) was aimed to remove an NPE bug on the return value of "_termPositionsQueue.peek()" in the method "skipTo" of the file "/lucene/java/trunk/src/java/org/apache/lucene/index/MultipleTermPositions.java" , but it is incomplete. <br/> Since the returned value "_termPositionsQueue.peek()" could be null during the run-time execution, its value should also be null-checked before being dereferenced in other methods. </p> <p>The buggy code locations the same fix needs to be applied at are as bellows: </p> <p>Line 118, 124, 135 of the method "next()" : </p> <p>public final boolean next() throws IOException {<br/> if (_termPositionsQueue.size() == 0)<br/> return false;</p> <p> _posList.clear();<br/> <span class="error">&#91;Line 118&#93;</span> _doc = _termPositionsQueue.peek().doc();</p> <p> TermPositions tp;<br/> do {<br/> tp = _termPositionsQueue.peek();</p> <p><span class="error">&#91;Line 124&#93;</span> for (int i = 0; i &lt; tp.freq(); i++) </p> { // NOTE: this can result in dup positions being added! _posList.add(tp.nextPosition()); } <p> if (tp.next())<br/> _termPositionsQueue.updateTop();<br/> else </p> { _termPositionsQueue.pop(); tp.close(); } <p><span class="error">&#91;Line 135&#93;</span> } while (_termPositionsQueue.size() &gt; 0 &amp;&amp; _termPositionsQueue.peek().doc() == _doc);</p> <p> _posList.sort();<br/> _freq = _posList.size();</p> <p> return true;</p> <p> }</p>
</description>
<environment/>
<key id="12542519">LUCENE-3779</key>
<summary>
An incomplete fix for the NPE bugs in MultipleTermPositions.java
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="guangtai">Guangtai Liang</reporter>
<labels></labels>
<created>Tue, 14 Feb 2012 12:38:22 +0000</created>
<updated>Tue, 14 Feb 2012 14:15:12 +0000</updated>
<version>3.0</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<timeoriginalestimate seconds="600">10m</timeoriginalestimate>
<timeestimate seconds="600">10m</timeestimate>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>227805</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04icn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24238</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3780] An incomplete fix for the NPE bugs in ParallelReader.java
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3780</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The fix revision 407851 was aimed to remove an NPE bug on the return value of "fieldToReader.get(field)" in the methods "getTermFreqVector", "hasNorms", "norms", "doSetNorm" of the file "/lucene/java/trunk/src/java/org/apache/lucene/index/ParallelReader.java<br/> " , but it is incomplete. <br/> Since the returned value "fieldToReader.get(field)" could be null during the runtime execution, its value should also be null-checked before being dereferenced in other methods. </p> <p>The buggy code locations the same fix needs to be applied at are as bellows: </p> <p>Line 499 of the method "ParallelTermEnum()" : </p> <p>public ParallelTermEnum() throws IOException {<br/> try </p> { field = fieldToReader.firstKey(); } <p> catch(NoSuchElementException e) </p> { // No fields, so keep field == null, termEnum == null return; } <p> if (field != null)<br/> <span class="error">&#91;Line 499&#93;</span> termEnum = fieldToReader.get(field).terms();<br/> }</p>
</description>
<environment/>
<key id="12542521">LUCENE-3780</key>
<summary>
An incomplete fix for the NPE bugs in ParallelReader.java
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="guangtai">Guangtai Liang</reporter>
<labels>
<label>incomplete_fix</label>
<label>missing_fixes</label>
</labels>
<created>Tue, 14 Feb 2012 12:55:33 +0000</created>
<updated>Tue, 14 Feb 2012 12:56:05 +0000</updated>
<version>3.0</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<timeoriginalestimate seconds="600">10m</timeoriginalestimate>
<timeestimate seconds="600">10m</timeestimate>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>227807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04icf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24237</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-3673] NativeFSLockFactory Race Condition</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3673</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>When the NativeFSLock releases, it deletes the lock file after lock release.<br/> In a concurrent situation, it is possible for another thread or process to acquire the lock before the delete happens. Any other third thread or process will then be able to recreate the lock file and acquire the lock while a lock is already held on the deleted file. </p>
</description>
<environment>
<p>Mac OS X 10.7, JDK 1.6<br/> CentOS 5, JDK 1.7u1</p>
</environment>
<key id="12537120">LUCENE-3673</key>
<summary>NativeFSLockFactory Race Condition</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jiangyaokai">Yaokai Jiang</reporter>
<labels>
<label>concurrency</label>
<label>locking</label>
</labels>
<created>Wed, 4 Jan 2012 00:57:28 +0000</created>
<updated>Wed, 4 Jan 2012 01:01:03 +0000</updated>
<version>3.4</version>
<version>3.5</version>
<component>core/store</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="13179187" author="jiangyaokai" created="Wed, 4 Jan 2012 00:58:54 +0000">
<p>This example demonstrate how the locking mechanism in NativeFSLock has a race condition. </p>
</comment>
<comment id="13179190" author="jiangyaokai" created="Wed, 4 Jan 2012 01:00:23 +0000"><p>Suggested patch</p></comment>
</comments>
<attachments>
<attachment id="12509364" name="BreakIt.java" size="2760" author="jiangyaokai" created="Wed, 4 Jan 2012 00:58:54 +0000"/>
<attachment id="12509365" name="LUCENE-3673.patch" size="665" author="jiangyaokai" created="Wed, 4 Jan 2012 01:00:23 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>222630</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04izz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24343</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6390] WeightedSpansTermExtractor has a broken IndexReader
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6390</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The DelegatingLeafReader there is broken, it does not implement getFieldInfos. This is not an optional method, and this is blocking performance improvements to spans.</p> <p>I'm gonna work around it for now, but if it won't be fixed, then this DelegatingLeafReader optimization should be removed.</p>
</description>
<environment/>
<key id="12787998">LUCENE-6390</key>
<summary>
WeightedSpansTermExtractor has a broken IndexReader
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Fri, 3 Apr 2015 14:20:30 +0000</created>
<updated>Wed, 15 Apr 2015 00:38:19 +0000</updated>
<fixVersion>5.2</fixVersion>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14394471" author="rcmuir" created="Fri, 3 Apr 2015 14:25:41 +0000">
<p>This is actually a pretty serious bug. It means none of the query stack can use FieldInfos without breaking highlighting.</p>
</comment>
<comment id="14394473" author="rcmuir" created="Fri, 3 Apr 2015 14:27:01 +0000">
<p>I set this as a 5.1 blocker because it will easily break highlighting for arbitrary queries.</p>
</comment>
<comment id="14394806" author="dsmiley" created="Fri, 3 Apr 2015 18:09:15 +0000">
<p>I agree it should be fixed, but I don't see this as a blocker, unless I'm misunderstanding the scope. This feature was added back in 4.2 by <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=simonw" class="user-hover" rel="simonw">Simon Willnauer</a> and has been there since. I've scanned through the usages of the method and I didn't see an occurrence from a Query. Of course a user might have something custom, but that seems awfully rare. Is there something I'm missing? Anyway, if you can get this fixed then great; I just don't see it as blocking.</p>
</comment>
<comment id="14394811" author="dsmiley" created="Fri, 3 Apr 2015 18:15:06 +0000">
<p>I just noticed <a href="https://issues.apache.org/jira/browse/LUCENE-6388" title="Optimize SpanNearQuery" class="issue-link" data-issue-key="LUCENE-6388"><del>LUCENE-6388</del></a> (though that's targeting 5.2) and see it has a perfectly fine work-around.<br/> Maybe I'm splitting hairs; 5.1 doesn't seem held up at the moment on the account of this any how.</p>
</comment>
<comment id="14394862" author="rcmuir" created="Fri, 3 Apr 2015 18:34:29 +0000">
<p>I think our query stack should have the ability to check fieldinfos and use everything it knows to make things efficient.</p> <p>It bothers me that I can make a perfectly valid improvement to what queries do behind the scenes, but highlighter tests will fail, because they have broken code.<br/> Maybe i should have just disabled their tests?</p> <p>We cannot let the highlighter hold back our core search code.</p>
</comment>
<comment id="14394897" author="rcmuir" created="Fri, 3 Apr 2015 18:42:49 +0000">
<p>I unset blocker. I can work to fix this, that is going to be by removing the optimization. The current optimization is incorrect so just pretend like it does not exist.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 3 Apr 2015 18:09:15 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i27r93:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6079] PatternReplaceCharFilter crashes JVM with OutOfMemoryError
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6079</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>PatternReplaceCharFilter fills memory with input data until an OutOfMemoryError is thrown.</p> <p>java.lang.OutOfMemoryError: Java heap space<br/> at java.util.Arrays.copyOf(Arrays.java:3332)<br/> at java.lang.AbstractStringBuilder.expandCapacity(AbstractStringBuilder.java:137)<br/> at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:121)<br/> at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:569)<br/> at java.lang.StringBuilder.append(StringBuilder.java:190)<br/> at org.apache.lucene.analysis.pattern.PatternReplaceCharFilter.fill(PatternReplaceCharFilter.java:84)<br/> at org.apache.lucene.analysis.pattern.PatternReplaceCharFilter.read(PatternReplaceCharFilter.java:74)<br/> ...</p> <p>PatternReplaceCharFilter should read data chunk-wise and pass the transformed output chunk-wise to the caller.</p>
</description>
<environment>
<p>Microsoft Windows, x86_64, 32 GB main memory</p>
</environment>
<key id="12758215">LUCENE-6079</key>
<summary>
PatternReplaceCharFilter crashes JVM with OutOfMemoryError
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="veita">Alexander Veit</reporter>
<labels></labels>
<created>Thu, 27 Nov 2014 13:09:30 +0000</created>
<updated>Thu, 27 Nov 2014 13:47:39 +0000</updated>
<version>4.10.2</version>
<component>modules/analysis</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14227671" author="jkrupan" created="Thu, 27 Nov 2014 13:47:39 +0000">
<p>But the pattern might in fact need the entire input, such as to match the end of the input with "$".</p> <p>Still, it would be nice to have an optional "chunked mode" for cases such as this (assuming that pattern doesn't end with "$"), such as input which is the full text of a multi-MB PDF file. I would suggest that such as mode be the default, with a reasonable chunk size such as 100K. There should also be an "overlap" size so that when reading the next chunk it would start matching with an overlap from the end of the previous chunk, and not perform a match that extends into the overlap area at the end of a chunk unless it is the last chunk, so that matches could be made across chunk boundaries.</p> <p>Actually, it turns out that there was such a feature, with a "maxBlockChars" parameter, but it was deprecated long ago - no mention in CHANGES.TXT. But... it's still supported in the factory code, with only a "TODO" comment suggesting that a warning would be appropriate, but the actual Lucene filter constructor simply ignores this parameter.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 27 Nov 2014 13:47:39 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i22ulz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6037] PendingTerm cannot be cast to PendingBlock
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6037</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>the error as follows:<br/> java.lang.ClassCastException: org.apache.lucene.codecs.BlockTreeTermsWriter$PendingTerm cannot be cast to org.apache.lucene.codecs.BlockTreeTermsWriter$PendingBlock<br/> at org.apache.lucene.codecs.BlockTreeTermsWriter$TermsWriter.finish(BlockTreeTermsWriter.java:1014)<br/> at org.apache.lucene.index.FreqProxTermsWriterPerField.flush(FreqProxTermsWriterPerField.java:553)<br/> at org.apache.lucene.index.FreqProxTermsWriter.flush(FreqProxTermsWriter.java:85)<br/> at org.apache.lucene.index.TermsHash.flush(TermsHash.java:116)<br/> at org.apache.lucene.index.DocInverter.flush(DocInverter.java:53)<br/> at org.apache.lucene.index.DocFieldProcessor.flush(DocFieldProcessor.java:81)<br/> at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:493)<br/> at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:480)<br/> at org.apache.lucene.index.DocumentsWriter.postUpdate(DocumentsWriter.java:378)<br/> at org.apache.lucene.index.DocumentsWriter.updateDocuments(DocumentsWriter.java:413)<br/> at org.apache.lucene.index.IndexWriter.updateDocuments(IndexWriter.java:1283)<br/> at org.apache.lucene.index.IndexWriter.addDocuments(IndexWriter.java:1243)<br/> at org.apache.lucene.index.IndexWriter.addDocuments(IndexWriter.java:1228)</p>
</description>
<environment><p>ubuntu 64bit</p></environment>
<key id="12751905">LUCENE-6037</key>
<summary>PendingTerm cannot be cast to PendingBlock</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="zhanlijun">zhanlijun</reporter>
<labels></labels>
<created>Fri, 31 Oct 2014 08:00:31 +0000</created>
<updated>Tue, 4 Nov 2014 01:53:41 +0000</updated>
<version>4.3.1</version>
<fixVersion>4.3.1</fixVersion>
<component>core/codecs</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14191585" author="mikemccand" created="Fri, 31 Oct 2014 08:30:21 +0000">
<p>Hmm, not good. Can you provide some details about how you hit this? Or maybe a small test case showing it?</p>
</comment>
<comment id="14191617" author="zhanlijun" created="Fri, 31 Oct 2014 09:05:19 +0000">
<p>I have multiple threads to operator IndexWriter.addDocuments()，and it very hard to reproduce the error after it run many hours</p>
</comment>
<comment id="14192362" author="mikemccand" created="Fri, 31 Oct 2014 20:02:17 +0000">
<p>Which JVM/OS are you using? Any customizations to Lucene, its default settings, codecs, etc.?</p>
</comment>
<comment id="14192959" author="zhanlijun" created="Sat, 1 Nov 2014 04:40:29 +0000">
<p>I have customized the lucene-spatial module, and there is no error when I use only one thread to operator IndexWriter.addDocuments.</p> <p>java environment：<br/> java version "1.7.0_21"<br/> Java(TM) SE Runtime Environment (build 1.7.0_21-b11)<br/> Java HotSpot(TM) 64-Bit Server VM (build 23.21-b01, mixed mode)</p> <p>OS environment：<br/> Linux version 2.6.32-431.20.3.el6.mt20140703.x86_64 (gcc version 4.4.7 20120313 (Red Hat 4.4.7-4) (GCC) ) #1 SMP</p>
</comment>
<comment id="14193159" author="dsmiley" created="Sat, 1 Nov 2014 13:30:44 +0000">
<p>Although the lucene-spatial module changes are likely unrelated to the bug here, could you please summarize what sorts of customizations you did?</p>
</comment>
<comment id="14193740" author="zhanlijun" created="Sun, 2 Nov 2014 06:53:39 +0000">
<p> Lucene-spatial module changes are unrelated to the bug, because the bug also happens when I use the native lucene-spatial module. <br/> lucene-spatial module is widely used in mobile internet applications of china. I have an application scenario is to calculate the distance between the user and all POIs in the city. However, when the number of POIs in one city more than 100000, the distance calculation of lucene becomes very slow (more than 10ms). Lucene use spatial4j HaversineRAD to calculate the distance, and I have do a test on my computer (2.9GHz Intel Core i7, 8GB mem)<br/> POI num	| time<br/> 50000 | 7ms<br/> 100000	| 14ms<br/> 1000000	| 144ms<br/> I did some simplified the distance calculation formula. This simplification greatly improve the computational efficiency under the premise of maintaining the use of precision. Here is the result of the test.<br/> test point pair | disSimplify(meter)	| distHaversineRAD(meter)	| diff(meter)<br/> (39.941, 116.45) (39.94, 116.451)	| 140.0242769266660 | 140.02851671981400	| 0.0<br/> (39.96 116.45) (39.94, 116.40)	| 4804.113098854450 | 4804.421153907680	| 0.3<br/> (39.96, 116.45) (39.94, 117.30)	| 72438.90919479560	| 72444.54071519510	| 5.6<br/> (39.26, 115.25) (41.04, 117.30)	| 263516.676171262	| 263508.55921886700	| 8.1</p> <p>POI num	| time<br/> 50000	| 0.1<br/> 100000	| 0.3<br/> 1000000	| 4</p>
</comment>
<comment id="14193742" author="zhanlijun" created="Sun, 2 Nov 2014 07:06:56 +0000">
<p>org.apache.lucene.codecs.BlockTreeTermsWriter$TermsWriter.finish(BlockTreeTermsWriter.java:1014). The code is <br/> "final PendingBlock root = (PendingBlock) pending.get(0);"</p> <p>please tell me in which cases pending.get (0) is PendingTerm type?</p>
</comment>
<comment id="14194130" author="zhanlijun" created="Mon, 3 Nov 2014 00:30:14 +0000">
<p>I found the cause of the problem. <br/> I have a application scenario that add a same document to the index by using indexwriter.addDocuments(). In order to improve the efficiency of indexing, I make the document into a static variable. This way running very well in a single-threaded environment, however, when I use multiple-threads to operator indexwriter.addDocuments(), it cause the error. </p> <p>The solution: I make a new document for each thread, and the error would no longer be reappeared.</p>
</comment>
<comment id="14195127" author="mikemccand" created="Mon, 3 Nov 2014 21:25:03 +0000">
<p>Hmm are you sure this was just a multi-threaded issue? I don't see how <span class="error">&#91;illegally&#93;</span> sharing a single Document across threads would lead to this exception.</p>
</comment>
<comment id="14195557" author="zhanlijun" created="Tue, 4 Nov 2014 01:53:40 +0000">
<p>Hi Michael<br/> I am sure that this will lead to the issue. I just make the following<br/> changes to the code, the program is no retrieval the issue.</p>
</comment>
</comments>
<attachments>
<attachment id="12679110" name="屏幕快照 2014-11-04 上午9.48.17.png" size="71126" author="zhanlijun" created="Tue, 4 Nov 2014 01:53:41 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 31 Oct 2014 08:30:21 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i21t27:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5931] DirectoryReader.openIfChanged(oldReader, commit) incorrectly assumes given commit point has deletes/field updates
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5931</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><tt>StandardDirectoryReader</tt> assumes that the segments from commit point have deletes, when they may not, yet the original SegmentReader for the segment that we are trying to reuse does. This is evident when running attached JUnit test case with asserts enabled (default): </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>java.lang.AssertionError at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:188) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:326) at org.apache.lucene.index.StandardDirectoryReader$2.doBody(StandardDirectoryReader.java:320) at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:702) at org.apache.lucene.index.StandardDirectoryReader.doOpenFromCommit(StandardDirectoryReader.java:315) at org.apache.lucene.index.StandardDirectoryReader.doOpenNoWriter(StandardDirectoryReader.java:311) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:262) at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:183) </pre> </div></div> <p>or, if asserts are disabled then it falls through into NPE:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>java.lang.NullPointerException at java.io.File.&lt;init&gt;(File.java:305) at org.apache.lucene.store.NIOFSDirectory.openInput(NIOFSDirectory.java:80) at org.apache.lucene.codecs.lucene40.BitVector.&lt;init&gt;(BitVector.java:327) at org.apache.lucene.codecs.lucene40.Lucene40LiveDocsFormat.readLiveDocs(Lucene40LiveDocsFormat.java:90) at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:131) at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:194) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:326) at org.apache.lucene.index.StandardDirectoryReader$2.doBody(StandardDirectoryReader.java:320) at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:702) at org.apache.lucene.index.StandardDirectoryReader.doOpenFromCommit(StandardDirectoryReader.java:315) at org.apache.lucene.index.StandardDirectoryReader.doOpenNoWriter(StandardDirectoryReader.java:311) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:262) at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:183) </pre> </div></div>
</description>
<environment/>
<key id="12740281">LUCENE-5931</key>
<summary>
DirectoryReader.openIfChanged(oldReader, commit) incorrectly assumes given commit point has deletes/field updates
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mikemccand">Michael McCandless</assignee>
<reporter username="vfunstein">Vitaly Funstein</reporter>
<labels></labels>
<created>Wed, 10 Sep 2014 01:01:23 +0000</created>
<updated>Tue, 23 Sep 2014 08:56:21 +0000</updated>
<version>4.6.1</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14129247" author="mikemccand" created="Wed, 10 Sep 2014 22:24:19 +0000">
<p>Patch, starting from Vitaly's test case (thank you!) and folding into Lucene's tests ... it fails with this on trunk:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>1) testReopenReaderToOlderCommit(org.apache.lucene.index.TestDirectoryReaderReopen) java.lang.IllegalStateException: same segment _0 has invalid changes; likely you are re-opening a reader after illegally removing index files yourself and building a new index in their place. Use IndexWriter.deleteAll or OpenMode.CREATE instead at __randomizedtesting.SeedInfo.seed([D3F22B13D5839643:931C8A9673D003F4]:0) at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:190) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:323) at org.apache.lucene.index.StandardDirectoryReader$2.doBody(StandardDirectoryReader.java:317) at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:649) at org.apache.lucene.index.StandardDirectoryReader.doOpenFromCommit(StandardDirectoryReader.java:312) at org.apache.lucene.index.StandardDirectoryReader.doOpenNoWriter(StandardDirectoryReader.java:308) at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:259) at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:137) at org.apache.lucene.index.TestDirectoryReaderReopen.testReopenReaderToOlderCommit(TestDirectoryReaderReopen.java:824) </pre> </div></div>
</comment>
<comment id="14129463" author="rcmuir" created="Thu, 11 Sep 2014 01:04:27 +0000">
<p>Patch: I think the use-case is cool and it should be supported: its just adding an 'if' and removing the current exception (which is geared at protecting some user who manually rm -rf's files from their index.)</p> <p>I improved the test a bit to ensure that cores are shared and also tested the dv updates case.</p>
</comment>
<comment id="14129776" author="mikemccand" created="Thu, 11 Sep 2014 08:11:54 +0000">
<p>Thanks Rob, patch looks great, except: I think we can keep the illegalDocCountChange safety? I think I could make a test case to trip that ...</p>
</comment>
<comment id="14129873" author="rcmuir" created="Thu, 11 Sep 2014 10:51:50 +0000">
<p>Can you make a test change to trip it without manually removing files from your index?</p>
</comment>
<comment id="14133664" author="mikemccand" created="Mon, 15 Sep 2014 07:46:06 +0000">
<blockquote><p>Can you make a test change to trip it without manually removing files from your index?</p></blockquote> <p>I don' t think so ... the only way I know of this happening is if an app has a reader open, then removes the index, rebuilds it, then tries to openIfChanged the reader.</p> <p>We can remove the defensive safety if you really want to, but we put it in last time when this happened and it sure looked like index corruption... it's nice not to have false scares even if the app is doing something it shouldn't...</p>
</comment>
<comment id="14133766" author="rcmuir" created="Mon, 15 Sep 2014 10:23:23 +0000">
<p>Yes, I really want to. We can't let such abuse prevent real features, thats just wrong.</p> <p>If you want safety against deleting files, maybe look at NIO.2 WatchService. This is general and would give you notification when such things happen rather than having a hack for one particular user's mistake.</p>
</comment>
<comment id="14133770" author="rcmuir" created="Mon, 15 Sep 2014 10:24:54 +0000">
<blockquote> <p>We can remove the defensive safety if you really want to, but we put it in last time when this happened and it sure looked like index corruption</p></blockquote> <p>It is index corruption though. The user went and manually corrupted their index. Why hide that Mike?</p>
</comment>
<comment id="14135183" author="mikemccand" created="Tue, 16 Sep 2014 09:21:04 +0000">
<p>I think we can do both (keep our best effort check, and allow reopening to "older" commit point) ... here's a patch.</p>
</comment>
<comment id="14138564" author="vfunstein" created="Thu, 18 Sep 2014 06:06:19 +0000">
<p>Mike/Robert,</p> <p>I have a follow-up question. I have backported the fix to 4.6 and now I believe I am seeing another serious issue here. <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/sad.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>If the old reader passed in to <tt>DirectoryReader.openIfChanged(DirectoryReader, IndexCommit)</tt> is actually an NRT reader, then it seems that if there is unflushed/uncommitted data in the associated writer's buffers, in particular deletes, the returned reader will see those changes - thus violating the intent of opening the index at just the commit point we wanted, frozen in time. Here's my original test case modified to show the problem:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.junit.Assert.assertEquals; <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.junit.Assert.assertTrue; <span class="code-keyword">import</span> org.apache.lucene.document.Document; <span class="code-keyword">import</span> org.apache.lucene.document.Field.Store; <span class="code-keyword">import</span> org.apache.lucene.document.StringField; <span class="code-keyword">import</span> org.apache.lucene.index.DirectoryReader; <span class="code-keyword">import</span> org.apache.lucene.index.IndexCommit; <span class="code-keyword">import</span> org.apache.lucene.index.IndexWriter; <span class="code-keyword">import</span> org.apache.lucene.index.IndexWriterConfig; <span class="code-keyword">import</span> org.apache.lucene.index.KeepOnlyLastCommitDeletionPolicy; <span class="code-keyword">import</span> org.apache.lucene.index.ReaderManager; <span class="code-keyword">import</span> org.apache.lucene.index.SnapshotDeletionPolicy; <span class="code-keyword">import</span> org.apache.lucene.index.Term; <span class="code-keyword">import</span> org.apache.lucene.search.IndexSearcher; <span class="code-keyword">import</span> org.apache.lucene.search.Query; <span class="code-keyword">import</span> org.apache.lucene.search.TermQuery; <span class="code-keyword">import</span> org.apache.lucene.search.TopDocs; <span class="code-keyword">import</span> org.apache.lucene.store.Directory; <span class="code-keyword">import</span> org.apache.lucene.store.FSDirectory; <span class="code-keyword">import</span> org.apache.lucene.util.Version; <span class="code-keyword">import</span> org.junit.After; <span class="code-keyword">import</span> org.junit.Before; <span class="code-keyword">import</span> org.junit.Test; <span class="code-keyword">import</span> java.io.File; <span class="code-keyword">public</span> class CommitReuseTest { <span class="code-keyword">private</span> <span class="code-keyword">final</span> File path = <span class="code-keyword">new</span> File(<span class="code-quote">"indexDir"</span>); <span class="code-keyword">private</span> IndexWriter writer; <span class="code-keyword">private</span> <span class="code-keyword">final</span> SnapshotDeletionPolicy snapshotter = <span class="code-keyword">new</span> SnapshotDeletionPolicy(<span class="code-keyword">new</span> KeepOnlyLastCommitDeletionPolicy()); @Before <span class="code-keyword">public</span> void initIndex() <span class="code-keyword">throws</span> Exception { path.mkdirs(); IndexWriterConfig idxWriterCfg = <span class="code-keyword">new</span> IndexWriterConfig(Version.LUCENE_46, <span class="code-keyword">null</span>); idxWriterCfg.setIndexDeletionPolicy(snapshotter); idxWriterCfg.setInfoStream(<span class="code-object">System</span>.out); Directory dir = FSDirectory.open(path); writer = <span class="code-keyword">new</span> IndexWriter(dir, idxWriterCfg); writer.commit(); <span class="code-comment">// make sure all index metadata is written out </span> } @After <span class="code-keyword">public</span> void stop() <span class="code-keyword">throws</span> Exception { writer.close(); } @Test <span class="code-keyword">public</span> void test() <span class="code-keyword">throws</span> Exception { Document doc; ReaderManager rm = <span class="code-keyword">new</span> ReaderManager(writer, <span class="code-keyword">true</span>); <span class="code-comment">// Index some data </span> <span class="code-keyword">for</span> (<span class="code-object">int</span> i = 0; i &lt; 100; i++) { doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> StringField(<span class="code-quote">"key-"</span> + i, <span class="code-quote">"ABC"</span>, Store.YES)); writer.addDocument(doc); } writer.commit(); IndexCommit ic1 = snapshotter.snapshot(); doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> StringField(<span class="code-quote">"key-"</span> + 0, <span class="code-quote">"AAA"</span>, Store.YES)); writer.updateDocument(<span class="code-keyword">new</span> Term(<span class="code-quote">"key-"</span> + 0, <span class="code-quote">"ABC"</span>), doc); rm.maybeRefreshBlocking(); DirectoryReader latest = rm.acquire(); assertTrue(latest.hasDeletions()); <span class="code-comment">// This reader will be used <span class="code-keyword">for</span> searching against commit point 1 </span> DirectoryReader searchReader = DirectoryReader.openIfChanged(latest, ic1); <span class="code-comment">// assertFalse(searchReader.hasDeletions()); // XXX - <span class="code-keyword">this</span> fails too! </span> rm.release(latest); IndexSearcher s = <span class="code-keyword">new</span> IndexSearcher(searchReader); Query q = <span class="code-keyword">new</span> TermQuery(<span class="code-keyword">new</span> Term(<span class="code-quote">"key-0"</span>, <span class="code-quote">"ABC"</span>)); TopDocs td = s.search(q, 10); assertEquals(1, td.totalHits); searchReader.close(); rm.close(); snapshotter.release(ic1); } } </pre> </div></div> <p>Note, that if I comment out the <tt>updateDocument()</tt> call, the test passes. Also, if you only have one entry in the index, then it appears that while refreshing the NRT reader, the segment containing just the single delete will be removed, making it look like the test passes:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>IW 0 [Wed Sep 17 22:32:47 PDT 2014; main]: drop 100% deleted segments: _4(4.6):c1/1 </pre> </div></div> <p>This output does not appear when running the code above, unchanged. Hope this helps... I can't make further headway myself though.</p>
</comment>
<comment id="14140264" author="mikemccand" created="Fri, 19 Sep 2014 09:56:13 +0000">
<p>OK, here's another iteration on the patch ...</p> <blockquote><p>I have backported the fix to 4.6 and now I believe I am seeing another serious issue here. </p></blockquote> <p>Thanks Vitaly, that's a good catch (opening to an older commit point<br/> from an NRT reader that's carrying deletes in RAM), and we don't<br/> properly handle that case because SegmentReader doesn't know whether<br/> its liveDocs came from disk (matching the delGen from the<br/> SegmentCommitInfo) or were carried in RAM from IndexWriter.</p> <p>I fixed this in this new patch by recording whether the<br/> SegmentReader is NRT, and then fixing the reopen logic to load<br/> liveDocs from disk in that case. I folded in your example as another<br/> test case (failed at first but now passes).</p> <p>Also I moved the "best-effort detection of rm -rf index" up<br/> higher... it's currently too low now, i.e. will fail to detect some<br/> cases that it should.</p>
</comment>
<comment id="14143710" author="vfunstein" created="Mon, 22 Sep 2014 20:06:44 +0000">
<p>Michael,</p> <p>Your updated patch definitely fixes the issue. But I just wanted to understand why deletes are so special, in that - if I don't have any buffered deletes for the segment, but new documents only, the reused reader instance won't pick them up, even without the fix in place. This is because liveDocs won't capture unflushed doc ids?</p>
</comment>
<comment id="14144569" author="mikemccand" created="Tue, 23 Sep 2014 08:56:21 +0000">
<p>Hi <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=vfunstein" class="user-hover" rel="vfunstein">Vitaly Funstein</a>, I'm glad the patched fixed your issue ... thanks for<br/> testing.</p> <p>Deletes are special because 1) they are allowed to change after a<br/> segment is written, and 2) IndexWriter carries them in RAM, rather<br/> than writing to / reading from the filesystem, so the only<br/> "point-in-time-ness" is maintained by IW being careful to not change a<br/> liveDocs already paired up with a SegmentReader.</p>
</comment>
</comments>
<attachments>
<attachment id="12667562" name="CommitReuseTest.java" size="2576" author="vfunstein" created="Wed, 10 Sep 2014 01:06:16 +0000"/>
<attachment id="12669963" name="LUCENE-5931.patch" size="18615" author="mikemccand" created="Fri, 19 Sep 2014 09:56:13 +0000"/>
<attachment id="12669010" name="LUCENE-5931.patch" size="10412" author="mikemccand" created="Tue, 16 Sep 2014 09:21:04 +0000"/>
<attachment id="12667916" name="LUCENE-5931.patch" size="9421" author="rcmuir" created="Thu, 11 Sep 2014 01:04:27 +0000"/>
<attachment id="12667875" name="LUCENE-5931.patch" size="2184" author="mikemccand" created="Wed, 10 Sep 2014 22:24:19 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>5.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 10 Sep 2014 22:24:19 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1zuyn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-5814] JVM crash When Run Lucene</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5814</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>JVM crash when running Lucene in the case as follow:<br/> 1 Two Lucene servers A and B,Linux system. <br/> 2 Lucene index files on A server ,we mount A Lucene index path to B with NFS<br/> 3 We run another programer on A to refresh index .<br/> 4 Lucene programer on B always crash , but A not.<br/> when B crash it will give a JVM crash error file named hs_err_pid19495.log ,the conent as follow :</p> <p>#</p> <ol> <li>A fatal error has been detected by the Java Runtime Environment:<br/> #</li> <li>SIGBUS (0x7) at pc=0x00002aaaab0787a0, pid=6830, tid=1129146688<br/> #</li> <li>JRE version: 6.0_43-b01</li> <li>Java VM: Java HotSpot(TM) 64-Bit Server VM (20.14-b01 mixed mode linux-amd64 compressed oops)</li> <li>Problematic frame:</li> <li>v ~StubRoutines::jshort_disjoint_arraycopy<br/> #</li> <li>If you would like to submit a bug report, please visit:</li> <li><a href="http://java.sun.com/webapps/bugreport/crash.jsp" class="external-link" rel="nofollow">http://java.sun.com/webapps/bugreport/crash.jsp</a><br/> #</li> </ol> <p>--------------- T H R E A D ---------------</p> <p>Current thread (0x0000000054a49800): JavaThread "RMI TCP Connection(722)-192.168.251.56" daemon <span class="error">&#91;_thread_in_Java, id=7084, stack(0x00000000433d6000,0x00000000434d7000)&#93;</span></p> <p>siginfo:si_signo=SIGBUS: si_errno=0, si_code=2 (BUS_ADRERR), si_addr=0x00002aaab8dbd6f6</p> <p>Registers:<br/> RAX=0x00002aaab8dc1de8, RBX=0x0000000000000000, RCX=0x0000000000002379, RDX=0xfffffffffffff726<br/> RSP=0x00000000434d4b00, RBP=0x00000000434d4b00, RSI=0x000000079860fb40, RDI=0x00002aaab8dc1dde<br/> R8 =0x00002aaab8dbd6f6, R9 =0x00000000000046f2, R10=0x00002aaaab078d80, R11=0x0000000797f9c420<br/> R12=0x0000000000000000, R13=0x0000000000004702, R14=0x00002aaab8dc1de8, R15=0x0000000054a49800<br/> RIP=0x00002aaaab0787a0, EFLAGS=0x0000000000010282, CSGSFS=0x0000000000000033, ERR=0x0000000000000004<br/> TRAPNO=0x000000000000000e</p> <p>Top of Stack: (sp=0x00000000434d4b00)<br/> 0x00000000434d4b00: 00000000000046f6 00002aaaab0cbc74<br/> 0x00000000434d4b10: 000000079860b448 000046f200000000<br/> 0x00000000434d4b20: 0000000797f9c420 0000000797f9c998<br/> 0x00000000434d4b30: 0000000797f7ee70 0000000797f480f8<br/> 0x00000000434d4b40: 0000000054a49800 0000000797f49c98<br/> 0x00000000434d4b50: 0000000797f7cc08 0000000000000000<br/> 0x00000000434d4b60: 000000079860b3a8 00000000434d4ae0<br/> 0x00000000434d4b70: 0000000797f9cb70 00002aaaab3f7f90<br/> 0x00000000434d4b80: f2ff3884000046f2 0000000797f9c420<br/> 0x00000000434d4b90: 000000079860b288 0000000797f9cb70<br/> 0x00000000434d4ba0: f2fefd649860b288 000000079858c680<br/> 0x00000000434d4bb0: 0000000054a49800 0004000000000000<br/> 0x00000000434d4bc0: 0000006296bf6801 00002aaaab2f861c<br/> 0x00000000434d4bd0: 00000000d8c07bb6 00002aaaab3a3094<br/> 0x00000000434d4be0: 000000079860b408 000000079860b408<br/> 0x00000000434d4bf0: 000000079860b288 0000000798586b98<br/> 0x00000000434d4c00: 0000000797f7cc08 0000000797f7cc08<br/> 0x00000000434d4c10: 000000079858c190 0000000798586b38<br/> 0x00000000434d4c20: 0000000797f9daa8 00002aaaab1cfa70<br/> 0x00000000434d4c30: 000000079858ccf8 0000000000000000<br/> 0x00000000434d4c40: 0000000798586b98 0000000797f9d9f0<br/> 0x00000000434d4c50: 000000079858ccf8 0000000798586b98<br/> 0x00000000434d4c60: d82e822900000000 000000079858ccf8<br/> 0x00000000434d4c70: 00000007f2fe8a48 0000000797f45240<br/> 0x00000000434d4c80: 0000000798586b98 00002aaaab319440<br/> 0x00000000434d4c90: 000000079858ccf8 f3095552d8c32f35<br/> 0x00000000434d4ca0: 0000000000000000 00002aaaab301b6c<br/> 0x00000000434d4cb0: 0000000000000000 00002aaaab306b4c<br/> 0x00000000434d4cc0: 0000000797f9d9f0 00000007d82e8229<br/> 0x00000000434d4cd0: 00000007000046fa 00000006c6041a00<br/> 0x00000000434d4ce0: 00000007984aaa70 0000045dab416ca4<br/> 0x00000000434d4cf0: 00000000000186a0 00002aaaab29f730 </p> <p>Instructions: (pc=0x00002aaaab0787a0)<br/> 0x00002aaaab078780: c6 04 f7 c1 01 00 00 00 74 08 66 8b 47 08 66 89<br/> 0x00002aaaab078790: 46 08 48 33 c0 c9 c3 66 0f 1f 84 00 00 00 00 00<br/> 0x00002aaaab0787a0: 48 8b 44 d7 e8 48 89 44 d6 e8 48 8b 44 d7 f0 48<br/> 0x00002aaaab0787b0: 89 44 d6 f0 48 8b 44 d7 f8 48 89 44 d6 f8 48 8b </p> <p>Register to memory mapping:</p> <p>RAX=0x00002aaab8dc1de8 is an unknown value<br/> RBX=0x0000000000000000 is an unknown value<br/> RCX=0x0000000000002379 is an unknown value<br/> RDX=0xfffffffffffff726 is an unknown value<br/> RSP=0x00000000434d4b00 is pointing into the stack for thread: 0x0000000054a49800<br/> RBP=0x00000000434d4b00 is pointing into the stack for thread: 0x0000000054a49800<br/> RSI=0x000000079860fb40 is an unknown value<br/> RDI=0x00002aaab8dc1dde is an unknown value<br/> R8 =0x00002aaab8dbd6f6 is an unknown value<br/> R9 =0x00000000000046f2 is an unknown value<br/> R10=StubRoutines::unsafe_arraycopy [0x00002aaaab078d80, 0x00002aaaab078dbb[ (59 bytes)R11=0x0000000797f9c420 is an oop<br/> org.apache.lucene.store.MMapDirectory$MMapIndexInput </p> <ul class="alternate" type="square"> <li>klass: 'org/apache/lucene/store/MMapDirectory$MMapIndexInput'<br/> R12=0x0000000000000000 is an unknown value<br/> R13=0x0000000000004702 is an unknown value<br/> R14=0x00002aaab8dc1de8 is an unknown value<br/> R15=0x0000000054a49800 is a thread</li> </ul> <p>Stack: <span class="error">&#91;0x00000000433d6000,0x00000000434d7000&#93;</span>, sp=0x00000000434d4b00, free space=1018k<br/> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)<br/> v ~StubRoutines::jshort_disjoint_arraycopy</p> <p>--------------- P R O C E S S ---------------</p> <p>Java Threads: ( =&gt; current thread )<br/> 0x0000000054c21000 JavaThread "RMI TCP Connection(754)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7113, stack(0x00000000439dc000,0x0000000043add000)&#93;</span><br/> 0x0000000054c11800 JavaThread "RMI TCP Connection(743)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7112, stack(0x00000000415b1000,0x00000000416b2000)&#93;</span><br/> 0x0000000054cf0000 JavaThread "RMI TCP Connection(742)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7111, stack(0x0000000043add000,0x0000000043bde000)&#93;</span><br/> 0x0000000054d27000 JavaThread "RMI TCP Connection(745)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7110, stack(0x0000000043cdf000,0x0000000043de0000)&#93;</span><br/> 0x0000000054c32800 JavaThread "RMI TCP Connection(755)-192.168.251.52" daemon <span class="error">&#91;_thread_in_native, id=7109, stack(0x0000000044bee000,0x0000000044cef000)&#93;</span><br/> 0x000000005532b800 JavaThread "RMI TCP Connection(740)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7108, stack(0x00000000425c8000,0x00000000426c9000)&#93;</span><br/> 0x0000000054c00800 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=7099, stack(0x00000000434d7000,0x00000000435d8000)&#93;</span><br/> 0x0000000054cbc000 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=7098, stack(0x0000000043bde000,0x0000000043cdf000)&#93;</span><br/> =&gt;0x0000000054a49800 JavaThread "RMI TCP Connection(722)-192.168.251.56" daemon <span class="error">&#91;_thread_in_Java, id=7084, stack(0x00000000433d6000,0x00000000434d7000)&#93;</span><br/> 0x0000000054c69000 JavaThread "RMI TCP Connection(661)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7081, stack(0x0000000042bce000,0x0000000042ccf000)&#93;</span><br/> 0x0000000054bfe800 JavaThread "RMI TCP Connection(718)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7080, stack(0x0000000041976000,0x0000000041a77000)&#93;</span><br/> 0x0000000054d05000 JavaThread "RMI TCP Connection(747)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7078, stack(0x00000000445e8000,0x00000000446e9000)&#93;</span><br/> 0x0000000054c0f000 JavaThread "RMI TCP Connection(737)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7076, stack(0x0000000042ccf000,0x0000000042dd0000)&#93;</span><br/> 0x0000000054cba800 JavaThread "RMI TCP Connection(730)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7075, stack(0x00000000436d9000,0x00000000437da000)&#93;</span><br/> 0x0000000054bf6800 JavaThread "RMI TCP Connection(732)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7074, stack(0x00000000449ec000,0x0000000044aed000)&#93;</span><br/> 0x0000000054d17000 JavaThread "RMI TCP Connection(738)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7073, stack(0x00000000427ca000,0x00000000428cb000)&#93;</span><br/> 0x0000000054c65000 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=7067, stack(0x0000000042ed1000,0x0000000042fd2000)&#93;</span><br/> 0x0000000054c13800 JavaThread "RMI TCP Connection(712)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7061, stack(0x00000000452f5000,0x00000000453f6000)&#93;</span><br/> 0x0000000054d22800 JavaThread "RMI TCP Connection(749)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7059, stack(0x0000000040934000,0x0000000040a35000)&#93;</span><br/> 0x00000000549b8800 JavaThread "RMI TCP Connection(733)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7049, stack(0x00000000429cc000,0x0000000042acd000)&#93;</span><br/> 0x000000005532c000 JavaThread "RMI TCP Connection(717)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7045, stack(0x0000000043de0000,0x0000000043ee1000)&#93;</span><br/> 0x0000000054ce9000 JavaThread "RMI TCP Connection(752)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7041, stack(0x0000000040cff000,0x0000000040e00000)&#93;</span><br/> 0x0000000054d1b800 JavaThread "RMI TCP Connection(735)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7040, stack(0x0000000042dd0000,0x0000000042ed1000)&#93;</span><br/> 0x0000000054cb7000 JavaThread "RMI TCP Connection(736)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7034, stack(0x00000000442e5000,0x00000000443e6000)&#93;</span><br/> 0x0000000054bfe000 JavaThread "RMI TCP Connection(724)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7030, stack(0x00000000432d5000,0x00000000433d6000)&#93;</span><br/> 0x0000000054c0b000 JavaThread "RMI TCP Connection(751)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7029, stack(0x0000000043fe2000,0x00000000440e3000)&#93;</span><br/> 0x000000005532a800 JavaThread "RMI TCP Connection(729)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7010, stack(0x00000000440e3000,0x00000000441e4000)&#93;</span><br/> 0x0000000055329800 JavaThread "RMI TCP Connection(750)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=7009, stack(0x00000000424c7000,0x00000000425c8000)&#93;</span><br/> 0x0000000054d24800 JavaThread "RMI TCP Connection(719)-192.168.251.56" daemon <span class="error">&#91;_thread_in_native, id=6960, stack(0x00000000446e9000,0x00000000447ea000)&#93;</span><br/> 0x00002aaab43e2000 JavaThread "Druid-ConnectionPool-Destory" daemon <span class="error">&#91;_thread_blocked, id=6908, stack(0x00000000451f4000,0x00000000452f5000)&#93;</span><br/> 0x00002aaab4295000 JavaThread "Druid-ConnectionPool-Create" daemon <span class="error">&#91;_thread_blocked, id=6907, stack(0x00000000450f3000,0x00000000451f4000)&#93;</span><br/> 0x0000000054d49800 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=6906, stack(0x0000000044ff2000,0x00000000450f3000)&#93;</span><br/> 0x0000000054c67000 JavaThread "RMI TCP Connection(39)-192.168.251.52" daemon <span class="error">&#91;_thread_in_native, id=6883, stack(0x00000000438db000,0x00000000439dc000)&#93;</span><br/> 0x0000000054c1d800 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=6872, stack(0x00000000430d3000,0x00000000431d4000)&#93;</span><br/> 0x00000000548ed800 JavaThread "DestroyJavaVM" <span class="error">&#91;_thread_blocked, id=6831, stack(0x0000000041783000,0x0000000041884000)&#93;</span><br/> 0x0000000054b1f000 JavaThread "RMI RenewClean-<span class="error">&#91;192.168.251.58:936&#93;</span>" daemon <span class="error">&#91;_thread_blocked, id=6852, stack(0x0000000040ecf000,0x0000000040fd0000)&#93;</span><br/> 0x00002aaab40ce800 JavaThread "RMI Scheduler(0)" daemon <span class="error">&#91;_thread_blocked, id=6851, stack(0x00000000412f9000,0x00000000413fa000)&#93;</span><br/> 0x00002aaab40c9800 JavaThread "GC Daemon" daemon <span class="error">&#91;_thread_blocked, id=6849, stack(0x00000000421c4000,0x00000000422c5000)&#93;</span><br/> 0x00002aaab406a000 JavaThread "RMI Reaper" <span class="error">&#91;_thread_blocked, id=6848, stack(0x0000000041a77000,0x0000000041b78000)&#93;</span><br/> 0x0000000054b95000 JavaThread "RMI TCP Connection(idle)" daemon <span class="error">&#91;_thread_blocked, id=6847, stack(0x0000000040522000,0x0000000040623000)&#93;</span><br/> 0x00002aaab402c800 JavaThread "RMI TCP Accept-0" daemon <span class="error">&#91;_thread_in_native, id=6846, stack(0x000000004010c000,0x000000004020d000)&#93;</span><br/> 0x00002aaab4001000 JavaThread "RMI TCP Accept-836" daemon <span class="error">&#91;_thread_in_native, id=6845, stack(0x00000000414b0000,0x00000000415b1000)&#93;</span><br/> 0x0000000054b5d000 JavaThread "FlushIndexSearchThread" <span class="error">&#91;_thread_blocked, id=6842, stack(0x0000000040a61000,0x0000000040b62000)&#93;</span><br/> 0x00000000549a2800 JavaThread "Low Memory Detector" daemon <span class="error">&#91;_thread_blocked, id=6840, stack(0x0000000041fc2000,0x00000000420c3000)&#93;</span><br/> 0x00000000549a0800 JavaThread "C2 CompilerThread1" daemon <span class="error">&#91;_thread_blocked, id=6839, stack(0x0000000041ec1000,0x0000000041fc2000)&#93;</span><br/> 0x000000005499b000 JavaThread "C2 CompilerThread0" daemon <span class="error">&#91;_thread_blocked, id=6838, stack(0x0000000041dc0000,0x0000000041ec1000)&#93;</span><br/> 0x0000000054999000 JavaThread "Signal Dispatcher" daemon <span class="error">&#91;_thread_blocked, id=6837, stack(0x0000000041cbf000,0x0000000041dc0000)&#93;</span><br/> 0x0000000054977000 JavaThread "Finalizer" daemon <span class="error">&#91;_thread_blocked, id=6836, stack(0x00000000411f8000,0x00000000412f9000)&#93;</span><br/> 0x0000000054975000 JavaThread "Reference Handler" daemon <span class="error">&#91;_thread_blocked, id=6835, stack(0x00000000410f7000,0x00000000411f8000)&#93;</span></p> <p>Other Threads:<br/> 0x000000005496e800 VMThread <span class="error">&#91;stack: 0x0000000040ff6000,0x00000000410f7000&#93;</span> <span class="error">&#91;id=6834&#93;</span><br/> 0x00000000549ad800 WatcherThread <span class="error">&#91;stack: 0x00000000420c3000,0x00000000421c4000&#93;</span> <span class="error">&#91;id=6841&#93;</span></p> <p>VM state:not at safepoint (normal execution)</p> <p>VM Mutex/Monitor currently owned by a thread: None</p> <p>Heap<br/> PSYoungGen total 662720K, used 18736K [0x0000000797560000, 0x00000007d9160000, 0x0000000800000000)<br/> eden space 662080K, 2% used [0x0000000797560000,0x00000007987127e0,0x00000007bfbf0000)<br/> from space 640K, 96% used [0x00000007d90c0000,0x00000007d91599c0,0x00000007d9160000)<br/> to space 4224K, 0% used [0x00000007d8920000,0x00000007d8920000,0x00000007d8d40000)<br/> PSOldGen total 51520K, used 46456K [0x00000006c6000000, 0x00000006c9250000, 0x0000000797560000)<br/> object space 51520K, 90% used [0x00000006c6000000,0x00000006c8d5e1f8,0x00000006c9250000)<br/> PSPermGen total 24128K, used 16347K [0x00000006c0e00000, 0x00000006c2590000, 0x00000006c6000000)<br/> object space 24128K, 67% used [0x00000006c0e00000,0x00000006c1df6d88,0x00000006c2590000)</p> <p>Code Cache [0x00002aaaab037000, 0x00002aaaab457000, 0x00002aaaae037000)<br/> total_blobs=1448 nmethods=1117 adapters=285 free_code_cache=46100032 largest_free_block=17408</p> <p>Dynamic libraries:<br/> 40000000-40009000 r-xp 00000000 fc:00 3172330 /opt/srv/jdk1.6/bin/java<br/> 40108000-4010a000 rwxp 00008000 fc:00 3172330 /opt/srv/jdk1.6/bin/java<br/> 4010c000-4010f000 ---p 4010c000 00:00 0 <br/> 4010f000-4020d000 rwxp 4010f000 00:00 0 <br/> 4020d000-40210000 ---p 4020d000 00:00 0 <br/> 40210000-4030e000 rwxp 40210000 00:00 0 <br/> 4030e000-40311000 ---p 4030e000 00:00 0 <br/> 40311000-4040f000 rwxp 40311000 00:00 0 <br/> 40421000-40422000 ---p 40421000 00:00 0 <br/> 40422000-40522000 rwxp 40422000 00:00 0 <br/> 40522000-40525000 ---p 40522000 00:00 0 <br/> 40525000-40623000 rwxp 40525000 00:00 0 <br/> 406ef000-406f2000 ---p 406ef000 00:00 0 <br/> 406f2000-407f0000 rwxp 406f2000 00:00 0 <br/> 40833000-40836000 ---p 40833000 00:00 0 <br/> 40836000-40934000 rwxp 40836000 00:00 0 <br/> 40934000-40937000 ---p 40934000 00:00 0 <br/> 40937000-40a35000 rwxp 40937000 00:00 0 <br/> 40a61000-40a64000 ---p 40a61000 00:00 0 <br/> 40a64000-40b62000 rwxp 40a64000 00:00 0 <br/> 40bfe000-40c01000 ---p 40bfe000 00:00 0 <br/> 40c01000-40cff000 rwxp 40c01000 00:00 0 <br/> 40cff000-40d02000 ---p 40cff000 00:00 0 <br/> 40d02000-40e00000 rwxp 40d02000 00:00 0 <br/> 40ecf000-40ed2000 ---p 40ecf000 00:00 0 <br/> 40ed2000-40fd0000 rwxp 40ed2000 00:00 0 <br/> 40ff6000-40ff7000 ---p 40ff6000 00:00 0 <br/> 40ff7000-410f7000 rwxp 40ff7000 00:00 0 <br/> 410f7000-410fa000 ---p 410f7000 00:00 0 <br/> 410fa000-411f8000 rwxp 410fa000 00:00 0 <br/> 411f8000-411fb000 ---p 411f8000 00:00 0 <br/> 411fb000-412f9000 rwxp 411fb000 00:00 0 <br/> 412f9000-412fc000 ---p 412f9000 00:00 0 <br/> 412fc000-413fa000 rwxp 412fc000 00:00 0 <br/> 414b0000-414b3000 ---p 414b0000 00:00 0 <br/> 414b3000-415b1000 rwxp 414b3000 00:00 0 <br/> 415b1000-415b4000 ---p 415b1000 00:00 0 <br/> 415b4000-416b2000 rwxp 415b4000 00:00 0 <br/> 41783000-41786000 ---p 41783000 00:00 0 <br/> 41786000-41884000 rwxp 41786000 00:00 0 <br/> 41976000-41979000 ---p 41976000 00:00 0 <br/> 41979000-41a77000 rwxp 41979000 00:00 0 <br/> 41a77000-41a7a000 ---p 41a77000 00:00 0 <br/> 41a7a000-41b78000 rwxp 41a7a000 00:00 0 <br/> 41bbe000-41bbf000 ---p 41bbe000 00:00 0 <br/> 41bbf000-41cbf000 rwxp 41bbf000 00:00 0 <br/> 41cbf000-41cc2000 ---p 41cbf000 00:00 0 <br/> 41cc2000-41dc0000 rwxp 41cc2000 00:00 0 <br/> 41dc0000-41dc3000 ---p 41dc0000 00:00 0 <br/> 41dc3000-41ec1000 rwxp 41dc3000 00:00 0 <br/> 41ec1000-41ec4000 ---p 41ec1000 00:00 0 <br/> 41ec4000-41fc2000 rwxp 41ec4000 00:00 0 <br/> 41fc2000-41fc5000 ---p 41fc2000 00:00 0 <br/> 41fc5000-420c3000 rwxp 41fc5000 00:00 0 <br/> 420c3000-420c4000 ---p 420c3000 00:00 0 <br/> 420c4000-421c4000 rwxp 420c4000 00:00 0 <br/> 421c4000-421c7000 ---p 421c4000 00:00 0 <br/> 421c7000-422c5000 rwxp 421c7000 00:00 0 <br/> 424c7000-424ca000 ---p 424c7000 00:00 0 <br/> 424ca000-425c8000 rwxp 424ca000 00:00 0 <br/> 425c8000-425cb000 ---p 425c8000 00:00 0 <br/> 425cb000-426c9000 rwxp 425cb000 00:00 0 <br/> 426c9000-426cc000 ---p 426c9000 00:00 0 <br/> 426cc000-427ca000 rwxp 426cc000 00:00 0 <br/> 427ca000-427cd000 ---p 427ca000 00:00 0 <br/> 427cd000-428cb000 rwxp 427cd000 00:00 0 <br/> 428cb000-428ce000 ---p 428cb000 00:00 0 <br/> 428ce000-429cc000 rwxp 428ce000 00:00 0 <br/> 429cc000-429cf000 ---p 429cc000 00:00 0 <br/> 429cf000-42acd000 rwxp 429cf000 00:00 0 <br/> 42acd000-42ad0000 ---p 42acd000 00:00 0 <br/> 42ad0000-42bce000 rwxp 42ad0000 00:00 0 <br/> 42bce000-42bd1000 ---p 42bce000 00:00 0 <br/> 42bd1000-42ccf000 rwxp 42bd1000 00:00 0 <br/> 42ccf000-42cd2000 ---p 42ccf000 00:00 0 <br/> 42cd2000-42dd0000 rwxp 42cd2000 00:00 0 <br/> 42dd0000-42dd3000 ---p 42dd0000 00:00 0 <br/> 42dd3000-42ed1000 rwxp 42dd3000 00:00 0 <br/> 42ed1000-42ed4000 ---p 42ed1000 00:00 0 <br/> 42ed4000-42fd2000 rwxp 42ed4000 00:00 0 <br/> 430d3000-430d6000 ---p 430d3000 00:00 0 <br/> 430d6000-431d4000 rwxp 430d6000 00:00 0 <br/> 431d4000-431d7000 ---p 431d4000 00:00 0 <br/> 431d7000-432d5000 rwxp 431d7000 00:00 0 <br/> 432d5000-432d8000 ---p 432d5000 00:00 0 <br/> 432d8000-433d6000 rwxp 432d8000 00:00 0 <br/> 433d6000-433d9000 ---p 433d6000 00:00 0 <br/> 433d9000-434d7000 rwxp 433d9000 00:00 0 <br/> 434d7000-434da000 ---p 434d7000 00:00 0 <br/> 434da000-435d8000 rwxp 434da000 00:00 0 <br/> 435d8000-435db000 ---p 435d8000 00:00 0 <br/> 435db000-436d9000 rwxp 435db000 00:00 0 <br/> 436d9000-436dc000 ---p 436d9000 00:00 0 <br/> 436dc000-437da000 rwxp 436dc000 00:00 0 <br/> 437da000-437dd000 ---p 437da000 00:00 0 <br/> 437dd000-438db000 rwxp 437dd000 00:00 0 <br/> 438db000-438de000 ---p 438db000 00:00 0 <br/> 438de000-439dc000 rwxp 438de000 00:00 0 <br/> 439dc000-439df000 ---p 439dc000 00:00 0 <br/> 439df000-43add000 rwxp 439df000 00:00 0 <br/> 43add000-43ae0000 ---p 43add000 00:00 0 <br/> 43ae0000-43bde000 rwxp 43ae0000 00:00 0 <br/> 43bde000-43be1000 ---p 43bde000 00:00 0 <br/> 43be1000-43cdf000 rwxp 43be1000 00:00 0 <br/> 43cdf000-43ce2000 ---p 43cdf000 00:00 0 <br/> 43ce2000-43de0000 rwxp 43ce2000 00:00 0 <br/> 43de0000-43de3000 ---p 43de0000 00:00 0 <br/> 43de3000-43ee1000 rwxp 43de3000 00:00 0 <br/> 43ee1000-43ee4000 ---p 43ee1000 00:00 0 <br/> 43ee4000-43fe2000 rwxp 43ee4000 00:00 0 <br/> 43fe2000-43fe5000 ---p 43fe2000 00:00 0 <br/> 43fe5000-440e3000 rwxp 43fe5000 00:00 0 <br/> 440e3000-440e6000 ---p 440e3000 00:00 0 <br/> 440e6000-441e4000 rwxp 440e6000 00:00 0 <br/> 441e4000-441e7000 ---p 441e4000 00:00 0 <br/> 441e7000-442e5000 rwxp 441e7000 00:00 0 <br/> 442e5000-442e8000 ---p 442e5000 00:00 0 <br/> 442e8000-443e6000 rwxp 442e8000 00:00 0 <br/> 443e6000-443e9000 ---p 443e6000 00:00 0 <br/> 443e9000-444e7000 rwxp 443e9000 00:00 0 <br/> 444e7000-444ea000 ---p 444e7000 00:00 0 <br/> 444ea000-445e8000 rwxp 444ea000 00:00 0 <br/> 445e8000-445eb000 ---p 445e8000 00:00 0 <br/> 445eb000-446e9000 rwxp 445eb000 00:00 0 <br/> 446e9000-446ec000 ---p 446e9000 00:00 0 <br/> 446ec000-447ea000 rwxp 446ec000 00:00 0 <br/> 447ea000-447ed000 ---p 447ea000 00:00 0 <br/> 447ed000-448eb000 rwxp 447ed000 00:00 0 <br/> 448eb000-448ee000 ---p 448eb000 00:00 0 <br/> 448ee000-449ec000 rwxp 448ee000 00:00 0 <br/> 449ec000-449ef000 ---p 449ec000 00:00 0 <br/> 449ef000-44aed000 rwxp 449ef000 00:00 0 <br/> 44aed000-44af0000 ---p 44aed000 00:00 0 <br/> 44af0000-44bee000 rwxp 44af0000 00:00 0 <br/> 44bee000-44bf1000 ---p 44bee000 00:00 0 <br/> 44bf1000-44cef000 rwxp 44bf1000 00:00 0 <br/> 44cef000-44cf2000 ---p 44cef000 00:00 0 <br/> 44cf2000-44df0000 rwxp 44cf2000 00:00 0 <br/> 44df0000-44df3000 ---p 44df0000 00:00 0 <br/> 44df3000-44ef1000 rwxp 44df3000 00:00 0 <br/> 44ef1000-44ef4000 ---p 44ef1000 00:00 0 <br/> 44ef4000-44ff2000 rwxp 44ef4000 00:00 0 <br/> 44ff2000-44ff5000 ---p 44ff2000 00:00 0 <br/> 44ff5000-450f3000 rwxp 44ff5000 00:00 0 <br/> 450f3000-450f6000 ---p 450f3000 00:00 0 <br/> 450f6000-451f4000 rwxp 450f6000 00:00 0 <br/> 451f4000-451f7000 ---p 451f4000 00:00 0 <br/> 451f7000-452f5000 rwxp 451f7000 00:00 0 <br/> 452f5000-452f8000 ---p 452f5000 00:00 0 <br/> 452f8000-453f6000 rwxp 452f8000 00:00 0 <br/> 548e6000-563d8000 rwxp 548e6000 00:00 0 <span class="error">&#91;heap&#93;</span><br/> 6c0e00000-6c2590000 rwxp 6c0e00000 00:00 0 <br/> 6c2590000-6c2900000 ---p 6c2590000 00:00 0 <br/> 6c2900000-6c6000000 rwxp 6c2900000 00:00 0 <br/> 6c6000000-6c9250000 rwxp 6c6000000 00:00 0 <br/> 6c9250000-6c9e40000 ---p 6c9250000 00:00 0 <br/> 6c9e40000-797560000 rwxp 6c9e40000 00:00 0 <br/> 797560000-7d9160000 rwxp 797560000 00:00 0 <br/> 7d9160000-800000000 ---p 7d9160000 00:00 0 <br/> 30e2200000-30e221c000 r-xp 00000000 fc:00 1079550 /lib64/ld-2.5.so<br/> 30e241b000-30e241c000 r-xp 0001b000 fc:00 1079550 /lib64/ld-2.5.so<br/> 30e241c000-30e241d000 rwxp 0001c000 fc:00 1079550 /lib64/ld-2.5.so<br/> 30e2600000-30e274e000 r-xp 00000000 fc:00 1079551 /lib64/libc-2.5.so<br/> 30e274e000-30e294e000 ---p 0014e000 fc:00 1079551 /lib64/libc-2.5.so<br/> 30e294e000-30e2952000 r-xp 0014e000 fc:00 1079551 /lib64/libc-2.5.so<br/> 30e2952000-30e2953000 rwxp 00152000 fc:00 1079551 /lib64/libc-2.5.so<br/> 30e2953000-30e2958000 rwxp 30e2953000 00:00 0 <br/> 30e2a00000-30e2a82000 r-xp 00000000 fc:00 1079554 /lib64/libm-2.5.so<br/> 30e2a82000-30e2c81000 ---p 00082000 fc:00 1079554 /lib64/libm-2.5.so<br/> 30e2c81000-30e2c82000 r-xp 00081000 fc:00 1079554 /lib64/libm-2.5.so<br/> 30e2c82000-30e2c83000 rwxp 00082000 fc:00 1079554 /lib64/libm-2.5.so<br/> 30e2e00000-30e2e02000 r-xp 00000000 fc:00 1079436 /lib64/libdl-2.5.so<br/> 30e2e02000-30e3002000 ---p 00002000 fc:00 1079436 /lib64/libdl-2.5.so<br/> 30e3002000-30e3003000 r-xp 00002000 fc:00 1079436 /lib64/libdl-2.5.so<br/> 30e3003000-30e3004000 rwxp 00003000 fc:00 1079436 /lib64/libdl-2.5.so<br/> 30e3200000-30e3216000 r-xp 00000000 fc:00 1079553 /lib64/libpthread-2.5.so<br/> 30e3216000-30e3415000 ---p 00016000 fc:00 1079553 /lib64/libpthread-2.5.so<br/> 30e3415000-30e3416000 r-xp 00015000 fc:00 1079553 /lib64/libpthread-2.5.so<br/> 30e3416000-30e3417000 rwxp 00016000 fc:00 1079553 /lib64/libpthread-2.5.so<br/> 30e3417000-30e341b000 rwxp 30e3417000 00:00 0 <br/> 30e3a00000-30e3a07000 r-xp 00000000 fc:00 1079555 /lib64/librt-2.5.so<br/> 30e3a07000-30e3c07000 ---p 00007000 fc:00 1079555 /lib64/librt-2.5.so<br/> 30e3c07000-30e3c08000 r-xp 00007000 fc:00 1079555 /lib64/librt-2.5.so<br/> 30e3c08000-30e3c09000 rwxp 00008000 fc:00 1079555 /lib64/librt-2.5.so<br/> 30e6200000-30e6215000 r-xp 00000000 fc:00 1079567 /lib64/libnsl-2.5.so<br/> 30e6215000-30e6414000 ---p 00015000 fc:00 1079567 /lib64/libnsl-2.5.so<br/> 30e6414000-30e6415000 r-xp 00014000 fc:00 1079567 /lib64/libnsl-2.5.so<br/> 30e6415000-30e6416000 rwxp 00015000 fc:00 1079567 /lib64/libnsl-2.5.so<br/> 30e6416000-30e6418000 rwxp 30e6416000 00:00 0 <br/> 2aaaaaaad000-2aaaaaaaf000 r-xs 0001e000 fc:00 3008801 /opt/app/egame/mobile/egame.search/lib/egame.search.core.jar<br/> 2aaaaaaaf000-2aaaaaab1000 r-xs 0011d000 fc:00 3008812 /opt/app/egame/mobile/egame.search/lib/IKAnalyzer3.2.8.jar<br/> 2aaaaaab1000-2aaaaaab2000 r-xs 00000000 00:18 2257675 /data/search/index_new/egame.GameInfo/_3hy.cfs<br/> 2aaaaaab2000-2aaaaaab3000 r-xs 00000000 00:18 2257674 /data/search/index_new/egame.GameInfo/_3hx.cfs<br/> 2aaaaaab3000-2aaaaaab4000 r-xs 00000000 00:18 2257673 /data/search/index_new/egame.GameInfo/_3hw.cfs<br/> 2aaaaaab4000-2aaaaaab5000 r-xs 00000000 00:18 2257672 /data/search/index_new/egame.GameInfo/_3hv.cfs<br/> 2aaaaaab5000-2aaaaaab6000 r-xs 00000000 00:18 2257670 /data/search/index_new/egame.GameTagInfo/_1zl.cfs<br/> 2aaaaaab6000-2aaaaaab7000 r-xs 00000000 00:18 2257669 /data/search/index_new/egame.GameTagInfo/_1zk.cfs<br/> 2aaaaaab7000-2aaaaaab8000 r-xs 00000000 00:18 2257668 /data/search/index_new/egame.GameTagInfo/_1zj.cfs<br/> 2aaaaaab8000-2aaaaaab9000 r-xs 00000000 00:18 2257667 /data/search/index_new/egame.GameTagInfo/_1zi.cfs<br/> 2aaaaaab9000-2aaaaaaba000 r-xs 00000000 00:18 2257654 /data/search/index_new/egame.GameTagInfo/_1zh.cfs<br/> 2aaaaaaba000-2aaaaaabb000 r-xs 00000000 00:18 2257664 /data/search/index_new/egame.GameTagInfo/_1zg.cfs<br/> 2aaaaaabb000-2aaaaaabc000 r-xs 00000000 00:18 2257653 /data/search/index_new/egame.GameTagInfo/_1zf.cfs<br/> 2aaaaaabc000-2aaaaaac1000 r-xs 00000000 00:18 2257655 /data/search/index_new/egame.GameTagInfo/_1ze.fdx<br/> 2aaaaaac2000-2aaaaaacf000 r-xp 00000000 fc:00 3205692 /opt/srv/jdk1.6/jre/lib/amd64/libverify.so<br/> 2aaaaaacf000-2aaaaabce000 ---p 0000d000 fc:00 3205692 /opt/srv/jdk1.6/jre/lib/amd64/libverify.so<br/> 2aaaaabce000-2aaaaabd1000 rwxp 0000c000 fc:00 3205692 /opt/srv/jdk1.6/jre/lib/amd64/libverify.so<br/> 2aaaaabd1000-2aaaaabfa000 r-xp 00000000 fc:00 3205686 /opt/srv/jdk1.6/jre/lib/amd64/libjava.so<br/> 2aaaaabfa000-2aaaaacf9000 ---p 00029000 fc:00 3205686 /opt/srv/jdk1.6/jre/lib/amd64/libjava.so<br/> 2aaaaacf9000-2aaaaad00000 rwxp 00028000 fc:00 3205686 /opt/srv/jdk1.6/jre/lib/amd64/libjava.so<br/> 2aaaaad00000-2aaaaad01000 r-xp 2aaaaad00000 00:00 0 <br/> 2aaaaad01000-2aaaaad02000 rwxp 2aaaaad01000 00:00 0 <br/> 2aaaaad02000-2aaaaad0a000 rwxs 00000000 fc:00 4480455 /tmp/hsperfdata_root/6830<br/> 2aaaaad0a000-2aaaaad18000 r-xs 00000000 00:18 2257656 /data/search/index_new/egame.GameTagInfo/_1ze.frq<br/> 2aaaaad18000-2aaaaad22000 r-xp 00000000 fc:00 1079259 /lib64/libnss_files-2.5.so<br/> 2aaaaad22000-2aaaaaf21000 ---p 0000a000 fc:00 1079259 /lib64/libnss_files-2.5.so<br/> 2aaaaaf21000-2aaaaaf22000 r-xp 00009000 fc:00 1079259 /lib64/libnss_files-2.5.so<br/> 2aaaaaf22000-2aaaaaf23000 rwxp 0000a000 fc:00 1079259 /lib64/libnss_files-2.5.so<br/> 2aaaaaf23000-2aaaaaf31000 r-xp 00000000 fc:00 3205679 /opt/srv/jdk1.6/jre/lib/amd64/libzip.so<br/> 2aaaaaf31000-2aaaab033000 ---p 0000e000 fc:00 3205679 /opt/srv/jdk1.6/jre/lib/amd64/libzip.so<br/> 2aaaab033000-2aaaab036000 rwxp 00010000 fc:00 3205679 /opt/srv/jdk1.6/jre/lib/amd64/libzip.so<br/> 2aaaab036000-2aaaab457000 rwxp 2aaaab036000 00:00 0 <br/> 2aaaab457000-2aaaae037000 rwxp 2aaaab457000 00:00 0 <br/> 2aaaae037000-2aaaae048000 rwxp 2aaaae037000 00:00 0 <br/> 2aaaae048000-2aaaae0f7000 rwxp 2aaaae048000 00:00 0 <br/> 2aaaae0f7000-2aaaae103000 rwxp 2aaaae0f7000 00:00 0 <br/> 2aaaae103000-2aaaae105000 ---p 2aaaae103000 00:00 0 <br/> 2aaaae105000-2aaaae120000 rwxp 2aaaae105000 00:00 0 <br/> 2aaaae120000-2aaaae13a000 rwxp 2aaaae120000 00:00 0 <br/> 2aaaae13a000-2aaaae140000 ---p 2aaaae13a000 00:00 0 <br/> 2aaaae140000-2aaaae7aa000 rwxp 2aaaae140000 00:00 0 <br/> 2aaaae7aa000-2aaaae9b9000 rwxp 2aaaae7aa000 00:00 0 <br/> 2aaaae9b9000-2aaaaeaf0000 ---p 2aaaae9b9000 00:00 0 <br/> 2aaaaeaf0000-2aaaaeb0b000 rwxp 2aaaaeaf0000 00:00 0 <br/> 2aaaaeb0b000-2aaaaeb11000 ---p 2aaaaeb0b000 00:00 0 <br/> 2aaaaeb11000-2aaaaf17c000 rwxp 2aaaaeb11000 00:00 0 <br/> 2aaaaf17c000-2aaaaf188000 rwxp 2aaaaf17c000 00:00 0 <br/> 2aaaaf188000-2aaaaf18a000 ---p 2aaaaf188000 00:00 0 <br/> 2aaaaf18a000-2aaaaf1a5000 rwxp 2aaaaf18a000 00:00 0 <br/> 2aaaaf1a5000-2aaaaf33d000 r-xs 03083000 fc:00 3174137 /opt/srv/jdk1.6/jre/lib/rt.jar<br/> 2aaaaf33d000-2aaaaf674000 rwxp 2aaaaf33d000 00:00 0 <br/> 2aaaaf674000-2aaab2c41000 r-xp 00000000 fc:00 6743196 /usr/lib/locale/locale-archive<br/> 2aaab2c41000-2aaab2ca4000 r-xs 0052d000 fc:00 3008802 /opt/app/egame/mobile/egame.search/lib/activemq-all-5.8.0.jar<br/> 2aaab2ca4000-2aaab2ca5000 r-xs 00007000 fc:00 3008795 /opt/app/egame/mobile/egame.search/lib/egame.common-search.jar<br/> 2aaab2ca5000-2aaab2ca8000 r-xs 00023000 fc:00 3008814 /opt/app/egame/mobile/egame.search/lib/egame.common.jar<br/> 2aaab2ca8000-2aaab2cab000 r-xs 00015000 fc:00 3008807 /opt/app/egame/mobile/egame.search/lib/commons-pool-1.5.4.jar<br/> 2aaab2cab000-2aaab2cc6000 r-xs 0015e000 fc:00 3008799 /opt/app/egame/mobile/egame.search/lib/druid-0.2.8.jar<br/> 2aaab2cc6000-2aaab2ccf000 r-xs 0006d000 fc:00 3008790 /opt/app/egame/mobile/egame.search/lib/log4j-1.2.16.jar<br/> 2aaab2ccf000-2aaab2cd6000 r-xs 0005f000 fc:00 3008813 /opt/app/egame/mobile/egame.search/lib/mongo-java-driver-2.11.1.jar<br/> 2aaab2cd6000-2aaab2cdd000 r-xs 000b7000 fc:00 3008792 /opt/app/egame/mobile/egame.search/lib/mysql-connector-java-5.1.14-bin.jar<br/> 2aaab2cdd000-2aaab2ce6000 r-xs 00060000 fc:00 3008793 /opt/app/egame/mobile/egame.search/lib/egame.interfaces.jar<br/> 2aaab2ce6000-2aaab2ce8000 r-xs 00006000 fc:00 3008789 /opt/app/egame/mobile/egame.search/lib/geronimo-jms_1.1_spec-1.1.1.jar<br/> 2aaab2ce8000-2aaab2d01000 r-xs 0015e000 fc:00 3008808 /opt/app/egame/mobile/egame.search/lib/lucene-core-3.6.0.jar<br/> 2aaab2d01000-2aaab2d05000 r-xs 0002b000 fc:00 3008791 /opt/app/egame/mobile/egame.search/lib/pinyin4j-2.5.0.jar<br/> 2aaab2d05000-2aaab2d18000 r-xp 00000000 fc:00 3205691 /opt/srv/jdk1.6/jre/lib/amd64/libnet.so<br/> 2aaab2d18000-2aaab2e19000 ---p 00013000 fc:00 3205691 /opt/srv/jdk1.6/jre/lib/amd64/libnet.so<br/> 2aaab2e19000-2aaab2e1c000 rwxp 00014000 fc:00 3205691 /opt/srv/jdk1.6/jre/lib/amd64/libnet.so<br/> 2aaab2e1c000-2aaab32cd000 rwxp 2aaab2e1c000 00:00 0 <br/> 2aaab32cd000-2aaab32d4000 r-xp 00000000 fc:00 3205693 /opt/srv/jdk1.6/jre/lib/amd64/libnio.so<br/> 2aaab32d4000-2aaab33d3000 ---p 00007000 fc:00 3205693 /opt/srv/jdk1.6/jre/lib/amd64/libnio.so<br/> 2aaab33d3000-2aaab33d5000 rwxp 00006000 fc:00 3205693 /opt/srv/jdk1.6/jre/lib/amd64/libnio.so<br/> 2aaab33d5000-2aaab33d6000 r-xp 00000000 fc:00 3205665 /opt/srv/jdk1.6/jre/lib/amd64/librmi.so<br/> 2aaab33d6000-2aaab34d5000 ---p 00001000 fc:00 3205665 /opt/srv/jdk1.6/jre/lib/amd64/librmi.so<br/> 2aaab34d5000-2aaab34d6000 rwxp 00000000 fc:00 3205665 /opt/srv/jdk1.6/jre/lib/amd64/librmi.so<br/> 2aaab34d6000-2aaab377e000 r-xs 00000000 00:18 2257633 /data/search/index_new/egame.GameInfo/_3hu.tis<br/> 2aaab377e000-2aaab37fa000 r-xs 00000000 00:18 2257630 /data/search/index_new/egame.GameInfo/_3hu.frq<br/> 2aaab37fa000-2aaab3848000 r-xs 00000000 00:18 2257637 /data/search/index_new/egame.GameInfo/_3hu.prx<br/> 2aaab3848000-2aaab3c57000 r-xs 00000000 00:18 2257628 /data/search/index_new/egame.GameInfo/_3hu.fdt<br/> 2aaab3c57000-2aaab3c5f000 r-xs 00000000 00:18 2257632 /data/search/index_new/egame.GameInfo/_3hu.fdx<br/> 2aaab3c5f000-2aaab3c92000 r-xs 00000000 00:18 2257635 /data/search/index_new/egame.GameInfo/_3hu.nrm<br/> 2aaab3c92000-2aaab3cb1000 r-xs 00000000 00:18 2257657 /data/search/index_new/egame.GameTagInfo/_1ze.tis<br/> 2aaab3cb1000-2aaab3cba000 r-xs 00000000 00:18 2257660 /data/search/index_new/egame.GameTagInfo/_1ze.prx<br/> 2aaab3cba000-2aaab3ced000 r-xs 00000000 00:18 2257661 /data/search/index_new/egame.GameTagInfo/_1ze.fdt<br/> 2aaab3ced000-2aaab3cf3000 r-xs 00000000 00:18 2257665 /data/search/index_new/egame.GameTagInfo/_1ze.nrm<br/> 2aaab3cf3000-2aaab3d41000 r-xs 00000000 00:18 2257683 /data/search/index_new/egame.GameTagLinkInfo/_18un.tis<br/> 2aaab3d41000-2aaab3d8e000 r-xs 00000000 00:18 2257685 /data/search/index_new/egame.GameTagLinkInfo/_18un.frq<br/> 2aaab3d8e000-2aaab3dc3000 r-xs 00000000 00:18 2257686 /data/search/index_new/egame.GameTagLinkInfo/_18un.prx<br/> 2aaab3dc3000-2aaab3dc4000 r-xs 00000000 00:18 2257696 /data/search/index_new/egame.GameTagLinkInfo/_18zq.cfs<br/> 2aaab3dc4000-2aaab3dc5000 r-xs 00000000 00:18 2257695 /data/search/index_new/egame.GameTagLinkInfo/_18zp.cfs<br/> 2aaab3dc5000-2aaab3dc6000 r-xs 00000000 00:18 2257692 /data/search/index_new/egame.GameTagLinkInfo/_18zo.cfs<br/> 2aaab3dc6000-2aaab3dc7000 r-xs 00000000 00:18 2257752 /data/search/index_new/egame.GameTagLinkInfo/_18pr.cfs<br/> 2aaab3dc7000-2aaab3dc8000 r-xs 00000000 00:18 2257751 /data/search/index_new/egame.GameTagLinkInfo/_18pq.cfs<br/> 2aaab3dc8000-2aaab3dc9000 r-xs 00000000 00:18 2257750 /data/search/index_new/egame.GameTagLinkInfo/_18pp.cfs<br/> 2aaab3dc9000-2aaab3dca000 r-xs 00000000 00:18 2257749 /data/search/index_new/egame.GameTagLinkInfo/_18po.cfs<br/> 2aaab3dca000-2aaab3dcb000 r-xs 00000000 00:18 2257748 /data/search/index_new/egame.GameTagLinkInfo/_18pn.cfs<br/> 2aaab3dcb000-2aaab3dcc000 r-xs 00000000 00:18 2257746 /data/search/index_new/egame.GameTagLinkInfo/_18pm.cfs<br/> 2aaab3dcc000-2aaab3dcd000 r-xs 00000000 00:18 2257747 /data/search/index_new/egame.GameTagLinkInfo/_18pl.cfs<br/> 2aaab3dcd000-2aaab3dce000 r-xs 00000000 00:18 2257691 /data/search/index_new/egame.GameTagLinkInfo/_18zn.cfs<br/> 2aaab3dce000-2aaab3dcf000 r-xs 00000000 00:18 2257690 /data/search/index_new/egame.GameTagLinkInfo/_18zm.cfs<br/> 2aaab3dcf000-2aaab3dd0000 r-xs 00000000 00:18 2257686 /data/search/index_new/egame.GameTagLinkInfo/_18zl.cfs<br/> 2aaab3dd0000-2aaab3dd1000 r-xs 00000000 00:18 2257694 /data/search/index_new/egame.GameTagLinkInfo/_18zk.cfs<br/> 2aaab3dd1000-2aaab3dd2000 r-xs 00000000 00:18 2257693 /data/search/index_new/egame.GameTagLinkInfo/_18zj.cfs<br/> 2aaab3dd2000-2aaab3e21000 r-xs 00000000 00:18 2257676 /data/search/index_new/egame.GameTagLinkInfo/_18ze.tis<br/> 2aaab3e21000-2aaab3e6f000 r-xs 00000000 00:18 2257682 /data/search/index_new/egame.GameTagLinkInfo/_18ze.frq<br/> 2aaab3e6f000-2aaab3ea4000 r-xs 00000000 00:18 2257683 /data/search/index_new/egame.GameTagLinkInfo/_18ze.prx<br/> 2aaab3ea4000-2aaab3ea5000 r-xs 00000000 00:18 2257694 /data/search/index_new/egame.GameTagLinkInfo/_194u.cfs<br/> 2aaab3ea5000-2aaab3ea6000 r-xs 00000000 00:18 2257693 /data/search/index_new/egame.GameTagLinkInfo/_194t.cfs<br/> 2aaab3ea6000-2aaab3ea7000 r-xs 00000000 00:18 2257692 /data/search/index_new/egame.GameTagLinkInfo/_194s.cfs<br/> 2aaab3ea7000-2aaab3ea8000 r-xs 00000000 00:18 2257689 /data/search/index_new/egame.GameTagLinkInfo/_194r.cfs<br/> 2aaab3ea8000-2aaab3ea9000 r-xs 00000000 00:18 2257688 /data/search/index_new/egame.GameTagLinkInfo/_194q.cfs<br/> 2aaab3ea9000-2aaab3eaa000 r-xs 00000000 00:18 2257687 /data/search/index_new/egame.GameTagLinkInfo/_194p.cfs<br/> 2aaab3eaa000-2aaab3eab000 r-xs 00000000 00:18 2257686 /data/search/index_new/egame.GameTagLinkInfo/_194o.cfs<br/> 2aaab3eab000-2aaab3eac000 r-xs 00000000 00:18 2257684 /data/search/index_new/egame.GameTagLinkInfo/_194n.cfs<br/> 2aaab3eac000-2aaab3efb000 r-xs 00000000 00:18 2257556 /data/search/index_new/egame.GameTagLinkInfo/_194m.tis<br/> 2aaab3f00000-2aaab3f02000 r-xs 00000000 00:18 2257646 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j3.cfs<br/> 2aaab3f02000-2aaab3f04000 r-xs 00000000 00:18 2257650 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j2.cfs<br/> 2aaab3f04000-2aaab3f06000 r-xs 00000000 00:18 2257642 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j1.cfs<br/> 2aaab3f06000-2aaab3f68000 r-xs 00000000 00:18 2257643 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.frq<br/> 2aaab3f68000-2aaab3fb7000 r-xs 00000000 00:18 2257645 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.prx<br/> 2aaab3fb7000-2aaab3fb8000 r-xs 00000000 00:18 2257590 /data/search/index_new/egame.KeyWordSuggestion/_7.tis<br/> 2aaab3fb8000-2aaab3fb9000 r-xs 00000000 00:18 2257622 /data/search/index_new/egame.KeyWordSuggestion/_7.frq<br/> 2aaab3fb9000-2aaab3fba000 r-xs 00000000 00:18 2257584 /data/search/index_new/egame.KeyWordSuggestion/_7.prx<br/> 2aaab3fba000-2aaab3fbb000 r-xs 00000000 00:18 2257588 /data/search/index_new/egame.KeyWordSuggestion/_7.fdt<br/> 2aaab3fbb000-2aaab3fbc000 r-xs 00000000 00:18 2257577 /data/search/index_new/egame.KeyWordSuggestion/_7.fdx<br/> 2aaab3fbc000-2aaab3fbd000 r-xs 00000000 00:18 2257568 /data/search/index_new/egame.KeyWordSuggestion/_7.nrm<br/> 2aaab3fbd000-2aaab3fbe000 r-xs 00000000 00:18 2257583 /data/search/index_new/egame.KeyWordSuggestion/_6.tis<br/> 2aaab3fbe000-2aaab3fbf000 r-xs 00000000 00:18 2257595 /data/search/index_new/egame.KeyWordSuggestion/_6.frq<br/> 2aaab3fbf000-2aaab3fc0000 r-xs 00000000 00:18 2257617 /data/search/index_new/egame.KeyWordSuggestion/_6.prx<br/> 2aaab3fc0000-2aaab3fc1000 r-xs 00000000 00:18 2257624 /data/search/index_new/egame.KeyWordSuggestion/_6.fdt<br/> 2aaab3fc1000-2aaab3fc2000 r-xs 00000000 00:18 2257582 /data/search/index_new/egame.KeyWordSuggestion/_6.fdx<br/> 2aaab3fc2000-2aaab3fc3000 r-xs 00000000 00:18 2257609 /data/search/index_new/egame.KeyWordSuggestion/_6.nrm<br/> 2aaab3fc3000-2aaab3fc4000 r-xs 00000000 00:18 2257581 /data/search/index_new/egame.KeyWordSuggestion/_5.tis<br/> 2aaab3fc4000-2aaab3fc5000 r-xs 00000000 00:18 2257596 /data/search/index_new/egame.KeyWordSuggestion/_5.frq<br/> 2aaab3fc5000-2aaab3fc6000 r-xs 00000000 00:18 2257616 /data/search/index_new/egame.KeyWordSuggestion/_5.prx<br/> 2aaab3fc6000-2aaab3fc7000 r-xs 00000000 00:18 2257585 /data/search/index_new/egame.KeyWordSuggestion/_5.fdt<br/> 2aaab3fc7000-2aaab3fc8000 r-xs 00000000 00:18 2257600 /data/search/index_new/egame.KeyWordSuggestion/_5.fdx<br/> 2aaab3fc8000-2aaab3fc9000 r-xs 00000000 00:18 2257587 /data/search/index_new/egame.KeyWordSuggestion/_5.nrm<br/> 2aaab3fc9000-2aaab3fca000 r-xs 00000000 00:18 2257610 /data/search/index_new/egame.KeyWordSuggestion/_4.tis<br/> 2aaab3fca000-2aaab3fcb000 r-xs 00000000 00:18 2257612 /data/search/index_new/egame.KeyWordSuggestion/_4.frq<br/> 2aaab3fcb000-2aaab3fcc000 r-xs 00000000 00:18 2257615 /data/search/index_new/egame.KeyWordSuggestion/_4.prx<br/> 2aaab3fcc000-2aaab3fcd000 r-xs 00000000 00:18 2257580 /data/search/index_new/egame.KeyWordSuggestion/_4.fdt<br/> 2aaab3fcd000-2aaab3fce000 r-xs 00000000 00:18 2257625 /data/search/index_new/egame.KeyWordSuggestion/_4.fdx<br/> 2aaab3fce000-2aaab3fd6000 r-xs 00115000 fc:00 3174092 /opt/srv/jdk1.6/jre/lib/resources.jar<br/> 2aaab3fd6000-2aaab3fd7000 r-xs 00000000 00:18 2257606 /data/search/index_new/egame.KeyWordSuggestion/_4.nrm<br/> 2aaab4000000-2aaab4cc2000 rwxp 2aaab4000000 00:00 0 <br/> 2aaab4cc2000-2aaab8000000 ---p 2aaab4cc2000 00:00 0 <br/> 2aaab8000000-2aaab8105000 r-xs 00000000 00:18 2257649 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.tis<br/> 2aaab8105000-2aaab86bc000 r-xs 00000000 00:18 2257639 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.fdt<br/> 2aaab86bc000-2aaab86c9000 r-xs 00000000 00:18 2257651 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.fdx<br/> 2aaab86c9000-2aaab871b000 r-xs 00000000 00:18 2257641 /data/search/index_new/egame.GameTagInfoWithoutAnalyzer/_1j0.nrm<br/> 2aaab871b000-2aaab8721000 r-xp 00000000 fc:00 3205672 /opt/srv/jdk1.6/jre/lib/amd64/libmanagement.so<br/> 2aaab8721000-2aaab8820000 ---p 00006000 fc:00 3205672 /opt/srv/jdk1.6/jre/lib/amd64/libmanagement.so<br/> 2aaab8820000-2aaab8822000 rwxp 00005000 fc:00 3205672 /opt/srv/jdk1.6/jre/lib/amd64/libmanagement.so<br/> 2aaab8822000-2aaab8823000 r-xs 00000000 00:18 2257594 /data/search/index_new/egame.KeyWordSuggestion/_3.tis<br/> 2aaab8823000-2aaab8824000 r-xs 00000000 00:18 2257601 /data/search/index_new/egame.KeyWordSuggestion/_3.frq<br/> 2aaab8824000-2aaab8825000 r-xs 00000000 00:18 2257566 /data/search/index_new/egame.KeyWordSuggestion/_3.prx<br/> 2aaab8825000-2aaab8826000 r-xs 00000000 00:18 2257602 /data/search/index_new/egame.KeyWordSuggestion/_3.fdt<br/> 2aaab8826000-2aaab8827000 r-xs 00000000 00:18 2257621 /data/search/index_new/egame.KeyWordSuggestion/_3.fdx<br/> 2aaab8827000-2aaab8828000 r-xs 00000000 00:18 2257605 /data/search/index_new/egame.KeyWordSuggestion/_3.nrm<br/> 2aaab8828000-2aaab8829000 r-xs 00000000 00:18 2257623 /data/search/index_new/egame.KeyWordSuggestion/_2.tis<br/> 2aaab8829000-2aaab882a000 r-xs 00000000 00:18 2257579 /data/search/index_new/egame.KeyWordSuggestion/_2.frq<br/> 2aaab882a000-2aaab882b000 r-xs 00000000 00:18 2257599 /data/search/index_new/egame.KeyWordSuggestion/_2.prx<br/> 2aaab882b000-2aaab882c000 r-xs 00000000 00:18 2257578 /data/search/index_new/egame.KeyWordSuggestion/_2.fdt<br/> 2aaab882c000-2aaab882d000 r-xs 00000000 00:18 2257618 /data/search/index_new/egame.KeyWordSuggestion/_2.fdx<br/> 2aaab882d000-2aaab882e000 r-xs 00000000 00:18 2257620 /data/search/index_new/egame.KeyWordSuggestion/_2.nrm<br/> 2aaab882e000-2aaab882f000 r-xs 00000000 00:18 2257604 /data/search/index_new/egame.KeyWordSuggestion/_1.tis<br/> 2aaab882f000-2aaab8830000 r-xs 00000000 00:18 2257626 /data/search/index_new/egame.KeyWordSuggestion/_1.frq<br/> 2aaab8830000-2aaab8831000 r-xs 00000000 00:18 2257613 /data/search/index_new/egame.KeyWordSuggestion/_1.prx<br/> 2aaab8831000-2aaab8832000 r-xs 00000000 00:18 2257607 /data/search/index_new/egame.KeyWordSuggestion/_1.fdt<br/> 2aaab8832000-2aaab8833000 r-xs 00000000 00:18 2257576 /data/search/index_new/egame.KeyWordSuggestion/_1.fdx<br/> 2aaab8833000-2aaab8834000 r-xs 00000000 00:18 2257565 /data/search/index_new/egame.KeyWordSuggestion/_1.nrm<br/> 2aaab8834000-2aaab8835000 r-xs 00000000 00:18 2257562 /data/search/index_new/egame.KeyWordSuggestion/_0.tis<br/> 2aaab8835000-2aaab8836000 r-xs 00000000 00:18 2257619 /data/search/index_new/egame.KeyWordSuggestion/_0.frq<br/> 2aaab8836000-2aaab8837000 r-xs 00000000 00:18 2257597 /data/search/index_new/egame.KeyWordSuggestion/_0.prx<br/> 2aaab8837000-2aaab8838000 r-xs 00000000 00:18 2257561 /data/search/index_new/egame.KeyWordSuggestion/_0.fdt<br/> 2aaab8838000-2aaab8839000 r-xs 00000000 00:18 2257586 /data/search/index_new/egame.KeyWordSuggestion/_0.fdx<br/> 2aaab8839000-2aaab883a000 r-xs 00000000 00:18 2257598 /data/search/index_new/egame.KeyWordSuggestion/_0.nrm<br/> 2aaab883a000-2aaab8999000 r-xs 00000000 00:18 2257681 /data/search/index_new/egame.GameTagLinkInfo/_18un.fdt<br/> 2aaab8999000-2aaab89bc000 r-xs 00000000 00:18 2257682 /data/search/index_new/egame.GameTagLinkInfo/_18un.fdx<br/> 2aaab89bc000-2aaab89f1000 r-xs 00000000 00:18 2257687 /data/search/index_new/egame.GameTagLinkInfo/_18un.nrm<br/> 2aaab89f1000-2aaab8b53000 r-xs 00000000 00:18 2257556 /data/search/index_new/egame.GameTagLinkInfo/_18ze.fdt<br/> 2aaab8b53000-2aaab8b77000 r-xs 00000000 00:18 2257671 /data/search/index_new/egame.GameTagLinkInfo/_18ze.fdx<br/> 2aaab8b77000-2aaab8bac000 r-xs 00000000 00:18 2257685 /data/search/index_new/egame.GameTagLinkInfo/_18ze.nrm<br/> 2aaab8bac000-2aaab8bfb000 r-xs 00000000 00:18 2257558 /data/search/index_new/egame.GameTagLinkInfo/_194m.frq<br/> 2aaab8bfb000-2aaab8c31000 r-xs 00000000 00:18 2257559 /data/search/index_new/egame.GameTagLinkInfo/_194m.prx<br/> 2aaab8c31000-2aaab8d95000 r-xs 00000000 00:18 2257553 /data/search/index_new/egame.GameTagLinkInfo/_194m.fdt<br/> 2aaab8d95000-2aaab8db9000 r-xs 00000000 00:18 2257554 /data/search/index_new/egame.GameTagLinkInfo/_194m.fdx<br/> 2aaab8db9000-2aaab8def000 r-xs 00000000 00:18 2257681 /data/search/index_new/egame.GameTagLinkInfo/_194m.nrm<br/> 2aaab8e26000-2aaab8e74000 r-xs 00000000 00:18 2257735 /data/search/index_new/egame.GameTagLinkInfo/_18pj.tis<br/> 2aaab8e74000-2aaab8ec1000 r-xs 00000000 00:18 2257737 /data/search/index_new/egame.GameTagLinkInfo/_18pj.frq<br/> 2aaab8ec1000-2aaab8ef5000 r-xs 00000000 00:18 2257738 /data/search/index_new/egame.GameTagLinkInfo/_18pj.prx<br/> 2aaab8ef5000-2aaab9051000 r-xs 00000000 00:18 2257718 /data/search/index_new/egame.GameTagLinkInfo/_18pj.fdt<br/> 2aaab9051000-2aaab9074000 r-xs 00000000 00:18 2257724 /data/search/index_new/egame.GameTagLinkInfo/_18pj.fdx<br/> 2aaab9074000-2aaab90a8000 r-xs 00000000 00:18 2257740 /data/search/index_new/egame.GameTagLinkInfo/_18pj.nrm<br/> 2aaabc000000-2aaabd895000 rwxp 2aaabc000000 00:00 0 <br/> 2aaabd895000-2aaac0000000 ---p 2aaabd895000 00:00 0 <br/> 2b95ebf91000-2b95ebf93000 rwxp 2b95ebf91000 00:00 0 <br/> 2b95ebfa9000-2b95ebfb0000 r-xp 00000000 fc:00 3205689 /opt/srv/jdk1.6/jre/lib/amd64/jli/libjli.so<br/> 2b95ebfb0000-2b95ec0b1000 ---p 00007000 fc:00 3205689 /opt/srv/jdk1.6/jre/lib/amd64/jli/libjli.so<br/> 2b95ec0b1000-2b95ec0b3000 rwxp 00008000 fc:00 3205689 /opt/srv/jdk1.6/jre/lib/amd64/jli/libjli.so<br/> 2b95ec0b3000-2b95ec0b6000 rwxp 2b95ec0b3000 00:00 0 <br/> 2b95ec0b6000-2b95ec9d4000 r-xp 00000000 fc:00 3205698 /opt/srv/jdk1.6/jre/lib/amd64/server/libjvm.so<br/> 2b95ec9d4000-2b95ecad6000 ---p 0091e000 fc:00 3205698 /opt/srv/jdk1.6/jre/lib/amd64/server/libjvm.so<br/> 2b95ecad6000-2b95ecc8c000 rwxp 00920000 fc:00 3205698 /opt/srv/jdk1.6/jre/lib/amd64/server/libjvm.so<br/> 2b95ecc8c000-2b95eccc6000 rwxp 2b95ecc8c000 00:00 0 <br/> 7fff4afed000-7fff4b002000 rwxp 7ffffffe9000 00:00 0 <span class="error">&#91;stack&#93;</span><br/> 7fff4b100000-7fff4b104000 r-xp 7fff4b100000 00:00 0 <span class="error">&#91;vdso&#93;</span><br/> ffffffffff600000-ffffffffffe00000 ---p 00000000 00:00 0 <span class="error">&#91;vsyscall&#93;</span></p> <p>VM Arguments:<br/> jvm_args: -Xmx5024m -Djava.rmi.server.hostname=192.168.251.58 -Dpath=/opt/app/egame/mobile/egame.search <br/> java_command: ../lib/egame.search.core.jar<br/> Launcher Type: SUN_STANDARD</p> <p>Environment Variables:<br/> JAVA_HOME=/opt/srv/jdk1.6<br/> CLASSPATH=.:/opt/srv/jdk1.6/lib/dt.jar:/opt/srv/jdk1.6/lib/tools.jar<br/> PATH=/opt/srv/jdk1.6/bin:/usr/kerberos/sbin:/usr/kerberos/bin:/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/root/bin<br/> LD_LIBRARY_PATH=/opt/srv/jdk1.6/jre/lib/amd64/server:/opt/srv/jdk1.6/jre/lib/amd64:/opt/srv/jdk1.6/jre/../lib/amd64<br/> SHELL=/bin/bash</p> <p>Signal Handlers:<br/> SIGSEGV: <span class="error">&#91;libjvm.so+0x862a30&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGBUS: <span class="error">&#91;libjvm.so+0x862a30&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGFPE: <span class="error">&#91;libjvm.so+0x7106f0&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGPIPE: <span class="error">&#91;libjvm.so+0x7106f0&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGXFSZ: <span class="error">&#91;libjvm.so+0x7106f0&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGILL: <span class="error">&#91;libjvm.so+0x7106f0&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGUSR1: SIG_DFL, sa_mask<span class="error">&#91;0&#93;</span>=0x00000000, sa_flags=0x00000000<br/> SIGUSR2: <span class="error">&#91;libjvm.so+0x713520&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x00000000, sa_flags=0x10000004<br/> SIGHUP: SIG_IGN, sa_mask<span class="error">&#91;0&#93;</span>=0x00000000, sa_flags=0x00000000<br/> SIGINT: SIG_IGN, sa_mask<span class="error">&#91;0&#93;</span>=0x00000000, sa_flags=0x00000000<br/> SIGTERM: <span class="error">&#91;libjvm.so+0x713120&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004<br/> SIGQUIT: <span class="error">&#91;libjvm.so+0x713120&#93;</span>, sa_mask<span class="error">&#91;0&#93;</span>=0x7ffbfeff, sa_flags=0x10000004</p> <p>--------------- S Y S T E M ---------------</p> <p>OS:Red Hat Enterprise Linux Server release 5.6 (Tikanga)</p> <p>uname:Linux 2.6.18-238.el5 #1 SMP Sun Dec 19 14:22:44 EST 2010 x86_64<br/> libc:glibc 2.5 NPTL 2.5 <br/> rlimit: STACK 10240k, CORE 0k, NPROC 53248, NOFILE 102400, AS infinity<br/> load average:2.21 2.51 2.99</p> <p>/proc/meminfo:<br/> MemTotal: 6113332 kB<br/> MemFree: 3795176 kB<br/> Buffers: 198936 kB<br/> Cached: 501388 kB<br/> SwapCached: 0 kB<br/> Active: 1594852 kB<br/> Inactive: 489768 kB<br/> HighTotal: 0 kB<br/> HighFree: 0 kB<br/> LowTotal: 6113332 kB<br/> LowFree: 3795176 kB<br/> SwapTotal: 8191992 kB<br/> SwapFree: 8191896 kB<br/> Dirty: 372 kB<br/> Writeback: 0 kB<br/> AnonPages: 1384336 kB<br/> Mapped: 35552 kB<br/> Slab: 195044 kB<br/> PageTables: 9360 kB<br/> NFS_Unstable: 0 kB<br/> Bounce: 0 kB<br/> CommitLimit: 11248656 kB<br/> Committed_AS: 1843416 kB<br/> VmallocTotal: 34359738367 kB<br/> VmallocUsed: 4856 kB<br/> VmallocChunk: 34359731859 kB<br/> HugePages_Total: 0<br/> HugePages_Free: 0<br/> HugePages_Rsvd: 0<br/> Hugepagesize: 2048 kB</p> <p>CPU:total 2 (1 cores per cpu, 1 threads per core) family 6 model 13 stepping 3, cmov, cx8, fxsr, mmx, sse, sse2, sse3</p> <p>/proc/cpuinfo:<br/> processor	: 0<br/> vendor_id	: GenuineIntel<br/> cpu family	: 6<br/> model	: 13<br/> model name	: QEMU Virtual CPU version (cpu64-rhel6)<br/> stepping	: 3<br/> cpu MHz	: 1795.671<br/> cache size	: 4096 KB<br/> fpu	: yes<br/> fpu_exception	: yes<br/> cpuid level	: 4<br/> wp	: yes<br/> flags	: fpu de pse tsc msr pae mce cx8 apic mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx lm pni cx16 lahf_lm<br/> bogomips	: 3591.34<br/> clflush size	: 64<br/> cache_alignment	: 64<br/> address sizes	: 46 bits physical, 48 bits virtual<br/> power management:</p> <p>processor	: 1<br/> vendor_id	: GenuineIntel<br/> cpu family	: 6<br/> model	: 13<br/> model name	: QEMU Virtual CPU version (cpu64-rhel6)<br/> stepping	: 3<br/> cpu MHz	: 1795.671<br/> cache size	: 4096 KB<br/> fpu	: yes<br/> fpu_exception	: yes<br/> cpuid level	: 4<br/> wp	: yes<br/> flags	: fpu de pse tsc msr pae mce cx8 apic mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx lm pni cx16 lahf_lm<br/> bogomips	: 3591.10<br/> clflush size	: 64<br/> cache_alignment	: 64<br/> address sizes	: 46 bits physical, 48 bits virtual<br/> power management:</p> <p>Memory: 4k page, physical 6113332k(3795176k free), swap 8191992k(8191896k free)</p> <p>vm_info: Java HotSpot(TM) 64-Bit Server VM (20.14-b01) for linux-amd64 JRE (1.6.0_43-b01), built on Mar 1 2013 03:16:05 by "java_re" with gcc 3.2.2 (SuSE Linux)</p> <p>time: Thu Jul 10 19:26:18 2014<br/> elapsed time: 1694 seconds</p>
</description>
<environment>
<p>JVM Info:<br/> java version "1.6.0_43"<br/> Java(TM) SE Runtime Environment (build 1.6.0_43-b01)<br/> Java HotSpot(TM) 64-Bit Server VM (build 20.14-b01, mixed mode)</p>
</environment>
<key id="12726732">LUCENE-5814</key>
<summary>JVM crash When Run Lucene</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="AllenYang">杨维云</reporter>
<labels></labels>
<created>Fri, 11 Jul 2014 02:27:05 +0000</created>
<updated>Fri, 11 Jul 2014 02:27:05 +0000</updated>
<version>3.6</version>
<due/>
<votes>4</votes>
<watches>5</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>404839</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1xo8v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>404877</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5195] 2013-08-30 02:00:01,062 [pool-24-thread-1] ERROR [org.apache.solr.handler.ReplicationHandler] - SnapPull failed
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5195</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>2013-08-30 02:00:01,062 <span class="error">&#91;pool-24-thread-1&#93;</span> ERROR <span class="error">&#91;org.apache.solr.handler.ReplicationHandler&#93;</span> - SnapPull failed <br/> org.apache.solr.common.SolrException: Failed to create temporary config folder: conf.20130830020001<br/> at org.apache.solr.handler.SnapPuller.downloadConfFiles(SnapPuller.java:513)<br/> at org.apache.solr.handler.SnapPuller.fetchLatestIndex(SnapPuller.java:299)<br/> at org.apache.solr.handler.ReplicationHandler.doFetch(ReplicationHandler.java:271)<br/> at org.apache.solr.handler.SnapPuller$1.run(SnapPuller.java:159)<br/> at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)<br/> at java.util.concurrent.FutureTask$Sync.innerRunAndReset(FutureTask.java:317)<br/> at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:150)<br/> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:98)<br/> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.runPeriodic(ScheduledThreadPoolExecutor.java:181)<br/> at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:205)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/> at java.lang.Thread.run(Thread.java:619)</p>
</description>
<environment/>
<key id="12666315">LUCENE-5195</key>
<summary>
2013-08-30 02:00:01,062 [pool-24-thread-1] ERROR [org.apache.solr.handler.ReplicationHandler] - SnapPull failed
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="2" iconUrl="https://issues.apache.org/jira/images/icons/priorities/critical.png">Critical</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="youyi377">richie</reporter>
<labels>
<label>SnapPull</label>
<label>failed</label>
<label>masterSlave</label>
<label>sorl</label>
</labels>
<created>Fri, 30 Aug 2013 12:45:32 +0000</created>
<updated>Fri, 30 Aug 2013 12:55:26 +0000</updated>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13754655" author="youyi377" created="Fri, 30 Aug 2013 12:46:35 +0000">
<p>2013-08-29 22:38:41,128 <span class="error">&#91;&quot;http-bio-/172.28.4.153-30518&quot;-exec-31&#93;</span> ERROR <span class="error">&#91;org.apache.solr.servlet.SolrDispatchFilter&#93;</span> - java.lang.OutOfMemoryError: OutOfMemoryError likely caused by the Sun VM Bug described in <a href="https://issues.apache.org/jira/browse/LUCENE-1566" class="external-link" rel="nofollow">https://issues.apache.org/jira/browse/LUCENE-1566</a>; try calling FSDirectory.setReadChunkSize with a value smaller than the current chunk size (104857600)<br/> at org.apache.lucene.store.NIOFSDirectory$NIOFSIndexInput.readInternal(NIOFSDirectory.java:173)<br/> at org.apache.lucene.store.BufferedIndexInput.refill(BufferedIndexInput.java:270)<br/> at org.apache.lucene.store.BufferedIndexInput.readByte(BufferedIndexInput.java:40)<br/> at org.apache.lucene.store.DataInput.readVInt(DataInput.java:107)<br/> at org.apache.lucene.store.BufferedIndexInput.readVInt(BufferedIndexInput.java:217)<br/> at org.apache.lucene.index.SegmentTermDocs.read(SegmentTermDocs.java:153)<br/> at org.apache.lucene.search.TermScorer.nextDoc(TermScorer.java:112)<br/> at org.apache.lucene.util.ScorerDocQueue.topNextAndAdjustElsePop(ScorerDocQueue.java:120)<br/> at org.apache.lucene.search.DisjunctionSumScorer.advanceAfterCurrent(DisjunctionSumScorer.java:171)<br/> at org.apache.lucene.search.DisjunctionSumScorer.advance(DisjunctionSumScorer.java:229)<br/> at org.apache.lucene.search.BooleanScorer2.advance(BooleanScorer2.java:320)<br/> at org.apache.lucene.search.DisjunctionMaxScorer.advance(DisjunctionMaxScorer.java:120)<br/> at org.apache.lucene.search.ConjunctionScorer.doNext(ConjunctionScorer.java:99)<br/> at org.apache.lucene.search.ConjunctionScorer.nextDoc(ConjunctionScorer.java:128)<br/> at org.apache.lucene.search.BooleanScorer2.nextDoc(BooleanScorer2.java:303)<br/> at org.apache.lucene.search.BooleanScorer2$SingleMatchScorer.nextDoc(BooleanScorer2.java:137)<br/> at org.apache.lucene.search.ReqOptSumScorer.nextDoc(ReqOptSumScorer.java:48)<br/> at org.apache.lucene.search.BooleanScorer2.score(BooleanScorer2.java:280)<br/> at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:581)<br/> at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:364)<br/> at org.apache.solr.search.SolrIndexSearcher.getDocListNC(SolrIndexSearcher.java:1296)<br/> at org.apache.solr.search.SolrIndexSearcher.getDocListC(SolrIndexSearcher.java:1176)<br/> at org.apache.solr.search.SolrIndexSearcher.search(SolrIndexSearcher.java:375)<br/> at org.apache.solr.handler.component.QueryComponent.process(QueryComponent.java:427)<br/> at org.apache.solr.handler.component.SearchHandler.handleRequestBody(SearchHandler.java:186)<br/> at org.apache.solr.handler.RequestHandlerBase.handleRequest(RequestHandlerBase.java:129)<br/> at org.apache.solr.core.SolrCore.execute(SolrCore.java:1391)<br/> at org.apache.solr.servlet.SolrDispatchFilter.execute(SolrDispatchFilter.java:365)<br/> at org.apache.solr.servlet.SolrDispatchFilter.doFilter(SolrDispatchFilter.java:260)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)<br/> at com.paic.wcm.search.web.filter.DmzSearchFilter.doFilter(DmzSearchFilter.java:97)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)<br/> at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:240)<br/> at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:164)<br/> at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:462)<br/> at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:164)<br/> at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:100)<br/> at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:563)<br/> at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)<br/> at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:403)<br/> at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:301)<br/> at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:162)<br/> at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:140)<br/> at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:309)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)<br/> at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)<br/> at java.lang.Thread.run(Thread.java:619)</p>
</comment>
<comment id="13754656" author="youyi377" created="Fri, 30 Aug 2013 12:46:58 +0000"><p>二个问题，请高手指点</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>346254</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1npiv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>346555</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3036] TestFSTs.testRealTerms is a terrible unit test
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3036</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This test:</p> <ul> <li>uses FSDirectory.open (platform-specific behavior)</li> <li>is a random test, but runs to a certain amount of seconds, then quits (makes it hard to reproduce with seed, as its behavior is dependent on your computers speed etc)</li> </ul> <p>After waiting 3 hours to download the 1 gigabyte file to reproduce the corrupt index it made in (<a href="https://hudson.apache.org/hudson/job/Lucene-trunk/1533/testReport/junit/org.apache.lucene.util.automaton.fst/TestFSTs/testRealTerms/" class="external-link" rel="nofollow">https://hudson.apache.org/hudson/job/Lucene-trunk/1533/testReport/junit/org.apache.lucene.util.automaton.fst/TestFSTs/testRealTerms/</a>), I found some of this frustrating.</p> <p>I managed to finally reproduce it but its no fun fiddling with a test that runs for 5 minutes to reproduce a fail.</p>
</description>
<environment/>
<key id="12504596">LUCENE-3036</key>
<summary>TestFSTs.testRealTerms is a terrible unit test</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Mon, 18 Apr 2011 20:46:06 +0000</created>
<updated>Sat, 23 Apr 2011 22:21:56 +0000</updated>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13021248" author="rcmuir" created="Mon, 18 Apr 2011 20:50:34 +0000">
<p>also, i don't like that the test data file hudson uses for nightly tests seems to only be available on hudson itself. this limits debugging fails to pmc members. we should put this file somewhere public.</p>
</comment>
<comment id="13021689" author="rcmuir" created="Tue, 19 Apr 2011 18:00:24 +0000">
<p>here's a patch that makes the test work in reproducible fashion</p>
</comment>
<comment id="13023610" author="mikemccand" created="Sat, 23 Apr 2011 22:21:56 +0000"><p>Patch looks good!</p></comment>
</comments>
<attachments>
<attachment id="12476753" name="LUCENE-3036.patch" size="1441" author="rcmuir" created="Tue, 19 Apr 2011 18:00:23 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 23 Apr 2011 22:21:56 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10865</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04mw7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24974</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3008] NumberFormatException: For input string: "gen.before_restore_2011-03-21_07.15.36.372112"
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3008</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Hello,</p> <p>One of our users reported the following stacktrace:</p> <p>Exception in thread "Thread-3" java.lang.NumberFormatException: For input string: "gen.before_restore_2011-03-21_07.15.36.372112"<br/> at java.lang.NumberFormatException.forInputString(NumberFormatException.java:48)<br/> at java.lang.Long.parseLong(Long.java:419)<br/> at org.apache.lucene.index.SegmentInfos.generationFromSegmentsFileName(SegmentInfos.java:199)<br/> at org.apache.lucene.index.SegmentInfos.getCurrentSegmentGeneration(SegmentInfos.java:134)<br/> at org.apache.lucene.index.SegmentInfos.getCurrentSegmentGeneration(SegmentInfos.java:151)<br/> at org.apache.lucene.index.IndexReader.indexExists(IndexReader.java:626)<br/> at org.apache.lucene.index.IndexWriter.init(IndexWriter.java:1015)<br/> at org.apache.lucene.index.IndexWriter.&lt;init&gt;(IndexWriter.java:887)<br/> at net.sourceforge.docfetcher.model.RootScope.updateIndex(RootScope.java:138)<br/> at net.sourceforge.docfetcher.model.ScopeRegistry$2.run(ScopeRegistry.java:392)</p> <p>I'm afraid I can't provide any more information than this, other than the Lucene version: 3.0.0</p> <p>Best regards<br/> Tran Nam Quang</p>
</description>
<environment/>
<key id="12502919">LUCENE-3008</key>
<summary>
NumberFormatException: For input string: "gen.before_restore_2011-03-21_07.15.36.372112"
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="qforce">Tran Nam Quang</reporter>
<labels></labels>
<created>Wed, 30 Mar 2011 19:31:27 +0000</created>
<updated>Wed, 20 Apr 2011 20:15:24 +0000</updated>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13022348" author="hossman" created="Wed, 20 Apr 2011 20:15:24 +0000">
<p>it appears that maybe someone attempted to "backup" the segments file in an index directory by copying it to a new filename with an extension (".before_restore_2011-03-21_07.15.36.372112") and this confused the SegmentInfos code into thinking that extension was the segment generation number.</p> <p>in general, this is a no-no on the users part &#8211; you shouldn't muck with the file names in an index directory (but you can copy the entire directory to your hearts content)</p> <p>that said, we should probably consider hardening SegmentInfos.getCurrentSegmentGeneration to be more strict about which "segment*" files it's willing to consider candidates for the current generation.</p> <p>at worst: we should wrap the NumberFormatException in something more useful.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 20 Apr 2011 20:15:24 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10884</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04n2f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25002</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2905] Sep codec writes insane amounts of skip data
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2905</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Currently, even if we use better compression algorithms via Fixed or Variable Intblock<br/> encodings, we have problems with both performance and index size versus StandardCodec.</p> <p>Consider the following numbers:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>standard: frq: 1,862,174,204 bytes prx: 1,146,898,936 bytes tib: 541,128,354 bytes complete index: 4,321,032,720 bytes bulkvint: doc: 1,297,215,588 bytes frq: 725,060,776 bytes pos: 1,163,335,609 bytes tib: 729,019,637 bytes complete index: 5,180,088,695 bytes simple64: doc: 1,260,869,240 bytes frq: 234,491,576 bytes pos: 1,055,024,224 bytes skp: 473,293,042 bytes tib: 725,928,817 bytes complete index: 4,520,488,986 bytes </pre> </div></div> <p>I think there are several reasons for this:</p> <ul> <li>Splitting into separate files (e.g. postings into .doc + .freq).</li> <li>Having to store both a relative delta to the block start, and an offset into the block.</li> <li>In a lot of cases various numbers involved are larger than they should be: e.g. they are file pointer deltas, but blocksize is fixed...</li> </ul> <p>Here are some ideas (some are probably stupid) of things we could do to try to fix this:</p> <p>Is Sep really necessary? Instead should we make an alternative to Sep, Interleaved? that interleaves doc and freq blocks (doc,freq,doc,freq) into one file? the concrete impl could implement skipBlock() for when they only want docdeltas: e.g. for Simple64 blocks on disk are fixed size so it could just skip N bytes. Fixed Int Block codecs like PFOR and BulkVint just read their single numBytes header they already have today, and skip numBytes.</p> <p>Isn't our skipInterval too low? Most of our codecs are using block sizes such as 64 or 128, so a skipInterval of 16 seems a little overkill.</p> <p>Shouldn't skipInterval not even be a final constant in SegmentWriteState, but instead completely private to the codec?</p> <p>For block codecs, doesn't it make sense for them to only support skipping to the start of a block? Then, their skip pointers dont need to be a combination of delta + upto, because upto is always zero. What would we have to modify in the bulkpostings api for jump() to work with this?</p> <p>For block codecs, shouldn't skipInterval then be some sort of divisor, based on block size (maybe by default its 1, meaning we can skip to the start of a every block)</p> <p>For codecs like Simple64 that encode fixed length frames, shouldnt we use 'blockid' instead of file pointer so that we get smaller numbers? e.g. simple64 can do blockid * 8 to get to the file pointer.</p> <p>Going along with the blockid concept, couldnt pointers in the terms dict be blockid deltas from the index term, instead of fp deltas? This would be smaller numbers and we could compress this metadata better.</p>
</description>
<environment/>
<key id="12497700">LUCENE-2905</key>
<summary>Sep codec writes insane amounts of skip data</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Fri, 4 Feb 2011 17:10:46 +0000</created>
<updated>Tue, 1 Oct 2013 18:41:03 +0000</updated>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="12990638" author="rcmuir" created="Fri, 4 Feb 2011 17:29:23 +0000">
<p>As a quick experiment, i compared simple64-varint with the default skipInterval (16) against one with a higher interval (32).</p> <p>Total index size decreased from 4,520,488,986 bytes to 4,269,022,166 bytes.</p> <p>MMapDirectory:</p> <table class='confluenceTable'><tbody> <tr> <th class='confluenceTh'>Query</th> <th class='confluenceTh'>QPS base</th> <th class='confluenceTh'>QPS patch</th> <th class='confluenceTh'>Pct diff</th> </tr> <tr> <td class='confluenceTd'>unit~0.7</td> <td class='confluenceTd'>29.83</td> <td class='confluenceTd'>28.84</td> <td class='confluenceTd'><font color="red">-3.3%</font></td> </tr> <tr> <td class='confluenceTd'>states</td> <td class='confluenceTd'>36.26</td> <td class='confluenceTd'>35.49</td> <td class='confluenceTd'><font color="red">-2.1%</font></td> </tr> <tr> <td class='confluenceTd'>+united +states</td> <td class='confluenceTd'>12.02</td> <td class='confluenceTd'>11.80</td> <td class='confluenceTd'><font color="red">-1.9%</font></td> </tr> <tr> <td class='confluenceTd'>un*d</td> <td class='confluenceTd'>17.37</td> <td class='confluenceTd'>17.24</td> <td class='confluenceTd'><font color="red">-0.7%</font></td> </tr> <tr> <td class='confluenceTd'>uni*</td> <td class='confluenceTd'>16.46</td> <td class='confluenceTd'>16.36</td> <td class='confluenceTd'><font color="red">-0.6%</font></td> </tr> <tr> <td class='confluenceTd'>u*d</td> <td class='confluenceTd'>9.27</td> <td class='confluenceTd'>9.22</td> <td class='confluenceTd'><font color="red">-0.5%</font></td> </tr> <tr> <td class='confluenceTd'>unit*</td> <td class='confluenceTd'>28.43</td> <td class='confluenceTd'>28.49</td> <td class='confluenceTd'><font color="green">0.2%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"</td> <td class='confluenceTd'>8.19</td> <td class='confluenceTd'>8.25</td> <td class='confluenceTd'><font color="green">0.8%</font></td> </tr> <tr> <td class='confluenceTd'>doctitle:.<b><span class="error">&#91;Uu&#93;</span>nited.</b></td> <td class='confluenceTd'>4.00</td> <td class='confluenceTd'>4.04</td> <td class='confluenceTd'><font color="green">1.0%</font></td> </tr> <tr> <td class='confluenceTd'>doctimesecnum:<span class="error">&#91;10000 TO 60000&#93;</span></td> <td class='confluenceTd'>10.10</td> <td class='confluenceTd'>10.25</td> <td class='confluenceTd'><font color="green">1.5%</font></td> </tr> <tr> <td class='confluenceTd'>unit~0.5</td> <td class='confluenceTd'>17.52</td> <td class='confluenceTd'>17.82</td> <td class='confluenceTd'><font color="green">1.7%</font></td> </tr> <tr> <td class='confluenceTd'>spanNear(<span class="error">&#91;unit, state&#93;</span>, 10, true)</td> <td class='confluenceTd'>31.77</td> <td class='confluenceTd'>32.33</td> <td class='confluenceTd'><font color="green">1.7%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.6</td> <td class='confluenceTd'>7.96</td> <td class='confluenceTd'>8.20</td> <td class='confluenceTd'><font color="green">3.0%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.75</td> <td class='confluenceTd'>10.94</td> <td class='confluenceTd'>11.49</td> <td class='confluenceTd'><font color="green">5.0%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"~3</td> <td class='confluenceTd'>4.14</td> <td class='confluenceTd'>4.40</td> <td class='confluenceTd'><font color="green">6.2%</font></td> </tr> <tr> <td class='confluenceTd'>united states</td> <td class='confluenceTd'>11.21</td> <td class='confluenceTd'>12.07</td> <td class='confluenceTd'><font color="green">7.7%</font></td> </tr> <tr> <td class='confluenceTd'>spanFirst(unit, 5)</td> <td class='confluenceTd'>107.66</td> <td class='confluenceTd'>116.32</td> <td class='confluenceTd'><font color="green">8.0%</font></td> </tr> <tr> <td class='confluenceTd'>+nebraska +states</td> <td class='confluenceTd'>111.04</td> <td class='confluenceTd'>120.41</td> <td class='confluenceTd'><font color="green">8.4%</font></td> </tr> </tbody></table>
</comment>
<comment id="12990642" author="rcmuir" created="Fri, 4 Feb 2011 17:37:38 +0000">
<p>Here's SimpleFSDirectory:</p> <table class='confluenceTable'><tbody> <tr> <th class='confluenceTh'>Query</th> <th class='confluenceTh'>QPS base</th> <th class='confluenceTh'>QPS patch</th> <th class='confluenceTh'>Pct diff</th> </tr> <tr> <td class='confluenceTd'>doctimesecnum:<span class="error">&#91;10000 TO 60000&#93;</span></td> <td class='confluenceTd'>8.93</td> <td class='confluenceTd'>8.80</td> <td class='confluenceTd'><font color="red">-1.4%</font></td> </tr> <tr> <td class='confluenceTd'>states</td> <td class='confluenceTd'>31.27</td> <td class='confluenceTd'>31.19</td> <td class='confluenceTd'><font color="red">-0.3%</font></td> </tr> <tr> <td class='confluenceTd'>spanNear(<span class="error">&#91;unit, state&#93;</span>, 10, true)</td> <td class='confluenceTd'>23.34</td> <td class='confluenceTd'>23.34</td> <td class='confluenceTd'><font color="red">-0.0%</font></td> </tr> <tr> <td class='confluenceTd'>unit*</td> <td class='confluenceTd'>25.77</td> <td class='confluenceTd'>25.84</td> <td class='confluenceTd'><font color="green">0.3%</font></td> </tr> <tr> <td class='confluenceTd'>unit~0.7</td> <td class='confluenceTd'>14.18</td> <td class='confluenceTd'>14.31</td> <td class='confluenceTd'><font color="green">0.9%</font></td> </tr> <tr> <td class='confluenceTd'>uni*</td> <td class='confluenceTd'>14.21</td> <td class='confluenceTd'>14.38</td> <td class='confluenceTd'><font color="green">1.3%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"</td> <td class='confluenceTd'>6.53</td> <td class='confluenceTd'>6.64</td> <td class='confluenceTd'><font color="green">1.6%</font></td> </tr> <tr> <td class='confluenceTd'>unit~0.5</td> <td class='confluenceTd'>8.19</td> <td class='confluenceTd'>8.37</td> <td class='confluenceTd'><font color="green">2.2%</font></td> </tr> <tr> <td class='confluenceTd'>un*d</td> <td class='confluenceTd'>13.12</td> <td class='confluenceTd'>13.44</td> <td class='confluenceTd'><font color="green">2.4%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.6</td> <td class='confluenceTd'>4.34</td> <td class='confluenceTd'>4.46</td> <td class='confluenceTd'><font color="green">2.8%</font></td> </tr> <tr> <td class='confluenceTd'>u*d</td> <td class='confluenceTd'>5.88</td> <td class='confluenceTd'>6.05</td> <td class='confluenceTd'><font color="green">2.9%</font></td> </tr> <tr> <td class='confluenceTd'>+united +states</td> <td class='confluenceTd'>10.17</td> <td class='confluenceTd'>10.47</td> <td class='confluenceTd'><font color="green">2.9%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"~3</td> <td class='confluenceTd'>3.77</td> <td class='confluenceTd'>3.89</td> <td class='confluenceTd'><font color="green">3.1%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.75</td> <td class='confluenceTd'>6.95</td> <td class='confluenceTd'>7.23</td> <td class='confluenceTd'><font color="green">4.0%</font></td> </tr> <tr> <td class='confluenceTd'>doctitle:.<b><span class="error">&#91;Uu&#93;</span>nited.</b></td> <td class='confluenceTd'>2.33</td> <td class='confluenceTd'>2.47</td> <td class='confluenceTd'><font color="green">6.0%</font></td> </tr> <tr> <td class='confluenceTd'>spanFirst(unit, 5)</td> <td class='confluenceTd'>91.85</td> <td class='confluenceTd'>98.12</td> <td class='confluenceTd'><font color="green">6.8%</font></td> </tr> <tr> <td class='confluenceTd'>united states</td> <td class='confluenceTd'>9.91</td> <td class='confluenceTd'>10.61</td> <td class='confluenceTd'><font color="green">7.0%</font></td> </tr> <tr> <td class='confluenceTd'>+nebraska +states</td> <td class='confluenceTd'>63.09</td> <td class='confluenceTd'>72.34</td> <td class='confluenceTd'><font color="green">14.7%</font></td> </tr> </tbody></table>
</comment>
<comment id="12990649" author="renaud.delbru" created="Fri, 4 Feb 2011 17:52:42 +0000">
<p>Hi Robert,</p> <p>it is good to see we are going in the same direction ;o). Here is a short paper about an extension of skip list for block based inverted file <span class="error">&#91;1&#93;</span> which was accepted at the European Conference of Information Retrieval. I shared this paper in a previous discussion with Michael. Maybe you will find some ideas inside that are worth keeping in mind.</p> <p>Also, the main problem of the current skip list implementation when it is applied on Sep codec is in my opinion the fact that we have to store for each skip list entry the fp of each of the sep file. And more you have files (in the SIREn case, we had 5 files), more the skip list data structure get bigger.<br/> However, if you think of it, the main goal of the skip list is to skip doc id, not freq or pos. We are storing the fps of the freq and pos files only because we need to synchronise the position of the "inverted file pointer" on each file. <br/> Also, this occurs some overhead when you only need to answer</p> <ul class="alternate" type="square"> <li>pure boolean query: we only need to scan the doc file, but we are still reading and decoding the fp pointers of the freq and pos file;</li> <li>extended boolean query: we only need to scan the doc and freq file, but we are still reading and decoding the fp pointers of the pos file;</li> </ul> <p>An idea I had a few months ago (but never found the time to implement it and test it) was to change the way the skip list data structure is created. The idea was to store the pointer to the doc file in the skip entry, and nothing else. The other pointers (to the freq file and position file) are in fact stored into the block header.<br/> When using the skip list, you will traverse the skip list until you find the skip point of interest, then decode the associated skip entry and get the doc file pointer. The doc file pointer indicates the beginning of the block that contains the identifiers that you are looking for.<br/> After reading the block from the disk and load it into memory, you can decode its header, which contains a pointer to the associated block into the frequency file. Similarly, into the block header of the frequency file, you have a pointer to the associated block into the pos file. In fact, you can picture this by a linked list of block. The skip list provides only the first pointer to the block doc file, then pointers to subsequent blocks are included into the block headers.<br/> On one hand, this considerably reduce the size of the skip list, since most of the information are "exported" and encoded into block headers. On the other hand, I am not sure if it reduces the size of the index, as it just move the data from the skip list to the inverted file. In addition, I think it makes impossible the delta-encoding of the fp for the freq and pos file. But they might be other optimisation possible with this data model.</p> <p><span class="error">&#91;1&#93;</span> <a href="http://dl.dropbox.com/u/1278798/ecir2011-skipblock.pdf" class="external-link" rel="nofollow">http://dl.dropbox.com/u/1278798/ecir2011-skipblock.pdf</a></p>
</comment>
<comment id="12990654" author="mikemccand" created="Fri, 4 Feb 2011 18:00:29 +0000">
<p>These are all great ideas!</p> <p>Interleaving frq/doc makes tons of sense, not only for better<br/> compression, but because for large (can't-be-hot) indexes the need to<br/> seek to 2 files during search is costly.</p> <p>If we are <em>REALLY</em> sure keeping int alignment in these intblock<br/> encoded files is not important (ie, we really do get best perf by<br/> slurping in byte[] and then decoding from there), then we should also<br/> store eg skip data into the frq/doc file (this is what Standard<br/> does).</p> <p>Maybe similarly interleave payload/positions packets?</p> <p>I think our skipInterval is too low for the block codecs (and, should<br/> be private) Separately, I think we should break out "when skip is even<br/> stored" vs "how frequently we index skip data". EG maybe we should<br/> only store skip data if dF &gt;= 1024 (say), and then separately index<br/> skip data every N docs.</p> <p>Skip only to start-of-block is tempting, but, tricky for the varint<br/> case since the blocks don't "line up" across frq/doc. For fixed<br/> block, it's silly to store separate seek points since they are always<br/> "aligned".</p> <p>BlockID for Simple64 (and more generally any varint codec whose blocks<br/> are fixed number of bytes) makes great sense.</p> <p>For low DF terms w/in a block I think we shouldn't store their<br/> pointers into the posting; instead, you should load an earlier term's<br/> postings and scan over its postings. This should save tons of space<br/> in the tib file.</p>
</comment>
<comment id="12990662" author="rcmuir" created="Fri, 4 Feb 2011 18:16:53 +0000">
<p>Renaud thanks for the paper... I will spend some time trying to digest it!<br/> But I think its always an option to try to reduce the number of files, too.<br/> This is important also for # of open files and other practical reasons.</p> <p>Mike a few questions:</p> <blockquote> <p>If we are REALLY sure keeping int alignment in these intblock<br/> encoded files is not important (ie, we really do get best perf by<br/> slurping in byte[] and then decoding from there), then we should also<br/> store eg skip data into the frq/doc file (this is what Standard<br/> does).</p></blockquote> <p>Well, I measured this a lot, but why box ourselves out? As a first step <br/> we can still keep the .skp file as-is, but it only needs point to <br/> the start of the doc block in the frq/doc file.</p> <blockquote> <p>Maybe similarly interleave payload/positions packets?</p></blockquote> <p>I think we should do something here. But when i started trying to draw<br/> this up, I came to the conclusion that payload byte[]s should themselves<br/> be actual terms (e.g. deduplicated), and we store some sort of ord to get<br/> to them instead of bytes and length, etc. if they were themselves terms,<br/> then they could also store forward postings back to their docs, and you <br/> could query on payloads (attributes) efficiently too... but I know this<br/> would be a fairly large change.</p> <blockquote> <p>Separately, I think we should break out "when skip is even<br/> stored" vs "how frequently we index skip data".</p></blockquote> <p>I agree, another reason to pull skipInterval completely codec-private.<br/> Then a codec could itself have a separate "skipMinimum" too.</p> <blockquote> <p>For low DF terms w/in a block I think we shouldn't store their<br/> pointers into the posting; instead, you should load an earlier term's<br/> postings and scan over its postings. This should save tons of space<br/> in the tib file.</p></blockquote> <p>How would this work? Isnt everything right now in the .tib delta-encoded<br/> against the index term? What if there are 'large' terms in between?<br/> And for some queries like rangequery, wouldnt this create a little O(n^2)<br/> of sorts? I don't think this is a big deal, most people should be using<br/> e.g. NumericRangeQuery, and maybe we could still prevent it...?</p>
</comment>
<comment id="12993205" author="rcmuir" created="Thu, 10 Feb 2011 20:22:49 +0000">
<p>here's a patch with what Mike suggested, moving the skipping stuff private to the codecs, and separating the interval from the minimum df necessary to index skip data.</p> <p>i also added the 'dont skip when close' opto to Sep and Preflex codecs (since i neglected to do this and only did Standard).</p> <p>I kept all parameters the same (I think we should benchmark etc before changing) but I did some experiments with a fairly large skipMinimum and it looked promising. I think we later (after we have good benchmarks) set this reasonable, and maybe bump skipInterval for Sep codec too, especially if we improve its 'pendingPositions' consuming to balance it out.</p> <p>So, I think we should apply this little patch as-is as a small step.</p>
</comment>
<comment id="12993345" author="rcmuir" created="Fri, 11 Feb 2011 05:05:42 +0000">
<p>here's a patch solving a lot of the issue for the skiplists and doc/freq/prox etc pointers for Simple64.</p> <p>as discussed above, because its size on disk is fixed, we encode blockID and blockID deltas instead of file pointers. </p> <p>with the saved bits, we steal one for the case where the delta is within-block, in this case this delta is really the upto delta.</p> <p>this puts my simple64 indexes smaller than standardcodec (and speeds up the queries too)</p>
</comment>
<comment id="12993463" author="rcmuir" created="Fri, 11 Feb 2011 12:03:11 +0000">
<p>I edited my comment above, because the new version of jira works differently somehow with newlines/pasting and it screwed up the quoting.</p> <p>To add insult to injury, when you edit there is no longer a way to comment on what you changed... </p>
</comment>
<comment id="12993478" author="mikemccand" created="Fri, 11 Feb 2011 13:02:49 +0000"><p>Both patches look great! Bit by bit...</p></comment>
<comment id="12993639" author="rcmuir" created="Fri, 11 Feb 2011 18:59:12 +0000">
<p>here's a patch for the regular FixedIntBlock and VariableIntBlock cases: they write upto first, if a bit is set then its within block and upto is the upto delta. otherwise they then read the vlong for the fp delta.</p> <p>this saves about 5% total bulkvint index size.</p>
</comment>
<comment id="12994175" author="rcmuir" created="Mon, 14 Feb 2011 00:12:18 +0000">
<p>attached is an initial stab at an interleaved block layout for fixed int block coders.</p> <p>its limited, and optimized for the case where doc,freq,pos have the same blocksize...</p> <p>the existing fixed int block api is not really changed, only extended. so you can implement this api and easily choose between Sep or Fixed index layout.</p> <p>the docs and freq blocks are interleaved (doc block, freq block) in such a way that its generally transparent to bulk enum consumers. So they work in lock-step, on the same actual underlying index input (sharing io buffer, etc).</p> <p>pointers in the term dictionary and skipdata are reduced, because they only point to the block/offset in the single .doc file, and the freq is implied and parallel following it.</p> <p>i added skipBlock() which for these fixed encoders, means they only read their header (typically a single vint) and skip their compressed payload. Because of this, i increased skip interval (to blocksize actually) in the patch. </p> <p>This might seem scary, but its not so bad, because without using any skip data, we can skip over the blocks themselves... e.g. skipping over 16,384 pending positions is only 128 vint reads.</p> <p>for now, i only cutover BulkVInt for testing, here's what i have so far:<br/> The total index size for the wikipedia benchmark index decreased from to 4,936,834,246 to 4,568,172,525 bytes (note this was already recently reduced from 5,180,088,695 bytes).</p> <p>Here is the perf results:</p> <table class='confluenceTable'><tbody> <tr> <th class='confluenceTh'>Query</th> <th class='confluenceTh'>QPS branch</th> <th class='confluenceTh'>QPS patch</th> <th class='confluenceTh'>Pct diff</th> </tr> <tr> <td class='confluenceTd'>unit~0.7</td> <td class='confluenceTd'>29.17</td> <td class='confluenceTd'>28.34</td> <td class='confluenceTd'><font color="red">-2.9%</font></td> </tr> <tr> <td class='confluenceTd'>unit*</td> <td class='confluenceTd'>30.28</td> <td class='confluenceTd'>29.65</td> <td class='confluenceTd'><font color="red">-2.1%</font></td> </tr> <tr> <td class='confluenceTd'>uni*</td> <td class='confluenceTd'>17.56</td> <td class='confluenceTd'>17.20</td> <td class='confluenceTd'><font color="red">-2.0%</font></td> </tr> <tr> <td class='confluenceTd'>unit~0.5</td> <td class='confluenceTd'>17.89</td> <td class='confluenceTd'>17.54</td> <td class='confluenceTd'><font color="red">-1.9%</font></td> </tr> <tr> <td class='confluenceTd'>doctitle:.<b><span class="error">&#91;Uu&#93;</span>nited.</b></td> <td class='confluenceTd'>4.02</td> <td class='confluenceTd'>3.97</td> <td class='confluenceTd'><font color="red">-1.3%</font></td> </tr> <tr> <td class='confluenceTd'>un*d</td> <td class='confluenceTd'>17.43</td> <td class='confluenceTd'>17.28</td> <td class='confluenceTd'><font color="red">-0.9%</font></td> </tr> <tr> <td class='confluenceTd'>u*d</td> <td class='confluenceTd'>8.97</td> <td class='confluenceTd'>8.92</td> <td class='confluenceTd'><font color="red">-0.5%</font></td> </tr> <tr> <td class='confluenceTd'>doctimesecnum:<span class="error">&#91;10000 TO 60000&#93;</span></td> <td class='confluenceTd'>10.88</td> <td class='confluenceTd'>10.92</td> <td class='confluenceTd'><font color="green">0.3%</font></td> </tr> <tr> <td class='confluenceTd'>+united +states</td> <td class='confluenceTd'>13.98</td> <td class='confluenceTd'>14.04</td> <td class='confluenceTd'><font color="green">0.5%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.6</td> <td class='confluenceTd'>8.19</td> <td class='confluenceTd'>8.24</td> <td class='confluenceTd'><font color="green">0.6%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"</td> <td class='confluenceTd'>9.00</td> <td class='confluenceTd'>9.13</td> <td class='confluenceTd'><font color="green">1.4%</font></td> </tr> <tr> <td class='confluenceTd'>states</td> <td class='confluenceTd'>37.75</td> <td class='confluenceTd'>38.72</td> <td class='confluenceTd'><font color="green">2.6%</font></td> </tr> <tr> <td class='confluenceTd'>united~0.75</td> <td class='confluenceTd'>11.45</td> <td class='confluenceTd'>11.75</td> <td class='confluenceTd'><font color="green">2.6%</font></td> </tr> <tr> <td class='confluenceTd'>+nebraska +states</td> <td class='confluenceTd'>88.60</td> <td class='confluenceTd'>92.81</td> <td class='confluenceTd'><font color="green">4.7%</font></td> </tr> <tr> <td class='confluenceTd'>united states</td> <td class='confluenceTd'>11.71</td> <td class='confluenceTd'>12.80</td> <td class='confluenceTd'><font color="green">9.3%</font></td> </tr> <tr> <td class='confluenceTd'>"united states"~3</td> <td class='confluenceTd'>4.88</td> <td class='confluenceTd'>5.41</td> <td class='confluenceTd'><font color="green">10.7%</font></td> </tr> <tr> <td class='confluenceTd'>spanFirst(unit, 5)</td> <td class='confluenceTd'>166.83</td> <td class='confluenceTd'>198.12</td> <td class='confluenceTd'><font color="green">18.8%</font></td> </tr> <tr> <td class='confluenceTd'>spanNear(<span class="error">&#91;unit, state&#93;</span>, 10, true)</td> <td class='confluenceTd'>36.10</td> <td class='confluenceTd'>47.48</td> <td class='confluenceTd'><font color="green">31.5%</font></td> </tr> </tbody></table> <p>the patch is really ugly, the whole thing is basically a nocommit, but in general the tests pass (i have at least one long-tail random fail to hunt down), but i think it has some promise.</p> <p>i mostly only added the capabilities to the old docsEnums and docsAndPositionsEnums, so we dont see all the benefits i think... ideally we can tweak the bulkpostings apis (especially positions) to take advantage of some of this stuff.</p>
</comment>
<comment id="12994304" author="rcmuir" created="Mon, 14 Feb 2011 14:10:34 +0000">
<p>seems hudson just hit the "long-tail random fail" i was talking about, in trunk.</p> <p>so i don't think its a problem with this codec: <a href="https://hudson.apache.org/hudson/job/Lucene-Solr-tests-only-trunk/4884/" class="external-link" rel="nofollow">https://hudson.apache.org/hudson/job/Lucene-Solr-tests-only-trunk/4884/</a></p>
</comment>
<comment id="12994370" author="rcmuir" created="Mon, 14 Feb 2011 17:16:56 +0000">
<p>OK I committed this for now to the branch (r1070580), we can always revert it.</p> <p>I cutover FOR, PFOR, and PFOR2 to use this, and all tests pass with all these codecs.</p>
</comment>
</comments>
<attachments>
<attachment id="12470885" name="LUCENE-2905_intblock.patch" size="5649" author="rcmuir" created="Fri, 11 Feb 2011 18:59:12 +0000"/>
<attachment id="12470971" name="LUCENE-2905_interleaved.patch" size="98317" author="rcmuir" created="Mon, 14 Feb 2011 00:12:18 +0000"/>
<attachment id="12470832" name="LUCENE-2905_simple64.patch" size="14433" author="rcmuir" created="Fri, 11 Feb 2011 05:05:42 +0000"/>
<attachment id="12470800" name="LUCENE-2905_skipIntervalMin.patch" size="12536" author="rcmuir" created="Thu, 10 Feb 2011 20:22:49 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>4.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 4 Feb 2011 17:52:42 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10963</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04npb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25105</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2823] contrib/demo's tests leave threads running
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2823</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>contrib/demo for some reason parses html in a strange way with PipedInputStream and a separate thread.<br/> I don't understand why it needs to do this or be this complicated (its an example), and its tests leave rogue threads running.</p>
</description>
<environment/>
<key id="12493611">LUCENE-2823</key>
<summary>contrib/demo's tests leave threads running</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Sat, 18 Dec 2010 21:33:02 +0000</created>
<updated>Sat, 18 Dec 2010 21:33:02 +0000</updated>
<component>modules/examples</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11037</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04o7j:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25187</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2827] JaroWinklerDistance returns 0f when s1.length()=s2.length()=0
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2827</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>StringDistance sd = new JaroWinklerDistance();<br/> System.out.println(sd.getDistance("",""));</p> <p>console prints 0.</p> <p>but when use LevensteinDistance or NGramDistance, that console prints 1.0</p>
</description>
<environment><p>JDK1.6.17</p></environment>
<key id="12493730">LUCENE-2827</key>
<summary>
JaroWinklerDistance returns 0f when s1.length()=s2.length()=0
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tom_lt">tom liu</reporter>
<labels></labels>
<created>Tue, 21 Dec 2010 08:32:19 +0000</created>
<updated>Tue, 21 Dec 2010 08:32:19 +0000</updated>
<version>4.0-ALPHA</version>
<component>modules/spellchecker</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11033</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04o6n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25183</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2806] ArrayIndexOutOfBoundsException thrown from TermScorer.score while doing a regular index search.
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2806</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>java.lang.ArrayIndexOutOfBoundsException: 51064<br/> org.apache.lucene.search.TermScorer.score(TermScorer.java:130)<br/> org.apache.lucene.search.TopScoreDocCollector$InOrderTopScoreDocCollector.collect(TopScoreDocCollector.java:47)<br/> org.apache.lucene.search.TermScorer.score(TermScorer.java:78)<br/> org.apache.lucene.search.TermScorer.score(TermScorer.java:70)<br/> org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:212)<br/> org.apache.lucene.search.Searcher.search(Searcher.java:67)</p>
</description>
<environment><p>Ubuntu linux</p></environment>
<key id="12492596">LUCENE-2806</key>
<summary>
ArrayIndexOutOfBoundsException thrown from TermScorer.score while doing a regular index search.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="soujanya">Soujanya</reporter>
<labels></labels>
<created>Tue, 7 Dec 2010 09:18:47 +0000</created>
<updated>Tue, 7 Dec 2010 09:59:16 +0000</updated>
<version>3.0.3</version>
<component>core/search</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12968643" author="shaie" created="Tue, 7 Dec 2010 09:31:26 +0000">
<p>Can you please post a patch with a short test case that reproduces the bug? If not, can you please describe the environment: index size, num docs, query used etc.</p> <p>From TermScorer's code, the AIOOBE can be thrown if the 'freq' is larger than the scoreCache array size, however there is an if validating that freq is smaller than the array size, so I don't get it ...</p>
</comment>
<comment id="12968647" author="soujanya" created="Tue, 7 Dec 2010 09:42:11 +0000">
<p>I used SimpleAnalyzer to build the index. There are totally 240,000+<br/> documents (multiple fielded documents).<br/> I use SimpleAnalyzer to generate the query. The query has two fields to<br/> search like this: field1:searchstring* AND field2:searchstring2. The first<br/> one has a regular expression '*' at the end of the query string. To match<br/> obtain matches when the query string is not entered completely. The query<br/> string is a single word appended with a '<b>', say like 'field1:glamour</b> AND<br/> type:document'.<br/> I run this query on the index and it throws this error.</p> <p>Could you please tell me what 'freq' is? Is the frequency of a word or is it<br/> an array?</p> <p>Thanks,<br/> Soujanya</p>
</comment>
<comment id="12968654" author="shaie" created="Tue, 7 Dec 2010 09:59:16 +0000">
<p>Ok &#8211; I looked at 3x source code, but I see you marked the issue as 3.0.3 and that TermScorer's lines are different between 3x and 3.0.3. The offending line looks like:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">return</span> norms == <span class="code-keyword">null</span> ? raw : raw * SIM_NORM_DECODER[norms[doc] &amp; 0xFF]; <span class="code-comment">// normalize <span class="code-keyword">for</span> field</span> </pre> </div></div> <p>And it can be thrown by either invalid access to the 'norms' array, or the SIM_NORM_DECODER array. Are you using a custom Similarity maybe? I think it's less likely that the invalid access is caused from the 'norms' array, as it is allocated in the size of the index (one norm per document).</p> <p>Are you able to rebuild the index? If so, I'd suggest to rebuild it and add all content as ANALYZED_NO_NORMS to disable norms. If the AIOOBE still happens, then we know it's from the SIM_NORM_DECODER, otherwise it's from the norms[] array.</p> <p>Also, does it happen in other queries too? Maybe to remove some noise, remove the <b>field:word</b>* part and only keep the type:document part? Trying to minimize the query down to few select terms to ease on the debugging.</p> <p>Can you perhaps post the index here?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 7 Dec 2010 09:31:26 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11051</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04obb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25204</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2801] getOffsetGap should not be called for non-anaylyzed fields
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2801</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>from: <a href="https://issues.apache.org/jira/browse/LUCENE-2235" title="implement PerFieldAnalyzerWrapper.getOffsetGap" class="issue-link" data-issue-key="LUCENE-2235"><del>LUCENE-2235</del></a></p> <p>Since Lucene 3.0.3, when a PerFieldAnalyzerWrapper is constructed with a null defaultAnalyzer it will NPE when DocInverterPerField calls:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> fieldState.offset += docState.analyzer.getOffsetGap(field); </pre> </div></div> <p>This block should first check that the field is analyzed, or the javadoc on PerFieldAnalyzerWrapper could mention that a null defaultAnalyzer is disallowed.</p> <p>Also, the main reason for checking for isAnalyzed, from Uwe Schindler in <a href="https://issues.apache.org/jira/browse/LUCENE-2235" title="implement PerFieldAnalyzerWrapper.getOffsetGap" class="issue-link" data-issue-key="LUCENE-2235"><del>LUCENE-2235</del></a></p> <blockquote> <p>One problem coming from not checking for "analyzed" is this:<br/> You add a field indexed and it gets analyzed by PFAW - After that you add the same field name stored-only (which is perfectly legal and often used, e.g. when the stored value is binary or in some other format and does not correspond to the indexed text), the positionIncrement is increased. After that you again add another instance of the same field as indexed-only, which also increases posIncr. So you have 2 times the gap between both indexed sub-fields. This is definitely wrong.</p> </blockquote>
</description>
<environment/>
<key id="12492142">LUCENE-2801</key>
<summary>
getOffsetGap should not be called for non-anaylyzed fields
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="npellow">Nick Pellow</reporter>
<labels></labels>
<created>Mon, 6 Dec 2010 10:33:15 +0000</created>
<updated>Mon, 6 Dec 2010 10:33:49 +0000</updated>
<version>3.0.3</version>
<component>modules/analysis</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12446515">LUCENE-2235</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3675</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ocf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25209</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2800] Search Index Generation fails</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2800</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Hi,</p> <p>We are using lucene 2.0.0 for search index In our Comergent application<br/> It was working fine since from more than 3 years. <br/> From this week, it is throwing Exception while creating New Index and also for Incremental Index.<br/> Below is the exception</p> <p>com.comergent.api.appservices.productService.ProductServiceException: java.io.IOException: Cannot delete ...\searchIndex\en_US\MasterIndex_602580\segments <br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.indexPCFromCache(CatalogIndexSetBuilder.java:634) <br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.buildIndexSet(CatalogIndexSetBuilder.java:276) <br/> at com.comergent.appservices.search.indexBuilder.IndexSetBuilder$BuilderThread.run(IndexSetBuilder.java:469) <br/> Caused by: java.io.IOException: Cannot delete ----searchIndex\en_US\MasterIndex_602580\segments <br/> at org.apache.lucene.store.FSDirectory.renameFile(FSDirectory.java:268) <br/> at org.apache.lucene.index.SegmentInfos.write(SegmentInfos.java:95) <br/> at org.apache.lucene.index.IndexWriter$4.doBody(IndexWriter.java:726) <br/> at org.apache.lucene.store.Lock$With.run(Lock.java:99) <br/> at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:724) <br/> at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:686) <br/> at org.apache.lucene.index.IndexWriter.maybeMergeSegments(IndexWriter.java:674) <br/> at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:479) <br/> at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:462) <br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.indexPCFromCache(CatalogIndexSetBuilder.java:630) <br/> ... 2 more <br/> 2010.12.05 06:25:13:532 Env/Thread-21961:ERROR:CatalogIndexSetBuilder CatalogIndexSetBuilder: <span class="error">&#91;MasterIndex_602580&#93;</span> - Exception: com.comergent.api.appservices.productService.ProductServiceException: java.io.IOException: Cannot delete ...\MasterIndex_602580\segments<br/> 2010.12.05 06:25:13:532 Env/Thread-21961:INFO:CMGT_SEARCH IndexSetBuilder$BuilderThread: error building the index for: MasterIndex_602580<br/> com.comergent.api.exception.ComergentException: com.comergent.api.appservices.productService.ProductServiceException: java.io.IOException: Cannot delete \searchIndex\en_US\MasterIndex_602580\segments<br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.buildIndexSet(CatalogIndexSetBuilder.java:305)<br/> at com.comergent.appservices.search.indexBuilder.IndexSetBuilder$BuilderThread.run(IndexSetBuilder.java:469)<br/> Caused by: com.comergent.api.appservices.productService.ProductServiceException: java.io.IOException: Cannot delete ...\MasterIndex_602580\segments<br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.indexPCFromCache(CatalogIndexSetBuilder.java:634)<br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.buildIndexSet(CatalogIndexSetBuilder.java:276)<br/> ... 1 more<br/> Caused by: java.io.IOException: Cannot delete ...\MasterIndex_602580\segments<br/> at org.apache.lucene.store.FSDirectory.renameFile(FSDirectory.java:268)<br/> at org.apache.lucene.index.SegmentInfos.write(SegmentInfos.java:95)<br/> at org.apache.lucene.index.IndexWriter$4.doBody(IndexWriter.java:726)<br/> at org.apache.lucene.store.Lock$With.run(Lock.java:99)<br/> at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:724)<br/> at org.apache.lucene.index.IndexWriter.mergeSegments(IndexWriter.java:686)<br/> at org.apache.lucene.index.IndexWriter.maybeMergeSegments(IndexWriter.java:674)<br/> at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:479)<br/> at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:462)<br/> at com.comergent.reference.appservices.productService.search.indexBuilder.CatalogIndexSetBuilder.indexPCFromCache(CatalogIndexSetBuilder.java:630)<br/> ... 2 more</p> <p>2010.12.05 06:25:13:938 Env/http-8080-Processor75:INFO:CMGT_SEARCH IndexSetBuilder: error building the index: com.comergent.api.appservices.search.exception.IndexingException: Error in executing some builder threads...<br/> at com.comergent.appservices.search.indexBuilder.IndexSetBuilder.monitor(IndexSetBuilder.java:440)<br/> at com.comergent.appservices.search.indexBuilder.IndexSetBuilder.build(IndexSetBuilder.java:185)<br/> at com.comergent.reference.appservices.search.indexBuilder.ComergentIndexSetManager.startIndexBuilder(ComergentIndexSetManager.java:269)<br/> at com.comergent.appservices.search.indexBuilder.IndexSetManager.startFullIndexBuilder(IndexSetManager.java:516)<br/> at com.comergent.reference.appservices.search.indexBuilder.IndexMaintenanceBLC.service(IndexMaintenanceBLC.java:145)<br/> at com.comergent.dcm.core.AppExecutionEnv.runAppObj(AppExecutionEnv.java:77)<br/> at com.comergent.dcm.messaging.MessagingController.handleRequest(MessagingController.java:199)<br/> at com.comergent.dcm.messaging.MessagingController.execute(MessagingController.java:103)<br/> at com.comergent.dcm.core.DispatchServlet.executeController(DispatchServlet.java:485)<br/> at com.comergent.dcm.core.DispatchServlet.doExecute(DispatchServlet.java:434)<br/> at com.comergent.dcm.messaging.MessagingServlet.execute(MessagingServlet.java:161)<br/> at com.comergent.dcm.core.DispatchServlet.dispatch(DispatchServlet.java:189)<br/> at com.comergent.dcm.core.DispatchServlet.doPost(DispatchServlet.java:157)<br/> at javax.servlet.http.HttpServlet.service(HttpServlet.java:709)<br/> at javax.servlet.http.HttpServlet.service(HttpServlet.java:802)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:252)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.CredentialPropagationFilter.executeFilter(CredentialPropagationFilter.java:57)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.AAFilter.executeFilter(AAFilter.java:54)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.WrappingFilter.executeFilter(WrappingFilter.java:113)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.StatsFilter.executeFilter(StatsFilter.java:38)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.SSLSessionKeyFilter.handleHttpRequest(SSLSessionKeyFilter.java:79)<br/> at com.comergent.dcm.core.filters.SSLSessionKeyFilter.doFilter(SSLSessionKeyFilter.java:186)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.IPSessionTrackingFilter.doFilter(IPSessionTrackingFilter.java:67)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.RequestControlFilter.executeFilter(RequestControlFilter.java:102)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.TimingFilter.executeFilter(TimingFilter.java:46)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:50)<br/> at com.comergent.dcm.core.filters.EntryFilter.executeFilter(EntryFilter.java:51)<br/> at com.comergent.dcm.core.filters.ComergentFilter.doFilter(ComergentFilter.java:58)<br/> at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:202)<br/> at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:173)<br/> at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:213)<br/> at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:178)<br/> at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:126)<br/> at org.jstripe.tomcat.probe.Tomcat55AgentValve.invoke(Tomcat55AgentValve.java:20)<br/> at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:105)<br/> at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:107)<br/> at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:148)<br/> at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:869)<br/> at org.apache.coyote.http11.Http11BaseProtocol$Http11ConnectionHandler.processConnection(Http11BaseProtocol.java:664)<br/> at org.apache.tomcat.util.net.PoolTcpEndpoint.processSocket(PoolTcpEndpoint.java:527)<br/> at org.apache.tomcat.util.net.LeaderFollowerWorkerThread.runIt(LeaderFollowerWorkerThread.java:80)<br/> at org.apache.tomcat.util.threads.ThreadPool$ControlRunnable.run(ThreadPool.java:684)<br/> at java.lang.Thread.run(Unknown Source)</p> <p>Could you please help us to solve this issue.</p>
</description>
<environment><p>Windows Server 2003 </p></environment>
<key id="12492132">LUCENE-2800</key>
<summary>Search Index Generation fails</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="suni_cb">Sunitha Belavagi</reporter>
<labels></labels>
<created>Mon, 6 Dec 2010 07:13:15 +0000</created>
<updated>Sat, 30 Nov 2013 14:04:06 +0000</updated>
<version>2.0.0</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="13835683" author="erickerickson" created="Sat, 30 Nov 2013 13:14:28 +0000"><p>2013 Old JIRA cleanup</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 30 Nov 2013 13:14:28 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11056</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ocn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25210</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3153] Adding field w/ norms should fail if same field was added w/o norms already
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3153</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>A spinoff from <a href="https://issues.apache.org/jira/browse/LUCENE-3146" title="IndexReader.setNorms is no op if one of the field instances omits norms" class="issue-link" data-issue-key="LUCENE-3146"><del>LUCENE-3146</del></a>. Consider the following two scenarios, according to how 4.0 currently works:</p> <ul> <li>Field "a" is added w/ norms. Sometime later field "a" is added to a document w/o norms &#8211; norms are disabled for field "a", for all docs.</li> <li>Field "a" is added w/o norms - norms are disabled for field "a". Sometime later field "a" is added to a document w/ norms &#8211; app thinks norms were added, while in fact they are dropped.</li> </ul> <p>This is a bug and case #2 should fail on add/updateDocument - app should know norms were not added. While case #1 isn't great either, it's the only way an app can choose to disable norms for field "a", after instances of it already contain norms, so we should support that scenario.</p> <p>In order to detect that early, we should track norms info in .fnx, as Mike describes at <a href="https://issues.apache.org/jira/browse/LUCENE-3146" title="IndexReader.setNorms is no op if one of the field instances omits norms" class="issue-link" data-issue-key="LUCENE-3146"><del>LUCENE-3146</del></a>. Since this changes the index format, we should also update the "file format" page after we do it.</p> <p>Not sure what's the deal w/ 3.x indexes that are read by 4.0 code. Initially they won't have .fnx file, so no central norms information exist to detect the cases I've described above. Over time, as segments are merged, .fnx will include information from more and more segments, but there's always a chance few segments will still contain the norms for field "a". I'm not very familiar w/ that part of the code, but I think that:</p> <ul> <li>If .fnx says "no norms for field a", the we ignore any norms information that may or may not exist in segments.</li> <li>If .fnx says "norms for field a", then we need to make up some norms values for (old) segments w/ no norms? We need to make up values during segment merge and search?</li> </ul>
</description>
<environment/>
<key id="12508744">LUCENE-3153</key>
<summary>
Adding field w/ norms should fail if same field was added w/o norms already
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="shaie">Shai Erera</reporter>
<labels></labels>
<created>Mon, 30 May 2011 19:21:28 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:23 +0000</updated>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13041403" author="doronc" created="Tue, 31 May 2011 04:05:16 +0000">
<p>Can this be checked before any commit (/flush)?</p> <p>Assume 10 docs were added without norms to a fresh index, now, without a commit or even a flush, a document is added with norms. Is the info required for checking the "configuration" for that field available at that time?</p> <p>If it is not, this is still just a best effort check.</p>
</comment>
<comment id="13041448" author="shaie" created="Tue, 31 May 2011 06:01:00 +0000">
<p>The difference between the two is that on add/UpdateDocument, we can fail fast. Upon commit, it's a failure that happens too late.</p> <p>So I'm not at all convinced now that we should fail on this. Really, apps shouldn't be fiddling w/ norms, at least the apps I know of always index a field the same way. I don't know how common it is for apps to flip the norms bit, and clearly they can only do it one way. So maybe what we should be doing is:</p> <ul> <li>Consolidate norms info in .fnx &#8211; that's a good idea irregardless of the issue.</li> <li>Have javadocs sort out any confusion &#8211; we don't fail add/updateDoc attempts, just follow javadocs semantics</li> <li>Provide API for apps to disable norms for a field, since that practically the only direction we want to allow a/ the aforementioned changed.</li> </ul> <p>Hmm ... another scenario hit me as I wrote the above lines:</p> <ul> <li>App adds a field w/o norms.</li> <li>App deletes the document w/ the field</li> <li>App adds a field w/ norms &#8211; now what? norms are marked disabled for that field, but the only document that caused that is deleted.</li> </ul> <p>commit() can be called in between and several documents can be added w/ and w/o norms &#8211; point is, this just gets complicated. This is another reason IMO to let apps manage norms and trust that they don't do fiddle w/ norms. The 'disableNorms' API may still be useful for an app that does not fiddle w/ norms, but decides it does not need norms for a field anymore.</p>
</comment>
<comment id="13041461" author="doronc" created="Tue, 31 May 2011 07:02:32 +0000">
<p>I was not clear enough.</p> <p>I meant that when deciding on consistency of requested NORMS state, if relying only on committed data, then the handling of add/update requests is in a best effort manner, while the handling at commit is complete.</p> <p>So, for this example:</p> <ul> <li>Index does not contain field F</li> <li>doc1 is added with F set to NO NORMS</li> <li>doc2 is added with F set to WITH NORMS</li> </ul> <p>I was not sure about the ability to tell that F in doc2 is inconsistent, because of relying on committed data, and, perhaps, especially with DWPT.</p> <p>At commit, it is def possible to check this.</p> <p>Similarly this scenario has same problem:</p> <ul> <li>Index contains (committed) field F WITH NORMS</li> <li>doc1 is added with F set to NO NORMS</li> <li>doc2 is added with F set to WITH NORMS</li> </ul> <p>Again, F in doc2, while consistent with F as committed in the index, is inconsistent with previously added F in doc1.</p> <p>In this situation, throwing the exception due to inconsistencies might have to be late in some scenarios (at commit) and hence unacceptable IMO. At the least, such a behavior should be specifically requested by application, e.g. by setting a STRICT_NORMS mode or something like that in iwcfg. </p> <p>I am not convinced going that far is justified.</p>
</comment>
<comment id="13041608" author="mikemccand" created="Tue, 31 May 2011 14:56:32 +0000">
<p>This is quickly getting scary hairy <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>Maybe we should not move "omits norms" bit into fnx and continue leaving the checking as "best effort"?</p>
</comment>
<comment id="13041611" author="simonw" created="Tue, 31 May 2011 15:02:29 +0000">
<blockquote><p>Maybe we should not move "omits norms" bit into fnx and continue leaving the checking as "best effort"?</p></blockquote> <p>the .fnx file is the way to go here. We can even move hasProx there too eventually.</p> <p>simon</p>
</comment>
<comment id="13412302" author="hossman" created="Wed, 11 Jul 2012 23:03:45 +0000">
<p>bulk cleanup of 4.0-ALPHA / 4.0 Jira versioning. all bulk edited issues have hoss20120711-bulk-40-change in a comment</p>
</comment>
<comment id="13429717" author="rcmuir" created="Tue, 7 Aug 2012 03:41:31 +0000"><p>rmuir20120906-bulk-40-change</p></comment>
<comment id="13716924" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:21 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970738" author="thetaphi" created="Wed, 16 Apr 2014 12:54:23 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 31 May 2011 04:05:16 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>2949</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04m73:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24861</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3088] inconsistency of tokenstream.end() with OffsetLimitTokenFilter and LimitTokenCountFilter
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3088</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>In <a href="https://issues.apache.org/jira/browse/LUCENE-3064" title="add checks to MockTokenizer to enforce proper consumption" class="issue-link" data-issue-key="LUCENE-3064"><del>LUCENE-3064</del></a>, we added some state and checks to MockTokenizer to validate that consumers<br/> are properly using the tokenstream workflow (described here: <a href="http://lucene.apache.org/java/3_0_3/api/core/org/apache/lucene/analysis/TokenStream.html" class="external-link" rel="nofollow">http://lucene.apache.org/java/3_0_3/api/core/org/apache/lucene/analysis/TokenStream.html</a>)</p> <p>One inconsistency is the following steps:<br/> 4. The consumer calls incrementToken() until it returns false consuming the attributes after each call.<br/> 5. The consumer calls end() so that any end-of-stream operations can be performed.</p> <p>In the case of these limitingfilters, end() is called on the Tokenizer <b>before</b> incrementToken() returns false. This is a little strange for a few reasons: one is that the tokenizer might not even be "ready" for end(), e.g. it might be coded where end() only works correctly if its entirely consumed. The other problem of course is that the finalOffset, the general use of end(), will most often be wrong in this case, so multi-valued field highlighting will not work.</p> <p>We should probably figure out a way to address the inconsistency, some ideas are:</p> <ol> <li>fixing the javadocs, perhaps documenting that end() could be called at any time, and accepting the fact that the finalOffset will be wrong.</li> <li>the limiting filters could consume the rest of the tokens in a while (incrementToken()) loop to ensure totally proper behavior.</li> <li>the limiting filters could do something tricky like override end() so that its not invoked on the Tokenizer in a surprising state. This is still evil but perhaps less evil than calling it "out of order".</li> <li>...</li> </ol>
</description>
<environment/>
<key id="12506982">LUCENE-3088</key>
<summary>
inconsistency of tokenstream.end() with OffsetLimitTokenFilter and LimitTokenCountFilter
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Thu, 12 May 2011 13:45:08 +0000</created>
<updated>Thu, 12 May 2011 13:45:08 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10836</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04mkv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24923</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3089] CachingTokenFilter can cause close() to be called twice.
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3089</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>In <a href="https://issues.apache.org/jira/browse/LUCENE-3064" title="add checks to MockTokenizer to enforce proper consumption" class="issue-link" data-issue-key="LUCENE-3064"><del>LUCENE-3064</del></a>, we added some state and checks to MockTokenizer to validate that consumers<br/> are properly using the tokenstream workflow (described here: <a href="http://lucene.apache.org/java/3_0_3/api/core/org/apache/lucene/analysis/TokenStream.html" class="external-link" rel="nofollow">http://lucene.apache.org/java/3_0_3/api/core/org/apache/lucene/analysis/TokenStream.html</a>)</p> <p>One problem I noticed in TestTermVectorsWriter.testEndOffsetPositionWithCachingTokenFilter is that providing a CachingTOkenFilter directly will result<br/> in close() being called twice on the underlying tokenstream... this seems wrong.</p> <p>Some ideas to fix this could be:</p> <ol> <li>CachingTokenFilter overrides close() and we document that you must close the underlying stream yourself. I think this is what the queryparser does anyway.</li> <li>CachingTokenFilter does something tricky to ensure it only closes the underlying stream once.</li> </ol>
</description>
<environment/>
<key id="12506987">LUCENE-3089</key>
<summary>
CachingTokenFilter can cause close() to be called twice.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Thu, 12 May 2011 13:49:11 +0000</created>
<updated>Mon, 14 Nov 2011 12:11:51 +0000</updated>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13149564" author="simonw" created="Mon, 14 Nov 2011 11:00:31 +0000">
<p>robert, since TokenStream impl. Closeable we should be able to call close as often as we want to. we should actually check that we do that in our tests to make sure nothing fails. </p>
</comment>
<comment id="13149566" author="thetaphi" created="Mon, 14 Nov 2011 11:03:41 +0000">
<p>Yes, the java.io.Closeable interface requires the underlying implementation to ignore additional close calls. But we should still fix our code to actually call it only once.</p>
</comment>
<comment id="13149568" author="rcmuir" created="Mon, 14 Nov 2011 11:04:32 +0000">
<p>Hmm i'm not sure i like that... perhaps its not appropriate to implement closeable.</p> <p>Lots of people seem to have problems with the analysis workflow and I think this adds confusion.</p>
</comment>
<comment id="13149570" author="rcmuir" created="Mon, 14 Nov 2011 11:05:20 +0000">
<blockquote> <p>Yes, the java.io.Closeable interface requires the underlying implementation to ignore additional close calls. </p></blockquote> <p>Just because java.io.Closeable exists doesn't mean we must use it everywhere: if these<br/> semantics are inappropriate we can simply have .close() ourselves.</p>
</comment>
<comment id="13149571" author="thetaphi" created="Mon, 14 Nov 2011 11:06:29 +0000">
<p>I disagree, removing the Closeable interface makes it stupid to use in Java 7 (try-with-resources).</p>
</comment>
<comment id="13149572" author="rcmuir" created="Mon, 14 Nov 2011 11:07:31 +0000">
<p>I think java 7 close-with-resources is stupid too.</p>
</comment>
<comment id="13149573" author="thetaphi" created="Mon, 14 Nov 2011 11:08:12 +0000">
<p>Why? For TokenStreams try-with-resources is great.</p>
</comment>
<comment id="13149575" author="simonw" created="Mon, 14 Nov 2011 11:10:15 +0000">
<blockquote><p>Why? For TokenStreams close-with-resources is great.</p></blockquote> <p>+1</p>
</comment>
<comment id="13149580" author="rcmuir" created="Mon, 14 Nov 2011 11:31:56 +0000">
<p>I just don't think it should be blanket policy without thinking things thru.</p> <p>for example: lots of code you see on the internet opens a new indexreader for every search and closes it</p> <p>should we seriously encourage this?! If someone seriously needs to do this, thats an expert case and<br/> they can use try + finally and close themselves.</p> <p>So for example, there I think it makes sense for IndexReader to not support AutoCLoseable, and separately<br/> to remove the stupid IndexSearcher(Directory) so that IndexSearcher only takes IndexReader, so its <b>always</b><br/> a thin wrapper like we claim it is (which is an outright lie today). Then IndexSearcher would implement <span class="error">&#91;Auto&#93;</span>Closeable<br/> since its cheap.</p>
</comment>
<comment id="13149586" author="mikemccand" created="Mon, 14 Nov 2011 11:48:01 +0000">
<blockquote> <p>So for example, there I think it makes sense for IndexReader to not support AutoCLoseable, and separately<br/> to remove the stupid IndexSearcher(Directory) so that IndexSearcher only takes IndexReader, so its always<br/> a thin wrapper like we claim it is (which is an outright lie today). </p></blockquote> <p>+1</p> <p>We should deprecate/remove the IS ctor that takes a Directory. It's trappy.</p>
</comment>
<comment id="13149595" author="thetaphi" created="Mon, 14 Nov 2011 12:11:51 +0000">
<p>Then we should also rename close() to something else: closeThisIfYouAreReallySure() - implementing Closeable is then already out-of scope. When adding a close method to classes it leads you to take care of closing after using it. Also everybody expects what Closeable interface defines: You can use it multiple times.</p> <p>For TokenStreams thats find, as close is just a cleanup and is not even required if you dont have a Tokenizer with Reader.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 14 Nov 2011 11:00:31 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10835</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04mkn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24922</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-3055] LUCENE-2372, LUCENE-2389 made it impossible to subclass core analyzers
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3055</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><a href="https://issues.apache.org/jira/browse/LUCENE-2372" title="Replace deprecated TermAttribute by new CharTermAttribute" class="issue-link" data-issue-key="LUCENE-2372"><del>LUCENE-2372</del></a> and <a href="https://issues.apache.org/jira/browse/LUCENE-2389" title="Enforce TokenStream impl / Analyzer finalness by an assertion" class="issue-link" data-issue-key="LUCENE-2389"><del>LUCENE-2389</del></a> marked all analyzers as final. This makes ReusableAnalyzerBase useless, and makes it impossible to subclass e.g. StandardAnalyzer to make a small modification e.g. to tokenStream(). These issues don't indicate a new method of doing this. The issues don't give a reason except for design considerations, which seems a poor reason to make a backward-incompatible change</p>
</description>
<environment/>
<key id="12505818">LUCENE-3055</key>
<summary>
LUCENE-2372, LUCENE-2389 made it impossible to subclass core analyzers
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="isoboroff">Ian Soboroff</reporter>
<labels></labels>
<created>Fri, 29 Apr 2011 20:05:51 +0000</created>
<updated>Sun, 25 Sep 2011 05:05:59 +0000</updated>
<version>3.1</version>
<component>modules/analysis</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13027171" author="rcmuir" created="Fri, 29 Apr 2011 20:34:03 +0000">
<p>Hi Ian, you are right the justifications don't totally explain the reasoning behind this change.</p> <p>From my perspective the most important reason is to avoid a huge performance trap: previously if you subclassed one of these analyzers, override tokenStream(), and added SpecialFilter for example, most of the time users would actually slow down indexing, because now reusableTokenStream() cannot be used by the indexer.</p> <p>This created worst-case situations like <a href="https://issues.apache.org/jira/browse/LUCENE-2279" title="eliminate pathological performance on StopFilter when using a Set&lt;String&gt; instead of CharArraySet" class="issue-link" data-issue-key="LUCENE-2279">LUCENE-2279</a>.</p> <p>Instead, the recommended approach is to just let analyzers be tokenstream factories (which is all they are). They aren't really "extendable" only "overridable" since they are just factories for tokenstreams, and by doing so it creates the worst-case performance trap where new objects are created for every document. I would instead recommend writing your analyzer by extending ReusableAnalyzerBase instead, which is easy and safe:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Analyzer analyzer = new ReusableAnalyzerBase() { protected TokenStreamComponents createComponents(String fieldName, Reader reader) { Tokenizer tokenizer = new WhitespaceTokenizer(...); TokenStream filteredStream = new FooTokenFilter(tokenizer, ...); filteredStream = new BarTokenFilter(filteredStream, ...); return new TokenStreamComponents(tokenizer, filteredStream); } }; </pre> </div></div>
</comment>
<comment id="13027179" author="thetaphi" created="Fri, 29 Apr 2011 20:50:12 +0000">
<blockquote> <p>From my perspective the most important reason is to avoid a huge performance trap: previously if you subclassed one of these analyzers, override tokenStream(), and added SpecialFilter for example, most of the time users would actually slow down indexing, because now reusableTokenStream() cannot be used by the indexer.</p></blockquote> <p>Additionally, exactly this special case (overwriting one of the methods) was the biggest problem, leading to ugly reflection based checks in Lucene 3.0: In 3.0 StandardAnalyzer correctly implemented both tokenStream() and reuseableTokenStream(). As soon as one subclass only overrided tokenStream(), but the indexer still calling reuseableTokenStream() the changes were not even used, leading to lots of bug reports. Because of this, a reflection based backwards hack was done in 3.0 (see o.a.l.util.VirtualMethod class to make this easier), that prevented the indexer from calling reuseableTokenStream if a subclass suddenly overwrote only one of the methods. With moving forward in 3.1, these backwards hacks even got heavier (e.g. changes in TokenStreams, new base class ReuseableAnalyzerBase,...), so the only solution was to enforce the decorator pattern.</p> <p>The above example by Robert is the correct way to implement your "factory" of TokenStreams. Everything else like subclassing StandardAnalyzer is ugly as it hides what you are really doing. The above pattern does exactly what also Solr's Schema does: You have to explicitely list all your components, making it clear what your TokenStreams are doing.</p> <p>Trust me, the above example is shorter than subclassing previous StandardAnalyzer completely (both tokenStream and reuseableTokenStream) and is showing like solrschema.xml what your Analyzer looks like (no hidden stuff in superfactories,...)</p>
</comment>
<comment id="13027361" author="earwin" created="Sat, 30 Apr 2011 19:12:33 +0000">
<p>Could anyone remind me, why the hell do we still have Analyzer.tokenStream AND reusableTokenStream rampaging around and confusing minds? We always recommend to use the latter, Robert just fixed some of the core classes to use the latter.</p> <p>Also, if reusableTokenStream is the only method left standing, isn't it wise to hide actual reuse somewhere in Lucene internals and turn Analyzer into plain and dumb factory interface?</p>
</comment>
<comment id="13028189" author="rcmuir" created="Tue, 3 May 2011 12:40:38 +0000">
<blockquote> <p>Also, if reusableTokenStream is the only method left standing, isn't it wise to hide actual reuse somewhere in Lucene internals and turn Analyzer into plain and dumb factory interface?</p></blockquote> <p>Hi Earwin: I completely agree that somehow Analyzer should be a "plain and dumb" interface, but are you suggesting we should move the responsibility of reuse onto the consumer? I think this could be challenging, alternatively there might be a way to present a "plain and dumb" API with the reuse guts buried inside Analyzer itself (like ReusableAnalyzerBase), and reuse enforced (e.g. the tokenStream() is final and you cannot "disable" reuse). The trick would be handling the special cases such as AnalyzerWrappers but I feel like we could still do this.</p> <p>Either way, I really think we should try to do this for 4.0. Though I think to get there it would be safest if we addressed a few issues first:</p> <ul> <li><a href="https://issues.apache.org/jira/browse/LUCENE-2788" title="Make CharFilter reusable" class="issue-link" data-issue-key="LUCENE-2788">LUCENE-2788</a>: make charfilters reusable, otherwise we will make the same mistake again!</li> <li><a href="https://issues.apache.org/jira/browse/LUCENE-3064" title="add checks to MockTokenizer to enforce proper consumption" class="issue-link" data-issue-key="LUCENE-3064"><del>LUCENE-3064</del></a>: ensure consumers are properly using the API e.g. calling reset()</li> <li><a href="https://issues.apache.org/jira/browse/LUCENE-3040" title="analysis consumers should use reusable tokenstreams" class="issue-link" data-issue-key="LUCENE-3040"><del>LUCENE-3040</del></a>: cut all consumers over to reusable API, so its really the "one left standing"</li> </ul>
</comment>
<comment id="13114148" author="rcmuir" created="Sun, 25 Sep 2011 05:05:58 +0000">
<p>Chris has made a ton of progress here, I think we are very close, though it would be good revisit <a href="https://issues.apache.org/jira/browse/LUCENE-2788" title="Make CharFilter reusable" class="issue-link" data-issue-key="LUCENE-2788">LUCENE-2788</a> in the future and ensure that for 4.0 charfilters have a reusable API as well (this is currently not the case).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 29 Apr 2011 20:34:03 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3490</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ms7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24956</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-3085] MultiBulkPostingsEnum is buggy</title>
<link>https://issues.apache.org/jira/browse/LUCENE-3085</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><a href="https://issues.apache.org/jira/browse/LUCENE-3053" title="improve test coverage for Multi*" class="issue-link" data-issue-key="LUCENE-3053"><del>LUCENE-3053</del></a> uncovers some bugs in MultiBulkPostingsEnum,<br/> for now i've disabled <a href="https://issues.apache.org/jira/browse/LUCENE-3053" title="improve test coverage for Multi*" class="issue-link" data-issue-key="LUCENE-3053"><del>LUCENE-3053</del></a> in the branch (see r1101148).</p>
</description>
<environment/>
<key id="12506649">LUCENE-3085</key>
<summary>MultiBulkPostingsEnum is buggy</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Mon, 9 May 2011 18:59:40 +0000</created>
<updated>Tue, 1 Oct 2013 18:41:02 +0000</updated>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10837</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04mlj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>24926</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2942] toString() methods on term/queries/etc are wrong: assume utf-8 encoded bytes.
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2942</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>In Lucene's trunk, a Term is just a Bytesref.<br/> In a lot of cases this is a UTF-8 encoded string, but in some cases its not (e.g. collation fields).</p> <p>The problem is that the toString methods all currently call utf8ToString().<br/> This is wrong, though from a practical point of view i think just printing the bytes won't be very helpful for debugging most cases where the bytes really are utf-8 encoded.</p> <p>So i think in these cases we should use the following technique: if the bytes are a valid utf-8 sequence, use BytesRef.utf8tostring(), otherwise just print the bytes: BytesRef.toString()</p> <p>its no problem for performance because toString is only for debugging anyway.</p>
</description>
<environment/>
<key id="12499949">LUCENE-2942</key>
<summary>
toString() methods on term/queries/etc are wrong: assume utf-8 encoded bytes.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Mon, 28 Feb 2011 17:33:38 +0000</created>
<updated>Mon, 28 Feb 2011 18:25:54 +0000</updated>
<version>4.0-ALPHA</version>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="13000427" author="thetaphi" created="Mon, 28 Feb 2011 17:44:46 +0000">
<p>Maybe we should add a method to BytesRef that is called: toHumanReadableString(). Internally it could quickly be implemneted as calling utf8ToString() and fallback on Exception. Or is there a faster was to detect if its valid UTF-8?</p> <p>This method could also be used e.g. in analysis.jsp in Solr, where it currently always prints utf8ToString(), which may also fail.</p>
</comment>
<comment id="13000435" author="rcmuir" created="Mon, 28 Feb 2011 17:59:35 +0000">
<p>Uwe: my plan is to actually fix toString itself (toString should be human readable, thats its purpose!)</p> <p>The existing code should be bytesToString() or hexToString() or something of that nature,<br/> this way if you explicitly want bytes you can get that.</p> <blockquote> <p>Internally it could quickly be implemneted as calling utf8ToString() and fallback on Exception. Or is there a faster was to detect if its valid UTF-8?</p></blockquote> <p>Not really, you cannot trust the JRE to do this correctly, e.g. <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6982052" class="external-link" rel="nofollow">http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6982052</a></p> <p>Additionally the behavior of malformed bytes is undefined, e.g. IBM JREs use IGNORE but Sun JREs use REPLACE... even if they actually detected correctly <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>Don't worry I will take care of this part.</p>
</comment>
<comment id="13000451" author="rcmuir" created="Mon, 28 Feb 2011 18:25:54 +0000">
<p>here's a patch, i only converted the really safe stuff over: toString()s and assertions and some tools in contrib/misc such as HighFreqTerms.</p>
</comment>
</comments>
<attachments>
<attachment id="12472210" name="LUCENE-2942.patch" size="16126" author="rcmuir" created="Mon, 28 Feb 2011 18:25:54 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 28 Feb 2011 17:44:46 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3658</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04nh3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25068</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2987] QueryParser throwing null pointer exception if input is invalid
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2987</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I was using org.apache.lucene.queryParser.QueryParser for parsing the input.<br/> My input:<br/> Input query string: "category: (4 or 6 or 8)"<br/> Analyzer: StandardAnalyzer<br/> QueryParser's parse() method is resulting in Null Pointer Exception.</p> <p>If i give input query string as "category: (4 OR 6 OR 8)" which is uppercase 'OR', it works fine and i get the desired results.<br/> I'm seeing the problem only with lower case 'or'</p>
</description>
<environment/>
<key id="12502257">LUCENE-2987</key>
<summary>
QueryParser throwing null pointer exception if input is invalid
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="ramesh.b.d">Ramesh</reporter>
<labels>
<label>newdev</label>
</labels>
<created>Thu, 24 Mar 2011 06:16:14 +0000</created>
<updated>Wed, 11 Jan 2012 05:17:16 +0000</updated>
<version>3.0.2</version>
<component>core/queryparser</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="13177427" author="joecabrera" created="Thu, 29 Dec 2011 22:21:12 +0000">
<p>Currently the grammar accepts conjunctions AND and OR. Should it be expanded to accept lowercase and and or as well or should they return an explicit error?</p>
</comment>
<comment id="13183864" author="joecabrera" created="Wed, 11 Jan 2012 05:17:16 +0000">
<p>Patch updates AND and OR tokens to now accept the lowercase versions.</p>
</comment>
</comments>
<attachments>
<attachment id="12510156" name="LUCENE-2987.patch" size="23220" author="joecabrera" created="Wed, 11 Jan 2012 05:17:16 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 29 Dec 2011 22:21:12 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>10893</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04n73:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25023</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2775] Sorting of search results can fail</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2775</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>When retrieving long values for sorting via the createValue method of the LongCache class in FieldCacheImpl.java, there are cases where there are terms for a given field that are not longs. These values have no documents associated with them so they can be safely ignored. The problem is that if the value could not be parsed into a long, as was my case, then an exception is thrown and the value 0 is returned for all documents. This causes the sort to fail.</p> <p>In my case the offending value was "0-73080000". I do not know how that got into the index and as such, have no way of reproducing this bug.</p> <p>The solution was to simply catch the exception and move on to the next term without bailing out of the sort.</p>
</description>
<environment/>
<key id="12480858">LUCENE-2775</key>
<summary>Sorting of search results can fail</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="kphayen">Kevin Hayen</reporter>
<labels></labels>
<created>Wed, 24 Nov 2010 20:23:26 +0000</created>
<updated>Wed, 24 Nov 2010 20:25:20 +0000</updated>
<version>3.0.1</version>
<component>core/search</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments>
<attachment id="12460396" name="sort.patch" size="685" author="kphayen" created="Wed, 24 Nov 2010 20:25:20 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11078</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04oi7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25235</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2673] CJKAnalyzer not matching mutlibyte character followed by non-multibyte character
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2673</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Here is a listing of text indexed in a field, followed by various search terms that did or did not match the document.</p> <p><span class="error">&#91;QES様文字化けテスト&#93;</span><br/> QES -&gt; retrievable<br/> QES様 -&gt; not retrievable<br/> QES様文字化けテスト -&gt; retrievable</p> <p><span class="error">&#91;SOA基盤&#93;</span><br/> SOA -&gt;retrievable<br/> SOA基 -&gt; not retrievable<br/> SOA基盤 -&gt; retrievable</p> <p><span class="error">&#91;日経BP&#93;</span><br/> 日経 -&gt; retrievable<br/> 日経B -&gt; not retrievable<br/> 日経BP -&gt; retrievable</p>
</description>
<environment/>
<key id="12475195">LUCENE-2673</key>
<summary>
CJKAnalyzer not matching mutlibyte character followed by non-multibyte character
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="kphayen">Kevin Hayen</reporter>
<labels></labels>
<created>Mon, 27 Sep 2010 14:23:04 +0000</created>
<updated>Mon, 16 May 2011 18:16:04 +0000</updated>
<version>3.0.1</version>
<component>modules/analysis</component>
<due/>
<votes>1</votes>
<watches>0</watches>
<comments>
<comment id="12915323" author="koji" created="Mon, 27 Sep 2010 14:45:03 +0000">
<p>I think CJKAnalyzer works as expected.</p> <blockquote> <p>QES様 -&gt; not retrievable<br/> SOA基 -&gt; not retrievable</p></blockquote> <p>Because CJK chars are tokenized 2-gram, "様" and "基" are not token.</p> <blockquote> <p>日経B -&gt; not retrievable</p></blockquote> <p>Because non CJK chars are tokenized at white space, "B" is not token.</p>
</comment>
<comment id="12917994" author="kphayen" created="Tue, 5 Oct 2010 14:35:10 +0000">
<p>That is the current behavior however, after checking with our Japanese office, I have confirmed that it is a common occurrence for western and Asian characters to be placed side by side. So the current behavior does not match what the user will expect.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 27 Sep 2010 14:45:03 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3687</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04p4v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25337</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2666] ArrayIndexOutOfBoundsException when iterating over TermDocs
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2666</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>A user got this very strange exception, and I managed to get the index that it happens on. Basically, iterating over the TermDocs causes an AAOIB exception. I easily reproduced it using the FieldCache which does exactly that (the field in question is indexed as numeric). Here is the exception:</p> <p>Exception in thread "main" java.lang.ArrayIndexOutOfBoundsException: 114<br/> at org.apache.lucene.util.BitVector.get(BitVector.java:104)<br/> at org.apache.lucene.index.SegmentTermDocs.next(SegmentTermDocs.java:127)<br/> at org.apache.lucene.search.FieldCacheImpl$LongCache.createValue(FieldCacheImpl.java:501)<br/> at org.apache.lucene.search.FieldCacheImpl$Cache.get(FieldCacheImpl.java:183)<br/> at org.apache.lucene.search.FieldCacheImpl.getLongs(FieldCacheImpl.java:470)<br/> at TestMe.main(TestMe.java:56)</p> <p>It happens on the following segment: _26t docCount: 914 delCount: 1 delFileName: _26t_1.del</p> <p>And as you can see, it smells like a corner case (it fails for document number 912, the AIOOB happens from the deleted docs). The code to recreate it is simple:</p> <p> FSDirectory dir = FSDirectory.open(new File("index"));<br/> IndexReader reader = IndexReader.open(dir, true);</p> <p> IndexReader[] subReaders = reader.getSequentialSubReaders();<br/> for (IndexReader subReader : subReaders) {<br/> Field field = subReader.getClass().getSuperclass().getDeclaredField("si");<br/> field.setAccessible(true);<br/> SegmentInfo si = (SegmentInfo) field.get(subReader);<br/> System.out.println("--&gt; " + si);<br/> if (si.getDocStoreSegment().contains("_26t")) </p> { // this is the probleatic one... System.out.println("problematic one..."); FieldCache.DEFAULT.getLongs(subReader, "__documentdate", FieldCache.NUMERIC_UTILS_LONG_PARSER); } <p> }</p> <p>Here is the result of a check index on that segment:</p> <p> 8 of 10: name=_26t docCount=914<br/> compound=true<br/> hasProx=true<br/> numFiles=2<br/> size (MB)=1.641<br/> diagnostics = </p> {optimize=false, mergeFactor=10, os.version=2.6.18-194.11.1.el5.centos.plus, os=Linux, mergeDocStores=true, lucene.version=3.0.2 953716 - 2010-06-11 17:13:53, source=merge, os.arch=amd64, java.version=1.6.0, java.vendor=Sun Microsystems Inc.} <p> has deletions <span class="error">&#91;delFileName=_26t_1.del&#93;</span><br/> test: open reader.........OK <span class="error">&#91;1 deleted docs&#93;</span><br/> test: fields..............OK <span class="error">&#91;32 fields&#93;</span><br/> test: field norms.........OK <span class="error">&#91;32 fields&#93;</span><br/> test: terms, freq, prox...ERROR <span class="error">&#91;114&#93;</span><br/> java.lang.ArrayIndexOutOfBoundsException: 114<br/> at org.apache.lucene.util.BitVector.get(BitVector.java:104)<br/> at org.apache.lucene.index.SegmentTermDocs.next(SegmentTermDocs.java:127)<br/> at org.apache.lucene.index.SegmentTermPositions.next(SegmentTermPositions.java:102)<br/> at org.apache.lucene.index.CheckIndex.testTermIndex(CheckIndex.java:616)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:509)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:299)<br/> at TestMe.main(TestMe.java:47)<br/> test: stored fields.......ERROR <span class="error">&#91;114&#93;</span><br/> java.lang.ArrayIndexOutOfBoundsException: 114<br/> at org.apache.lucene.util.BitVector.get(BitVector.java:104)<br/> at org.apache.lucene.index.ReadOnlySegmentReader.isDeleted(ReadOnlySegmentReader.java:34)<br/> at org.apache.lucene.index.CheckIndex.testStoredFields(CheckIndex.java:684)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:512)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:299)<br/> at TestMe.main(TestMe.java:47)<br/> test: term vectors........ERROR <span class="error">&#91;114&#93;</span><br/> java.lang.ArrayIndexOutOfBoundsException: 114<br/> at org.apache.lucene.util.BitVector.get(BitVector.java:104)<br/> at org.apache.lucene.index.ReadOnlySegmentReader.isDeleted(ReadOnlySegmentReader.java:34)<br/> at org.apache.lucene.index.CheckIndex.testTermVectors(CheckIndex.java:721)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:515)<br/> at org.apache.lucene.index.CheckIndex.checkIndex(CheckIndex.java:299)<br/> at TestMe.main(TestMe.java:47)</p> <p>The creation of the index does not do something fancy (all defaults), though there is usage of the near real time aspect (IndexWriter#getReader) which does complicate deleted docs handling. Seems like the deleted docs got written without matching the number of docs?. Sadly, I don't have something that recreates it from scratch, but I do have the index if someone want to have a look at it (mail me directly and I will provide a download link).</p> <p>I will continue to investigate why this might happen, just wondering if someone stumbled on this exception before. Lucene 3.0.2 is used.</p>
</description>
<environment/>
<key id="12475017">LUCENE-2666</key>
<summary>
ArrayIndexOutOfBoundsException when iterating over TermDocs
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="kimchy">Shay Banon</reporter>
<labels></labels>
<created>Fri, 24 Sep 2010 09:06:48 +0000</created>
<updated>Mon, 7 Feb 2011 19:46:51 +0000</updated>
<version>3.0.2</version>
<component>core/index</component>
<due/>
<votes>1</votes>
<watches>1</watches>
<comments>
<comment id="12914401" author="mikemccand" created="Fri, 24 Sep 2010 10:23:22 +0000">
<p>This looks like index corruption &#8211; somehow the deleted docs bit vector is too small for that segment. We have to get to the root cause of how the corruption happened.</p> <p>EG if you can enable IndexWriter's infoStream, then get the corruption to happen, and post the resulting log...</p> <p>Also, try enabling assertions... it may catch the corruption sooner.</p> <p>Can you describe how you use Lucene? Do you do any direct file IO in the index dir? (eg, for backup/restore or something).</p> <p>Are you certain only one writer is open on the index? (Do you disable Lucene's locking?)</p> <p>Which OS, filesystem, java impl are you using?</p>
</comment>
<comment id="12981649" author="npellow" created="Fri, 14 Jan 2011 07:15:05 +0000">
<p>Hi, </p> <p>I am getting this issue as well?<br/> We are doing quite a lot of update updates during indexing. Could this be causing the problem ?</p> <p>This seems to only have happened when we deployed to our linux test server - it didn't appear to occur on MAC OS X during development - with the same data set.</p> <p>Does this only affect Lucene 3.0.2 ? Would a rollback be a good work around ? </p> <p>The exact stack strace:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.ArrayIndexOutOfBoundsException: 5475 at org.apache.lucene.util.BitVector.get(BitVector.java:104) at org.apache.lucene.index.SegmentTermDocs.next(SegmentTermDocs.java:127) at org.apache.lucene.index.SegmentTermPositions.next(SegmentTermPositions.java:102) at org.apache.lucene.index.SegmentTermDocs.skipTo(SegmentTermDocs.java:207) at org.apache.lucene.search.PhrasePositions.skipTo(PhrasePositions.java:52) at org.apache.lucene.search.PhraseScorer.advance(PhraseScorer.java:120) at org.apache.lucene.search.IndexSearcher.searchWithFilter(IndexSearcher.java:249) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:218) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:199) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:177) at org.apache.lucene.search.MultiSearcher$MultiSearcherCallableWithSort.call(MultiSearcher.java:410) at org.apache.lucene.search.MultiSearcher.search(MultiSearcher.java:230) at org.apache.lucene.search.Searcher.search(Searcher.java:49) </pre> </div></div>
</comment>
<comment id="12981650" author="npellow" created="Fri, 14 Jan 2011 07:16:24 +0000">
<p>I've also noticed this occurring since I started using a numeric field and accessing the its field cache for boosting.</p>
</comment>
<comment id="12981843" author="mikemccand" created="Fri, 14 Jan 2011 17:58:01 +0000">
<p>Can you run CheckIndex on this index and post the result? And, enable assertions.</p> <p>And if possible turn on IndexWriter's infoStream and capture/post the output leading up to the corruption.</p> <p>Many updates during indexing is just fine... and I know whether rolling back to older Lucene releases will help (until we've isolated the issue). But: maybe try rolling forward to 3.0.3? It's possible you're hitting a big fixed in 3.0.3 (though this doesn't ring a bell for me).</p>
</comment>
<comment id="12982468" author="npellow" created="Mon, 17 Jan 2011 04:01:21 +0000">
<p>Hi MIchael, </p> <p>Thanks for the update. I have added an infoStream to the writer and triggered a re-index. Unfortunately, I didn't see the corruption occur this time.<br/> I am about to deploy to a different environment so will let you know.</p> <p>We are already upgraded to Lucene 3.0.3, unfortunately.</p> <p>Hopefully we will see the problem re-occur and be able to capture the necessary output to track down the problem.</p> <p>I've also added a call to writer.prepareCommit(). Previously, only writer.commit() was being called. Could that have an effect ?</p> <p>Cheers,<br/> Nick</p>
</comment>
<comment id="12982597" author="mikemccand" created="Mon, 17 Jan 2011 11:25:30 +0000">
<p>OK thanks. Hopefully we can catch this under infoStream's watch.</p> <p>Not calling prepareCommit is harmless &#8211; IW simply calls it for you under the hood when commit() is called, if you hadn't already called prepareCommit().</p> <p>The two APIs are separate in case you want to involve Lucene in a 2 phased commit w/ other resources.</p>
</comment>
<comment id="12985474" author="npellow" created="Mon, 24 Jan 2011 00:56:34 +0000">
<p>Hi Michael, </p> <p>We managed to catch this happening again. I've created a bug for our project over at: <a href="http://jira.atlassian.com/browse/CRUC-5486" class="external-link" rel="nofollow">http://jira.atlassian.com/browse/CRUC-5486</a> ( Since I can't seem to upload the log to this JIRA instance?).</p> <p>My hunch is that this occurs if a search is performed at the same time as a re-index - and a lucene cache is potentially not being closed/cleared correctly.<br/> It appears that a re-start of the application causes this problem to go away.</p> <p>Cheers,<br/> Nick.</p>
</comment>
<comment id="12985833" author="mikemccand" created="Mon, 24 Jan 2011 17:30:55 +0000">
<p>Thanks Nick; I'll look at the log.</p> <p>Aside: you should be able to attach files here... not sure why you saw otherwise...</p>
</comment>
<comment id="12985873" author="mikemccand" created="Mon, 24 Jan 2011 18:25:11 +0000">
<p>Nick, the infoStream output looks healthy &#8211; I don't see any exceptions. Can you post the output from CheckIndex against the index that corresponds to this infoStream?</p>
</comment>
<comment id="12986209" author="npellow" created="Tue, 25 Jan 2011 04:14:13 +0000">
<p>Hi Michael, </p> <p>Thanks for looking at that log.<br/> I ran CheckIndex on the corrupt index - and have attached the output here. It doesn't appear to have detected any problems.</p> <p>Do you think this problem could be caused by a cache not being flushed correctly ?</p> <p>Cheers,<br/> Nick</p>
</comment>
<comment id="12986566" author="mikemccand" created="Tue, 25 Jan 2011 18:11:03 +0000">
<p>Hmmm &#8212; given that exception, I would expect CheckIndex to have also seen this issue.</p> <p>Searching at the same time as indexing shouldn't cause this. Lucene doesn't cache postings, but does cache metadata for the term, though I can't see how that could lead to this exception.</p> <p>This could also be a hardware issue? Do you see the problem on more than one machine?</p>
</comment>
<comment id="12987328" author="npellow" created="Thu, 27 Jan 2011 01:17:20 +0000">
<p>Hi MIchael, </p> <p>We have now seen this issue on more than 1 machine. I don't think it is a hardware issue.<br/> We are using the ConcurrentMergeScheduler on the writer - so not sure if that has known issues?<br/> A restart definitely 'fixes' this problem though.</p> <p>The stack-trace is:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.ArrayIndexOutOfBoundsException: 3740 at org.apache.lucene.util.BitVector.get(BitVector.java:104) at org.apache.lucene.index.SegmentTermDocs.next(SegmentTermDocs.java:127) at org.apache.lucene.index.SegmentTermPositions.next(SegmentTermPositions.java:102) at org.apache.lucene.search.PhrasePositions.next(PhrasePositions.java:41) at org.apache.lucene.search.PhraseScorer.init(PhraseScorer.java:147) at org.apache.lucene.search.PhraseScorer.nextDoc(PhraseScorer.java:78) at org.apache.lucene.search.DisjunctionSumScorer.initScorerDocQueue(DisjunctionSumScorer.java:101) at org.apache.lucene.search.DisjunctionSumScorer.&lt;init&gt;(DisjunctionSumScorer.java:85) at org.apache.lucene.search.BooleanScorer2$1.&lt;init&gt;(BooleanScorer2.java:154) at org.apache.lucene.search.BooleanScorer2.countingDisjunctionSumScorer(BooleanScorer2.java:149) at org.apache.lucene.search.BooleanScorer2.makeCountingSumScorerNoReq(BooleanScorer2.java:218) at org.apache.lucene.search.BooleanScorer2.makeCountingSumScorer(BooleanScorer2.java:208) at org.apache.lucene.search.BooleanScorer2.&lt;init&gt;(BooleanScorer2.java:101) at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:336) at org.apache.lucene.search.function.CustomScoreQuery$CustomWeight.scorer(CustomScoreQuery.java:359) at org.apache.lucene.search.BooleanQuery$BooleanWeight.scorer(BooleanQuery.java:306) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:210) at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:170) at org.apache.lucene.search.MultiSearcher$MultiSearcherCallableNoSort.call(MultiSearcher.java:363) at org.apache.lucene.search.MultiSearcher.search(MultiSearcher.java:208) at org.apache.lucene.search.Searcher.search(Searcher.java:98) </pre> </div></div> <p>I am going to spend some time trying to reproduce this locally today, with a debugger attached.</p> <p>Cheers,<br/> Nick</p>
</comment>
<comment id="12987415" author="npellow" created="Thu, 27 Jan 2011 07:19:35 +0000">
<p>Hi Michael, </p> <p>We've done some analysis on how we are using Lucene and discovered the following:</p> <ul> <li>the <b>only</b> time we construct a new reader <tt>IndexReader.open(directory, true)</tt> is when we search the index for the first time since the server start.</li> <li>every other time, we are using reader.reopen() each time we detect that a write has occurred to the index. <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">final</span> IndexReader newReader = oldReader.reopen(); <span class="code-keyword">if</span> (newReader != oldReader) { oldReader.decRef(); reader = newReader; } </pre> </div></div></li> <li>the bug definitely goes away when the system is restarted and a new Reader is instantiated.</li> <li>once we see the AIOOBE, it happens on <em>every search</em> until we restart</li> <li>running CheckIndex never reports any errors</li> </ul> <p>Therefore we believe that reader.reopen() is most likely causing certain data structures to be shared and creates inconsistency which leads to this exception.</p> <p>The latest stack trace we are getting is in the comment above.</p> <p>Given this information would you have any more clues for us?</p> <p>Thank you very much for your help so far,<br/> greatly appreciated.<br/> Nick</p>
</comment>
<comment id="12987829" author="npellow" created="Thu, 27 Jan 2011 23:31:02 +0000">
<p>Hi Michael, </p> <p>We have a memory dump of the instance that is affected by this. Would you know the best place to start looking for the possibly outdated BitVector?<br/> We could make this available to you if you wish - all 1.8GB of it though <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/sad.gif" height="16" width="16" align="absmiddle" alt="" border="0"/> </p> <p>Cheers,<br/> Nick</p>
</comment>
<comment id="12988086" author="mikemccand" created="Fri, 28 Jan 2011 14:01:31 +0000">
<p>Nick, are you running Lucene w/ asserts enabled? Are you able to take a src patch and run it through your test? If so, I can add some verbosity/asserts and we can try to narrow this down.</p> <p>It does sound like somehow the wrong delete BitVector is getting associated w/ a SegmentReader.</p> <p>It looks like you don't use NRT readers right? Ie, you always .commit() from IW and then do IR.reopen?</p>
</comment>
<comment id="12991315" author="npellow" created="Mon, 7 Feb 2011 09:48:00 +0000">
<p>Hi Michael, </p> <p>This issue was entirely a problem with our code, and I doubt Lucene could have done a better job.</p> <p>The problem was that on upgrade of the index (done when fields have changed etc), we recreate the index in the same location using <br/> <tt>IndexWriter.create(directory, analyzer, true, MAX_FIELD_LENGTH)</tt>.</p> <p>Some code was added just before this however, that deleted every single file in the directory. This meant that some other thread performing a search could have seen a corrupt index, thus causing the AIOOBE. The developer was paranoid that IndexWriter.create was leaving old files lying around.</p> <p>I'm glad we got to the bottom of this, and very much so that it was not a bug in Lucene!</p> <p>Thanks again for helping us track this down.</p> <p>Best Regards,<br/> Nick Pellow</p>
</comment>
<comment id="12991545" author="mikemccand" created="Mon, 7 Feb 2011 19:46:51 +0000">
<p>Ahh, thanks for bringing closure Nick! Although, I'm a little confused how removing files from the index while readers are using it, could lead to those exceptions...</p> <p>Note that it's perfectly fine to pass create=true to IW, over an existing index, even while readers are using it; IW will gracefully remove the old files itself, even if open IRs are still using them. IW just makes a new commit point that drops all references to prior segments...</p>
</comment>
</comments>
<attachments>
<attachment id="12469235" name="checkindex-out.txt" size="10823" author="npellow" created="Tue, 25 Jan 2011 04:14:12 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 24 Sep 2010 10:23:22 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11175</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04p6f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25344</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2698] Intermittent exc in TestIndexWriter.testAddDocumentOnDiskFull
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2698</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>3.x build just hit this:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Stacktrace junit.framework.AssertionFailedError at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:693) at org.apache.lucene.util.LuceneTestCase$LuceneTestCaseRunner.runChild(LuceneTestCase.java:666) at org.apache.lucene.index.TermVectorsReader.&lt;init&gt;(TermVectorsReader.java:91) at org.apache.lucene.index.SegmentReader$CoreReaders.openDocStores(SegmentReader.java:304) at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:585) at org.apache.lucene.index.SegmentReader.get(SegmentReader.java:561) at org.apache.lucene.index.DirectoryReader.&lt;init&gt;(DirectoryReader.java:102) at org.apache.lucene.index.ReadOnlyDirectoryReader.&lt;init&gt;(ReadOnlyDirectoryReader.java:27) at org.apache.lucene.index.DirectoryReader$1.doBody(DirectoryReader.java:78) at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:692) at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:72) at org.apache.lucene.index.IndexReader.open(IndexReader.java:344) at org.apache.lucene.index.IndexReader.open(IndexReader.java:230) at org.apache.lucene.index.TestIndexWriter.testAddDocumentOnDiskFull(TestIndexWriter.java:515) Standard Output NOTE: reproduce with: ant test -Dtestcase=TestIndexWriter -Dtestmethod=testAddDocumentOnDiskFull -Dtests.seed=3136129128141482592:-2364438756268371069 NOTE: test params are: locale=nl_BE, timezone=Asia/Tel_Aviv </pre> </div></div>
</description>
<environment/>
<key id="12477196">LUCENE-2698</key>
<summary>
Intermittent exc in TestIndexWriter.testAddDocumentOnDiskFull
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Tue, 12 Oct 2010 23:55:33 +0000</created>
<updated>Tue, 12 Oct 2010 23:55:33 +0000</updated>
<version>3.1</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3672</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ozb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25312</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2684] it's not possible to access sub-query's freq information if BooleanScorer is use
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2684</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><a href="https://issues.apache.org/jira/browse/LUCENE-2590" title="Enable access to the freq information in a Query&#39;s sub-scorers" class="issue-link" data-issue-key="LUCENE-2590"><del>LUCENE-2590</del></a> added an advanced feature, allowing an app to gather all sub-scorers for any Query.</p> <p>This is powerful because then, during collection, the app can get some details about how each sub-query "participated" in the overall match for the given document.</p> <p>However, I think this is completely broken if the BooleanQuery uses BooleanScorer, because that scorer is not doc-at-once. Instead, it batch processes chunks of 2048 sequential docIDs per scorer. This is a big performance gain, but it means that the sub scorers will all be positioned to the end of the 2048 doc chunk while the docs that matched within that chunk are collected.</p> <p>I don't think we can easily fix this... likely the "fix" is to make it easy(ier) to force BQ to use BooleanScorer2 (which is doc-at-once)? It is actually possible to force this, today, by having your collector return false from acceptDocsOutOfOrder...</p>
</description>
<environment/>
<key id="12475745">LUCENE-2684</key>
<summary>
it's not possible to access sub-query's freq information if BooleanScorer is use
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Mon, 4 Oct 2010 09:41:03 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:44 +0000</updated>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/search</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="12985322" author="mikemccand" created="Sun, 23 Jan 2011 13:39:47 +0000">
<p>Clearing 3.1 fix version... it's not clear how we can fix this w/o drastic API changes...</p>
</comment>
<comment id="13453199" author="rcmuir" created="Tue, 11 Sep 2012 17:24:30 +0000">
<blockquote> <p>It is actually possible to force this, today, by having your collector return false from acceptDocsOutOfOrder...</p></blockquote> <p>Well you are using a custom collector anyway if you are doing this, so can't we just add a sentence to that<br/> method's javadocs indicating that you should return false if you want to use the scorer navigation apis?</p>
</comment>
<comment id="13453218" author="thetaphi" created="Tue, 11 Sep 2012 17:41:29 +0000">
<p>I think this issue is fixed already? VisitSubScorers works in 3.6.2 (if it gets released, Robert backported) and in 4.0 its working, too?</p> <p>As you need a custom collector anyway to make use of Scorer.getChildren(), we should maybe make BS1 throw UOE on getChildren() in 4.0 (explaining that you need inOrder) and visitSubScorers in 3.6.2?</p>
</comment>
<comment id="13453223" author="rcmuir" created="Tue, 11 Sep 2012 17:43:50 +0000">
<blockquote> <p>As you need a custom collector anyway to make use of Scorer.getChildren(), we should maybe make BS1 throw UOE on getChildren() in 4.0 (explaining that you need inOrder) and visitSubScorers in 3.6.2?</p></blockquote> <p>+1, i think for freq() and getChildren() we should throw UOE with text like this. But we can also do the javadocs too.</p> <p>Then i think there would be a lot less surprises.</p>
</comment>
<comment id="13453238" author="mikemccand" created="Tue, 11 Sep 2012 18:07:17 +0000">
<p>+1</p> <p>But we should word it as a "workaround" ... ie, it's sort of strange that returning false from this unrelated method means suddenly scorer.freq() works: that's really an implementation detail. EG someday we could make BS1 score docs in order (it is possible, just not sure it'd be performant), and then this workaround no longer works.</p>
</comment>
<comment id="13453245" author="thetaphi" created="Tue, 11 Sep 2012 18:13:58 +0000">
<p>It does not only affect freq(). In my case it was "retrieving the subquery score"...</p> <blockquote><p>EG someday we could make BS1 score docs in order (it is possible, just not sure it'd be performant), and then this workaround no longer works.</p></blockquote> <p>But with in-order scoring we are in all cases use correctly positioned scorers, otherwise it is a bug (like the DisjunctionSumScorer bug in 3.6 and 4.0 we fixed recently). So returning "false" works around the issue currently, but it would not hurt if somebody would return false, although our new BS1 can handle in order. But on the other hand, if BS1 would score in order, but not position sub-scorers correctly it is clearly a bug!</p>
</comment>
<comment id="13453246" author="rcmuir" created="Tue, 11 Sep 2012 18:14:05 +0000">
<blockquote> <p>But we should word it as a "workaround" ... ie, it's sort of strange that returning false from this unrelated method means suddenly scorer.freq() works: that's really an implementation detail. EG someday we could make BS1 score docs in order (it is possible, just not sure it'd be performant), and then this workaround no longer works.</p></blockquote> <p>I don't agree: the strangeness is the two booleans toplevelScorer and scoreDocsInOrder. If we wanted to do this in the future, we could just rename scoreDocsInOrder<br/> to needsNavigation. </p> <p>Or we could just fold both the booleans into 'BS1 is ok' ... are they used anywhere else? <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="13453259" author="thetaphi" created="Tue, 11 Sep 2012 18:25:49 +0000">
<p>An idea (separate issue!) would be:<br/> BS1 completely violates the scorer interface, the only method you can call is the one taking a Collector. In my opinion, BS1 should <b>not</b> implement the Scorer interface, that the whole bug! It should maybe some separate class like OutOfOrderDocIdReporter (name is just an example) that only implements collect(Collector). And the navigation api (advance, next) should be separated from score() and freq() - a simple java interface Scorer. So the current in-order scorer would be a simple DocIdSetIterator that additionally implements the Scorer interface (to provide score() and freq()) and current out-of-order scorers would implement only the OutOfOrderDocIdReporter API and pass a inlined Scorer interface (without advance and next) to the setScorer() method (like BucketScorer currently).</p>
</comment>
<comment id="13453261" author="rcmuir" created="Tue, 11 Sep 2012 18:26:58 +0000"><p>Collectible... (not serious)</p></comment>
<comment id="13453262" author="mikemccand" created="Tue, 11 Sep 2012 18:28:00 +0000">
<p>The problem is that "scoresDocsInOrder" doesn't really capture what's necessary here (yes, it works today, but, not necessarily tomorrow....).</p> <p>I agree Uwe: if we add a Collector.needsNavigation() then even a "fixed" BS1 that sorted the docIDs before collection would not be usable since the subs will not be "on" the doc during collect().</p> <p>And I agree Robert: the current booleans "topLevelScorer" and "scoreDocsInOrder", and then a new "needsNavigation", will make things rather confusing. Really I think topLevelScorer should be strongly typed: the intent is to declare whether you will call Scorer.score(Collector) or whether you will call .nextDoc()/.score() ... they really should be different classes.</p> <p>If we don't think any other future scorer would want to score docs NOT in order ... then maybe we should simple rename scoreDocsInOrder to needsNavigation? (Or scoreDocAtOnce, scoreDocAtATime, something else...).</p>
</comment>
<comment id="13453269" author="rcmuir" created="Tue, 11 Sep 2012 18:32:27 +0000">
<blockquote> <p>If we don't think any other future scorer would want to score docs NOT in order ... then maybe we should simple rename scoreDocsInOrder to needsNavigation? (Or scoreDocAtOnce, scoreDocAtATime, something else...).</p></blockquote> <p>I actually just remembered the query-time join i think does this too?</p> <p>But yeah, if we are going to have booleans, i would prefer something more along the lines of document-at-a-time since its less confusing than<br/> scoreDocsInOrder (its standard IR terminology and less confusing).</p>
</comment>
<comment id="13453274" author="mikemccand" created="Tue, 11 Sep 2012 18:37:10 +0000">
<blockquote><p>BS1 completely violates the scorer interface, the only method you can call is the one taking a Collector. In my opinion, BS1 should not implement the Scorer interface, that the whole bug!</p></blockquote> <p>Well let's remember that the "must have doc-at-once scoring, for all subs too" is a very rare use-case.</p> <p>The vast majority of users just need a fast .score(Collector) interface.</p> <p>But yeah I agree: it should be strongly typed, and BS1 should only implement the .score(Collector) interface. The ScoresDocAtOnce interface can easily implement the .score(Collector) interface (as Scorer does today...).</p>
</comment>
<comment id="13716974" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:31 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970864" author="thetaphi" created="Wed, 16 Apr 2014 12:54:44 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 11 Sep 2012 17:24:30 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>2936</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04p2f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25326</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2605] queryparser parses on whitespace</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2605</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The queryparser parses input on whitespace, and sends each whitespace separated term to its own independent token stream.</p> <p>This breaks the following at query-time, because they can't see across whitespace boundaries:</p> <ul> <li>n-gram analysis</li> <li>shingles</li> <li>synonyms (especially multi-word for whitespace-separated languages)</li> <li>languages where a 'word' can contain whitespace (e.g. vietnamese)</li> </ul> <p>Its also rather unexpected, as users think their charfilters/tokenizers/tokenfilters will do the same thing at index and querytime, but<br/> in many cases they can't. Instead, preferably the queryparser would parse around only real 'operators'.</p>
</description>
<environment/>
<key id="12471774">LUCENE-2605</key>
<summary>queryparser parses on whitespace</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Tue, 17 Aug 2010 03:30:26 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:55 +0000</updated>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/queryparser</component>
<due/>
<votes>25</votes>
<watches>48</watches>
<comments>
<comment id="13105979" author="shenzhuxi" created="Fri, 16 Sep 2011 10:18:13 +0000"><p>subscribed </p></comment>
<comment id="13139429" author="hossman" created="Sat, 29 Oct 2011 20:31:50 +0000">
<p>since (unescaped, unquoted) whitespace characters is the syntax that QueryParser uses to indicate the transition between clauses in a BooleanQuery, changing this (either in QueryParser or in some new query parser) would require coming up with some new syntax. (or in the case of a special case query parser like the FieldQParser in Solr, eliminating the possibility of expressing multi-clause queries)</p>
</comment>
<comment id="13292620" author="berryman" created="Mon, 11 Jun 2012 02:44:48 +0000">
<p>subscribed - Current client has index full of clothing - a search for "dress shoes" will return results containing womens' dresses and running shoes. That's not really acceptable.</p>
</comment>
<comment id="13293722" author="berryman" created="Tue, 12 Jun 2012 16:08:38 +0000">
<p>There is somewhat of a workaround for this for defType=lucene. Just escape every whitespace with a slash. So instead of <b><tt>new dress shoes</tt></b> search for <b><tt>new\ dress\ shoes</tt></b>. Of course you lose the ability to use normal lucene syntax.</p> <p>I was hoping that this workaround would also work for defType=dismax, but with or without the escaped whitespace, queries get interpreted the same, incorrect way. For instance, assume I have the following line in my synonyms.txt: <b><tt>dress shoes =&gt; dress_shoes</tt></b>. Further assume that I have a field <b><tt>experiment</tt></b> that gets analysed with synonyms. A search for <b><tt>new dress shoes</tt></b> (with or without escaped spaces) will be interpreted as </p> <p><b><tt>+((experiment:new)~0.01 (experiment:dress)~0.01 (experiment:shoes)~0.01) (experiment:"new dress_shoes"~3)~0.01</tt></b></p> <p>The first clause is manditory and contains independently analysed tokens, so this will only match documents that contain "dress", "new", or "shoes", but never "dress shoes" because analysis takes place as expected at index time.</p>
</comment>
<comment id="13293748" author="jkrupan" created="Tue, 12 Jun 2012 16:33:52 +0000">
<p>My thought on the original issue is that most query parsers should accumulate adjacent terms without intervening operators as a "term list" (quoted phrases would be a second level of term list) and that there needs to be a "list" interface for query term analysis.</p> <p>Rather than simply present a raw text stream for the sequence/list of terms, each term would be fed into the token stream with an attribute that indicates which source term it belongs to.</p> <p>The synonym processor would see a clean flow of terms and do its processing, but would also need to associate an id with each term of a multi-term synonym phrase so that multiple multi-word synonym choices for the same input term(s) don't get mixed up (i.e., multiple tokens at the same position with no indication of which original synonym phrase they came from).</p> <p>By having those ID's for each multi-term synonym phrase, the caller of the list analyzer could then recontruct the tree of "OR" expressions for the various multi-term synonym phrases.</p>
</comment>
<comment id="13293940" author="berryman" created="Tue, 12 Jun 2012 21:41:21 +0000">
<p>(How's it going Jack) Interesting idea, though I really need to crack into the QueryParser and play around a little bit before I have a strong opinion myself.</p>
</comment>
<comment id="13717067" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:49 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970926" author="thetaphi" created="Wed, 16 Apr 2014 12:54:55 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12675275">SOLR-5379</issuekey>
</issuelink>
</outwardlinks>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12629811">SOLR-4381</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 16 Sep 2011 10:18:13 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11229</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04pjz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25405</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2607] IndexWriter.isLocked() fails on a read-only directory
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2607</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This appears to be a regression of some sort because the issue was only discovered by us some time after upgrading to the 2.9 series, and was not present when we were using 2.3 (big gap between those two, though.)</p> <p>We had some code like:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">if</span> (IndexWriter.isLocked(directory)) { IndexWriter.unlock(directory); } </pre> </div></div> <p>And now we get an exception when this code runs on a read-only location:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>java.lang.RuntimeException: Failed to acquire random test lock; please verify filesystem for lock directory 'X:\Data\Index' supports locking at org.apache.lucene.store.NativeFSLockFactory.acquireTestLock(NativeFSLockFactory.java:99) at org.apache.lucene.store.NativeFSLockFactory.makeLock(NativeFSLockFactory.java:137) at org.apache.lucene.store.Directory.makeLock(Directory.java:131) at org.apache.lucene.index.IndexWriter.isLocked(IndexWriter.java:5672) at </pre> </div></div> <p>I think it makes more logical sense to return <b>false</b> - if locking is not possible then it cannot be locked, therefore isLocked should always return false.</p>
</description>
<environment/>
<key id="12471865">LUCENE-2607</key>
<summary>
IndexWriter.isLocked() fails on a read-only directory
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="trejkaz">Trejkaz</reporter>
<labels></labels>
<created>Wed, 18 Aug 2010 00:18:07 +0000</created>
<updated>Fri, 24 Sep 2010 00:10:25 +0000</updated>
<version>2.9.2</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3710</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04pjj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25403</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2557] FuzzyQuery - fuzzy terms and misspellings are ranked higher than exact matches
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2557</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The FuzzyQuery often causes misspellings to be ranked higher than the exact match, which seems to be an undesirable property generally. </p> <p>For example, in an index of surnames, if I search using a FuzzyQuery for "smith", the misspellings such as "smiith", or "smiht" would appear near the top of the search results ahead of documents that match "smith".</p>
</description>
<environment/>
<key id="12470026">LUCENE-2557</key>
<summary>
FuzzyQuery - fuzzy terms and misspellings are ranked higher than exact matches
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jly">Jingkei Ly</reporter>
<labels></labels>
<created>Fri, 23 Jul 2010 16:22:43 +0000</created>
<updated>Fri, 9 Mar 2012 15:44:07 +0000</updated>
<version>3.0.2</version>
<component>core/query/scoring</component>
<due/>
<votes>1</votes>
<watches>1</watches>
<comments>
<comment id="12891660" author="jly" created="Fri, 23 Jul 2010 16:25:20 +0000">
<p>I've attached a test case which demonstrates some of the scoring issues (the patch applies to the existing TestFuzzyQuery class). With the default FuzzyQuery, the fuzzy terms "joness" and "smiith" get promoted to the top of the search results because they have higher IDFs than the exact matches.</p> <p>If you modify the test so that the FuzzyQuerys use TopTermsBoostOnlyBooleanQueryRewrite, i.e. uncomment these lines in the test case:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> smithQuery.setRewriteMethod(<span class="code-keyword">new</span> MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite()); jonesQuery.setRewriteMethod(<span class="code-keyword">new</span> MultiTermQuery.TopTermsBoostOnlyBooleanQueryRewrite()); </pre> </div></div> <p>The fuzzy terms are correctly relegated to the bottom of the search results but, because IDF is ignored, "jones" appears more highly scored than "smith" even though "smith" is the rarer term.</p> <p>Ideally the solution should solve both these issues.</p>
</comment>
<comment id="12891661" author="rcmuir" created="Fri, 23 Jul 2010 16:25:42 +0000">
<p>Duplicate of <a href="https://issues.apache.org/jira/browse/LUCENE-124" title="Fuzzy Searches do not get a boost of 0.2 as stated in &quot;Query Syntax&quot; doc" class="issue-link" data-issue-key="LUCENE-124"><del>LUCENE-124</del></a>, which added this new rewrite method in trunk and 3.x:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>* LUCENE-124: Add a TopTermsBoostOnlyBooleanQueryRewrite to MultiTermQuery. This rewrite method is similar to TopTermsScoringBooleanQueryRewrite, but only scores terms by their boost values. For example, this can be used with FuzzyQuery to ensure that exact matches are always scored higher, because only the boost will be used in scoring. </pre> </div></div>
</comment>
<comment id="12891665" author="jly" created="Fri, 23 Jul 2010 16:38:40 +0000">
<p>Robert,</p> <p>I posted a comment just before your one (apparently in the same minute) - I made an additional point that TopTermsBoostOnlyBooleanQueryRewrite ignores the IDF undesirably - does that make the issue valid again?</p>
</comment>
<comment id="12891672" author="jly" created="Fri, 23 Jul 2010 16:54:56 +0000">
<p>I've had a crack at implementing a fix, based on suggestions in <a href="https://issues.apache.org/jira/browse/LUCENE-329" title="Fuzzy query scoring issues" class="issue-link" data-issue-key="LUCENE-329"><del>LUCENE-329</del></a>. It takes the IDF of the term used in the FuzzyQuery if it exists in the index and uses that as the IDF. If the term is not in the index it uses the average IDF of all the terms.</p> <p>It is implemented as a rewrite method similar to TopTermsBoostOnlyBooleanQueryRewrite from <a href="https://issues.apache.org/jira/browse/LUCENE-124" title="Fuzzy Searches do not get a boost of 0.2 as stated in &quot;Query Syntax&quot; doc" class="issue-link" data-issue-key="LUCENE-124"><del>LUCENE-124</del></a>, although it required modifying TopTermsBooleanQueryRewrite a little bit.</p>
</comment>
<comment id="12891673" author="rcmuir" created="Fri, 23 Jul 2010 16:58:40 +0000">
<p>I dont understand why we need to average any idfs? this seems really costly and i think in general the idea of fuzzy is to find misspellings.</p> <p>furthermore i dont understand why its important if the idf if the query term exists in the index or not, because the query itself could be misspelled.</p>
</comment>
<comment id="12891678" author="jly" created="Fri, 23 Jul 2010 17:13:34 +0000">
<blockquote> <p>I dont understand why we need to average any idfs? this seems really costly and i think in general the idea of fuzzy is to find misspellings. </p></blockquote> <p>I agree that fuzzy is to find misspellings, but I don't think it should favour misspellings above an exact match. I think the reasoning behind the average IDFs (I based that on comments in <a href="https://issues.apache.org/jira/browse/LUCENE-329" title="Fuzzy query scoring issues" class="issue-link" data-issue-key="LUCENE-329"><del>LUCENE-329</del></a>), is that in the absence of an IDF from the exact match it's better than nothing to have an average of the terms you do know. Perhaps, there is a better heuristic for that case, though.</p> <blockquote> <p>furthermore i dont understand why its important if the idf if the query term exists in the index or not, because the query itself could be misspelled.</p></blockquote> <p>I think it's a fair assumption that users are searching for specific terms (+fore:john +sur:smith), so are unlikely that they would have a misspelling in the original query. If they did misspell it and got erroneous results, it seems it's immediately clear that the cause is a misspelt query.</p>
</comment>
<comment id="12891680" author="rcmuir" created="Fri, 23 Jul 2010 17:33:16 +0000">
<blockquote><p>I agree that fuzzy is to find misspellings, but I don't think it should favour misspellings above an exact match.</p></blockquote> <p>So what is the problem with TopTermsBoostOnlyBooleanQueryRewrite? it will never do this.</p> <p>While I agree this is a really simple solution to the problem, It seemed to me from the comments in <a href="https://issues.apache.org/jira/browse/LUCENE-329" title="Fuzzy query scoring issues" class="issue-link" data-issue-key="LUCENE-329"><del>LUCENE-329</del></a> that there were differing opinions on how one might want to combine the factors of edit distance boost, tf, idf, etc... it seems it will depend on the application.</p> <p>So I definitely don't think this is any bug in fuzzyquery. Personally, I am not against adding new alternative rewrite methods like the one you added here, so that more choices are available. But this just seems to be the same issue as <a href="https://issues.apache.org/jira/browse/LUCENE-329" title="Fuzzy query scoring issues" class="issue-link" data-issue-key="LUCENE-329"><del>LUCENE-329</del></a> to me.</p> <p>My personal preference would be to take this code and bring <a href="https://issues.apache.org/jira/browse/LUCENE-329" title="Fuzzy query scoring issues" class="issue-link" data-issue-key="LUCENE-329"><del>LUCENE-329</del></a> up to speed, e.g. creating an alternative in contrib/queries or something that uses Mark Harwoods "smart fuzzy" logic which is currently limited to FuzzyLikeThis.</p>
</comment>
<comment id="12892285" author="markh" created="Mon, 26 Jul 2010 12:23:31 +0000">
<p>I think we're agreed that the effects of IDF are troublesome when ranking variant term matches but I question that the default solution should be to remove IDF from the equation completely.</p> <p>Doing that reminds me of the time my mother thought the shadow in a photograph was annoying and cut it out with a pair of scissors leaving a big hole in its place.<br/> What we're proposing here instead is the equivalent of some "photoshopping" to retain some of the original information but suitably blurred to provide a more natural balance to the overall picture.</p> <p>Some degree of IDF can be usefully retained from a FuzzyQuery in order to acheive balance with all the other (potentially non-fuzzy) optional clauses that may exist in a BooleanQuery. <br/> The proposal is that the most natural blending of IDF scores within a FuzzyQuery is to use only the IDF of the input term (which defines the user's original intent) and use this to score a match on any suggested variant . If the input term does not exist the average IDF of all variants is used as the next best alternative for scoring each variant.</p> <p>This approach has exactly the same ranking effect as the existing "remove IDF" policy within a single FuzzyQuery but has the added advantage of sitting better with the other optional clauses that may exist in a containing query.</p> <p>The question over core vs contrib comes down to what is considered the more natural/expected behaviour. </p>
</comment>
<comment id="12892290" author="rcmuir" created="Mon, 26 Jul 2010 12:38:35 +0000">
<blockquote><p>I think we're agreed that the effects of IDF are troublesome when ranking variant term matches but I question that the default solution should be to remove IDF from the equation completely.</p></blockquote> <p>Mark, just fyi, the boost-only rewrite method isnt the default (its just a simple option, but no runtime behavior has changed, it still uses "normal" boolean expansion as default).</p> <p>I basically agree with your idea that it would be nicer to add a smarter rewrite method, and if so, probably change the defaults. But my concerns are:</p> <ul> <li>this input term / does not exist thing seems a little wierd to me as mentioned.</li> <li>doing a lot of docfreq/idf calls seems expensive? this is no problem with FuzzyLikeThis i think though, doesnt it uses a more reasonable PQ size? (50 or something)</li> </ul>
</comment>
<comment id="12892297" author="rcmuir" created="Mon, 26 Jul 2010 12:51:11 +0000">
<p>so here is an option for this issue. we could reword the whole issue as 'improve FuzzyQuery defaults'.</p> <p>If we were to do this, i would suggest the following at the minimum:</p> <ul> <li>instead of a default distance of 0.5 (from queryparser), if distance isnt provided (~0.6 etc), calculate one that will perform well and never brute-force compare all the terms.</li> <li>instead of a default max expansions of booleanquery max clause count (1024), use a more reasonable # of expansions by default (such as 50)</li> <li>instead of the current rewrite, use a rewrite similar to FuzzyLikeThis. maybe we dont need to average docfreq across all 50 terms even, maybe the top-5 or so is sufficient.</li> </ul> <p>If we were to do something like this, maybe we could improve performance and behavior instead of making tradeoffs.</p>
</comment>
<comment id="12892311" author="markh" created="Mon, 26 Jul 2010 13:57:29 +0000">
<blockquote><p>I dont understand why we need to average any idfs? this seems really costly </p></blockquote> <p>IDF lookups and averaging etc should only be calculated for the top "n" terms that finally make it into the query. "Top" in this case being some edit distance threshold or synonymity measure. All the required doc frequency info for IDF is available in RAM on TermEnum which is iterated across anyway and so shouldn't incur any extra disk seeks. So given a query that expands to 1,000 terms the cost of computing the average IDF for that set of terms is surely lost in the cost of 1,000 disk seeks on the TermDocs as part of query evaluation? I need to review the code to remind myself of how it is processed but it feels like it should be cheap.</p> <blockquote><p>average docfreq across all 50 terms even, maybe the top-5 or so is sufficient.</p></blockquote> <p>That could work. The IDF score simply has to be a value that is used as a constant for all the expanded terms in a fuzzy query and, as an added bonus, represents a value that can be usefully contrasted with other query clauses. The averaging policy is just a fall-back position in the rarer situations when a user's original input term has no associated IDF value we can use. If this policy is a performance concern then we could reduce the number of terms as you suggest or just ignore IDF entirely in this case but I'm not sure the averaging costs represent any kind of real performance concern given the IO costs of accessing TermDocs.</p>
</comment>
<comment id="12892315" author="rcmuir" created="Mon, 26 Jul 2010 14:09:31 +0000">
<blockquote><p>If this policy is a performance concern then we could reduce the number of terms as you suggest or just ignore IDF entirely in this case but I'm not sure the averaging costs represent any kind of real performance concern given the IO costs of accessing TermDocs.</p></blockquote> <p>I suggested reducing the number of terms (for the averaging), but also the number of default expansions.<br/> I think in general expanding to 1024 is obscene...</p> <p>But also, if we reduce this number, FuzzyTermsEnum itself gets faster, too.<br/> FuzzyTermsEnum is aware (via an attribute) when the priority queue is filled, and it knows the minimal score to be competitive.<br/> When a certain edit distance is no longer competitive, it optimizes itself by swapping in a more efficient Automaton.<br/> This is safe because the pq's comparator is score, then the term's compareTo (lexicographic order).</p> <p>Simple example: lets say you ask for a max of 1 expansions, but with a fuzzy query of max 1 edit distance.<br/> as soon as the enum finds a term of ed=1, terms of ed=1 are no longer competitive, so it will then try to seek<br/> to an exact match (swapping in an ed=0 automaton) and exit, instead of wasting time seeking to useless terms.</p> <p>its a bit more complicated since the boost value is really not just edit distance but also string length, but I think this illustration works,<br/> its one reason why I think we should try to 'improve the defaults'.</p>
</comment>
<comment id="12892341" author="eksdev" created="Mon, 26 Jul 2010 16:10:58 +0000">
<p>It looks like we have one invariant:<br/> IDF(QueryTerm) &gt;= IDF(Expansion Term) // Preventing better scoring documents with ET then Documents with exact match on QT.</p> <p>Fixing all expansions to IDF(QT) would remove dynamics of the score, making the contribution to the score for all expansions identical. Maybe proportionally scaling IDF of all expansions to preserve mutual IDF dynamics, (relative to IDF(QT) to keep-up with invariant) would work better?</p> <p>In case when there is no matching QueryTerm, why not simply preserving expansion Term IDF, what is averaging good for, performance?</p>
</comment>
<comment id="12892344" author="markh" created="Mon, 26 Jul 2010 16:24:36 +0000">
<blockquote><p>Fixing all expansions to IDF(QT) would remove dynamics of the score, making the contribution to the score for all expansions identical. </p></blockquote> <p>The "boost" property is used by fuzzy/synonyms etc to express the preference for one term variant over another. The effects of this boost setting are demonstrably wiped out when unfiltered IDF of term variants is used (see the attached Junit)</p> <blockquote><p>, why not simply preserving expansion Term IDF,</p></blockquote> <p>See above. The objective is for all variants in an expanded query to share the same IDF setting in order for the boost setting to work as required.</p>
</comment>
<comment id="13226038" author="ijabz" created="Fri, 9 Mar 2012 12:23:43 +0000">
<p>This post explains why this would be useful for Prefix queries as well<br/> <a href="http://stackoverflow.com/questions/9632602/there-is-a-mismatch-between-the-score-for-a-wildcard-match-and-an-exact-match" class="external-link" rel="nofollow">http://stackoverflow.com/questions/9632602/there-is-a-mismatch-between-the-score-for-a-wildcard-match-and-an-exact-match</a></p>
</comment>
<comment id="13226068" author="thetaphi" created="Fri, 9 Mar 2012 13:38:37 +0000">
<p>In general for PrefixQueries (which are contant score), the trick to match exact matches higher is to add the exact match query as an additional SHOULD clause: "exact exact*". This way an exact match scores always higher.</p>
</comment>
<comment id="13226075" author="ijabz" created="Fri, 9 Mar 2012 13:56:27 +0000">
<p>Ive simplified my usecase for this example, the exact match and prefix match are both in the query but Im creating a disjunction query so it takes the max value rather than sum of matches. This is required because the user query actually get searched over multiple fields and I just want the best match I dont need a search term to match more than one field.</p>
</comment>
<comment id="13226080" author="thetaphi" created="Fri, 9 Mar 2012 14:01:30 +0000">
<p>Maybe put exact and prefix in one separate BQ and then add this BQ to the DisjMax.</p>
</comment>
<comment id="13226089" author="ijabz" created="Fri, 9 Mar 2012 14:19:42 +0000">
<p>This would prevent prefix matches from being higher then exact matches but doesn't work for the opposite problem, the differential between exact score match and prefix match only is too great when using constant score for prefix queries, and unreliable when prefix queries are scored. BUt I think my link explains it much more clearly.</p>
</comment>
<comment id="13226094" author="rcmuir" created="Fri, 9 Mar 2012 14:26:10 +0000">
<p>In the example of the link, I'm still lost as to why its really useful.</p> <p>If all queries are prefix queries, what is the use case for that? Maybe really what is needed is <br/> suggester, stemming, decompounding, or some combination of those?</p> <p>If its really some unique use case that isnt one of the above, and every query must be a prefix query,<br/> at least bake it in with edge-ngrams filter at index time for better performance. (and just use termquery)</p>
</comment>
<comment id="13226113" author="ijabz" created="Fri, 9 Mar 2012 14:46:07 +0000">
<p>I think you are missing point here whilst there may be some way I can achieve my aim by changing indexing (heres an only slight outof date example using the actual code <a href="http://svn.musicbrainz.org/search_server/trunk/servlet/src/main/java/org/musicbrainz/search/servlet/DismaxQueryParser.java" class="external-link" rel="nofollow">http://svn.musicbrainz.org/search_server/trunk/servlet/src/main/java/org/musicbrainz/search/servlet/DismaxQueryParser.java</a>) the fact is that it doesn't make sense to fully score fuzzy queries if your query contains exact and fuzzy matches (the current default), and it doesnt make sense to use a constant score either (your suggestion), a default that does score but uses the idf of the search term would give much better default results.</p>
</comment>
<comment id="13226115" author="rcmuir" created="Fri, 9 Mar 2012 14:50:01 +0000">
<blockquote> <p>the fact is that it doesn't make sense to fully score fuzzy queries if your query contains exact and fuzzy matches (the current default), and it doesnt make sense to use a constant score either (your suggestion), a default that does score but uses the idf of the search term would give much better default results.</p></blockquote> <p>IDF is an implementation detail of the similarity in trunk. Some scoring systems don't even use IDF.</p> <p>If you want what you describe: what is the problem? use TopTermsBoostOnlyRewrite and apply the "IDF" or whatever you want of the search-term yourself as the query boost.</p>
</comment>
<comment id="13226122" author="ijabz" created="Fri, 9 Mar 2012 15:04:04 +0000">
<p>Sure, but idf is used by default, my current problem is I dont know how to do code it to use the tf of the search term. But I was really commenting on this query to agree with the op that the default (as of 3.5) does not work well </p>
</comment>
<comment id="13226151" author="ijabz" created="Fri, 9 Mar 2012 15:44:07 +0000">
<p>.. and the patch doesnt seme to work when applies against the version specified of 3.0.2</p>
</comment>
</comments>
<attachments>
<attachment id="12450325" name="LUCENE-2557.patch" size="7519" author="jly" created="Fri, 23 Jul 2010 16:54:56 +0000"/>
<attachment id="12450320" name="idf-scoring-test-case.patch" size="3241" author="jly" created="Fri, 23 Jul 2010 16:25:20 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 23 Jul 2010 16:25:42 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11273</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04pun:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25453</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2585] DirectoryReader.isCurrent might fail to see the segments file during concurrent index changes
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2585</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I could reproduce the issue several times but only by running long and stressfull benchmarks, the high number of files is likely part of the scenario.<br/> All tests run on local disk, using ext3.</p> <p>Sample stacktrace:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>java.io.FileNotFoundException: no segments* file found in org.apache.lucene.store.NIOFSDirectory@/home/sanne/infinispan-41/lucene-directory/tempIndexName: files: _2l3.frq _uz.fdt _1q4.fnm _1q0.fdx _4bc.fdt _v2.tis _4ll.fdx _2l8.tii _ux.fnm _3g7.fdx _4bb.tii _4bj.prx _uy.fdx _3g7.prx _2l7.frq _2la.fdt _3ge.nrm _2l6.prx _1py.fdx _3g6.nrm _v0.prx _4bi.tii _2l2.tis _v2.fdx _2l3.nrm _2l8.fnm _4bg.tis _2la.tis _uu.fdx _3g6.fdx _1q3.frq _2la.frq _4bb.tis _3gb.tii _1pz.tis _2lb.nrm _4lm.nrm _3g9.tii _v0.fdt _2l5.fnm _v2.prx _4ll.tii _4bd.nrm _2l7.fnm _2l4.nrm _1q2.tis _3gb.fdx _4bh.fdx _1pz.nrm _ux.fdx _ux.tii _1q6.nrm _3gf.fdx _4lk.fdt _3gd.nrm _v3.fnm _3g8.prx _1q2.nrm _4bh.prx _1q0.frq _ux.fdt _1q7.fdt _4bb.fnm _4bf.nrm _4bc.nrm _3gb.fdt _4bh.fnm _2l5.tis _1pz.fnm _1py.fnm _3gc.fnm _2l2.prx _2l4.frq _3gc.fdt _ux.tis _1q3.prx _2l7.fdx _4bj.nrm _4bj.fdx _4bi.tis _3g9.prx _1q4.prx _v3.fdt _1q3.fdx _2l9.fdt _4bh.tis _3gb.nrm _v2.nrm _3gd.tii _2l7.nrm _2lb.tii _4lm.tis _3ga.fdx _1pz.fdt _3g7.fnm _2l3.fnm _4lk.fnm _uz.fnm _2l2.frq _4bd.fdx _1q2.fdt _3g7.tis _4bi.frq _4bj.frq _2l7.prx _ux.prx _3gd.fnm _1q4.fdt _1q1.fdt _v1.fnm _1py.nrm _3gf.nrm _4be.fdt _1q3.tii _1q1.prx _2l3.fdt _4lk.frq _2l4.fdx _4bd.fnm _uw.frq _3g8.fdx _2l6.tii _1q5.frq _1q5.tis _3g8.nrm _uw.nrm _v0.tii _v2.fdt _2l7.fdt _v0.tis _uy.tii _3ge.tii _v1.tii _3gb.tis _4lm.fdx _4bc.fnm _2lb.frq _2l6.fnm _3g6.tii _3ge.prx _uu.frq _1pz.fdx _1q2.fnm _4bi.prx _3gc.frq _2l9.tis _3ge.fdt _uy.fdt _4ll.fnm _3gc.prx _1q7.tii _2l5.nrm _uy.nrm _uv.frq _1q6.frq _4ba.tis _3g9.tis _4be.nrm _4bi.fnm _ux.frq _1q1.fnm _v0.fnm _2l4.fnm _4ba.fnm _4be.tis _uz.prx _1q6.fdx _uw.tii _2l6.nrm _1pz.prx _2l7.tis _1q7.fdx _2l9.tii _4lk.tii _uz.frq _3g8.frq _4bb.prx _1q5.tii _1q5.prx _v2.frq _4bc.tii _1q7.prx _v2.tii _2lb.tis _4bi.fdt _uv.nrm _2l2.fnm _4bd.tii _1q7.tis _4bg.fnm _3ga.frq _uu.fnm _2l9.fnm _3ga.fnm _uw.fnm _1pz.frq _1q1.fdx _3ge.fdx _2l3.prx _3ga.nrm _uv.fdt _4bb.nrm _1q7.fnm _uv.tis _3gb.fnm _2l6.tis _1pz.tii _uy.fnm _3gf.fdt _3gc.nrm _4bf.tis _1q5.fnm _uu.tis _4bh.tii _2l5.fdt _1q6.tii _4bc.tis _3gc.tii _3g9.fnm _2l6.fdt _4bj.fnm _uu.tii _v3.frq _3g9.fdx _v0.nrm _2l7.tii _1q0.fdt _3ge.fnm _4bf.fdt _1q6.prx _uz.nrm _4bi.fdx _3gf.fnm _4lm.frq _v0.fdx _4ba.fdt _1py.tii _4bf.tii _uw.fdx _2l5.frq _3g9.nrm _v1.fdt _uw.fdt _4bd.frq _4bg.prx _3gd.tis _1q4.tis _2l9.nrm _2la.nrm _v3.tii _4bf.prx _1q1.nrm _4ba.tii _3gd.fdx _1q4.tii _4lm.tii _3ga.tis _4bf.fnm write.lock _2l8.prx _2l8.fdt segments.gen _2lb.fnm _2l4.fdt _1q2.prx _4be.fnm _3gf.prx _2l6.fdx _3g6.fnm _4bb.fdt _4bd.tis _4lk.nrm _2l5.fdx _2la.tii _4bd.prx _4ln.fnm _3gf.tis _4ba.nrm _v3.prx _uv.prx _1q3.fnm _3ga.tii _uz.tii _3g9.frq _v0.frq _3ge.tis _3g6.tis _4ln.prx _3g7.tii _3g8.fdt _3g7.nrm _3ga.prx _2l2.fdx _2l8.fdx _4ba.prx _1py.frq _uz.fdx _2l3.tii _3g6.prx _v3.fdx _1q6.fdt _v1.nrm _2l2.tii _1q0.tis _4ba.fdx _4be.tii _4ba.frq _4ll.fdt _4bh.nrm _4lm.fdt _1q7.frq _4lk.tis _4bc.frq _1q6.fnm _3g7.frq _uw.tis _3g8.tis _2l9.fdx _2l4.tii _1q4.fdx _4be.prx _1q3.nrm _1q0.tii _1q0.fnm _v3.nrm _1py.tis _3g9.fdt _4bh.fdt _4ll.nrm _4lk.prx _3gd.prx _1q3.tis _1q2.tii _2l2.nrm _3gd.fdt _2l3.fdx _3g6.fdt _3gd.frq _1q1.tis _4bb.fdx _1q2.frq _1q3.fdt _v1.tis _2l8.frq _3gc.fdx _1q1.frq _4bg.frq _4bb.frq _2la.fdx _2l9.frq _uy.tis _uy.prx _4bg.fdx _3gb.prx _uy.frq _1q2.fdx _4lm.prx _2la.prx _2l4.prx _4bg.fdt _4be.frq _1q7.nrm _2l5.prx _4bf.frq _v1.prx _4bd.fdt _2l9.prx _1q6.tis _3g8.fnm _4ln.tis _2l3.tis _4bc.fdx _2lb.prx _3gb.frq _3gf.frq _2la.fnm _3ga.fdt _uz.tis _4bg.nrm _uv.tii _4bg.tii _3g8.tii _4ll.frq _uv.fnm _2l8.tis _2l8.nrm _2l2.fdt _4bj.tis _4lk.fdx _uw.prx _4bc.prx _4bj.fdt _4be.fdx _1q4.frq _uu.fdt _1q1.tii _2l5.tii _2lb.fdt _4bh.frq _3ge.frq _1py.prx _1q5.nrm _v1.fdx _3g7.fdt _4ln.fdt _1q4.nrm _1py.fdt _3gc.tis _4ll.prx _v3.tis _4bf.fdx _1q5.fdx _1q0.prx _4bi.nrm _4ll.tis _2l4.tis _3gf.tii _v2.fnm _uu.nrm _1q0.nrm _4lm.fnm _uu.prx _2l6.frq _4ln.nrm _ux.nrm _3g6.frq _1q5.fdt _4bj.tii _2lb.fdx _uv.fdx _v1.frq at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:634) at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:517) at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:306) at org.apache.lucene.index.SegmentInfos.readCurrentVersion(SegmentInfos.java:408) at org.apache.lucene.index.DirectoryReader.isCurrent(DirectoryReader.java:797) at org.apache.lucene.index.DirectoryReader.doReopenNoWriter(DirectoryReader.java:407) at org.apache.lucene.index.DirectoryReader.doReopen(DirectoryReader.java:386) at org.apache.lucene.index.DirectoryReader.reopen(DirectoryReader.java:348) at org.infinispan.lucene.profiling.LuceneReaderThread.refreshIndexReader(LuceneReaderThread.java:79) at org.infinispan.lucene.profiling.LuceneReaderThread.testLoop(LuceneReaderThread.java:60) at org.infinispan.lucene.profiling.LuceneUserThread.run(LuceneUserThread.java:60) at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908) at java.lang.Thread.run(Thread.java:619) </pre> </div></div>
</description>
<environment/>
<key id="12470757">LUCENE-2585</key>
<summary>
DirectoryReader.isCurrent might fail to see the segments file during concurrent index changes
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="sanne">Sanne Grinovero</reporter>
<labels></labels>
<created>Tue, 3 Aug 2010 20:28:38 +0000</created>
<updated>Sat, 11 Apr 2015 20:44:46 +0000</updated>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="12895027" author="sanne" created="Tue, 3 Aug 2010 20:32:17 +0000">
<p>I'm going to see if I can contribute a patch myself, but I don't think I'll be able to provide a unit test.</p>
</comment>
<comment id="12895046" author="yseeley@gmail.com" created="Tue, 3 Aug 2010 21:29:10 +0000">
<p>Background: via irc we brainstormed that the most likely cause of the exception was that listing the files<br/> in a directory is probably not atomic (at the JVM level) - hence it's possible to miss the segments file in a rapidly changing index.<br/> The simplest fix would seem to be to retry the directory listing a few times if the segments file isn't found.</p>
</comment>
<comment id="12895047" author="mikemccand" created="Tue, 3 Aug 2010 21:30:57 +0000">
<p>Man it's hard to add a comment here. Had to scroll way to the right... silly Jira.</p> <p>The best guess here is that this is due to non-atomicity of listing a directory right? Ie, Lucene, in order to find the most recent segments_N file, lists the directory. But if, as the listing is happening, a commit is done from IndexWriter, writing a new segments_N+1 and removing the old one, it's possible that the directory listing would show no segments file.</p> <p>Lucene then falls back to reading segments.gen, but somehow this is also stale/unusable (probably because another commit kicked off after the dir listing and before we could read segments.gen).</p> <p>I'm not sure offhand how we can fix this...</p> <p>Can you describe the stress test you're running?</p>
</comment>
<comment id="12895059" author="sanne" created="Tue, 3 Aug 2010 22:16:30 +0000">
<p>sure, the test is totally open source; the directory implementation based on Infinispan is hosted as submodule of Infinispan:<br/> <a href="http://anonsvn.jboss.org/repos/infinispan/branches/4.1.x/lucene-directory/" class="external-link" rel="nofollow">http://anonsvn.jboss.org/repos/infinispan/branches/4.1.x/lucene-directory/</a></p> <p>The test is<br/> org.infinispan.lucene.profiling.PerformanceCompareStressTest</p> <p>it is included in the default test suite but disabled in Maven's configuration, so you should run it manually<br/> mvn clean test -Dtest=PerformanceCompareStressTest<br/> (running it requires the jboss.org repositories to be enabled in maven settings)</p> <p>To describe it at higher level: there are 5 IndexRead-ing threads using reopen() before each search, 2 threads writing to the index, 1 additional thread as a coordinator and asserting that readers find what they expect to see in the index.<br/> Exactly the same test scenario is then applied in sequence to RAMDirectory (not having issues), NIOFSDirectory, and 4 differently configured Infinispan directories.<br/> Only the FSDirectory is affected by the issue, and it can never complete the full hour of stresstest succesfully, while all other implementations behave fine.</p> <p>IndexWriter is set to MaxMergeDocs(5000) and setUseCompoundFile(false); the issue is reveled both using SerialMergeScheduler and while using the default merger.</p> <p>During the last execution the test managed to perform 22,192,006 searches and 26,875 writes before hitting the exceptional case.</p> <p>If you deem it useful I'd be happy in contributing a similar testcase to Lucene, but I assume you won't be excited in having such a long running test. Open to ideas to build a simpler one.</p>
</comment>
<comment id="12895060" author="sanne" created="Tue, 3 Aug 2010 22:20:59 +0000">
<p>reformatted the description: all filenames where on the same line making this page hard to use.</p>
</comment>
<comment id="12895236" author="mikemccand" created="Wed, 4 Aug 2010 12:36:28 +0000">
<p>Thanks for the details Sanne! Your Infinispan directories sounds interesting.</p> <p><a href="http://fixunix.com/linux/356378-opendir-readdir-atomicity.html" class="external-link" rel="nofollow">http://fixunix.com/linux/356378-opendir-readdir-atomicity.html</a> is relevant, assuming the JVM is using opendir/readdir on Linux (which I assume it is?).</p> <p>Basically Posix makes no guarantee that opendir/readir will see a "point in time" directory listing. Ie, file add/deletes can be seen out-of-order, much like write operations in different threads in Java if you don't sync.</p> <p>So maybe we should add an additional retry cycle in the case that we don't find a segments file? (We already have various retries if we do see a segments file in the listing, but, we hit an IOExc when trying to load it).</p> <p>Sanne do you want to work out a patch?</p>
</comment>
<comment id="12922751" author="sanne" created="Tue, 19 Oct 2010 22:22:16 +0000">
<p>Hello, sorry for the late answer, for some reason I didn't see the notification.</p> <p>Sure I'm very interested in providing a patch for this.<br/> I've to say I was only able to reproduce this issue in synthetic benchmarks, so I thought it might be <b>very</b> unlikely in real world scenarios, but now I actually received reports of people having issues with this during real use cases, so I'll definitely give another look.</p> <p>Thanks for the pointers!</p>
</comment>
<comment id="12926249" author="rcmuir" created="Fri, 29 Oct 2010 12:47:14 +0000"><p>moving out... there is no patch</p></comment>
<comment id="12983618" author="shaie" created="Wed, 19 Jan 2011 08:50:35 +0000"><p>There is no patch, moving to 3.2</p></comment>
<comment id="13043540" author="rcmuir" created="Fri, 3 Jun 2011 16:40:40 +0000"><p>bulk move 3.2 -&gt; 3.3</p></comment>
<comment id="13237028" author="hossman" created="Fri, 23 Mar 2012 20:28:20 +0000">
<p>Bulk changing fixVersion 3.6 to 4.0 for any open issues that are unassigned and have not been updated since March 19.</p> <p>Email spam suppressed for this bulk edit; search for hoss20120323nofix36 to identify all issues edited</p>
</comment>
<comment id="13717082" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:52 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970844" author="thetaphi" created="Wed, 16 Apr 2014 12:54:41 +0000"><p>Move issue to Lucene 4.9.</p></comment>
<comment id="14491191" author="deshpandeashu" created="Sat, 11 Apr 2015 20:44:46 +0000">
<p>I seem to be hitting this issue in my application. The simplified use case is: we have about 1000 new documents being processed simultaneously by multiple threads and multiple threads potentially try to store/read the same document, but with different data. One thread searches, finds nothing and updates the document; and at the same time other thread tries to search for it before update and ends up not finding it, thus creating a duplicate document with different data instead of having a single merged document. This happens very frequently and we end up having over 50% duplicates at times. This causes an issue in search.</p> <p>Is there any fix available for this issue? </p> <p>Thanks and Regards,<br/> Ashutosh.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12739477">LUCENE-5925</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 3 Aug 2010 21:29:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>2935</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04pof:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25425</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2527] FieldCache.getTermsIndex should cache fasterButMoreRAM=true|false to the same cache key
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2527</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>When we cutover FieldCache to use shared byte[] blocks, we added the boolean fasterButMoreRAM option, so you could tradeoff time/space.</p> <p>It defaults to true.</p> <p>The thinking is that an expert user, who wants to use false, could pre-populate FieldCache by loading the field with false, and then later when sorting on that field it'd use that same entry.</p> <p>But there's a bug &#8211; when sorting, it then loads a 2nd entry with "true". This is because the Entry.custom in FieldCache participates in equals/hashCode.</p>
</description>
<environment/>
<key id="12468558">LUCENE-2527</key>
<summary>
FieldCache.getTermsIndex should cache fasterButMoreRAM=true|false to the same cache key
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mikemccand">Michael McCandless</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Mon, 5 Jul 2010 12:35:29 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:42 +0000</updated>
<version>4.0-ALPHA</version>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/search</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12914386" author="mikemccand" created="Fri, 24 Sep 2010 09:23:40 +0000">
<p>I wonder if the pending improvements to FieldCache will handle preventing this FC insanity?</p>
</comment>
<comment id="12914990" author="mikemccand" created="Sun, 26 Sep 2010 16:09:36 +0000">
<p>I believe <a href="https://issues.apache.org/jira/browse/LUCENE-2649" title="FieldCache should include a BitSet for matching docs" class="issue-link" data-issue-key="LUCENE-2649"><del>LUCENE-2649</del></a> has fixed this, in that you will no longer get a double entry, and so whoever first populates this key "wins".</p> <p>I think this is the right policy (vs a 2nd requires upgrading to fasterButMoreRAM=true, in place).</p> <p>So I think all we should do here is add a test case that asserts that you don't get a double entry.</p>
</comment>
<comment id="12915058" author="ryantxu" created="Sun, 26 Sep 2010 22:26:10 +0000">
<p>Yes, <a href="https://issues.apache.org/jira/browse/LUCENE-2649" title="FieldCache should include a BitSet for matching docs" class="issue-link" data-issue-key="LUCENE-2649"><del>LUCENE-2649</del></a> puts fasterButMoreRAM= true or false in the same entry. Whatever is called first is what gets used (without warning)</p> <p>One option is to 'upgrade' the cache value &#8211; but I'm not sure which one is the upgrade. Perhaps the last one that you ask for? If that is the case, would we need another option that says "I would like it fasterButMoreRAM unless you already have it cached different"</p> <p>I think documenting that the setting needs to be used consistently is good. If we have an error stream, then this would be an appropriate place to log an error/warning.</p>
</comment>
<comment id="13717056" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:47 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970850" author="thetaphi" created="Wed, 16 Apr 2014 12:54:42 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12474983">LUCENE-2665</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sun, 26 Sep 2010 22:26:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11300</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04q1b:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25483</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2525] make MultiPhraseQuery's UnionDocsAndPositionsEnum public
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2525</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Somehow during flex development, we (unnecessarily, I think) lost the public oal.index.MultiTermPositions, absorbing it into MultiPhraseQuery as a private class. We should move it back to oal.index, and make it public again.</p>
</description>
<environment/>
<key id="12468518">LUCENE-2525</key>
<summary>
make MultiPhraseQuery's UnionDocsAndPositionsEnum public
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mikemccand">Michael McCandless</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Sun, 4 Jul 2010 17:06:49 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:32 +0000</updated>
<version>4.0-ALPHA</version>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="12885053" author="mikemccand" created="Sun, 4 Jul 2010 17:17:16 +0000"><p>Attached simple patch; I'll commit shortly.</p></comment>
<comment id="12885056" author="thetaphi" created="Sun, 4 Jul 2010 17:37:06 +0000">
<p>As far as I remember we left out those combined enums for now, as we have no sultion, how to handle Attributes with it. This is the same as MultiTermsEnum &amp; Co. See <a href="https://issues.apache.org/jira/browse/LUCENE-2154" title="Need a clean way for Dir/MultiReader to &quot;merge&quot; the AttributeSources of the sub-readers" class="issue-link" data-issue-key="LUCENE-2154">LUCENE-2154</a>.</p>
</comment>
<comment id="12885058" author="mikemccand" created="Sun, 4 Jul 2010 17:47:55 +0000">
<p>Ahh so that was a reason...</p> <p>But: I don't think this is a reason to make this class private, now? First off, we have at least one user who was using it and now misses it... second off, we are uncertain still how <a href="https://issues.apache.org/jira/browse/LUCENE-2154" title="Need a clean way for Dir/MultiReader to &quot;merge&quot; the AttributeSources of the sub-readers" class="issue-link" data-issue-key="LUCENE-2154">LUCENE-2154</a> will/should be solved, or even when it will be.</p> <p>In the worst case, we would simply declare (in the future) that this UnionDocsAndPositions cannot handle attrs at all, and it'll still be a useful class, right?</p>
</comment>
<comment id="13716973" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:31 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970789" author="thetaphi" created="Wed, 16 Apr 2014 12:54:32 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<attachments>
<attachment id="12448650" name="LUCENE-2525.patch" size="12826" author="mikemccand" created="Sun, 4 Jul 2010 17:17:15 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sun, 4 Jul 2010 17:37:06 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>2901</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04q1r:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25485</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2520] Unsafe synchronization in CachingWrapperFilterHelper
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2520</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>CachingWrapperFilterHelper has unsaft synchronization as follow:</p> <p> public DocIdSet getDocIdSet(IndexReader reader) throws IOException {<br/> if (cache == null) </p> { cache = new WeakHashMap(); } <p> synchronized (cache) </p> { ... } <p>It is not safe to assgine a new object to cache before synchronizing on. it may results sycnchronize on two different object if the method is called concurrently when cache =null.</p>
</description>
<environment/>
<key id="12468215">LUCENE-2520</key>
<summary>
Unsafe synchronization in CachingWrapperFilterHelper
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="cashcrop">Wendy Feng</reporter>
<labels></labels>
<created>Wed, 30 Jun 2010 01:49:57 +0000</created>
<updated>Wed, 30 Jun 2010 06:23:45 +0000</updated>
<version>3.0.1</version>
<component>core/search</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<timeoriginalestimate seconds="7200">2h</timeoriginalestimate>
<timeestimate seconds="7200">2h</timeestimate>
<comments>
<comment id="12883803" author="thetaphi" created="Wed, 30 Jun 2010 06:23:45 +0000">
<p>We discussed several times about that, this is not a problem here, as its a cache and there is no guarantee needed that every object only exists one time. For speed issues in this filter we decided to keep it like that. There are other places in Lucene using caches working the same way.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 30 Jun 2010 06:23:45 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3677</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04q2v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25490</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2145] TokenStream.close() is called multiple times per TokenStream instance
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2145</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I have a Tokenizer that uses an external resource. I wrote this Tokenizer so that the external resource is released in its close() method.<br/> This should work because close() is supposed to be called when the caller is done with the TokenStream of which Tokenizer is a subclass. TokenStream's API document &lt;<a href="http://lucene.apache.org/java/2_9_1/api/core/org/apache/lucene/analysis/TokenStream.html" class="external-link" rel="nofollow">http://lucene.apache.org/java/2_9_1/api/core/org/apache/lucene/analysis/TokenStream.html</a>&gt; states:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>6. The consumer calls close() to release any resource when finished using the TokenStream. </pre> </div></div> <p>When I used my Tokenizer from Solr 1.4.0, it did not work as expected. An error analysis suggests an instance of my Tokenizer is used even after close() is called and the external resource is released. After a further analysis it seems that it is not Solr but Lucene itself that is breaking the contract.</p> <p>This is happening in two places.</p> <p>src/java/org/apache/lucene/queryParser/QueryParser.java:</p> <p> protected Query getFieldQuery(String field, String queryText) throws ParseException {<br/> // Use the analyzer to get all the tokens, and then build a TermQuery,<br/> // PhraseQuery, or nothing based on the term count</p> <p> TokenStream source;<br/> try {<br/> source = analyzer.reusableTokenStream(field, new StringReader(queryText));<br/> source.reset();<br/> .<br/> .<br/> .<br/> try </p> { // rewind the buffer stream buffer.reset(); // close original stream - all tokens buffered source.close(); // &lt;---- HERE } <p>src/java/org/apache/lucene/index/DocInverterPerField.java</p> <p>public void processFields(final Fieldable[] fields,<br/> final int count) throws IOException </p> { ... } <p> finally </p> { stream.close(); } <p>Calling close() would be good if the TokenStream is not reusable one. But when it is reusable, it might be used again, so the resource associated with the TokenStream instance should not be released. close() needs to be called selectively only when it know it is not going to be reused. </p>
</description>
<environment><p>Solr 1.4.0</p></environment>
<key id="12443054">LUCENE-2145</key>
<summary>
TokenStream.close() is called multiple times per TokenStream instance
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tkurosaka">KuroSaka TeruHiko</reporter>
<labels></labels>
<created>Fri, 11 Dec 2009 01:33:25 +0000</created>
<updated>Thu, 13 Jun 2013 15:02:44 +0000</updated>
<version>2.9</version>
<version>2.9.1</version>
<version>3.0</version>
<component>core/index</component>
<component>core/queryparser</component>
<due/>
<votes>1</votes>
<watches>2</watches>
<comments>
<comment id="13430554" author="bbdouglas-basis" created="Tue, 7 Aug 2012 19:28:01 +0000">
<p>This looks to be intentional. Calling close() on the token stream is designed to release the Reader, which should happen as soon as you know you are done with it. <a href="https://issues.apache.org/jira/browse/LUCENE-2387" title="IndexWriter retains references to Readers used in Fields (memory leak)" class="issue-link" data-issue-key="LUCENE-2387"><del>LUCENE-2387</del></a> explains the negative side-effects of holding onto Readers too long. Calling analyzer.reusableTokenStream() the next time will provide a new Reader. </p> <p>If the external resource is tied to the Reader, then it should also be released when TokenStream.close() is called. Only that data that is independent of current text should survive to the next reusableTokenStream() call.</p>
</comment>
<comment id="13681129" author="bmargulies" created="Wed, 12 Jun 2013 11:27:45 +0000">
<p>However, that leaves no way to clean up resources.</p>
</comment>
<comment id="13682144" author="bmargulies" created="Thu, 13 Jun 2013 11:47:12 +0000">
<p>At the risk of proving to Rob that I've lost my mind, I want to offer an argument why this might not really be a bug.</p> <p>Think about the lifecycle of a TokenStream in Lucene, (as opposed to Solr). Nothing in the library calls Tokenizer constructors, as far as I know. Applications create TokenStreams and pass them into the library to use in analyzing fields. So, if a particular application is using a particular TokenStream that requires cleanup, why isn't it up to the application to clean it up?</p> <p>According to this analysis, if there's a bug here, it is that the use of the name 'close()' for the current method is confusing. If it were called <em>closeReader</em>, then the name '<em>close</em>' would be available for use in particular implementations that needed cleanup, but it would still be up to those applications to call it.</p>
</comment>
<comment id="13682316" author="rcmuir" created="Thu, 13 Jun 2013 15:02:44 +0000">
<p>I think its a bug: someone made a non-reusable API reusable and that caused the issue.</p> <p>It would be better to adjust to fit, e.g. close readers in end() or something like that, and let close() be close()</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12649895">SOLR-4872</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 7 Aug 2012 19:28:01 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3668</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04slj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25898</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2172] lucli in contrib lacking run.sh</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2172</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The README in contrib/lucli is unhelpful. It calls for a run of ant, but there's no source or build, and it describes a run.sh, but there's none of them.</p> <p>It has dependencies that aren't mentioned in the README and aren't provided, except in the passing reference to jline.</p>
</description>
<environment/>
<key id="12443856">LUCENE-2172</key>
<summary>lucli in contrib lacking run.sh</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="bmargulies">Benson Margulies</reporter>
<labels>
<label>newdev</label>
</labels>
<created>Sun, 20 Dec 2009 00:26:34 +0000</created>
<updated>Mon, 21 Apr 2014 21:45:43 +0000</updated>
<version>2.9.1</version>
<component>modules/other</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12793093" author="clofresh" created="Mon, 21 Dec 2009 06:17:32 +0000">
<p>For some reason the missing files are in the source tarball but not the binary tarball.</p>
</comment>
<comment id="13184792" author="joecabrera" created="Thu, 12 Jan 2012 07:54:15 +0000">
<p>The build.xml builds correctly with ant. Is this still a problem?</p>
</comment>
<comment id="13976087" author="joecabrera" created="Mon, 21 Apr 2014 21:45:43 +0000"><p>I'm guessing this got fixed?</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 21 Dec 2009 06:17:32 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3688</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04sfj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25871</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2154] Need a clean way for Dir/MultiReader to "merge" the AttributeSources of the sub-readers
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2154</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The flex API allows extensibility at the Fields/Terms/Docs/PositionsEnum levels, for a codec to set custom attrs.</p> <p>But, it's currently broken for Dir/MultiReader, which must somehow share attrs across all the sub-readers. Somehow we must make a single attr source, and tell each sub-reader's enum to use that instead of creating its own. Hopefully Uwe can work some magic here <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</description>
<environment/>
<key id="12443139">LUCENE-2154</key>
<summary>
Need a clean way for Dir/MultiReader to "merge" the AttributeSources of the sub-readers
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Fri, 11 Dec 2009 20:30:24 +0000</created>
<updated>Wed, 16 Apr 2014 12:54:40 +0000</updated>
<version>4.0-ALPHA</version>
<fixVersion>4.9</fixVersion>
<fixVersion>master</fixVersion>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12789571" author="thetaphi" created="Fri, 11 Dec 2009 22:11:46 +0000">
<p>I have an idea, but please don't hurt me, it uses reflection.<br/> What is needed:<br/> Like in the TokenStream BW layer, we had a class called TokenWrapper that implemented all interfaces for basic Tokens but was a wrapper around a Token. This Token was exchangeable.<br/> The idea for this case is:</p> <ul class="alternate" type="square"> <li>DirReader/MultiReader cannot share thesame AttributeSource at all, because e.g. if th DirReader's enum first tries to call next() on on the first enum, the attributes are overriden. If DirrReader then instead also calls next() on the second sub-enum, the data of the first is overriden and cannot be restaured. The idea is now, to have the same Wrapper like TokenWrapper, where the interface impls behind can be exchanged, so the Dir/MultiReader enum just points its own attribute wrapper to the correct attributeset behind.</li> <li>The problem are custom attributes or e.g. BoostAttribute. Nobody knows what attributes may be generated, so it is impossible to create an wrapper for all.<br/> But Java has a solution: <a href="http://java.sun.com/j2se/1.5.0/docs/api/java/lang/reflect/Proxy.html" class="external-link" rel="nofollow">http://java.sun.com/j2se/1.5.0/docs/api/java/lang/reflect/Proxy.html</a>. This class implements a proxy stub for a set of interfaces (you just pass all interfaces needed) andthe returned object can be added to the local DirReader/MultiReaders enum attsource using addAttribute(). You only have to point to a implementation class that gets the Method reference and calls the corresponding method in the current interface (Like the actual Token in TokenWrapper) of the sub-enum.</li> </ul> <p>Sounds like ugly magic, but I have to test how fast it is and how it exactly works with AttributeSource. But the proxy instances could be cached like the TokenStream BW compatibility.</p>
</comment>
<comment id="12789580" author="mikemccand" created="Fri, 11 Dec 2009 22:28:16 +0000">
<p>Good grief... pulling out the heavy guns here!</p>
</comment>
<comment id="12789875" author="thetaphi" created="Sun, 13 Dec 2009 11:30:22 +0000">
<p>I tried to implement that with JDK's reflect.Proxy, which would be really cool, but sucess stopped once I reached the point that the attribute interface implementation must subclass AttributeImpl vs. generated proxies subclass reflect.Proxy.<br/> A fix would be to use cglib, but that would be an external reference. With cglib it would even be possible to autogenerate a fast proxy without reflection at all (e.g. using the Emitter class on the lowest level)!</p> <p>The only current solution I see is to enforce all Attributes not only to implement a *Impl, but also provide a class *Proxy, that respects the above code. But this classes would be so stupid (only contain a modifiable delegate of the same attribute type and forward all methods to it). Cglib code that does this is hard stuff, but simply to implement.</p>
</comment>
<comment id="12831483" author="renaud.delbru" created="Tue, 9 Feb 2010 15:16:01 +0000">
<p>Sorry in advance, maybe what I am saying is out of scope due to my partial understanding of the problem.</p> <p>I have start to look at the problem, in order to be able to use my own attributes from my own DocsAdnPositionsEnum classes.<br/> would it not be simpler to create a MultiAttributeSource that is instantiated in the MultiDocsAndPositionsEnum. At creation time, all the AttributeSource of the subreaders (which are available) will be passed in its constructor. This MultiAttributeSource will delegate the getAttribute call to the right DocsAndPositionsEnum$AttributeSource. </p> <p>There is not a single AttributeSource shared by all the subreader, but each subreader keeps its own AttributeSource. In this way, attributes are not overridden. The MultiAttributeSource is in fact like a Wrapper.</p> <p>One problem is when there is custom attributes, e.g. BoostAttribute. If I understand correctly, if the user tries to access the BoostAttribute, but one of the subreader does not know it, the IllegalArgumentException will be thrown. Under the hood, the MultiAttributeSource can check if the attribute exists on the current subreader, and if not it can rely on a default attribute, or a previously stored attribute (coming from a previous subreader).</p> <p>I am not sure if what I am saying is making some sense. It looks to me too simple to cover all the cases. Are there cases I am not aware of ? Could you give me some examples to make me aware of other problems ?</p>
</comment>
<comment id="12831489" author="thetaphi" created="Tue, 9 Feb 2010 15:25:38 +0000">
<p>The problem is the following:</p> <p>Attributes are not to be retrieved on every call to next(), they are get/added after construction. If you have a consumer of your MultiEnum, it calls attributes().getAttribute exactly one time before start to enumerate tokens/positions/whatever. If your proposed MultiAttributeSource would return the attribute of the first sub-enum, the consumer would stay with this attribute instance forever. If the MultiEnum then changes to another sub-enum, the consumer would not see the new attribute.</p> <p>Because of that the right way is not to have a MultiAttributeSource. What you need are proxy attributes. The Attributes itsself must be proxies, delegating the call to the current enum's corresponding attribute. The same was done in Lucene 2.9 to emulate the backwards compatibility for TokenStreams. The proxy was TokenWrapper. These ProxyAttributes would look exactly like this TokenWrapper impl class.</p>
</comment>
<comment id="12831521" author="renaud.delbru" created="Tue, 9 Feb 2010 16:20:20 +0000">
<p>I see. The problem is to return to the consumer a unique attribute reference when attributes().getAttribute is called, and then updates the references when iterating the enums in order to propagate the attribute changes to the consumer.</p> <p>I am trying to propose a (possible) alternative solution (if I understood the problem correctly), which can avoid reflection, but could potentially need a modification of the Attribute interface.</p> <p>If the MultiAttributeSource will create its own set of unique references for each attribute (the list of different attribute classes can be retrieved by calling the getAttributeClassesIterator() method of the AttributeSource for each subreader, we can then create a list of unique references, one reference for each type of attributes), the goal is then to update these references after each enum iteration or sub-enum change (in order to propagate the changes to the consumer).</p> <p>Unfortunately, I don't see any interface on the Attribute interface to 'copy' a given attribute. Each AttributeImpl could implement this 'copy method', which copies the state of a given attribute of the same class.<br/> Then, in the MultiDocsAndPositionsEnum, after each iteration or each sub-enum change, a call to MultiAttributeSource can be made explicitly to update the unique references of the different attributes. This update method will under the hood (1) check if the sub-enum is aware of the attribute class, (2) get the attribute from the sub-enum, and (3) copy the attribute to the unique attribute reference kept by MultiAttributeSource.</p> <p>Could this solution possibly work ?</p>
</comment>
<comment id="12831646" author="mikemccand" created="Tue, 9 Feb 2010 20:24:20 +0000">
<p>What if we require that all segments are the same codec, if you want to use attributes from a Multi*Enum? (I think this limitation is fine... and if it's not, one could still operate per-segment with different attr impls per segment).</p> <p>This way, every segment would share the same attr impl for a given attr interface?</p> <p>And then couldn't we somehow force each segment to use the same attr impl as the last segment(s)?</p>
</comment>
<comment id="12831938" author="thetaphi" created="Wed, 10 Feb 2010 10:47:16 +0000">
<p>That would work. So the MultiEnum would use its own AttributeSource and passes it downto the sub-enums. For that the ctor of *Enums should allow to pass an AttrubuteSource. I can provide patch.</p>
</comment>
<comment id="12832435" author="thetaphi" created="Thu, 11 Feb 2010 10:04:03 +0000">
<p>Here is a first patch about cglib-generated proxy attributes.</p> <p>In IRC we found out yesterday, that the proposed idea to share the attributes accross all Multi*Enums would result in problems as the call to next() on any sub-enum would overwrite the contents of the attributes of the previous sub-enum which would make TermsEnum not working (because e.g. TermsEnum looks forward by calling next() an all sub-enums and choosing the lowest term to return - after calling each enums next() the attributes of the first enums cannot be restored without captureState &amp; co, as overwritten by the next() call to the last enum).</p> <p>This patch needs cglib-nodep-2.2.jar put into the lib-folder of the checkout <a href="http://sourceforge.net/projects/cglib/files/cglib2/2.2/cglib-nodep-2.2.jar/download" class="external-link" rel="nofollow">http://sourceforge.net/projects/cglib/files/cglib2/2.2/cglib-nodep-2.2.jar/download</a>.</p> <p>It contains a test and that shows how the usage is. The central part is cglib's Enhancer that creates a dynamic class extending ProxyAttributeImpl (which defines the general AttributeImpl methods delegating to the delegate) and implementing the requested Attribute interface using a MethodInterceptor.</p> <p>Please note: This uses no reflection (only during in-memory class file creation, which is only run one time on "loading" the proxy class). The proxy implements MethodInterceptor and uses the fast MethodProxy class (which is also generated by cglib for each proxied method, too) and can invoke the delegated method directly (without reflection) on the delegate.</p> <p>The test verifies everything works and also compares speed by using a TermAttribute natively and proxied. The speed is lower (which is not caused by reflection, but by the MethodInterceptor creating an array of parameters and boxing/unboxing native parameters into the Object[]), but for the testcase I have seen about only 50% more time needed.</p> <p>The generated classes are cached and reused (like DEFAULT_ATTRIBUTE_FACTORY does).</p> <p>To get maximum speed and no external libraries, the code implemented by Enhancer can be rewritten natively using the Apache Harmony java.lang.reflect.Proxy implementation source code as basis. The hardest part in generating bytecode is the ConstantPool in class files. But as the proxy methods are simply delegating and no magic like boxing/unboxing is needed, the generated bytecode is rather simple.</p> <p>One other use-case for these proxies is AppendingTokenStream, which is not possible since 3.0 without captureState (in old TS API it was possible, because you could reuse the same TokenInstance even over the appended streams). In the new TS api, the appending stream must have a "view" on the attributes of the current consuming sub-stream.</p>
</comment>
<comment id="12832447" author="thetaphi" created="Thu, 11 Feb 2010 11:24:13 +0000">
<p>I had some more fun. Made ProxyAttributeSource non-final and added class name policy to also contain the corresponding interface (to make stack traces on errors nicer).</p> <p>Here the example output:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit] DEBUG: Created class org.apache.lucene.util.ProxyAttributeSource$ProxyAttributeImpl$$TermAttribute$$EnhancerByCGLIB$$6100bdf9 for attribute org.apache.lucene.analysis.tokenattributes.TermAttribute [junit] DEBUG: Created class org.apache.lucene.util.ProxyAttributeSource$ProxyAttributeImpl$$TypeAttribute$$EnhancerByCGLIB$$6f89c3ff for attribute org.apache.lucene.analysis.tokenattributes.TypeAttribute [junit] DEBUG: Created class org.apache.lucene.util.ProxyAttributeSource$ProxyAttributeImpl$$FlagsAttribute$$EnhancerByCGLIB$$4668733c for attribute org.apache.lucene.analysis.tokenattributes.FlagsAttribute [junit] Time taken using org.apache.lucene.analysis.tokenattributes.TermAttributeImpl: [junit] 1476.090658 ms for 10000000 iterations [junit] Time taken using org.apache.lucene.util.ProxyAttributeSource$ProxyAttributeImpl$$TermAttribute$$EnhancerByCGLIB$$6100bdf 9: [junit] 1881.295734 ms for 10000000 iterations </pre> </div></div>
</comment>
<comment id="12833095" author="thetaphi" created="Fri, 12 Feb 2010 18:04:01 +0000">
<p>Here the last CGLIB patch for reference.</p> <p>Now the real cool class created using JAVASSIST <a href="http://www.javassist.org/" class="external-link" rel="nofollow">http://www.javassist.org/</a>:<br/> You have to place the latest javassist.jar (Mozilla/LGPL licensed) in the lib/ folder and apply the patch. What it does is the fastest proxy we can think of:<br/> It creates a subclass of ProxyAttributeImpl that implements all methods of the interface natively in bytecode using JAVASSIST's bytecode generation tools (a subset of the Java language spec).</p> <p>The micro-benchmark shows, no difference between proxied and native method - as hotspot removes the extra method call.</p> <p>With Javassist it would even be possible to create classes that implement our interfaces around simple fields that are set by get/setters. Just like Eclipse's create get/set around a private field. That would be really cool. Or we could create combining attributes on the fly, Michael Busch would be excited. All *Impl classes we currently have would be almost obsolete (except TermAttributeImpl, which is rather complex). We could also create dynamic State classes for capturing state...</p> <p>Nice, but a little bit hackish. Maybe we put this first into contrib and supply a ConcenatingTokenStream as demo impl and also other Solr TokenStreams that are no longer easy with the Attributes without proxies (Robert listed some).</p>
</comment>
<comment id="12833121" author="thetaphi" created="Fri, 12 Feb 2010 19:28:22 +0000"><p>Better patch without classloader problems.</p></comment>
<comment id="12833285" author="thetaphi" created="Sat, 13 Feb 2010 01:53:45 +0000"><p>More cool, less casts, more speed.</p></comment>
<comment id="12839808" author="thetaphi" created="Mon, 1 Mar 2010 19:20:58 +0000">
<p>Here the third incarnation of the patch. A little bit more complicated, because directly assemblying bytecode, but much cleaner and without strange parsers. It uses Jakarta BCEL, which is e.g. also used by Apache XALAN XSLTC, and its even included in JDK5 (somehow inofficial in renamed com.sun.internal packages).</p> <p>The approach is the same as with JavAssist, but has several advantages:</p> <ul class="alternate" type="square"> <li>The typing is hard, so all bytecode is generated using real Type classes, retrieved from reflection analysis of the Attribute-Interface to proxy. The method signature is copied.</li> <li>It will not likely break with later VDKs if the class format changes again. The Problem with JavAssist is, that it loads the interface and implementation classes from the bytecode and must analyze it. If we get Java 7 and a new classformat, this will likely break (as e.g. classes loaded from rt.jar may not be analyzed). The BCEL approach does not use loading classes in bytecode, it just uses reflection to generate the proxy method signatures and inserts the byte code to delegate to the delegate.</li> <li>The generated class is not loaded by a hack, but instead a delegating ClassLoader is dynamically created to load the class into the JVM. The classloader delegates all other requests to the proxied Attribute's classloader.</li> </ul> <p>By the way, XALAN is bundling BCEL, in old version, but under the original package names, which may lead to conflics when also bundling in lucene. I would prefer to import the whole source (in parts) like automaton was put into o.a.l.util. But that only, if we really want to do it like this way. But I still think for some TokenStreams this would be a real speed improvement, so we can also make a contrib package out of it.</p>
</comment>
<comment id="12855725" author="thetaphi" created="Sun, 11 Apr 2010 13:54:52 +0000">
<p>Slightly improved patch to correctly work with CharTermAttribute (as it defines methods also defined by ProxyAttributeImpl as final, so override failure).</p>
</comment>
<comment id="13717035" author="steve_rowe" created="Tue, 23 Jul 2013 18:44:43 +0000"><p>Bulk move 4.4 issues to 4.5 and 5.0</p></comment>
<comment id="13970833" author="thetaphi" created="Wed, 16 Apr 2014 12:54:40 +0000"><p>Move issue to Lucene 4.9.</p></comment>
</comments>
<attachments>
<attachment id="12441388" name="ASF.LICENSE.NOT.GRANTED--LUCENE-2154-Jakarta-BCEL.patch" size="21278" author="thetaphi" created="Sun, 11 Apr 2010 13:54:52 +0000"/>
<attachment id="12437501" name="LUCENE-2154-Jakarta-BCEL.patch" size="20691" author="thetaphi" created="Mon, 1 Mar 2010 19:20:58 +0000"/>
<attachment id="12435713" name="LUCENE-2154-cglib.patch" size="14225" author="thetaphi" created="Fri, 12 Feb 2010 18:04:01 +0000"/>
<attachment id="12435757" name="LUCENE-2154-javassist.patch" size="16695" author="thetaphi" created="Sat, 13 Feb 2010 01:53:45 +0000"/>
<attachment id="12435721" name="LUCENE-2154-javassist.patch" size="15630" author="thetaphi" created="Fri, 12 Feb 2010 19:28:22 +0000"/>
<attachment id="12435568" name="LUCENE-2154.patch" size="13973" author="thetaphi" created="Thu, 11 Feb 2010 11:24:13 +0000"/>
<attachment id="12435565" name="LUCENE-2154.patch" size="13463" author="thetaphi" created="Thu, 11 Feb 2010 10:04:03 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>7.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 11 Dec 2009 22:11:46 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11629</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04sjj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25889</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-1964] InstantiatedIndex : TermFreqVector is missing
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-1964</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>TermFrecVector is missing when index is created via constructor.<br/> The constructor expect that fields with TermVector are retreived with the getFields call, but this call returns only stored field, but such fields are never/rarely stored.<br/> I've attached a patch to fix this issue.<br/> I had to add a int freq field to InstantiatedTermDocumentInformation because we are not sure we can use the size of termPositions array as freq information, this information may not be available with TermVector.YES.<br/> Don't know if did well but works with unit test attached.</p>
</description>
<environment><p>java 1.6</p></environment>
<key id="12437631">LUCENE-1964</key>
<summary>InstantiatedIndex : TermFreqVector is missing</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="dcausse">David Causse</reporter>
<labels></labels>
<created>Thu, 8 Oct 2009 18:26:28 +0000</created>
<updated>Sat, 30 Nov 2013 14:01:57 +0000</updated>
<version>2.9</version>
<component>modules/other</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="12763611" author="dcausse" created="Thu, 8 Oct 2009 18:28:58 +0000"><p>Fix the TermVector storing problem.</p></comment>
<comment id="12763627" author="dcausse" created="Thu, 8 Oct 2009 18:49:42 +0000">
<p>My previous patch has broken the Writer, sorry...<br/> I tried to fix but this class is way too much complicated for me, so here my attempt to repair my mistake.</p>
</comment>
<comment id="13835669" author="erickerickson" created="Sat, 30 Nov 2013 12:40:35 +0000"><p>2013 Old JIRA cleanup</p></comment>
</comments>
<attachments>
<attachment id="12421649" name="iiw-regression-fix.patch" size="1101" author="dcausse" created="Thu, 8 Oct 2009 18:49:42 +0000"/>
<attachment id="12421645" name="term-vector-fix.patch" size="16262" author="dcausse" created="Thu, 8 Oct 2009 18:28:58 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 30 Nov 2013 12:40:35 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04tpr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>26079</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2469] inconsistency in SolrParams.get()</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2469</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The returned value from solrParams.get( key ) depends on the implementing class such that:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> modifiableParams = <span class="code-keyword">new</span> ModifiableSolrParams( req.getParams() ); <span class="code-keyword">assert</span> modifiableParams.get(<span class="code-quote">"key"</span>).equals( req.getParams().get(<span class="code-quote">"key"</span>) ); </pre> </div></div> <p>fails for requests built from a SimpleRequestParser or StandardRequestParser where the parameter "key" was given, but empty ( e.g. localhost:8393/select/?key=&amp;para1=val1&amp;parm2=val2 ). </p> <p>The reason is that oas.request.ServletSolrParams returns null for values with length() == 0,<br/> but all other SolrParams implementations return the empty String.</p> <p>This behaviour has also side effects on search components:<br/> Most, if not all, standard search components check for something like</p> <p>if (reg.getParams().getBool(myTriggerParameter, false) ) </p> { ...do what I am supposed to do... } <p>In case of ServletSolrParams getBool() returns the desired and expected "false", all other Implementations throw a "bad request" Exception. <br/> One may argue that suppling a parameter with an empty value indeed is a malformed request, ... </p> <p>Nonetheless I think, the above mentioned equality check should hold true for any request and any SolrParams. </p> <p>Because I cannot oversee the implications, I currently don't have a better suggestion to achieve this, than<br/> to make ServleSolrParams also return the empty String, which is in my opinion counter-intuitive and does not the right thing for the getBool(), getInt() etc. cases. </p>
</description>
<environment><p>all</p></environment>
<key id="12464896">LUCENE-2469</key>
<summary>inconsistency in SolrParams.get()</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="wese">Frank Wesemann</reporter>
<labels></labels>
<created>Wed, 19 May 2010 14:42:10 +0000</created>
<updated>Fri, 11 Jun 2010 12:31:31 +0000</updated>
<component>core/other</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12869152" author="wese" created="Wed, 19 May 2010 14:46:15 +0000">
<p>Chris Hostetter already comment on the mailing list:</p> <blockquote> <p>: this test fails for requests built from a SimpleRequestParser or<br/> : StandardRequestParser where the parameter "key" was given, but empty ( e.g.<br/> : localhost:8393/select/?key=&amp;para1=val1&amp;parm2=val2 ).<br/> : <br/> : The reason is that oas.request.ServletSolrParams returns null for values with<br/> : length() == 0,<br/> : but all other SolrParams implementations return the empty String.</p> <p>Hmmm, can you please open a bug for this?</p> <p>: In case of ServletSolrParams getBool() returns the desired and expected<br/> : "false",<br/> : all other Implementations throw a "bad request" Exception.<br/> : One may argue that suppling a parameter with an empty value indeed is a<br/> : malformed request,</p> <p>that would be my off the cuff opinion &#8211; It seems like ServletSolrParams <br/> is the one with the bug since it isn't correctly retunring the empty <br/> string that was specified by the user (in the case of booleans this may be <br/> handy, but for other params the ineability to specify an empty string to <br/> override the default value could be problematic (ie: if you want <br/> highlighter fragments but you want blank pre/post markup)</p> <p>: Because I cannot oversee the implications, I currently don't have a better<br/> : suggestion to achieve this, than<br/> : to make ServleSolrParams also return the empty String, which is in my opinion<br/> : counter-intuitive and does not the right thing for the getBool(), getInt()</p> <p>there may be ways to address these in particular: treating the empty <br/> string as equivilent to null in the type specific parsing code, but i also <br/> haven't through it through all the way.</p> <p>-Hoss</p> </blockquote>
</comment>
<comment id="12877806" author="markrmiller@gmail.com" created="Fri, 11 Jun 2010 12:31:31 +0000"><p>This should be in the Solr JIRA, not Lucene</p></comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 11 Jun 2010 12:31:31 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11350</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04qe7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25541</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-2438] BytesRef improvements</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2438</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Make BytesRef comparable, document that byte[] should not be null, remove explicit null check + allocation.</p>
</description>
<environment/>
<key id="12463565">LUCENE-2438</key>
<summary>BytesRef improvements</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="yseeley@gmail.com">Yonik Seeley</reporter>
<labels></labels>
<created>Mon, 3 May 2010 14:59:32 +0000</created>
<updated>Tue, 4 May 2010 17:11:00 +0000</updated>
<version>3.1</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="12863380" author="yseeley@gmail.com" created="Mon, 3 May 2010 15:36:11 +0000">
<p>Here's an updated version. Uwe is now also working on this, so I won't make further changes.</p>
</comment>
<comment id="12863381" author="thetaphi" created="Mon, 3 May 2010 15:38:22 +0000">
<p>Here my version with other CTA and NTS changes.</p>
</comment>
<comment id="12863384" author="yseeley@gmail.com" created="Mon, 3 May 2010 15:54:20 +0000">
<p>Looks good.<br/> This is trunk, and currently lucene.internal, so I'll commit shortly.</p>
</comment>
<comment id="12863393" author="yseeley@gmail.com" created="Mon, 3 May 2010 16:31:02 +0000">
<p>Looks like BytesRef.equals() is incorrect... I'll fix.</p> <p>edit: no it's not... I keep seeing length as bytes.length <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="12863414" author="thetaphi" created="Mon, 3 May 2010 17:25:09 +0000">
<p>We should keep the issue open after the commit, as there is more to do. I only changed the code parts that were done by me, maybe Mike has other ones with null checks.</p>
</comment>
<comment id="12863422" author="yseeley@gmail.com" created="Mon, 3 May 2010 17:41:36 +0000">
<p>Another issue is that it looks like some code assumes that offset==0 (and this is reinforced by the naming of BytesRef.length, which we should consider changing to BytesRef.len)</p> <p>Most of these seem sort-of OK... it's after a UTF16TOUTF8, which always makes the offset zero. But if we depend on this, it should be documented.</p> <p>For example:<br/> org.apache.lucene.document.CompressionTools#compressString<br/> org.apache.lucene.index.codecs.pulsing.PulsingPostingsWriterImpl#finishTerm<br/> org.apache.lucene.store.DataOutput#writeString</p>
</comment>
<comment id="12863433" author="yseeley@gmail.com" created="Mon, 3 May 2010 18:07:16 +0000">
<p>I've added javadoc that defines result.offset to be 0 after the UTF16toUTF8 methods.<br/> I also clarified that the byte[] one passes in is directly referenced instead of copied... which implies that BytesRef(byte[]) will cause offset to be 0.</p>
</comment>
<comment id="12863440" author="thetaphi" created="Mon, 3 May 2010 18:17:19 +0000">
<p>I fixed NumericUtils to do the same in rev 940545.</p>
</comment>
</comments>
<attachments>
<attachment id="12443468" name="LUCENE-2438.patch" size="7756" author="thetaphi" created="Mon, 3 May 2010 15:38:22 +0000"/>
<attachment id="12443467" name="LUCENE-2438.patch" size="4151" author="yseeley@gmail.com" created="Mon, 3 May 2010 15:36:11 +0000"/>
<attachment id="12443465" name="LUCENE-2438.patch" size="3571" author="yseeley@gmail.com" created="Mon, 3 May 2010 15:01:33 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 3 May 2010 15:38:22 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3697</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04ql3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25572</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2348] DuplicateFilter incorrectly handles multiple calls to getDocIdSet for segment readers
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2348</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>DuplicateFilter currently works by building a single doc ID set, without taking into account that getDocIdSet() will be called once per segment and only with each segment's local reader.</p>
</description>
<environment/>
<key id="12460311">LUCENE-2348</key>
<summary>
DuplicateFilter incorrectly handles multiple calls to getDocIdSet for segment readers
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="trejkaz">Trejkaz</reporter>
<labels></labels>
<created>Fri, 26 Mar 2010 04:55:31 +0000</created>
<updated>Tue, 25 Nov 2014 20:23:53 +0000</updated>
<version>2.9.2</version>
<component>modules/other</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="12850006" author="trejkaz" created="Fri, 26 Mar 2010 05:05:38 +0000">
<p>Changing to contrib, only just realised it was in that location...</p>
</comment>
<comment id="12874185" author="mikemccand" created="Tue, 1 Jun 2010 19:36:12 +0000">
<p>I don't understand the problem here... looking at 2.9.x's DuplicateFilter, it looks like every call to .getDocIdSet will create a new OpenBitSet, per reader? Can you post a testcase showing the issue?</p>
</comment>
<comment id="12874186" author="mikemccand" created="Tue, 1 Jun 2010 19:36:34 +0000"><p>Clearing fix version.</p></comment>
<comment id="12874370" author="trejkaz" created="Wed, 2 Jun 2010 01:46:28 +0000">
<p>What you describe is precisely the problem. It will deduplicate only over each segment, not over the text index as one would expect given the name of the class.</p>
</comment>
<comment id="12874373" author="trejkaz" created="Wed, 2 Jun 2010 01:53:54 +0000">
<p>I attempted to make a test but it fails with matching 0 instead of matching 2 like I would have expected. Here is the code:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> @Test <span class="code-keyword">public</span> void testDuplicateFilterAcrossSegments() <span class="code-keyword">throws</span> Exception { RAMDirectory index1Dir = <span class="code-keyword">new</span> RAMDirectory(); addDoc(index1Dir); RAMDirectory index2Dir = <span class="code-keyword">new</span> RAMDirectory(); addDoc(index2Dir); IndexReader reader1 = IndexReader.open(index1Dir, <span class="code-keyword">true</span>); IndexReader reader2 = IndexReader.open(index2Dir, <span class="code-keyword">true</span>); IndexReader multi = <span class="code-keyword">new</span> MultiReader(<span class="code-keyword">new</span> IndexReader[] { reader1, reader2 }); IndexSearcher searcher = <span class="code-keyword">new</span> IndexSearcher(multi); TopDocs docs; docs = searcher.search(<span class="code-keyword">new</span> MatchAllDocsQuery(), <span class="code-keyword">null</span>, 10); assertEquals(<span class="code-quote">"Should only be two hits without the filter (just checking)"</span>, 2, docs.totalHits); docs = searcher.search(<span class="code-keyword">new</span> MatchAllDocsQuery(), <span class="code-keyword">new</span> DuplicateFilter(<span class="code-quote">"id"</span>), 10); assertEquals(<span class="code-quote">"Should only be one hit because the second was a duplicate"</span>, 1, docs.totalHits); } <span class="code-keyword">private</span> void addDoc(Directory dir) <span class="code-keyword">throws</span> IOException { IndexWriter writer = <span class="code-keyword">new</span> IndexWriter(dir, <span class="code-keyword">new</span> WhitespaceAnalyzer(), <span class="code-keyword">true</span>, IndexWriter.MaxFieldLength.UNLIMITED); <span class="code-keyword">try</span> { Document doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"id"</span>, <span class="code-quote">"1"</span>, Field.Store.YES, Field.Index.NO)); writer.addDocument(doc); writer.commit(); } <span class="code-keyword">finally</span> { writer.close(); } } </pre> </div></div>
</comment>
<comment id="12874529" author="mikemccand" created="Wed, 2 Jun 2010 10:43:37 +0000">
<blockquote><p>What you describe is precisely the problem. It will deduplicate only over each segment, not over the text index as one would expect given the name of the class.</p></blockquote> <p>Duh, right! You want dedup to apply to the entire index....</p> <p>Ugh, so this has been broken since the cutover to per-segment searching (2.9.x).</p> <p>This is tricky to fix. Somehow DuplicateFilter needs to get ahold of the top reader. It then must run its dup detection against the TermEnum from that top reader, but then when requested per sub-reader, it must return a slice into the bits for the top reader.</p> <p>There's no way, now, given a sub-reader to figure out which parent reader it belongs to... so I think we'd have to change DuplicateFilter to take in the top reader to its ctor? (But this is sort of messy &#8211; no other core/contrib filters have this "state" &#8211; they are normally free to be reused across readers).</p> <p>The only other <span class="error">&#91;big&#93;</span> change I can think of is if we could change the Filter API to be more like Scorer, which does first receive the top reader (since it needs to init measures like idf across all segments), and then separately steps through each sub-reader.</p>
</comment>
<comment id="12874841" author="trejkaz" created="Wed, 2 Jun 2010 22:53:10 +0000">
<p>That change broke nearly all our own filters. We have a lot of filters which get their data from a database where the IDs are across the top-level reader's doc IDs. The DuplicateFilter in contrib was noticed because I was reading about how the Filter API had changed, but when I went to find an example of a filter which (in theory <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/>) would have worked the same way so that I could borrow its solution, I found it was also making the same assumptions we were.</p> <p>Our workaround was the same as described, passing the top-level reader into the constructor and then computing the doc ID set for that, and splitting it up and doing the maths to create the sub-sets for each segment reader.</p> <p>The downside is that now you can only use this Filter instance with this reader, whereas the original DuplicateFilter would have worked on multiple top-level readers happily.</p> <p>Having the top reader passed in before each sub-reader sounds like a good idea. It might make it possible for the same filter instance to support multiple top-level readers as well.</p>
</comment>
<comment id="12881010" author="karthick" created="Tue, 22 Jun 2010 01:55:10 +0000">
<p>Hi, All,</p> <p>Having run into this very issue in our platform, I decided to take a stab at addressing it by defining what is essentially a stateful type of filter (for details, please see <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a>). In my mind, the stateful filter affords an easy and intuitive way for filters such as the DuplicateFilter, to work seamlessly across (the potentially many) segments of the index. </p> <p>In a nutshell, I tweaked the DuplicateFilter so that it accepts a given term if and only if it does not already exist in its "memory". For details, please see the DedupingTermsEnum#accept method in the revised DuplicateFilter class attached here. </p> <p>Note that I took the liberty of incorporating the test case shown above into DuplicateFilterTest, which is included in the patch. Finally, just to clarify, the patch for <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a> must be applied prior to the one attached herein, given that the latter relies on the former. </p> <p>Regards,<br/> Karthick Sankarachary</p>
</comment>
<comment id="12881500" author="trejkaz" created="Wed, 23 Jun 2010 00:51:13 +0000">
<p>That does solve the specific issue I reported (against this specific filter)... I wonder if I need to open a new ticket now for our real problem, because there are two things not solved by that approach:</p> <p>1. If your filterable data is in another store (e.g. a database), then you would still need either some way to get to the top level reader or a way to know what its offset is, but there is no way to get that information from the reader which was passed in.</p> <p>2. If you want to return the <b>newest</b> item instead of the <b>oldest</b> item, it will be too late if getStatefulDocIdSet for an earlier call has already returned the older one.</p>
</comment>
<comment id="12881502" author="karthick" created="Wed, 23 Jun 2010 01:10:42 +0000">
<blockquote><p>1. If your filterable data is in another store (e.g. a database), then you would still need either some way to get to the top level reader or a way to know what its offset is, but there is no way to get that information from the reader which was passed in.</p></blockquote> <p>In theory, one could try to obtain the top-level reader from a segment reader as follows: IndexReader.open(((SegmentReader) reader).directory()), where reader is what is provided to the filter. However, this approach breaks down if the top-level reader spans multiple directory, as is the case with MultiReaders. Besides, the top-level reader that you obtain this way might be a little bit "ahead" of the segment reader's actual parent, given that it was created more recently. Given all that, I've introduced a StatefulFilter#setTopLevelReader method that can be used by the user to explicitly set the top-level reader. If the user chooses not to define the top-level reader, then the StatefulFilter will make a best-effort to guess what the top-level reader should be.</p> <blockquote><p>2. If you want to return the newest item instead of the oldest item, it will be too late if getStatefulDocIdSet for an earlier call has already returned the older one.</p></blockquote> <p>Actually, if you create a DuplicateFilter with keepMode set to KM_USE_FIRST_OCCURRENCE, then it will return the document from the first matching segment, and ignore the ones in subsequent segments (due to its stateful behavior). However, the initial approach will break in the event keepMode is set to KM_USE_LAST_OCCURRENCE. To handle that case, we have the DedupingTermsEnum that the DuplicateFilter defines, return a zero docFreq() in case the last term does not belong to the current segment being filtered. Specifically, the pre-condition for returning a non-zero docFreq is that the "top-level" and total of all the "segment-level" docFreq of the term are the same. In addition,the filter now automatically cleans up after itself (by detecting if the current segment is the last one or not). </p> <p>Also, please note that I changed the DuplicateFilter's default keepMode to KM_USE_FIRST_OCCURRENCE, given that it will potentially, no definitely, save on IO.</p> <p>The revised patches for <a href="https://issues.apache.org/jira/browse/LUCENE-2348" title="DuplicateFilter incorrectly handles multiple calls to getDocIdSet for segment readers" class="issue-link" data-issue-key="LUCENE-2348">LUCENE-2348</a> and <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a> have been attached, and successfully tested for all of the cases described above (on top of the existing ones). </p>
</comment>
<comment id="12882720" author="karthick" created="Fri, 25 Jun 2010 21:26:35 +0000">
<p>Trejkaz,</p> <p>Can you please take a look at the revised patch and the above comment to see if it address all of your concerns?</p> <p>Michael,</p> <p>Given that you have some context around this issue already, can you also review the attached patch in conjunction with that for <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a>, and let me know what you think?</p> <p>Regards,<br/> Karthick </p>
</comment>
<comment id="12933222" author="trejkaz" created="Wed, 17 Nov 2010 22:53:37 +0000">
<p>Finally got around to checking this out today, and it looks good to me. Unfortunate how Lucene has changed so much lately that we can't backport this. <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/> But will just await a release where it appears.</p>
</comment>
<comment id="12933498" author="mikemccand" created="Thu, 18 Nov 2010 17:46:52 +0000">
<p>Unfortunately I think <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a> is too heavyweight, in general (eg it seems to have an unbounded cache of seg -&gt; term -&gt; docFreq).</p>
</comment>
<comment id="12933659" author="trejkaz" created="Fri, 19 Nov 2010 03:28:09 +0000">
<p>Another way of solving this particular issue would be if segment readers knew which top-level reader they came from. Then when we get an unknown one called on our filter, we have a way to crawl to the top and build up the mappings on our side.</p> <p>If a segment reader can exist under more than one parent at the same time, though, it would cause issues for a solution like that.</p>
</comment>
<comment id="12933715" author="rcmuir" created="Fri, 19 Nov 2010 08:02:50 +0000">
<p>Here's my proposed patch for this issue.</p> <p>In truth I don't think this functionality makes much sense as a filter, but I think<br/> we should simply solve it in this way.</p> <p>If the end result is to collapse duplicates in search results, we should seriously<br/> consider pointing people at field collapsing or maybe doing this in a collector.</p>
</comment>
<comment id="12934214" author="trejkaz" created="Sun, 21 Nov 2010 01:34:52 +0000">
<p>Field collapsing has different semantics which don't match those of DuplicateFilter. It's useful if you want to collapse two hits down to one hit, but it doesn't work if you are using DuplicateFilter to filter out previous copies of a document (whether you are working around the issue of Lucene shifting doc IDs when deleting, or simply want to keep the history in case you need it later.) In this situation you want all but one filtered out, whether the one that matches the query matches the filter or not. Initially this might not seem like removing duplicates, but it really is, since you're just removing duplicates based on the "id" field.</p> <p>Similarly, I'm not sure how using a collector would help. There is even a note in HitCollector saying not to look at the document during collection because it will reduce performance by an order of magnitude or more. If you have to look at a field, then you have to look at the document. FieldCache was introduced to try and avoid this, but in practice, it doesn't work once you have tens of millions of documents in your index, unless you have an extraordinary amount of RAM allocated to the JVM (and not every application is a server application!) Even supposing you were willing to take the performance hit, or had a system where you had enough RAM to store the field cache, the collector only receives the ID of the document that hit, it doesn't provide any of the context you need to see which other documents had the same value in the field.</p>
</comment>
<comment id="12935731" author="rcmuir" created="Thu, 25 Nov 2010 11:59:17 +0000">
<p>Trejkaz, i think you are confused.</p> <p>This is only a special case of TopFieldCollector, your notes about Hits/Hitcollector are irrelevant.</p> <p>The situation here is it should never have been a filter in the first place, this is a bad design.<br/> So I plan to commit this patch in a few days, as well as marking @deprecated.</p> <p>If someone wants to later provide a 'replacement' thats fine, but this is contrib, and its not necessary<br/> for us provide one to deprecate problems like this!</p>
</comment>
<comment id="12935748" author="trejkaz" created="Thu, 25 Nov 2010 13:07:42 +0000">
<p>I don't really want to argue good or bad design, because the fact is that it worked, and then Lucene core broke the functionality, and now you are claiming that some kinds of filter shouldn't be done as a filter anymore (what should they be done as, then? I've already said that the other suggestions won't work in any fashion.)</p> <p>But fine.</p> <p>This wasn't the only filter in our system affected by this issue. As long as <a href="https://issues.apache.org/jira/browse/LUCENE-2506" title="A Stateful Filter That Works Across Index Segments" class="issue-link" data-issue-key="LUCENE-2506">LUCENE-2506</a> is put through, though, the rest of our filters which are <em>not</em> "bad design" will still be able to work in the future without hacks on our end to make them work.</p>
</comment>
<comment id="12935753" author="mikemccand" created="Thu, 25 Nov 2010 13:38:07 +0000">
<p>Actually I think Filter is the natural fit for this functionality. </p> <p>You should be able to compute it once, cache it, pass it along with<br/> your Query during searching, etc.</p> <p>Doing this during collection is of course possible, but not ideal<br/> since you waste CPU on the query finding a hit only to then filter it<br/> out. (In fact Filter used to be applied this way!). Plus you must<br/> have the dedup values RAM resident. Especially w/ optos like<br/> <a href="https://issues.apache.org/jira/browse/LUCENE-1536" title="if a filter can support random access API, we should use it" class="issue-link" data-issue-key="LUCENE-1536"><del>LUCENE-1536</del></a> on the horizon, doing this during collection will be even<br/> slower.</p> <p>That said, yes, it's trickier to implement, with the cutover to<br/> per-segment search, since it needs the full reader up front in order<br/> to decide how docs in each segment will be filtered.</p> <p>But I don't consider this a show stopper &#8211; it'd be simple to change<br/> DuplicateFilter to receive the top IR up front, and pre-compute and<br/> cache the bit set for all segments.</p>
</comment>
<comment id="12935765" author="trejkaz" created="Thu, 25 Nov 2010 13:58:30 +0000">
<p>That is exactly the workaround we performed for our own filters, including our private copy of a filter which works like DuplicateFilter. All the ones which need the context now take the reader up-front. The problem now, is that we have to use a different filter instance on each reader. Previously we were caching them globally, and somewhere in the system we are evidently still caching them globally, because one time in a million we find the wrong filter being used on the wrong reader. I am now thinking of making another kind of context-sensitive filter, which can somehow omnisciently know about all readers open in the entire JVM (e.g. we hook the place where we open the top-level reader, and push the information about its structure into some global watch.)</p> <p>I think Robert's comments possibly stem from the misconception that the duplicate filter somehow works like field collapsing. I wrote a test just to illustrate how it actually behaves, just to make sure I wasn't confused myself (since he seemed to think I was...)</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> class TestDuplicateFilter { IndexReader reader; IndexSearcher searcher; @Before <span class="code-keyword">public</span> void setUpSampleData() <span class="code-keyword">throws</span> Exception { RAMDirectory dir = <span class="code-keyword">new</span> RAMDirectory(); IndexWriter writer = <span class="code-keyword">new</span> IndexWriter(dir, <span class="code-keyword">new</span> WhitespaceAnalyzer(), <span class="code-keyword">true</span>, IndexWriter.MaxFieldLength.UNLIMITED); Document doc; doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"id"</span>, <span class="code-quote">"1"</span>, Field.Store.YES, Field.Index.ANALYZED)); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"text"</span>, <span class="code-quote">"a"</span>, Field.Store.YES, Field.Index.ANALYZED)); writer.addDocument(doc); doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"id"</span>, <span class="code-quote">"1"</span>, Field.Store.YES, Field.Index.ANALYZED)); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"text"</span>, <span class="code-quote">"b"</span>, Field.Store.YES, Field.Index.ANALYZED)); writer.addDocument(doc); doc = <span class="code-keyword">new</span> Document(); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"id"</span>, <span class="code-quote">"2"</span>, Field.Store.YES, Field.Index.ANALYZED)); doc.add(<span class="code-keyword">new</span> Field(<span class="code-quote">"text"</span>, <span class="code-quote">"c"</span>, Field.Store.YES, Field.Index.ANALYZED)); writer.addDocument(doc); writer.close(); reader = IndexReader.open(dir, <span class="code-keyword">true</span>); searcher = <span class="code-keyword">new</span> IndexSearcher(reader); } @Test <span class="code-keyword">public</span> void testHitOnOriginal() <span class="code-keyword">throws</span> Exception { Filter filter = <span class="code-keyword">new</span> DuplicateFilter(<span class="code-quote">"id"</span>, DuplicateFilter.KM_USE_FIRST_OCCURRENCE, DuplicateFilter.PM_FULL_VALIDATION); TopDocs docs = searcher.search(<span class="code-keyword">new</span> TermQuery(<span class="code-keyword">new</span> Term(<span class="code-quote">"text"</span>, <span class="code-quote">"a"</span>)), filter, 3); assertEquals(<span class="code-quote">"Expected one hit - matched the original"</span>, 1, docs.totalHits); assertEquals(<span class="code-quote">"Wrong doc hit"</span>, 0, docs.scoreDocs[0].doc); } @Test <span class="code-keyword">public</span> void testHitOnCopy() <span class="code-keyword">throws</span> Exception { Filter filter = <span class="code-keyword">new</span> DuplicateFilter(<span class="code-quote">"id"</span>, DuplicateFilter.KM_USE_FIRST_OCCURRENCE, DuplicateFilter.PM_FULL_VALIDATION); TopDocs docs = searcher.search(<span class="code-keyword">new</span> TermQuery(<span class="code-keyword">new</span> Term(<span class="code-quote">"text"</span>, <span class="code-quote">"b"</span>)), filter, 3); <span class="code-comment">// Field collapsing would <span class="code-keyword">return</span> one hit here, which would be undesirable: </span> assertEquals(<span class="code-quote">"Expected no hits - matched the copy"</span>, 0, docs.totalHits); } } </pre> </div></div>
</comment>
<comment id="12935835" author="rcmuir" created="Thu, 25 Nov 2010 18:37:32 +0000">
<blockquote> <p>I think Robert's comments possibly stem from the misconception that the duplicate filter somehow works like field collapsing. I wrote a test just to illustrate how it actually behaves, just to make sure I wasn't confused myself (since he seemed to think I was...)</p></blockquote> <p>No, I understand exactly how this filter works. which is why my patch, that uses SlowMultiReaderWrapper and forces the index to appear as if it were a single segment, fixes the issue. </p> <blockquote> <p>Actually I think Filter is the natural fit for this functionality.<br/> ...<br/> But I don't consider this a show stopper - it'd be simple to change<br/> DuplicateFilter to receive the top IR up front, and pre-compute and<br/> cache the bit set for all segments.</p></blockquote> <p>So now you contradict yourself. the only way is like you said, in the ctor, <br/> in other words, its forcefully cached. This is <b>unnatural</b> !</p> <p>We should deprecate this functionality.</p> <p>If someone wants to make a "DuplicateBitSetBuilder" that is a factory for creating a BitSet,<br/> to me that is more natural and obvious as to what is going on.</p> <p>if its not doing the work in getdocidset, it shouldn't extend Filter!</p>
</comment>
<comment id="12935894" author="trejkaz" created="Thu, 25 Nov 2010 22:23:45 +0000">
<p>It used to do the work in getDocIdSet() - it wasn't us who broke that, it was Lucene core!</p>
</comment>
<comment id="12935970" author="mikemccand" created="Fri, 26 Nov 2010 10:53:19 +0000">
<blockquote><p>if its not doing the work in getdocidset, it shouldn't extend Filter!</p></blockquote> <p>I don't think we can or should dictate that.</p> <p>I think it's fair game for a Filter to compute/cache whatever it<br/> wants. The only requirement for Filter is that it implement<br/> getDocIdSet. Where it does its work, what it's storing in its<br/> instance, etc., is up to it.</p> <p>Sure, we strive for a strong separation of "computing the bits" vs<br/> "caching them", but for some cases that ideal is not feasible.</p> <p>In fact in this case the filter is so costly to build that no<br/> realistic app can possibly rely on the filter without first wrapping<br/> it in CachingWrapperFilter. So I see no harm in conflating caching<br/> with this. We could rename it to CachingDuplicateFilter. In fact we<br/> could factor out the FilterCache utility class now inside<br/> CachingWrapperFilter and make it easily reused by other filters like<br/> this one that need to compute &amp; cache right off.</p> <p>This would also be cleaner if we change the filter API so getDocIdSet<br/> receives the top reader and docBase in addition to the sub; this way a<br/> CachingDuplicateFilter instance could be reused across reopened top<br/> readers.</p> <blockquote> <p>If someone wants to make a "DuplicateBitSetBuilder" that is a factory for creating a BitSet,<br/> to me that is more natural and obvious as to what is going on.</p></blockquote> <p>That sounds good... but how would it work? Ie how would an app tie<br/> that into a Filter?</p>
</comment>
<comment id="13212391" author="trejkaz" created="Tue, 21 Feb 2012 05:55:03 +0000">
<p>The IndexReaderContext API in Lucene trunk looks like a reasonable solution to this problem. It is now possible to figure out the docBase relative to the top-level reader, which allows putting the work back into getDocIdSet.</p>
</comment>
<comment id="13212423" author="thetaphi" created="Tue, 21 Feb 2012 07:31:52 +0000">
<p>The new AtomicReaderContexts passed to getDocIdSet are exactly made for this problem.</p>
</comment>
<comment id="14225148" author="s4ke" created="Tue, 25 Nov 2014 20:23:53 +0000">
<p>any update on this? Or should I use lucene grouping for this?</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="12310040">
<name>Required</name>
<outwardlinks description="requires">
<issuelink>
<issuekey id="12467521">LUCENE-2506</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12459980" name="LUCENE-2348.patch" size="2123" author="rcmuir" created="Fri, 19 Nov 2010 08:02:50 +0000"/>
<attachment id="12448086" name="LUCENE-2348.patch" size="18603" author="karthick" created="Fri, 25 Jun 2010 19:18:35 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 1 Jun 2010 19:36:12 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>11448</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04r4n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25660</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-2280] IndexWriter.optimize() throws NullPointerException
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-2280</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I am using lucene 2.3.2 search APIs for my application, i am indexing 45GB database which creates approax 200MB index file, after finishing the indexing and while running optimize() i can see NullPointerExcception thrown in my log and index file is getting corrupted, log says</p> <p>------------------------------------------------------------------------<br/> Caused by: <br/> java.lang.NullPointerException<br/> at org.apache.lucene.store.BufferedIndexOutput.writeBytes(BufferedIndexOutput.java:49)<br/> at org.apache.lucene.store.IndexOutput.writeBytes(IndexOutput.java:40)<br/> at org.apache.lucene.index.SegmentMerger.mergeNorms(SegmentMerger.java:566)<br/> at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:135)<br/> at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:3273)<br/> at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:2968)<br/> at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:240)<br/> ------------------------------------------------------------------------<br/> and this is happening quite frequently, although I am not able to reproduce it on demand, I saw an issue logged which is some what related to mine issue (<a href="http://mail-archives.apache.org/mod_mbox/lucene-solr-user/200809.mbox/%3C6E4A40DB-5EFC-42DA-A857-D59F4EC3496B@mikemccandless.com%3E" class="external-link" rel="nofollow">http://mail-archives.apache.org/mod_mbox/lucene-solr-user/200809.mbox/%3C6E4A40DB-5EFC-42DA-A857-D59F4EC3496B@mikemccandless.com%3E</a>) but the only difference here is I am not using Store.Compress for my fields, i am using Store.NO instead. please note that I am using IBM JRE for my application.</p> <p>Is this an issue with lucene?, if yes it is fixed in which version?</p>
</description>
<environment><p>Win 2003, lucene version 2.3.2, IBM JRE 1.6</p></environment>
<key id="12457120">LUCENE-2280</key>
<summary>IndexWriter.optimize() throws NullPointerException</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="4" iconUrl="https://issues.apache.org/jira/images/icons/statuses/reopened.png" description="This issue was once resolved, but the resolution was deemed incorrect. From here issues are either marked assigned or resolved.">Reopened</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="r_n7">Ritesh Nigam</reporter>
<labels>
<label>IndexWriter</label>
<label>NPE</label>
<label>optimize</label>
</labels>
<created>Tue, 23 Feb 2010 07:05:17 +0000</created>
<updated>Sat, 30 Nov 2013 14:04:12 +0000</updated>
<version>2.3.2</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="12837204" author="mikemccand" created="Tue, 23 Feb 2010 11:46:50 +0000">
<p>Are you sure you're using a stock version 2.3.2 of Lucene?</p> <p>I ask because... the line numbers in SegmentMerger (specifically 566) don't correlate to 2.3.2. The other line numbers do match. It's odd.</p> <p>But looking at the code I don't see how either of the arrays being passed to System.arraycopy can be null.</p> <p>Can you turn on IndexWriter's infoStream and capture &amp; post the output?</p> <p>It's also strange that this leads to index corruption; it shouldn't (the merge should just fail, and the index should be untouched). Can you run CheckIndex on the index and post what corruption it uncovers.</p> <p>Does this happen in a Sun JRE?</p>
</comment>
<comment id="12837744" author="r_n7" created="Wed, 24 Feb 2010 11:23:33 +0000">
<p>Are you sure you're using a stock version 2.3.2 of Lucene?</p> <ul class="alternate" type="square"> <li>Yes, I checked the manifest of the jar.</li> </ul> <p>I ask because... the line numbers in SegmentMerger (specifically 566) don't correlate to 2.3.2. The other line numbers do match. It's odd.</p> <p>But looking at the code I don't see how either of the arrays being passed to System.arraycopy can be null.</p> <p>Can you turn on IndexWriter's infoStream and capture &amp; post the output?</p> <ul class="alternate" type="square"> <li>I have turned on the infostream for IndexWriter, it will take some time to get the result. once I get the result I will post that.</li> </ul> <p>It's also strange that this leads to index corruption; it shouldn't (the merge should just fail, and the index should be untouched). Can you run CheckIndex on the index and post what corruption it uncovers.</p> <ul class="alternate" type="square"> <li>Here index corruption I mean that the main index file is getting deleted and search is not returning expected result. Hence there is no index file exists after the NullPointerExcepton, I cannot run CheckIndex.</li> </ul> <p>Does this happen in a Sun JRE?</p> <ul class="alternate" type="square"> <li>I have not yet tested the same scenario on Sun JRE till now.</li> </ul>
</comment>
<comment id="12837799" author="r_n7" created="Wed, 24 Feb 2010 14:24:16 +0000">
<p>Attaching the lucene.jar which i am using for my application.</p>
</comment>
<comment id="12837800" author="r_n7" created="Wed, 24 Feb 2010 14:25:42 +0000"><p>lucene.jar my application is using</p></comment>
<comment id="12837892" author="mikemccand" created="Wed, 24 Feb 2010 17:23:29 +0000">
<p>Indeed that JAR is identical to 2.3.2. Weird. Not sure why the line number doesn't line up. Irks me.</p> <blockquote><p>Here index corruption I mean that the main index file is getting deleted and search is not returning expected result. Hence there is no index file exists after the NullPointerExcepton, I cannot run CheckIndex.</p></blockquote> <p>That's even stranger &#8211; nothing should get deleted because a merge fails. Is it possible your app has an exception handler doing this? Or maybe this is a brand new index, and it doesn't get properly closed (ie, no commit) when this exception is hit? If not... can you provide more details? An exception like this should have no impact on the original index.</p> <p>Please post the infoStream output when you get it, and report back whether this happens on Sun's JVM. But I still can't see how either of the arrays could be null here... this is a weird one.</p> <p>Are you using the latest updates to the IBM 1.6 JRE?</p>
</comment>
<comment id="12840660" author="r_n7" created="Wed, 3 Mar 2010 13:55:07 +0000">
<p>Sorry for the delayed response but i was trying to collect some data, I still have to wait for the log created by lucene APIs after turning on infostream, i will post that log file as soon as i get it. To answer your questions, i am running on Windows 2003 server with IBM JRE 1.6 and I am trying to index a database that is about 45 GB in size. On Unix, i am not facing this issue.</p> <p>With the lucene logging on, i waited for about 2 days for the NPE to reoccur, but it did not happen. I was tyring with the stock jar file of lucene 2.3.2. However, indexing failed again and the index file was again deleted. Looking into the logs this time, I found the following exceptions:</p> <p>16:06:48 03/01/2010: Fatal error while indexing CRs.<br/> Stack trace: java.io.FileNotFoundException: index&#95;21f.fdt (The system cannot find the file specified.)<br/> at java.io.RandomAccessFile.open(Native Method)<br/> at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:218)<br/> at org.apache.lucene.store.FSDirectory$FSIndexInput$Descriptor.&lt;init&gt;(FSDirectory.java:506)<br/> at org.apache.lucene.store.FSDirectory$FSIndexInput.&lt;init&gt;(FSDirectory.java:536)<br/> at org.apache.lucene.store.FSDirectory.openInput(FSDirectory.java:445)<br/> at org.apache.lucene.store.FSDirectory.openInput(FSDirectory.java:440)<br/> at org.apache.lucene.index.CompoundFileWriter.copyFile(CompoundFileWriter.java:206)<br/> at org.apache.lucene.index.CompoundFileWriter.close(CompoundFileWriter.java:173)<br/> at org.apache.lucene.index.DocumentsWriter.createCompoundFile(DocumentsWriter.java:576)<br/> at org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:2708)<br/> at org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:2539)<br/> at org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:1222)<br/> at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1196)<br/> at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1164)</p> <p>I am not sure if deletion of the index file when these exceptions are thrown, is the right behaviour. </p> <p>I am re-running my test to try and reproduce the NPE issue which i had reported earlier and i intend to pass on the logs to you as soon as i have it. However, are you aware of any issue that a combination of IBM JRE + Windows 2003 server would have with lucene?</p> <p>As far as the code is concern I am closing the indexwriter in finally block, when is thrown I am logging it in catch block and then finally closing the indexwriter.</p>
</comment>
<comment id="12842244" author="mikemccand" created="Sat, 6 Mar 2010 10:53:24 +0000">
<blockquote><p>However, indexing failed again and the index file was again deleted. </p></blockquote> <p>Are you calling .commit() periodically? It's odd, otherwise, that you have no index on hitting any problem. (It's not necessary to call commit until the very end, if you don't need readers to see the ongoing changes, don't need the durability, etc.).</p> <blockquote><p>I am not sure if deletion of the index file when these exceptions are thrown, is the right behaviour.</p></blockquote> <blockquote><p>Stack trace: java.io.FileNotFoundException: index_21f.fdt (The system cannot find the file specified.)</p></blockquote> <p>Lucene isn't "intentionally" deleting files that are referenced by the commit. But if you're not committing during the whole IW session, then you'd see no index at the end.</p> <p>But, this FNFE is not expected in any event. Seeing the full infoStream leading to this may help...</p> <p>That FNFE is happening as IW tries to build the CFS of the segment flushed during close.</p> <p>Are you using autoCommit=true or false?</p> <p>The fact that this only happens on Windows is telling.... is there a virus checker running on this machine?</p> <p>It'd also be good to know if this still happens on newer versions of Lucene.</p>
</comment>
<comment id="12842657" author="r_n7" created="Mon, 8 Mar 2010 13:51:25 +0000">
<p>I checked the documentation of IndexWriter in 2.3.2, API commit() is not available with this version (I think it is introduced in 2.4), I am not explicitely setting autoCommit, so it should take default value which I believe is "true".</p> <p>One more thing I am catching any exception hitting during indexing or optimizing, and then in finally block i am closing the IndexWriter by calling close(), method which sould take care of commit internally? Please suggest me if there is any equivalent method which i can use in place of commit()</p> <p>I have not upgraded to the newer version of lucene, but probably i will try 3.0.0 version of lucene in future.</p>
</comment>
<comment id="12842710" author="mikemccand" created="Mon, 8 Mar 2010 16:06:11 +0000">
<blockquote><p>I checked the documentation of IndexWriter in 2.3.2, API commit() is not available with this version (I think it is introduced in 2.4), I am not explicitely setting autoCommit, so it should take default value which I believe is "true".</p></blockquote> <p>Ahh right sorry. Hard to remember that far back!</p> <blockquote><p>One more thing I am catching any exception hitting during indexing or optimizing, and then in finally block i am closing the IndexWriter by calling close(), method which sould take care of commit internally? Please suggest me if there is any equivalent method which i can use in place of commit()</p></blockquote> <p>That's right, though, Lucene doesn't call "fsync" (to the OS) in<br/> 2.3.x... so if the machine/OS crashes it could corrupt your index. So<br/> it's not quite doing the same thing as commit() does in newer Lucene<br/> releases (ensure durability), but it does save everything to the<br/> index.</p> <blockquote><p>I have not upgraded to the newer version of lucene, but probably i will try 3.0.0 version of lucene in future.</p></blockquote> <p>OK.</p>
</comment>
<comment id="12846408" author="r_n7" created="Wed, 17 Mar 2010 13:27:28 +0000">
<p>Yesterday again search indxer crashed for my application and index file got deleted, this time had turned on the infostream on for indexwriter, attaching the infostream log file.</p>
</comment>
<comment id="12846409" author="r_n7" created="Wed, 17 Mar 2010 13:29:22 +0000"><p>Lucene infostream log file.</p></comment>
<comment id="12846892" author="r_n7" created="Thu, 18 Mar 2010 13:26:10 +0000">
<p>I installed a test setup with lucene 3.0.0 and tried to reproduce the scenario with NPE, but after the Exception thrown, main index file is not getting deleted but only optimize is failing and i can see some small index file (.cfs) also along with main index file, and one more thing here is i am not using commit yet, but using close(), does close do the same thing as commit does?</p> <p>By looking at above behavior, is there a bug in 2.3.2 version where this kind of situaion is not handled properly?</p> <p>Can you please have a look at the log which i got after turning on the infostream for IndexWriter(for lucene 2.3.2). Attached as lucene.zip.</p>
</comment>
<comment id="12846984" author="mikemccand" created="Thu, 18 Mar 2010 16:32:42 +0000">
<p>From the log I can see that you run fine for a long time, opening IW,<br/> indexing a few docs, optimizing, then closing. Then suddenly the<br/> exceptions start happening on many (but not all) merges, and, merges<br/> involving different segments. JRE bug seems most likely I guess...</p> <p>Since you see this only on Windows (not eg on Linux), I think this is<br/> likely not a bug in Lucene but rather something particular about your<br/> Windows env &#8211; virus checker maybe? Is there anything in the Windows<br/> events log that correlate to when the exceptions start?</p> <p>Or it could be a JRE bug &#8211; you really should try on different (Sun)<br/> JRE.</p>
</comment>
<comment id="12846985" author="mikemccand" created="Thu, 18 Mar 2010 16:34:28 +0000">
<p>Yes close() does commit() internally.</p> <p>Are you saying you see the same exception on 3.0, using the IBM JRE? Can you try with the Sun JRE?</p>
</comment>
<comment id="12847376" author="r_n7" created="Fri, 19 Mar 2010 14:00:05 +0000">
<p>I will further investigate it if it is a JRE bug, There are few points which i need some advise<br/> 1. To fix this issue if i disable the optimize (remove the call to IndexWriter.optimize() from my code) will that create any problem in the long run? if yes what kind of problems it may create?<br/> 2. Just by knowing the scenario, that after a NullPointerException, index file gets deleted, can you provide me a patch where any kind of exception is handled by the Lucene API and my index remains untouched?</p>
</comment>
<comment id="12847471" author="mikemccand" created="Fri, 19 Mar 2010 17:51:40 +0000">
<blockquote><p>1. To fix this issue if i disable the optimize (remove the call to IndexWriter.optimize() from my code) will that create any problem in the long run? if yes what kind of problems it may create?</p></blockquote> <p>Most apps never need to optimize.</p> <p>You should only optimize if your search performance is not good enough, and really, before using optimize you should explore other ideas (see ImproveSearchingSpeed on the wiki).</p> <blockquote><p>2. Just by knowing the scenario, that after a NullPointerException, index file gets deleted, can you provide me a patch where any kind of exception is handled by the Lucene API and my index remains untouched?</p></blockquote> <p>Can't make a patch here until we understand what's actually happening...</p> <p>It looks like your index got truncated at IW 443. Hmm actually it looks like IW 442 never successfully closed. (do a grep for ": at close:" and you'll see it's missing).</p> <p>Maybe this is the problem. Because every merge kept hitting exceptions it looks like IW 442, even on close, was throwing the exceptions, and never closed properly.</p> <p>Can you try using IW.close(false) in your finally clause? This aborts all running merges and closes the index and likely will workaround whatever (seeming like a JRE bug) is causing the NPE during merging.</p> <p>Also, you could try using autoCommit=false.</p>
</comment>
<comment id="12848135" author="r_n7" created="Mon, 22 Mar 2010 14:06:04 +0000">
<p>Thanks michael, the fix you provided seems to be working fine for me, after using close(false) index file is not getting deleted and search is also working fine though optimization is not happening but still its fine as far as search is working. I have attached a sample application which replicates the actual application, please have a look at that and let me know if anything else can be fine tuned. </p>
</comment>
<comment id="12848137" author="r_n7" created="Mon, 22 Mar 2010 14:07:52 +0000">
<p>Sample application which replicates the actual application.</p>
</comment>
<comment id="13835686" author="erickerickson" created="Sat, 30 Nov 2013 13:15:15 +0000"><p>2013 Old JIRA cleanup</p></comment>
</comments>
<attachments>
<attachment id="12439459" name="LuceneUtils.zip" size="2512099" author="r_n7" created="Mon, 22 Mar 2010 14:07:52 +0000"/>
<attachment id="12436850" name="lucene.jar" size="665686" author="r_n7" created="Wed, 24 Feb 2010 14:25:42 +0000"/>
<attachment id="12439035" name="lucene.zip" size="3927421" author="r_n7" created="Wed, 17 Mar 2010 13:29:22 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 23 Feb 2010 11:46:50 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>3703</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i04rrj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>25763</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6883] Getting exception _t.si (No such file or directory)
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6883</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>We are getting following exception when we are trying to update cache. Following are two scenario when we get this error</p> <p>scenario 1:</p> <p>2015-11-03 06:45:18,213 <span class="error">&#91;main&#93;</span> ERROR java.io.FileNotFoundException: /app/cache/index-persecurity/PERSECURITY_INDEX-QCH/_mb.si (No such file or directory)<br/> at java.io.RandomAccessFile.open(Native Method)<br/> at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:241)<br/> at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:193)<br/> at org.apache.lucene.codecs.lucene40.Lucene40SegmentInfoReader.read(Lucene40SegmentInfoReader.java:50)<br/> at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:301)<br/> at org.apache.lucene.index.StandardDirectoryReader$1.doBody(StandardDirectoryReader.java:56)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:783)<br/> at org.apache.lucene.index.StandardDirectoryReader.open(StandardDirectoryReader.java:52)<br/> at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:65)<br/> .....</p> <p>scenario 2:</p> <p>java.io.FileNotFoundException: /app/1.0.5_loadtest/index-persecurity/PERSECURITY_INDEX-ITQ/_t.si (No such file or directory)<br/> at java.io.RandomAccessFile.open(Native Method)<br/> at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:241)<br/> at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:193)<br/> at org.apache.lucene.codecs.lucene40.Lucene40SegmentInfoReader.read(Lucene40SegmentInfoReader.java:50)<br/> at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:301)<br/> at org.apache.lucene.index.SegmentInfos$1.doBody(SegmentInfos.java:347)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:783)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:630)<br/> at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:343)<br/> at org.apache.lucene.index.StandardDirectoryReader.isCurrent(StandardDirectoryReader.java:326)<br/> at org.apache.lucene.index.StandardDirectoryReader.doOpenNoWriter(StandardDirectoryReader.java:284)<br/> at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:247)<br/> at org.apache.lucene.index.StandardDirectoryReader.doOpenIfChanged(StandardDirectoryReader.java:235)<br/> at org.apache.lucene.index.DirectoryReader.openIfChanged(DirectoryReader.java:169)<br/> ......</p> <p>What might be the possible reasons for this?	</p>
</description>
<environment/>
<key id="12910335">LUCENE-6883</key>
<summary>
Getting exception _t.si (No such file or directory)
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tejas.jethva">Tejas Jethva</reporter>
<labels></labels>
<created>Wed, 4 Nov 2015 12:35:47 +0000</created>
<updated>Wed, 25 Nov 2015 06:34:14 +0000</updated>
<version>4.2</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14993740" author="mikemccand" created="Fri, 6 Nov 2015 14:29:20 +0000">
<p>4.2 is quite old by now; it's possible this is a bug that was already fixed?</p> <p>Were these 3.x indices that you opened when you saw this exception?</p>
</comment>
<comment id="15003841" author="tejas.jethva" created="Fri, 13 Nov 2015 10:44:15 +0000">
<p>Thanks Michael,</p> <p>We are using 4.2 since long time and never used 3.x.</p> <p>If it is fixed, on which version we can check?</p>
</comment>
<comment id="15004018" author="mikemccand" created="Fri, 13 Nov 2015 14:09:19 +0000">
<p>OK, the only issue I could think of was when reading 3.x segments, but that's not happening here.</p> <blockquote><p>If it is fixed, on which version we can check?</p></blockquote> <p>Not sure if it's fixed since we don't quite know what you are hitting.</p> <p>But it's entirely possible whatever you're hitting is fixed: there have been many fixes since 4.2. Why not upgrade to the latest (5.3.1 as of now)?</p>
</comment>
<comment id="15026300" author="tejas.jethva" created="Wed, 25 Nov 2015 06:34:14 +0000">
<p>Thanks Michael,</p> <p>Will try upgrading it to latest version.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 6 Nov 2015 14:29:20 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2nxrr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6882] java.lang.NoClassDefFoundError: org/apache/lucene/codecs/lucene54/Lucene54Codec
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6882</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>-------------------------------------------------------------------------------<br/> Test set: org.apache.lucene.analysis.ar.TestArabicAnalyzer<br/> -------------------------------------------------------------------------------<br/> Tests run: 1, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 0.159 sec &lt;&lt;&lt; FAILURE! - in org.apache.lucene.analysis.ar.TestArabicAnalyzer<br/> org.apache.lucene.analysis.ar.TestArabicAnalyzer Time elapsed: 0.156 sec &lt;&lt;&lt; ERROR!<br/> java.lang.NoClassDefFoundError: org/apache/lucene/codecs/lucene54/Lucene54Codec<br/> at org.apache.lucene.util.LuceneTestCase.&lt;clinit&gt;(LuceneTestCase.java:606)<br/> at java.lang.Class.forName0(Native Method)<br/> at java.lang.Class.forName(Unknown Source)<br/> at com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:581)<br/> Caused by: java.lang.ClassNotFoundException: org.apache.lucene.codecs.lucene54.Lucene54Codec<br/> at java.net.URLClassLoader.findClass(Unknown Source)<br/> at java.lang.ClassLoader.loadClass(Unknown Source)<br/> at sun.misc.Launcher$AppClassLoader.loadClass(Unknown Source)<br/> at java.lang.ClassLoader.loadClass(Unknown Source)<br/> at org.apache.lucene.util.LuceneTestCase.&lt;clinit&gt;(LuceneTestCase.java:606)<br/> at java.lang.Class.forName0(Native Method)<br/> at java.lang.Class.forName(Unknown Source)<br/> at com.carrotsearch.randomizedtesting.RandomizedRunner$2.run(RandomizedRunner.java:581)</p>
</description>
<environment><p>maven 3.2.5<br/> JDK 1.8</p></environment>
<key id="12909965">LUCENE-6882</key>
<summary>
java.lang.NoClassDefFoundError: org/apache/lucene/codecs/lucene54/Lucene54Codec
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mgainty@hotmail.com">Martin Gainty</reporter>
<labels></labels>
<created>Tue, 3 Nov 2015 11:23:39 +0000</created>
<updated>Mon, 9 Nov 2015 03:09:08 +0000</updated>
<version>5.3</version>
<component>-tools</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<timeoriginalestimate seconds="28800">8h</timeoriginalestimate>
<timeestimate seconds="28800">8h</timeestimate>
<comments>
<comment id="14987329" author="mikemccand" created="Tue, 3 Nov 2015 14:19:26 +0000">
<p>Maybe something is wrong with your classpath: Lucene 5.3 doesn't even have a Lucene54Codec?</p>
</comment>
<comment id="14994667" author="mgainty@hotmail.com" created="Fri, 6 Nov 2015 23:12:47 +0000">
<p>I wanted to add a custom codec class called Lucene54 <br/> i enabled by editing <br/> core/src/resources/META-INF/services/org.apache.lucene.codecs.Codec</p> <p>recompile,rejar and placed on classpath the new codec is now discovered<br/> by org.apache.lucene.util.NamedSPILoader lookup('Lucene54')</p> <ol> <li>Licensed to the Apache Software Foundation (ASF) under one or more</li> <li>contributor license agreements. See the NOTICE file distributed with</li> <li>this work for additional information regarding copyright ownership.</li> <li>The ASF licenses this file to You under the Apache License, Version 2.0</li> <li>(the "License"); you may not use this file except in compliance with</li> <li>the License. You may obtain a copy of the License at<br/> #</li> <li><a href="http://www.apache.org/licenses/LICENSE-2.0" class="external-link" rel="nofollow">http://www.apache.org/licenses/LICENSE-2.0</a><br/> #</li> <li>Unless required by applicable law or agreed to in writing, software</li> <li>distributed under the License is distributed on an "AS IS" BASIS,</li> <li>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</li> <li>See the License for the specific language governing permissions and</li> <li>limitations under the License.</li> <li>as of 11/01/2015 the only class present is org.apache.lucene.codecs.lucene53.Lucene53Codec</li> </ol> <p>org.apache.lucene.codecs.FilterCodec<br/> org.apache.lucene.codecs.lucene50.Lucene50Codec<br/> org.apache.lucene.codecs.lucene53.Lucene53Codec<br/> org.apache.lucene.codecs.lucene54.Lucene54Codec</p> <p>BTW:maven pom.xml works like a charm for recompiling,packaging and running and reporting on testcases...<br/> Let me know if you would like a copy <br/> Thanks Mike!<br/> M-</p>
</comment>
<comment id="14995970" author="steve_rowe" created="Mon, 9 Nov 2015 03:09:08 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mgainty" class="user-hover" rel="mgainty">Martin Gainty</a>, sounds like this issue should be resolved as Not A Problem?</p> <blockquote> <p>BTW:maven pom.xml works like a charm for recompiling,packaging and running and reporting on testcases...<br/> Let me know if you would like a copy</p></blockquote> <p>Once again (copy/pasting my reply to you on the dev mailing list from 10 days ago):</p> <blockquote> <p>Do you know about the Maven build that already is included with the project? If not, start here: &lt;<a href="https://svn.apache.org/viewvc/lucene/dev/trunk/dev-tools/maven/README.maven?view=markup" class="external-link" rel="nofollow">https://svn.apache.org/viewvc/lucene/dev/trunk/dev-tools/maven/README.maven?view=markup</a>&gt;</p></blockquote>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 3 Nov 2015 14:19:26 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Flags</customfieldname>
<customfieldvalues>
<customfieldvalue key="10431">
<![CDATA[ Important ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2nvhj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6876] QueryNodeParseException is thrown without proper Error information
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6876</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Whenever an Error is caught in parse() method of StandardSyntaxParser.java, a new instance of QueryNodeParseException is created without any Error Information(like errorToken, beginColumn, beginLine) and thrown. Following is the parse method:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> QueryNode parse(CharSequence query, CharSequence field) <span class="code-keyword">throws</span> QueryNodeParseException { ReInit(<span class="code-keyword">new</span> FastCharStream(<span class="code-keyword">new</span> StringReader(query.toString()))); <span class="code-keyword">try</span> { <span class="code-comment">// TopLevelQuery is a Query followed by the end-of-input (EOF) </span> QueryNode querynode = TopLevelQuery(field); <span class="code-keyword">return</span> querynode; } <span class="code-keyword">catch</span> (ParseException tme) { tme.setQuery(query); <span class="code-keyword">throw</span> tme; } <span class="code-keyword">catch</span> (Error tme) { Message message = <span class="code-keyword">new</span> MessageImpl(QueryParserMessages.INVALID_SYNTAX_CANNOT_PARSE, query, tme.getMessage()); QueryNodeParseException e = <span class="code-keyword">new</span> QueryNodeParseException(tme); e.setQuery(query); e.setNonLocalizedMessage(message); <span class="code-keyword">throw</span> e; } } </pre> </div></div>
</description>
<environment/>
<key id="12909646">LUCENE-6876</key>
<summary>
QueryNodeParseException is thrown without proper Error information
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="dominicdsouza">Dominic Dsouza</reporter>
<labels></labels>
<created>Mon, 2 Nov 2015 12:33:54 +0000</created>
<updated>Mon, 2 Nov 2015 12:36:43 +0000</updated>
<version>5.3</version>
<component>core/queryparser</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ntgn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6865] BooleanQuery2ModifierNodeProcessor breaks the query node hierarchy
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6865</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>We discovered that one of our own implementations of QueryNodeProcessor was seeing node.getParent() returning null for nodes other than the root of the query tree.</p> <p>I put a diagnostic processor around every processor which runs and found that BooleanQuery2ModifierNodeProcessor (and possibly others, although it isn't clear) are mysteriously setting some of the node references to null.</p> <p>Example query tree before:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>GroupQueryNode, parent = null WithinQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = WithinQueryNode GroupQueryNode, parent = WithinQueryNode AndQueryNode, parent = GroupQueryNode GroupQueryNode, parent = AndQueryNode OrQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = OrQueryNode QuotedFieldQueryNode, parent = OrQueryNode GroupQueryNode, parent = AndQueryNode OrQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = OrQueryNode QuotedFieldQueryNode, parent = OrQueryNode </pre> </div></div> <p>And after BooleanQuery2ModifierNodeProcessor.process():</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>GroupQueryNode, parent = null WithinQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = WithinQueryNode GroupQueryNode, parent = WithinQueryNode AndQueryNode, parent = GroupQueryNode BooleanModifierNode, parent = AndQueryNode GroupQueryNode, parent = null OrQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = OrQueryNode QuotedFieldQueryNode, parent = OrQueryNode BooleanModifierNode, parent = AndQueryNode GroupQueryNode, parent = null OrQueryNode, parent = GroupQueryNode QuotedFieldQueryNode, parent = OrQueryNode QuotedFieldQueryNode, parent = OrQueryNode </pre> </div></div> <p>Looking at QueryNodeImpl, there is a lot of fiddly logic in there. Removing children can trigger setting the parent to null, but setting the parent can also trigger the child removing itself, so it's near impossible to figure out why this could be happening, but I'm closing in on it at least. My initial suspicion is that cloneTree() is responsible, because ironically the number of failures of this sort <em>increase</em> if I try to use cloneTree to defend against mutability bugs.</p> <p>The fix I have come up with is to clone the whole API but making QueryNode immutable. This removes the ability for processors to mess with nodes that don't belong to them, but also obviates the need for a parent reference in the first place, which I think is the entire source of the problem - keeping the parent and child in sync correctly is obviously going to be hard, and indeed we find that there is at least one bug of this sort lurking in there.</p> <p>But even if we rewrite it, I figured I would report the issue so that maybe it can be fixed for others.</p> <p>Code to use for diagnostics:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">import</span> java.util.List; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.QueryNodeException; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.config.QueryConfigHandler; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.QueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.processors.QueryNodeProcessor; <span class="code-keyword">public</span> class DiagnosticQueryNodeProcessor <span class="code-keyword">implements</span> QueryNodeProcessor { <span class="code-keyword">private</span> <span class="code-keyword">final</span> QueryNodeProcessor delegate; <span class="code-keyword">public</span> TreeFixingQueryNodeProcessor(QueryNodeProcessor delegate) { <span class="code-keyword">this</span>.delegate = delegate; } @Override <span class="code-keyword">public</span> QueryConfigHandler getQueryConfigHandler() { <span class="code-keyword">return</span> delegate.getQueryConfigHandler(); } @Override <span class="code-keyword">public</span> void setQueryConfigHandler(QueryConfigHandler queryConfigHandler) { delegate.setQueryConfigHandler(queryConfigHandler); } @Override <span class="code-keyword">public</span> QueryNode process(QueryNode queryNode) <span class="code-keyword">throws</span> QueryNodeException { <span class="code-object">System</span>.out.println(<span class="code-quote">"Before "</span> + delegate.getClass().getSimpleName() + <span class="code-quote">".process():"</span>); dumpTree(queryNode); queryNode = delegate.process(queryNode); <span class="code-object">System</span>.out.println(<span class="code-quote">"After "</span> + delegate.getClass().getSimpleName() + <span class="code-quote">".process():"</span>); dumpTree(queryNode); <span class="code-keyword">return</span> queryNode; } <span class="code-keyword">private</span> void dumpTree(QueryNode queryNode) { dumpTree(queryNode, ""); } <span class="code-keyword">private</span> void dumpTree(QueryNode queryNode, <span class="code-object">String</span> prefix) { <span class="code-object">System</span>.out.println(prefix + queryNode.getClass().getSimpleName() + <span class="code-quote">", parent = "</span> + (queryNode.getParent() == <span class="code-keyword">null</span> ? <span class="code-quote">"<span class="code-keyword">null</span>"</span> : queryNode.getParent().getClass().getSimpleName())); List&lt;QueryNode&gt; children = queryNode.getChildren(); <span class="code-keyword">if</span> (children != <span class="code-keyword">null</span>) { <span class="code-object">String</span> childPrefix = <span class="code-quote">" "</span> + prefix; <span class="code-keyword">for</span> (QueryNode child : children) { dumpTree(child, childPrefix); } } } } </pre> </div></div>
</description>
<environment/>
<key id="12908751">LUCENE-6865</key>
<summary>
BooleanQuery2ModifierNodeProcessor breaks the query node hierarchy
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="trejkaz">Trejkaz</reporter>
<labels></labels>
<created>Wed, 28 Oct 2015 23:55:16 +0000</created>
<updated>Mon, 2 Nov 2015 03:44:08 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14979528" author="trejkaz" created="Thu, 29 Oct 2015 00:05:44 +0000">
<p>Standalone reproduction:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">import</span> java.util.Arrays; <span class="code-keyword">import</span> java.util.List; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.AndQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.GroupQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.OrQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.QueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.QuotedFieldQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.processors.QueryNodeProcessor; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.standard.config.StandardQueryConfigHandler; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.standard.processors.BooleanQuery2ModifierNodeProcessor; <span class="code-keyword">import</span> org.junit.Test; <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.hamcrest.Matchers.*; <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.junit.Assert.*; /** * Tests <span class="code-keyword">for</span> {@link BooleanQuery2ModifierNodeProcessor}, */ <span class="code-keyword">public</span> class TestBooleanQuery2ModifierNodeProcessor { @Test <span class="code-keyword">public</span> void testProcess() <span class="code-keyword">throws</span> Exception { QueryNode before = <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> AndQueryNode(Arrays.asList( <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> OrQueryNode(Arrays.asList( <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0), <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0)))), <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> OrQueryNode(Arrays.asList( <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0), <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0))))))); QueryNodeProcessor processor = <span class="code-keyword">new</span> BooleanQuery2ModifierNodeProcessor(); processor.setQueryConfigHandler(<span class="code-keyword">new</span> StandardQueryConfigHandler()); QueryNode after = processor.process(before); checkTree(after); } <span class="code-keyword">private</span> <span class="code-keyword">static</span> void checkTree(QueryNode queryNode) { checkTree(queryNode, ""); } <span class="code-keyword">private</span> <span class="code-keyword">static</span> void checkTree(QueryNode queryNode, <span class="code-object">String</span> prefix) { List&lt;QueryNode&gt; children = queryNode.getChildren(); <span class="code-keyword">if</span> (children != <span class="code-keyword">null</span>) { <span class="code-object">String</span> childPrefix = <span class="code-quote">" "</span> + prefix; <span class="code-keyword">for</span> (QueryNode child : children) { assertThat(child.getParent(), is(queryNode)); checkTree(child, childPrefix); } } } } </pre> </div></div>
</comment>
<comment id="14979537" author="trejkaz" created="Thu, 29 Oct 2015 00:15:57 +0000">
<p>Suspicious code #1. A call to processIteration which is not using the return value.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">protected</span> void processChildren(QueryNode queryTree) <span class="code-keyword">throws</span> QueryNodeException { List children = queryTree.getChildren(); <span class="code-keyword">if</span>(children != <span class="code-keyword">null</span> &amp;&amp; children.size() &gt; 0) { Iterator var3 = children.iterator(); <span class="code-keyword">while</span>(var3.hasNext()) { QueryNode child = (QueryNode)var3.next(); <span class="code-keyword">this</span>.processIteration(child); } } } </pre> </div></div>
</comment>
<comment id="14979605" author="trejkaz" created="Thu, 29 Oct 2015 01:03:44 +0000">
<p>Another reproduction which doesn't use the processor, confirming my suspicions that this is a widespread problem with query nodes themselves:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">import</span> java.util.Collections; <span class="code-keyword">import</span> java.util.List; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.AndQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.GroupQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.ModifierQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.QueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.core.nodes.QuotedFieldQueryNode; <span class="code-keyword">import</span> org.apache.lucene.queryparser.flexible.standard.nodes.BooleanModifierNode; <span class="code-keyword">import</span> org.junit.Test; <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.hamcrest.Matchers.*; <span class="code-keyword">import</span> <span class="code-keyword">static</span> org.junit.Assert.*; /** * Tests <span class="code-keyword">for</span> query nodes, */ <span class="code-keyword">public</span> class TestQueryNodes { @Test <span class="code-keyword">public</span> void testCutDown() <span class="code-keyword">throws</span> Exception { QueryNode before = <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> AndQueryNode(Collections.singletonList( <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0)))); checkTree(before); <span class="code-comment">// This wrecks the query tree somehow. </span> before.set(Collections.singletonList( <span class="code-keyword">new</span> BooleanModifierNode(before.getChildren().get(0), ModifierQueryNode.Modifier.MOD_REQ))); checkTree(before); } <span class="code-keyword">private</span> <span class="code-keyword">static</span> void checkTree(QueryNode queryNode) { checkTree(queryNode, ""); } <span class="code-keyword">private</span> <span class="code-keyword">static</span> void checkTree(QueryNode queryNode, <span class="code-object">String</span> prefix) { List&lt;QueryNode&gt; children = queryNode.getChildren(); <span class="code-keyword">if</span> (children != <span class="code-keyword">null</span>) { <span class="code-object">String</span> childPrefix = <span class="code-quote">" "</span> + prefix; <span class="code-keyword">for</span> (QueryNode child : children) { assertThat(child.getParent(), is(queryNode)); checkTree(child, childPrefix); } } } } </pre> </div></div>
</comment>
<comment id="14979684" author="trejkaz" created="Thu, 29 Oct 2015 02:30:53 +0000">
<p>These tests fail too. Note these don't even call set() - the tree gets corrupted just by passing one of its nodes into another constructor. This is the sort of spooky mutability bug that I would rather avoid by just having the nodes immutable.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> @Test <span class="code-keyword">public</span> void testCutDown1() <span class="code-keyword">throws</span> Exception { QueryNode before = <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> AndQueryNode(Collections.singletonList( <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0)))); checkTree(before); <span class="code-comment">// This wrecks the query tree somehow. </span> <span class="code-keyword">new</span> ModifierQueryNode(before.getChildren().get(0), ModifierQueryNode.Modifier.MOD_REQ); checkTree(before); } @Test <span class="code-keyword">public</span> void testCutDown2() <span class="code-keyword">throws</span> Exception { QueryNode before = <span class="code-keyword">new</span> GroupQueryNode( <span class="code-keyword">new</span> AndQueryNode(Collections.singletonList( <span class="code-keyword">new</span> QuotedFieldQueryNode(<span class="code-quote">"a"</span>, <span class="code-quote">"a"</span>, 0, 0)))); checkTree(before); <span class="code-comment">// This wrecks the query tree somehow. </span> <span class="code-keyword">new</span> BooleanQueryNode(Collections.singletonList(before.getChildren().get(0))); checkTree(before); } </pre> </div></div>
</comment>
<comment id="14981682" author="trejkaz" created="Fri, 30 Oct 2015 01:14:18 +0000">
<p>The underlying issue here seems like it might be <a href="https://issues.apache.org/jira/browse/LUCENE-6506" title="QueryNodeImpl.removeFromParent() is not implemented right" class="issue-link" data-issue-key="LUCENE-6506"><del>LUCENE-6506</del></a> ... but to get that fix we have to update to 5.3. <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/sad.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14984675" author="trejkaz" created="Mon, 2 Nov 2015 03:04:20 +0000">
<p>Tried updating to 5.3, looks like backwards compatibility was broken in the 5.3 release, and we depend on elasticsearch as well, meaning we can't update even if we update all our own code to 5.3.</p>
</comment>
<comment id="14984702" author="trejkaz" created="Mon, 2 Nov 2015 03:43:43 +0000">
<p>Temporary workaround for now I guess. Override the process method to wedge in an extra call to a method which corrects the problem.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> @Override <span class="code-keyword">public</span> QueryNode process(QueryNode queryTree) <span class="code-keyword">throws</span> QueryNodeException { <span class="code-keyword">for</span> (QueryNodeProcessor processor : <span class="code-keyword">this</span>) { queryTree = processor.process(queryTree); fixQueryTree(queryTree); } <span class="code-keyword">return</span> queryTree; } /** * Recursively fixes parent-child links in the query tree. * Basically <span class="code-keyword">this</span> works by detaching and reattaching all descendants from their immediate parent. * * @param input the input query node. */ <span class="code-keyword">private</span> void fixQueryTree(QueryNode input) { List&lt;QueryNode&gt; children = input.getChildren(); <span class="code-keyword">if</span> (children != <span class="code-keyword">null</span>) { children.forEach(<span class="code-keyword">this</span>::fixQueryTree); <span class="code-comment">// This is what fixes it. </span> input.set(children); } } </pre> </div></div>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2nnxr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6853] Boolean perceptron classifier is too sensitive to threshold
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6853</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><tt>BooleanPerceptronClassifier</tt> is too sensitive to the value of its <tt>threshold</tt>, that should be weighted and adjusted against the classifier inputs instead.</p>
</description>
<environment/>
<key id="12907434">LUCENE-6853</key>
<summary>
Boolean perceptron classifier is too sensitive to threshold
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="teofili">Tommaso Teofili</assignee>
<reporter username="teofili">Tommaso Teofili</reporter>
<labels></labels>
<created>Fri, 23 Oct 2015 15:07:43 +0000</created>
<updated>Mon, 14 Dec 2015 21:04:44 +0000</updated>
<version>4.10.4</version>
<version>5.3</version>
<fixVersion>master</fixVersion>
<component>modules/classification</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14971129" author="jira-bot" created="Fri, 23 Oct 2015 15:09:27 +0000">
<p>Commit 1710230 from <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=teofili" class="user-hover" rel="teofili">Tommaso Teofili</a> in branch 'dev/trunk'<br/> [ <a href="https://svn.apache.org/r1710230" class="external-link" rel="nofollow">https://svn.apache.org/r1710230</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6853" title="Boolean perceptron classifier is too sensitive to threshold" class="issue-link" data-issue-key="LUCENE-6853">LUCENE-6853</a> - disabled accuracy check in BPC performance test until this is fixed</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 23 Oct 2015 15:09:27 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2nfvj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6841] LZ4 compression using too much CPU time
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6841</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I am using Lucene for search indexing, including storing a large number of small fields, and some larger plain text fields, and searching using both exact matches and analyzed queries.</p> <p>LZ4 (specifically the decompress method) is using nearly exactly 50% of the application's CPU time.</p> <p>It seems to me that LZ4 is inappropriate for my use case. I note that I can choose BEST_SPEED or BEST_COMPRESSION.</p> <p>Would it be palatable to add a NO_COMPRESSION option, or some way to pick and choose which fields get compressed? Perhaps a minimum length of a field could be specified before it's compressed? I'm not sure if that's possible.</p> <p>If this approach, or similar is palatable, I would be happy to contribute a patch (or to consume and test a patch).</p>
</description>
<environment><p>Linux, Java 8</p></environment>
<key id="12905405">LUCENE-6841</key>
<summary>LZ4 compression using too much CPU time</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="karlvr">Karl von Randow</reporter>
<labels></labels>
<created>Fri, 16 Oct 2015 03:03:06 +0000</created>
<updated>Fri, 16 Oct 2015 23:41:49 +0000</updated>
<version>5.3.1</version>
<component>core/codecs</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14960523" author="jpountz" created="Fri, 16 Oct 2015 11:21:10 +0000">
<p>This issue is a bit tricky, because we have some users wishing that stored fields compression was more aggressive, and other users wishing that compression was less aggressive. But on the other hand, we want to support as few options as possible in order to keep backward compatibility manageable (we already have 2 and certainly want to avoid 3).</p> <p>Are you sure that the issue is with lz4 and not I/O? The method that performs decompression performs I/O and actual decompression at the same time, so from the output of a profiler it could easily look like the issue is with lz4 while it actually is with I/O.</p> <p>Also what kind of workload do you have (number of docs, size of individual docs, number of docs retrieved per page)? Any chance that your index fits in memory entirely?</p>
</comment>
<comment id="14960553" author="thetaphi" created="Fri, 16 Oct 2015 11:48:59 +0000">
<blockquote><p>or some way to pick and choose which fields get compressed? Perhaps a minimum length of a field could be specified before it's compressed? I'm not sure if that's possible.</p></blockquote> <p>The compression is in blocks and not per field. To read a stored field it has to load and decompress the whole block, containing multiple fields (and maybe also multiple documents). If you do this for many small fields where you are only interested in some of them you may use the wrong type of storage. Since Lucene 4 there is an alternative, column-based store called docvalues. If you want to use data fields during scoring or to read sequentially a single field for all documents, then it is better to use column-based docvalues (which can be numeric, too - e.g. useful as scoring factors).</p> <p>Stored fields use-case is to load few documents as part of search result display of like 10 or 20 top-ranking documents. They are not made for processing millions of documents like to retrieve scoring factors.</p>
</comment>
<comment id="14961541" author="karlvr" created="Fri, 16 Oct 2015 23:41:49 +0000">
<p>Thank you both very much for your prompt responses.</p> <p>My search index on disk is 5.2G. My heap is larger than that and the box memory is larger than that, so possibly the entire index can fit in memory. Could you point me to something to try to verify this?</p> <p>Number of docs is in the low millions. Each doc is often quite small, 10-20 fields with only one containing more than a single line of text.</p> <p>My profiling was only of threads that were in the RUNNABLE state, so I don't <em>believe</em> that this includes IO waiting time. So I do suspect it is actually LZ4ing rather than IO.</p> <p>I feel like to proceed I may need to do a run without compression to compare the CPU usage. This will I presume require rebuilding the search index… there is an upgrade process isn't there for converting between codecs? Perhaps I could use that to speed the process?</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 16 Oct 2015 11:21:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2n3in:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6832] SynonymFilter behaves not as expected with "ignoreCase=true"
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6832</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>SynonymFilter with "ignoreCase=true" does not work as expected:</p> <ul> <li>Uppercase words in the SynonymMap are never matched</li> <li>Uppercase words will be lowercase in the resulting TokenStream regardless if being matched or not</li> </ul> <p>It seems like the SynonymMap pretty much screws up if you pass it an uppercase version of a word.</p>
</description>
<environment/>
<key id="12903086">LUCENE-6832</key>
<summary>
SynonymFilter behaves not as expected with "ignoreCase=true"
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jdemler">Jakob Demler</reporter>
<labels></labels>
<created>Wed, 7 Oct 2015 18:51:44 +0000</created>
<updated>Wed, 7 Oct 2015 18:55:20 +0000</updated>
<version>5.3</version>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14947364" author="jdemler" created="Wed, 7 Oct 2015 18:54:43 +0000">
<p>Patch contains a UnitTest failing because of this Bug</p>
</comment>
</comments>
<attachments>
<attachment id="12765434" name="LUCENE-6832.patch" size="10450" author="jdemler" created="Wed, 7 Oct 2015 18:54:43 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Flags</customfieldname>
<customfieldvalues>
<customfieldvalue key="10430">
<![CDATA[ Patch ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2mpef:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6758] Adding a SHOULD clause to a BQ over an empty field clears the score when using DefaultSimilarity
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6758</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Patch with unit test to show the bug will be attached.</p> <p>I've narrowed this change in behavior with git bisect to the following commit:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>commit 698b4b56f0f2463b21c9e3bc67b8b47d635b7d1f Author: Robert Muir &lt;rmuir@apache.org&gt; Date: Thu Aug 13 17:37:15 2015 +0000 LUCENE-6711: Use CollectionStatistics.docCount() for IDF and average field length computations git-svn-id: https://svn.apache.org/repos/asf/lucene/dev/trunk@1695744 13f79535-47bb-0310-9956-ffa450edef68 </pre> </div></div>
</description>
<environment/>
<key id="12857882">LUCENE-6758</key>
<summary>
Adding a SHOULD clause to a BQ over an empty field clears the score when using DefaultSimilarity
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="shebiki">Terry Smith</reporter>
<labels></labels>
<created>Fri, 21 Aug 2015 15:57:18 +0000</created>
<updated>Thu, 10 Sep 2015 00:57:45 +0000</updated>
<version>master</version>
<due/>
<votes>0</votes>
<watches>5</watches>
<comments>
<comment id="14706917" author="shebiki" created="Fri, 21 Aug 2015 16:00:35 +0000">
<p>Run this unit test a few times and you'll hit a failure when DefaultSimilarity is picked.</p> <p>The method testBQHitOrEmpty() will fail because the score is zero. It's friend testBQHitOrMiss() has a non-zero score.</p> <p>The difference between the two is that the field "empty" is unused, whereas the field "test" has one token ("hit").</p>
</comment>
<comment id="14706963" author="shebiki" created="Fri, 21 Aug 2015 16:27:07 +0000">
<p>Explain output for the failing query (testBQHitOrEmpty):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>0.0 = product of: 0.0 = sum of: 0.0 = weight(test:hit in 0) [DefaultSimilarity], result of: 0.0 = score(doc=0,freq=1.0), product of: 0.0 = queryWeight, product of: 0.30685282 = idf(docFreq=1, docCount=1) 0.0 = queryNorm 0.30685282 = fieldWeight in 0, product of: 1.0 = tf(freq=1.0), with freq of: 1.0 = termFreq=1.0 0.30685282 = idf(docFreq=1, docCount=1) 1.0 = fieldNorm(doc=0) 0.5 = coord(1/2) </pre> </div></div> <p>Explain output for the variant against a populated field (testBQHitOrMiss):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>0.04500804 = product of: 0.09001608 = sum of: 0.09001608 = weight(test:hit in 0) [DefaultSimilarity], result of: 0.09001608 = score(doc=0,freq=1.0), product of: 0.29335263 = queryWeight, product of: 0.30685282 = idf(docFreq=1, docCount=1) 0.9560043 = queryNorm 0.30685282 = fieldWeight in 0, product of: 1.0 = tf(freq=1.0), with freq of: 1.0 = termFreq=1.0 0.30685282 = idf(docFreq=1, docCount=1) 1.0 = fieldNorm(doc=0) 0.5 = coord(1/2) </pre> </div></div>
</comment>
<comment id="14734574" author="rcmuir" created="Tue, 8 Sep 2015 10:26:03 +0000">
<p>The problem is just with crappy queryNorm in DefaultSimilarity, as expected.</p> <p>Previously maxDoc was used, which was always assumed to be a positive integer... but docCount can be zero.</p>
</comment>
<comment id="14734713" author="jpountz" created="Tue, 8 Sep 2015 12:18:28 +0000"><p>+1</p></comment>
<comment id="14734796" author="shebiki" created="Tue, 8 Sep 2015 13:34:28 +0000">
<p>Ah, you've changed DefaultSimilarity.idf() to use (docCount + 1) instead of just docCount forcing it to be larger than 0.</p> <p>That looks like a great fix, thanks.</p>
</comment>
<comment id="14734875" author="rcmuir" created="Tue, 8 Sep 2015 14:23:39 +0000"><p>Thank you for contributing the tests.</p></comment>
<comment id="14734978" author="mikemccand" created="Tue, 8 Sep 2015 15:19:22 +0000"><p>+1</p></comment>
<comment id="14736071" author="jira-bot" created="Wed, 9 Sep 2015 03:16:16 +0000">
<p>Commit 1701895 from <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rcmuir" class="user-hover" rel="rcmuir">Robert Muir</a> in branch 'dev/trunk'<br/> [ <a href="https://svn.apache.org/r1701895" class="external-link" rel="nofollow">https://svn.apache.org/r1701895</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6758" title="Adding a SHOULD clause to a BQ over an empty field clears the score when using DefaultSimilarity" class="issue-link" data-issue-key="LUCENE-6758">LUCENE-6758</a>: don't let queries over nonexistent fields screw up querynorm</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="12310050">
<name>Regression</name>
<outwardlinks description="breaks">
<issuelink>
<issuekey id="12862877">SOLR-8026</issuekey>
</issuelink>
</outwardlinks>
<inwardlinks description="is broken by">
<issuelink>
<issuekey id="12850791">LUCENE-6711</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12754613" name="LUCENE-6758.patch" size="25182" author="rcmuir" created="Tue, 8 Sep 2015 10:26:03 +0000"/>
<attachment id="12751745" name="LUCENE-6758.patch" size="5912" author="shebiki" created="Fri, 21 Aug 2015 16:00:35 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 8 Sep 2015 10:26:03 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j7t3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6750] TestMergeSchedulerExternal failure</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6750</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Policeman Jenkins found a failure on OS X <a href="http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2649/" class="external-link" rel="nofollow">http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/2649/</a> that I can't reproduce on OS X 10.10.4 using Oracle Java 1.8.0_20, even after beasting 200 total suite iterations with the seed:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] Suite: org.apache.lucene.TestMergeSchedulerExternal [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestMergeSchedulerExternal -Dtests.method=testSubclassConcurrentMergeScheduler -Dtests.seed=3AF868F9E00E5EBA -Dtests.slow=true -Dtests.locale=ru -Dtests.timezone=Europe/London -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1 [junit4] FAILURE 0.37s J1 | TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError [junit4] &gt; at __randomizedtesting.SeedInfo.seed([3AF868F9E00E5EBA:BD79D554E42E24BE]:0) [junit4] &gt; at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene53): {id=PostingsFormat(name=Memory doPackFST= true)}, docValues:{}, sim=DefaultSimilarity, locale=ru, timezone=Europe/London [junit4] 2&gt; NOTE: Mac OS X 10.8.5 x86_64/Oracle Corporation 1.8.0_51 (64-bit)/cpus=3,threads=1,free=16232544,total=54853632 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestDateSort, TestWildcardRandom, TestIndexWriterMergePolicy, TestPackedInts, TestSpansAdvanced, TestBooleanOr, TestParallelReaderEmptyIndex, TestFixedBitDocIdSet, TestIndexWriterDeleteByQuery, Test4GBStoredFields, TestMultiThreadTermVectors, TestIndexWriterConfig, TestToken, TestMergeSchedulerExternal] [junit4] Completed [21/401] on J1 in 0.39s, 2 tests, 1 failure &lt;&lt;&lt; FAILURES! </pre> </div></div>
</description>
<environment/>
<key id="12857546">LUCENE-6750</key>
<summary>TestMergeSchedulerExternal failure</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Thu, 20 Aug 2015 14:37:50 +0000</created>
<updated>Sun, 7 Feb 2016 19:45:45 +0000</updated>
<version>5.4</version>
<version>master</version>
<version>5.x</version>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14713616" author="steve_rowe" created="Wed, 26 Aug 2015 15:01:23 +0000">
<p>New fail on Policeman Jenkins <a href="http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-MacOSX/2623/" class="external-link" rel="nofollow">http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-MacOSX/2623/</a>, this time on branch_5x: </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] Suite: org.apache.lucene.TestMergeSchedulerExternal [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestMergeSchedulerExternal -Dtests.method=testSubclassConcurrentMergeScheduler -Dtests.seed=A2D285B04961A340 -Dtests.slow=true -Dtests.locale=it -Dtests.timezone=Pacific/Majuro -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] FAILURE 0.57s J0 | TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError [junit4] &gt; at __randomizedtesting.SeedInfo.seed([A2D285B04961A340:2553381D4D41D944]:0) [junit4] &gt; at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene53): {id=PostingsFormat(name=MockRandom)}, docValues:{}, sim=DefaultSimilarity, locale=it, timezone=Pacific/Majuro [junit4] 2&gt; NOTE: Mac OS X 10.8.5 x86_64/Oracle Corporation 1.8.0_60 (64-bit)/cpus=3,threads=1,free=368533088,total=518979584 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestLogMergePolicy, TestSameTokenSamePosition, TestCustomNorms, TestTerms, Test2BPostings, TestSpansEnum, TestBinaryDocValuesUpdates, TestDocValuesScoring, TestSparseFixedBitSet, TestByteArrayDataInput, FuzzyTermOnShortTermsTest, TestLucene50StoredFieldsFormat, TestIndexWriterDelete, TestTopDocsCollector, TestIndexWriter, TestWildcard, TestSimilarityProvider, TestBytesRefArray, TestQueryRescorer, TestSpans, TestFilterCachingPolicy, TestNot, TestSpanNotQuery, TestTermRangeFilter, TestScorerPerf, TestTermsEnum, TestApproximationSearchEquivalence, TestMinimize, TestSizeBoundedForceMerge, TestReadOnlyIndex, TestConjunctions, TestLongBitSet, TestMinShouldMatch2, TestLucene50SegmentInfoFormat, TestCharTermAttributeImpl, TestRecyclingIntBlockAllocator, TestQueryBuilder, TestPhrasePrefixQuery, TestIndexWriterNRTIsCurrent, TestNeverDelete, TestMatchNoDocsQuery, TestSegmentReader, TestIntsRef, TestBytesStore, TestPackedTokenAttributeImpl, TestTransactions, TestSimpleExplanationsOfNonMatches, TestFieldsReader, TestSearch, TestLucene50DocValuesFormat, Test2BPositions, TestForceMergeForever, TestMultiFields, TestNorms, TestFrequencyTrackingRingBuffer, TestFastCompressionMode, TestNRTReaderCleanup, TestBooleanMinShouldMatch, TestElevationComparator, TestLRUFilterCache, TestPerFieldPostingsFormat2, TestSloppyPhraseQuery2, TestBytesRefHash, TestIndexCommit, TestWindowsMMap, TestLucene50StoredFieldsFormatHighCompression, TestBinaryDocument, TestSleepingLockWrapper, TestNRTReaderWithThreads, TestNamedSPILoader, TestMultiLevelSkipList, TestDirectoryReaderReopen, TestConcurrentMergeScheduler, TestDateSort, TestBoolean2, TestMultiThreadTermVectors, TestRecyclingByteBlockAllocator, Test2BPostingsBytes, TestCachingWrapperFilter, TestMultiPhraseEnum, TestDuelingCodecsAtNight, TestPrefixQuery, TestMergeSchedulerExternal] </pre> </div></div>
</comment>
<comment id="14721104" author="dweiss" created="Sat, 29 Aug 2015 12:34:45 +0000">
<p>I've tried no MacOSX (Darwin Kernel Version 14.4.0), Java 1.8.0_60. No luck, everything passes fine.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> ant test-core -Dtests.dups=200 -Dtestcase=TestMergeSchedulerExternal -Dtests.method=testSubclassConcurrentMergeScheduler -Dtests.seed=A2D285B04961A340 -Dtests.slow=<span class="code-keyword">true</span> -Dtests.locale=it -Dtests.timezone=Pacific/Majuro -Dtests.asserts=<span class="code-keyword">true</span> -Dtests.file.encoding=UTF-8 </pre> </div></div>
</comment>
<comment id="15121238" author="thetaphi" created="Thu, 28 Jan 2016 11:12:25 +0000">
<p>Happened last night again. I was afraid that this was new failure with Java 8u72, but then <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikemccand" class="user-hover" rel="mikemccand">Michael McCandless</a> reminded me about this issue:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Build: http://jenkins.thetaphi.de/job/Lucene-Solr-trunk-MacOSX/3044/ Java: 64bit/jdk1.8.0 -XX:-UseCompressedOops -XX:+UseG1GC 1 tests failed. FAILED: org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler Error Message: Stack Trace: java.lang.AssertionError at __randomizedtesting.SeedInfo.seed([211001F2A252178:8590BDB22E055B7C]:0) at org.junit.Assert.fail(Assert.java:92) at org.junit.Assert.assertTrue(Assert.java:43) at org.junit.Assert.assertTrue(Assert.java:54) at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764) at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871) at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907) at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921) at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367) at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809) at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460) at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880) at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781) at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816) at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367) at java.lang.Thread.run(Thread.java:745) Build Log: [...truncated 466 lines...] [junit4] Suite: org.apache.lucene.TestMergeSchedulerExternal [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestMergeSchedulerExternal -Dtests.method=testSubclassConcurrentMergeScheduler -Dtests.seed=211001F2A252178 -Dtests.slow=true -Dtests.locale=en-IN -Dtests.timezone=Etc/GMT+6 -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [junit4] FAILURE 0.60s J1 | TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError [junit4] &gt; at __randomizedtesting.SeedInfo.seed([211001F2A252178:8590BDB22E055B7C]:0) [junit4] &gt; at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=1, maxDocsPerChunk=7, blockSize=1022), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=1, blockSize=1022)), sim=RandomSimilarity(queryNorm=false,coord=crazy): {}, locale=en-IN, timezone=Etc/GMT+6 [junit4] 2&gt; NOTE: Mac OS X 10.8.5 x86_64/Oracle Corporation 1.8.0_72 (64-bit)/cpus=3,threads=1,free=245451384,total=322961408 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestFastDecompressionMode, TestIndexWriterMergePolicy, TestPerSegmentDeletes, TestTermVectorsReader, TestDocBoost, TestNotDocIdSet, TestTerms, TestIndexWriterUnicode, TestCharsRef, TestTimeLimitingCollector, TestPointQueries, TestTopFieldCollector, TestArrayUtil, TestMultiThreadTermVectors, Test2BPositions, TestConjunctions, TestLevenshteinAutomata, TestIndexReaderClose, TestLucene50SegmentInfoFormat, TestDocumentsWriterDeleteQueue, TestSloppyPhraseQuery, TestSegmentMerger, TestIndexWriterOnJRECrash, TestAssertions, TestLongPostings, TestParallelLeafReader, TestIntArrayDocIdSet, TestIndexFileDeleter, TestEarlyTermination, TestBKD, TestDocValues, TestBinaryTerms, TestTopDocsCollector, TestCrash, TestSort, TestIndexWriterOutOfFileDescriptors, TestTotalHitCountCollector, TestCachingCollector, TestMergeSchedulerExternal] [junit4] Completed [82/406 (1!)] on J1 in 0.62s, 2 tests, 1 failure &lt;&lt;&lt; FAILURES! [...truncated 1066 lines...] BUILD FAILED /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/build.xml:740: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/build.xml:684: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/build.xml:59: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/lucene/build.xml:50: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/lucene/common-build.xml:1457: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-trunk-MacOSX/lucene/common-build.xml:1014: There were test failures: 406 suites (1 ignored), 3349 tests, 1 failure, 55 ignored (51 assumptions) [seed: 211001F2A252178] </pre> </div></div>
</comment>
<comment id="15136324" author="steve_rowe" created="Sun, 7 Feb 2016 17:18:27 +0000">
<p>New fail this morning on branch_5x with Java7 (doesn't reproduce for me):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Build: http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-MacOSX/3015/ Java: 64bit/jdk1.7.0 -XX:-UseCompressedOops -XX:+UseParallelGC 1 tests failed. FAILED: org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler Error Message: Stack Trace: java.lang.AssertionError at __randomizedtesting.SeedInfo.seed([14D2D99D22341661:9353643026146C65]:0) at org.junit.Assert.fail(Assert.java:92) at org.junit.Assert.assertTrue(Assert.java:43) at org.junit.Assert.assertTrue(Assert.java:54) at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1764) at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:871) at com.carrotsearch.randomizedtesting.RandomizedRunner$9.evaluate(RandomizedRunner.java:907) at com.carrotsearch.randomizedtesting.RandomizedRunner$10.evaluate(RandomizedRunner.java:921) at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:49) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45) at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:48) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:64) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:47) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367) at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:809) at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:460) at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:880) at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:781) at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:816) at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:827) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:45) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:41) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:40) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:53) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:47) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:64) at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:54) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:367) at java.lang.Thread.run(Thread.java:745) Build Log: [...truncated 725 lines...] [junit4] Suite: org.apache.lucene.TestMergeSchedulerExternal [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestMergeSchedulerExternal -Dtests.method=testSubclassConcurrentMergeScheduler -Dtests.seed=14D2D99D22341661 -Dtests.slow=true -Dtests.locale=en-AU -Dtests.timezone=Poland -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] FAILURE 0.40s J1 | TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError [junit4] &gt; at __randomizedtesting.SeedInfo.seed([14D2D99D22341661:9353643026146C65]:0) [junit4] &gt; at org.apache.lucene.TestMergeSchedulerExternal.testSubclassConcurrentMergeScheduler(TestMergeSchedulerExternal.java:116) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene54): {id=BlockTreeOrds(blocksize=128)}, docValues:{}, sim=RandomSimilarity(queryNorm=false,coord=crazy): {}, locale=en-AU, timezone=Poland [junit4] 2&gt; NOTE: Mac OS X 10.8.5 x86_64/Oracle Corporation 1.7.0_80 (64-bit)/cpus=3,threads=1,free=169302056,total=234356736 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestReqExclBulkScorer, TestMultiValuedNumericRangeQuery, TestNRTReaderCleanup, TestLucene50StoredFieldsFormatHighCompression, TestQueryWrapperFilter, TestFieldReuse, TestSloppyMath, TestDocumentsWriterStallControl, TestNoDeletionPolicy, TestPhrasePrefixQuery, TestLucene50CompoundFormat, TestFilterDirectory, TestFieldValueFilter, TestDocIdSet, TestSpansAdvanced2, FiniteStringsIteratorTest, TestNGramPhraseQuery, TestExternalCodecs, TestStressDeletes, TestCharFilter, TestTimSorter, TestToken, TestSpans, TestNumericRangeQuery32, TestInPlaceMergeSorter, TestIndexWriterOutOfFileDescriptors, TestWildcard, Test2BTerms, TestBM25Similarity, TestStressAdvance, TestQueryCachingPolicy, TestSpansEnum, TestDisjunctionMaxQuery, TestFieldValueQuery, TestMultiMMap, TestUnicodeUtil, TestRegExp, TestRAMDirectory, TestMultiCollector, TestLongPostings, TestPrefixQuery, TestIndexWriterCommit, TestLockFactory, TestDemoParallelLeafReader, TestPriorityQueue, TestTragicIndexWriterDeadlock, TestTwoPhaseCommitTool, TestPayloadsOnVectors, TestField, TestApproximationSearchEquivalence, TestAddIndexes, TestLongBitSet, TestSloppyPhraseQuery, Test2BNumericDocValues, TestInfoStream, TestFilterSpans, TestIndexWriterOnDiskFull, TestIndexWriterForceMerge, TestFixedBitSet, TestSearchAfter, TestIntsRef, TestDocument, TestBoostQuery, TestIndexReaderClose, TestSpansAdvanced, TestSimilarity2, TestIndexWriterReader, TestIndexCommit, TestCheckIndex, TestRateLimiter, Test2BPagedBytes, TestDocValuesRewriteMethod, TestLucene50SegmentInfoFormat, TestRegexpRandom2, TestRoaringDocIdSet, TestSpanExplanationsOfNonMatches, TestTotalHitCountCollector, TestPackedInts, TestSegmentTermEnum, TestDocumentWriter, TestBooleanQueryVisitSubscorers, TestPostingsOffsets, TestMultiTermConstantScore, TestMultiset, TestFileSwitchDirectory, TestMergeSchedulerExternal] [junit4] Completed [165/422 (1!)] on J1 in 0.43s, 2 tests, 1 failure &lt;&lt;&lt; FAILURES! [...truncated 838 lines...] BUILD FAILED /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/build.xml:750: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/build.xml:694: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/build.xml:59: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/lucene/build.xml:50: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/lucene/common-build.xml:1477: The following error occurred while executing this line: /Users/jenkins/workspace/Lucene-Solr-5.x-MacOSX/lucene/common-build.xml:1033: There were test failures: 422 suites (1 ignored), 3385 tests, 1 failure, 48 ignored (44 assumptions) [seed: 14D2D99D22341661] </pre> </div></div>
</comment>
<comment id="15136367" author="jira-bot" created="Sun, 7 Feb 2016 18:34:21 +0000">
<p>Commit b027adc7dd75665a5d46b74f7113d301c8546e71 in lucene-solr's branch refs/heads/branch_5x from Mike McCandless<br/> [ <a href="https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b027adc" class="external-link" rel="nofollow">https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=b027adc</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6750" title="TestMergeSchedulerExternal failure" class="issue-link" data-issue-key="LUCENE-6750">LUCENE-6750</a>: add verbosity when this test fails</p>
</comment>
<comment id="15136369" author="jira-bot" created="Sun, 7 Feb 2016 18:35:14 +0000">
<p>Commit 1d4d9c588ca433262feb79297262dca73e327f2e in lucene-solr's branch refs/heads/master from Mike McCandless<br/> [ <a href="https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1d4d9c5" class="external-link" rel="nofollow">https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1d4d9c5</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6750" title="TestMergeSchedulerExternal failure" class="issue-link" data-issue-key="LUCENE-6750">LUCENE-6750</a>: add verbosity when this test fails</p>
</comment>
<comment id="15136371" author="mikemccand" created="Sun, 7 Feb 2016 18:35:46 +0000">
<p>I pushed a change to the test to print IW's infoStream when it next fails ...</p>
</comment>
<comment id="15136399" author="jira-bot" created="Sun, 7 Feb 2016 19:45:45 +0000">
<p>Commit 1d4d9c588ca433262feb79297262dca73e327f2e in lucene-solr's branch refs/heads/jira/lucene-5438-nrt-replication from Mike McCandless<br/> [ <a href="https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1d4d9c5" class="external-link" rel="nofollow">https://git-wip-us.apache.org/repos/asf?p=lucene-solr.git;h=1d4d9c5</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6750" title="TestMergeSchedulerExternal failure" class="issue-link" data-issue-key="LUCENE-6750">LUCENE-6750</a>: add verbosity when this test fails</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 29 Aug 2015 12:34:45 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j5rz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6749] TestPerfTasksLogic failure</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6749</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>My Jenkins found a benchmark module failure that I can't reproduce on Linux or OS X - I beasted 20 iterations with the seed on each platform:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] Suite: org.apache.lucene.benchmark.byTask.TestPerfTasksLogic [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Rounds [junit4] 1&gt; [junit4] 1&gt; ------------&gt; Report Sum By (any) Name (4 about 4 out of 5) [junit4] 1&gt; Operation round runCnt recsPerRun rec/s elapsedSec avgUsedMem avgTotalMem [junit4] 1&gt; Rounds 0 1 20 163.93 0.12 14,755,992 514,850,816 [junit4] 1&gt; CreateIndex - - - 0 - - 1 - - - - 0 - - - 0.00 - - 0.00 - 12,061,112 - 514,850,816 [junit4] 1&gt; AddDocs_Exhaust 0 1 20 1,333.33 0.01 13,408,552 514,850,816 [junit4] 1&gt; CloseIndex - - - 0 - - 1 - - - - 0 - - - 0.00 - - 0.02 - 14,755,992 - 514,850,816 [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Rounds [junit4] 1&gt; [junit4] 1&gt; ------------&gt; Report Sum By (any) Name (4 about 4 out of 5) [junit4] 1&gt; Operation round runCnt recsPerRun rec/s elapsedSec avgUsedMem avgTotalMem [junit4] 1&gt; Rounds 0 1 22 164.18 0.13 12,074,760 514,850,816 [junit4] 1&gt; CreateIndex - - - 0 - - 1 - - - - 1 - 1,000.00 - - 0.00 - 12,074,760 - 514,850,816 [junit4] 1&gt; AddDocs_Exhaust 0 1 20 4,000.00 0.00 12,074,760 514,850,816 [junit4] 1&gt; CloseIndex - - - 0 - - 1 - - - - 1 - - 41.67 - - 0.02 - 12,074,760 - 514,850,816 [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; [junit4] 1&gt; ------------&gt; Report Sum By Prefix (X) (1 about 1 out of 1012) [junit4] 1&gt; Operation round runCnt recsPerRun rec/s elapsedSec avgUsedMem avgTotalMem [junit4] 1&gt; XSearch_2_Par 0 1 7289 14,433.66 0.50 57,401,768 514,850,816 [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; 0.36 sec --&gt; TEST-TestPerfTasksLogic.testHighlightingNoTvNoStore-seed#[3DD556FDEBB99CC4] added 1000 docs [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; 0.45 sec --&gt; TEST-TestPerfTasksLogic.testHighlightingTV-seed#[3DD556FDEBB99CC4] added 1000 docs [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestPerfTasksLogic -Dtests.method=testHighlightingTV -Dtests.seed=3DD556FDEBB99CC4 -Dtests.slow=true -Dtests.locale=zh_CN -Dtests.timezone=America/Campo_Grande -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1 [junit4] ERROR 0.80s J0 | TestPerfTasksLogic.testHighlightingTV &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.NullPointerException [junit4] &gt; at __randomizedtesting.SeedInfo.seed([3DD556FDEBB99CC4:5DF7708B74A6745D]:0) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.ReadTask.getFieldsToHighlight(ReadTask.java:300) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.SearchTravRetHighlightTask.getFieldsToHighlight(SearchTravRetHighlightTask.java:115) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.ReadTask.doLogic(ReadTask.java:169) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:146) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:197) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:138) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:146) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doSerialTasks(TaskSequence.java:197) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.TaskSequence.doLogic(TaskSequence.java:138) [junit4] &gt; at org.apache.lucene.benchmark.byTask.tasks.PerfTask.runAndMaybeStats(PerfTask.java:146) [junit4] &gt; at org.apache.lucene.benchmark.byTask.utils.Algorithm.execute(Algorithm.java:332) [junit4] &gt; at org.apache.lucene.benchmark.byTask.Benchmark.execute(Benchmark.java:77) [junit4] &gt; at org.apache.lucene.benchmark.BenchmarkTestCase.execBenchmark(BenchmarkTestCase.java:75) [junit4] &gt; at org.apache.lucene.benchmark.byTask.TestPerfTasksLogic.testHighlightingTV(TestPerfTasksLogic.java:224) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; Changed Locale to: null [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: root locale [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: de [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: en_US [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: no_NO_NY [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; Changed Locale to: root locale [junit4] 1&gt; Changed Analyzer to: org.apache.lucene.collation.CollationKeyAnalyzer() [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: de [junit4] 1&gt; Changed Analyzer to: org.apache.lucene.collation.CollationKeyAnalyzer(de) [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: en_US [junit4] 1&gt; Changed Analyzer to: org.apache.lucene.collation.CollationKeyAnalyzer(en_US) [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; Changed Locale to: no_NO_NY [junit4] 1&gt; Changed Analyzer to: org.apache.lucene.collation.CollationKeyAnalyzer(no_NO_NY) [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1 [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Rounds_2 [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 0--&gt;1: doc.term.vector:false--&gt;true compound:true--&gt;false [junit4] 1&gt; [junit4] 1&gt; [junit4] 1&gt; --&gt; Round 1--&gt;2: doc.term.vector:true--&gt;false compound:false--&gt;true [junit4] 1&gt; [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; ------------&gt; starting task: CreateIndex [junit4] 1&gt; ------------&gt; starting task: Seq_Exhaust [junit4] 1&gt; ------------&gt; starting task: Seq_Exhaust [junit4] 1&gt; ------------&gt; starting task: CloseIndex [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 1&gt; 0.18 sec --&gt; TEST-TestPerfTasksLogic.testIndexAndSearchTasks-seed#[3DD556FDEBB99CC4] added 1000 docs [junit4] 1&gt; ------------&gt; starting task: Seq [junit4] 2&gt; NOTE: leaving temporary files on disk at: /var/lib/jenkins/jobs/Lucene-Solr-tests-trunk/workspace/lucene/build/benchmark/test/J0/temp/lucene.benchmark.byTask.TestPerfTasksLogic_3DD556FDEBB99CC4-001 [junit4] 2&gt; NOTE: test params are: codec=FastCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=FAST, chunkSize=9, maxDocsPerChunk=7, blockSize=7), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=FAST, chunkSize=9, blockSize=7)), sim=RandomSimilarityProvider(queryNorm=true,coord=crazy): {}, locale=zh_CN, timezone=America/Campo_Grande [junit4] 2&gt; NOTE: Linux 4.1.0-custom2-amd64 amd64/Oracle Corporation 1.8.0_45 (64-bit)/cpus=16,threads=1,free=486910752,total=514850816 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestPerfTasksLogic] [junit4] Completed [18/18] on J0 in 16.71s, 24 tests, 1 error &lt;&lt;&lt; FAILURES! [junit4] [junit4] [junit4] Tests with failures: [junit4] - org.apache.lucene.benchmark.byTask.TestPerfTasksLogic.testHighlightingTV [junit4] [junit4] [junit4] JVM J0: 2.38 .. 20.28 = 17.91s [junit4] JVM J1: 1.55 .. 11.34 = 9.80s [junit4] JVM J2: 2.06 .. 10.59 = 8.53s [junit4] JVM J3: 2.03 .. 10.59 = 8.57s [junit4] JVM J4: 1.64 .. 7.97 = 6.32s [junit4] JVM J5: 1.81 .. 8.62 = 6.80s [junit4] JVM J6: 2.05 .. 8.63 = 6.58s [junit4] JVM J7: 1.97 .. 8.23 = 6.27s [junit4] JVM J8: 1.43 .. 8.61 = 7.18s [junit4] Execution time total: 20 seconds [junit4] Tests summary: 18 suites, 93 tests, 1 error </pre> </div></div>
</description>
<environment/>
<key id="12857544">LUCENE-6749</key>
<summary>TestPerfTasksLogic failure</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Thu, 20 Aug 2015 14:24:37 +0000</created>
<updated>Thu, 20 Aug 2015 14:24:37 +0000</updated>
<component>modules/benchmark</component>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j5rj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6753] TestFieldSkew test failure</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6753</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This test adds empty documents with no field contents, then reopens and asserts that scores are the same. Its not supposed to be a random test, it just does a simple execution against each query.</p> <p>But it fails with this seed in trunk (i committed some improved debugging):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ant test -Dtestcase=TestSimilarity2 -Dtests.method=testNoFieldSkew -Dtests.seed=216F1F3C38561BEF -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.locale=es_ES -Dtests.timezone=America/Catamarca -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] &gt; Throwable #1: java.lang.AssertionError: DefaultSimilarity: actual=0.0 = No matching clauses [junit4] &gt; ,expected=0.2169777 = sum of: [junit4] &gt; 0.10848885 = weight(foo:bar in 0) [DefaultSimilarity], result of: [junit4] &gt; 0.10848885 = score(doc=0,freq=1.0), product of: [junit4] &gt; 0.70710677 = queryWeight, product of: [junit4] &gt; 0.30685282 = idf(docFreq=1, docCount=1) [junit4] &gt; 2.3043842 = queryNorm [junit4] &gt; 0.15342641 = fieldWeight in 0, product of: [junit4] &gt; 1.0 = tf(freq=1.0), with freq of: [junit4] &gt; 1.0 = termFreq=1.0 [junit4] &gt; 0.30685282 = idf(docFreq=1, docCount=1) [junit4] &gt; 0.5 = fieldNorm(doc=0) [junit4] &gt; 0.10848885 = weight(foo:baz in 0) [DefaultSimilarity], result of: [junit4] &gt; 0.10848885 = score(doc=0,freq=1.0), product of: [junit4] &gt; 0.70710677 = queryWeight, product of: [junit4] &gt; 0.30685282 = idf(docFreq=1, docCount=1) [junit4] &gt; 2.3043842 = queryNorm [junit4] &gt; 0.15342641 = fieldWeight in 0, product of: [junit4] &gt; 1.0 = tf(freq=1.0), with freq of: [junit4] &gt; 1.0 = termFreq=1.0 [junit4] &gt; 0.30685282 = idf(docFreq=1, docCount=1) [junit4] &gt; 0.5 = fieldNorm(doc=0) [junit4] &gt; expected:&lt;0.21697770059108734&gt; but was:&lt;0.0&gt; [junit4] &gt; at __randomizedtesting.SeedInfo.seed([216F1F3C38561BEF:89FA6BFD1F67BF87]:0) [junit4] &gt; at org.apache.lucene.search.similarities.TestSimilarity2.testNoFieldSkew(TestSimilarity2.java:201) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=16060, maxDocsPerChunk=1, blockSize=6), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=16060, blockSize=6)), sim=DefaultSimilarity, locale=es_ES, timezone=America/Catamarca [junit4] 2&gt; NOTE: Linux 3.19.0-25-generic amd64/Oracle Corporation 1.8.0_45 (64-bit)/cpus=8,threads=1,free=140426184,total=189267968 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestSimilarity2] [junit4] Completed [1/1] in 0.64s, 1 test, 1 failure &lt;&lt;&lt; FAILURES! </pre> </div></div> <p>This is scary, it means the first reopen did not make documents visible when it should have? (or there is a sneaky test bug)</p>
</description>
<environment/>
<key id="12857566">LUCENE-6753</key>
<summary>TestFieldSkew test failure</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Thu, 20 Aug 2015 15:29:40 +0000</created>
<updated>Thu, 20 Aug 2015 15:44:24 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14705136" author="rcmuir" created="Thu, 20 Aug 2015 15:36:23 +0000">
<p>Looks like after the reopen the simple boolean query no longer works (unless i screwed up actual/expected, which is possible):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] &gt; Throwable #1: java.lang.AssertionError: DefaultSimilarity: actual=0.0 = No matching clauses [junit4] &gt; ,expected=0.2169777 = sum of: </pre> </div></div> <p>Note, explanation is used to do the score comparison, so maybe there is some issue with explain() ?</p>
</comment>
<comment id="14705141" author="rcmuir" created="Thu, 20 Aug 2015 15:41:30 +0000"><p>test bug i think: I will enforce logMP</p></comment>
<comment id="14705146" author="jira-bot" created="Thu, 20 Aug 2015 15:44:24 +0000">
<p>Commit 1696808 from <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rcmuir" class="user-hover" rel="rcmuir">Robert Muir</a> in branch 'dev/trunk'<br/> [ <a href="https://svn.apache.org/r1696808" class="external-link" rel="nofollow">https://svn.apache.org/r1696808</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6753" title="TestFieldSkew test failure" class="issue-link" data-issue-key="LUCENE-6753">LUCENE-6753</a>: defend against MockRandomMergePolicy</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 20 Aug 2015 15:44:24 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j5wf:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6751] TestSimlarity2.testNoFieldSkew() failure
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6751</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>ASF Jenkins found a failing seed for <tt>TestSimilarity2.testNoFieldSkew()</tt> <a href="https://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/770/" class="external-link" rel="nofollow">https://builds.apache.org/job/Lucene-Solr-NightlyTests-trunk/770/</a> that reproduces for me on OS X:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] Suite: org.apache.lucene.search.similarities.TestSimilarity2 [junit4] 2&gt; NOTE: download the large Jenkins line-docs file by running 'ant get-jenkins-line-docs' in the lucene directory. [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestSimilarity2 -Dtests.method=testNoFieldSkew -Dtests.seed=216F1F3C38561BEF -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=es_ES -Dtests.timezone=America/Catamarca -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] FAILURE 0.21s J0 | TestSimilarity2.testNoFieldSkew &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError: expected:&lt;0.21697770059108734&gt; but was:&lt;0.0&gt; [junit4] &gt; at __randomizedtesting.SeedInfo.seed([216F1F3C38561BEF:89FA6BFD1F67BF87]:0) [junit4] &gt; at org.apache.lucene.search.similarities.TestSimilarity2.testNoFieldSkew(TestSimilarity2.java:198) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: leaving temporary files on disk at: /x1/jenkins/jenkins-slave/workspace/Lucene-Solr-NightlyTests-trunk/lucene/build/core/test/J0/temp/lucene.search.similarities.TestSimilarity2_216F1F3C38561BEF-001 [junit4] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=16060, maxDocsPerChunk=1, blockSize=6), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=16060, blockSize=6)), sim=DefaultSimilarity, locale=es_ES, timezone=America/Catamarca [junit4] 2&gt; NOTE: Linux 3.13.0-52-generic amd64/Oracle Corporation 1.8.0_45 (64-bit)/cpus=4,threads=1,free=192996984,total=288882688 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestNewestSegment, TestIndexWriterOnJRECrash, TestSizeBoundedForceMerge, TestLogMergePolicy, TestLockFactory, TestMaxPosition, TestNeverDelete, TestMultiTermQueryRewrites, TestToken, TestIndexInput, TestDocValues, TestSimpleExplanationsOfNonMatches, TestVirtualMethod, TestAllFilesHaveChecksumFooter, TestHighCompressionMode, TestFilterLeafReader, TestHugeRamFile, TestSearcherManager, TestIndexWriterCommit, TestTrackingDirectoryWrapper, Test4GBStoredFields, TestCachingCollector, TestIsCurrent, TestApproximationSearchEquivalence, Test2BPostings, TestRoaringDocIdSet, TestIndexWriterFromReader, TestNumericDocValuesUpdates, TestExitableDirectoryReader, TestTermScorer, TestDirectPacked, TestLazyProxSkipping, TestIndexWriterUnicode, TestSimilarity2] [junit4] Completed [229/401] on J0 in 0.58s, 8 tests, 1 failure &lt;&lt;&lt; FAILURES! </pre> </div></div>
</description>
<environment/>
<key id="12857555">LUCENE-6751</key>
<summary>TestSimlarity2.testNoFieldSkew() failure</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Thu, 20 Aug 2015 15:09:40 +0000</created>
<updated>Thu, 20 Aug 2015 15:13:48 +0000</updated>
<version>master</version>
<due/>
<votes>0</votes>
<watches>0</watches>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12850791">LUCENE-6711</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j5tz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6744] equals methods should compare classes directly, not use instanceof
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6744</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>from a 2015-07-12 email to the dev list from Fuxiang Chen...</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>We have found some inconsistencies in the overriding of the equals() method in some files with respect to the conforming to the contract structure based on the Java Specification. Affected files: 1) ConstValueSource.java 2) DoubleConstValueSource.java 3) FixedBitSet.java 4) GeohashFunction.java 5) LongBitSet.java 6) SpanNearQuery.java 7) StringDistanceFunction.java 8) ValueSourceRangeFilter.java 9) VectorDistanceFunction.java The above files all uses instanceof in the overridden equals() method in comparing two objects. According to the Java Specification, the equals() method must be reflexive, symmetric, transitive and consistent. In the case of symmetric, it is stated that x.equals(y) should return true if and only if y.equals(x) returns true. Using instanceof is asymmetric and is not a valid symmetric contract. A more preferred way will be to compare the classes instead. i.e. if (this.getClass() != o.getClass()). However, if compiling the source code using JDK 7 and above, and if developers still prefer to use instanceof, you can make use of the static methods of Objects such as Objects.equals(this.id, that.id). (Making use of the static methods of Objects is currently absent in the methods.) It will be easier to override the equals() method and will ensure that the overridden equals() method will fulfill the contract rules. </pre> </div></div>
</description>
<environment/>
<key id="12856963">LUCENE-6744</key>
<summary>
equals methods should compare classes directly, not use instanceof
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="hossman">Hoss Man</reporter>
<labels>
<label>newdev</label>
</labels>
<created>Tue, 18 Aug 2015 17:09:21 +0000</created>
<updated>Tue, 1 Dec 2015 04:42:18 +0000</updated>
<due/>
<votes>0</votes>
<watches>6</watches>
<comments>
<comment id="14701688" author="eribeiro" created="Tue, 18 Aug 2015 17:51:10 +0000">
<p>My two cents: I have always preferred to use <tt>instanceof</tt>, but was unaware of the potential problems and inconsistencies of using it. <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/sad.gif" height="16" width="16" align="absmiddle" alt="" border="0"/> So, for stir up a little bit of discussion, I would like let you with two SO links that discuss this issue in depth:</p> <p><a href="http://stackoverflow.com/questions/596462/any-reason-to-prefer-getclass-over-instanceof-when-generating-equals" class="external-link" rel="nofollow">http://stackoverflow.com/questions/596462/any-reason-to-prefer-getclass-over-instanceof-when-generating-equals</a></p> <p><a href="http://stackoverflow.com/questions/27581/what-issues-should-be-considered-when-overriding-equals-and-hashcode-in-java/32223#32223" class="external-link" rel="nofollow">http://stackoverflow.com/questions/27581/what-issues-should-be-considered-when-overriding-equals-and-hashcode-in-java/32223#32223</a></p> <p>Best,<br/> eddie</p>
</comment>
<comment id="14947564" author="sstults" created="Wed, 7 Oct 2015 20:57:37 +0000">
<p>Java 7 is the documented minimum language level for Solr, so I think it's okay to use the Objects class for its static equals(Object a, Object b) method. (While we're at it we might even consider using its hash(Object...) function.)</p> <p>That would make ConstValueSource.equals look something like this:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> @Override <span class="code-keyword">public</span> <span class="code-object">boolean</span> equals(<span class="code-object">Object</span> o) { <span class="code-keyword">if</span> (<span class="code-keyword">this</span> == o) <span class="code-keyword">return</span> <span class="code-keyword">true</span>; <span class="code-keyword">if</span> (o == <span class="code-keyword">null</span> || getClass() != o.getClass()) <span class="code-keyword">return</span> <span class="code-keyword">false</span>; ConstValueSource that = (ConstValueSource) o; <span class="code-keyword">return</span> Objects.equals(constant, that.constant) &amp;&amp; Objects.equals(dv, that.dv); } </pre> </div></div> <p>Moreover, if we want to jump into Objects usage with both feet we can change hashCode to this:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> @Override <span class="code-keyword">public</span> <span class="code-object">int</span> hashCode() { <span class="code-keyword">return</span> Objects.hash(constant, dv); } </pre> </div></div>
</comment>
<comment id="14948993" author="paul.elschot@xs4all.nl" created="Thu, 8 Oct 2015 17:05:32 +0000">
<p>There is also <a href="https://issues.apache.org/jira/browse/LUCENE-6467" title="Simplify Query.equals()" class="issue-link" data-issue-key="LUCENE-6467"><del>LUCENE-6467</del></a>, perhaps that can be merged here.</p>
</comment>
<comment id="15020631" author="srajendra" created="Sat, 21 Nov 2015 19:23:01 +0000">
<p>Newdev here. Wanted to know if I can do this. Kindly let me know.<br/> Thanks!</p>
</comment>
<comment id="15020656" author="erickerickson" created="Sat, 21 Nov 2015 19:57:29 +0000">
<p>Sure, just make a patch and add it to the JIRA <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="16" width="16" align="absmiddle" alt="" border="0"/>.</p> <p>Here's the page for getting code, making patches etc.<br/> <a href="https://wiki.apache.org/solr/HowToContribute" class="external-link" rel="nofollow">https://wiki.apache.org/solr/HowToContribute</a></p> <p>Before changing the code, I'd just get to the point where I could run 'ant precommit' and 'ant test' on the checked-out code.</p> <p>Note, assuming you have things like Java and ant installed, checking out the code and getting the above two commands to run should be just a few minutes. Actually <em>running</em> the precommit or test targets will take quite a whie longer, but you can just watch.....</p>
</comment>
<comment id="15021497" author="srajendra" created="Mon, 23 Nov 2015 04:11:06 +0000">
<p>I have attached the patch. From the above stackoverflow links and comments it seemed getClass is a better option. So I have replaced instanceOf in all the said classes other than SpanNearQuery (which already seemed to be doing the correct thing). </p> <p>ant test and ant precommit have passed. Also I am using the git repo to do this, kindly let me know if that will be any problem.</p> <p>Thanks!</p>
</comment>
<comment id="15030393" author="srajendra" created="Sat, 28 Nov 2015 05:41:56 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=erickerickson" class="user-hover" rel="erickerickson">Erick Erickson</a> A gentle reminder to kindly take a look at this.</p>
</comment>
<comment id="15030614" author="erickerickson" created="Sat, 28 Nov 2015 18:24:45 +0000">
<p>Well, a few things:</p> <p>&gt; I didn't offer to shepherd it through and commit it, just answered a question on how to get the ball rolling.</p> <p>&gt; There are no tests that unexpectedly fail with the old code and succeed with the new code.</p> <p>&gt; Most importantly, I'm not a fan of changing behavior to conform to abstract principle without there being a demonstrable problem. In this case the argument is that using instanceof is incorrect and we should switch to getClass() because it's "more correct" and "honors the contract". This will change <em>behavior</em> and nobody has shown that this current behavior is unintended. And rather than change to getClass(), an alternative is to make either the equals method in the superclass final (OK, this won't work for ValueSource-derived classes) or the entire class that uses instanceof in the equals method final. Are either of those more appropriate? This latter is true for both Bitset classes for instance.</p> <p>For example, looking at the history for ConstValueSource.java, <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yseeley%40gmail.com" class="user-hover" rel="yseeley@gmail.com">Yonik Seeley</a> committed the original code and the equals method used getClass. Then as part of <a href="https://issues.apache.org/jira/browse/SOLR-1568" title="Implement Spatial Filter" class="issue-link" data-issue-key="SOLR-1568"><del>SOLR-1568</del></a> he changed it to use instanceof. I don't know why, but I'm not about to undo an intentional change on his part without asking about it.</p> <p>The two Bitset classes are final classes, and according to a quote in one of the links mentioned it's OK to use instanceof in the equals method in that case. Perhaps using getClass wouldn't be appropriate here, but I'd like <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shaie" class="user-hover" rel="shaie">Shai Erera</a> to weigh in.</p> <p>So you see where this is going. I want the authors of the code, or at least people who've done maintenance on them to weigh in on why instanceof was used before changing code:</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=yseeley%40gmail.com" class="user-hover" rel="yseeley@gmail.com">Yonik Seeley</a> for<br/> ConstValueSource.java<br/> DoubleConstValueSource.java<br/> ValueSourceRangeFilter.java</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shaie" class="user-hover" rel="shaie">Shai Erera</a> for (although these are final classes so it's probably OK but does it matter?) <br/> FixedBitSet.java<br/> LongBitSet.java</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=gsingers" class="user-hover" rel="gsingers">Grant Ingersoll</a> for<br/> GeohashFunction.java<br/> StringDistanceFunction.java<br/> VectorDistanceFunction.java</p> <p>I've made too many gratuitous changes that weren't actually fixing something to go down that road without checking <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/wink.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>Now, all that notwithstanding, the patch passes precommit and test so at least it didn't break any explicit tests that depended on the behavior of instanceof and I can argue that if instanceof is intentionally used in preference to getClass then there <em>should</em> be tests that fail if we use getClass.... </p> <p>And don't get me wrong. Assuming the authors of the code are OK, with it I'm perfectly happy to commit this patch...</p>
</comment>
<comment id="15033065" author="srajendra" created="Tue, 1 Dec 2015 04:42:18 +0000">
<p>Hi <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=erickerickson" class="user-hover" rel="erickerickson">Erick Erickson</a>,</p> <p>Thanks for the detailed analysis. Good points. I will wait for the authors/maintainers of the respective classes to weigh in then.</p> <p>Thanks!</p>
</comment>
</comments>
<attachments>
<attachment id="12773767" name="LUCENE-6744.patch" size="5788" author="srajendra" created="Mon, 23 Nov 2015 04:01:46 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Tue, 18 Aug 2015 17:51:10 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2j28v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6769] Various codec formats' testRandomExceptions() are failing with unexpected FileNotFoundException
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6769</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>From <a href="https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/934/" class="external-link" rel="nofollow">https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/934/</a> (I'll attach the full Jenkins <tt>consoleText</tt>, which has a bunch of exception output):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestLucene46SegmentInfoFormat -Dtests.method=testRandomExceptions -Dtests.seed=DE5D0B60FB3DAD54 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=de -Dtests.timezone=America/Sao_Paulo -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [junit4] FAILURE 0.53s J1 | TestLucene46SegmentInfoFormat.testRandomExceptions &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError: hit unexpected FileNotFoundException: file=_5k.si [junit4] &gt; at __randomizedtesting.SeedInfo.seed([DE5D0B60FB3DAD54:B67265A46533F4F4]:0) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deleteFile(IndexFileDeleter.java:753) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deletePendingFiles(IndexFileDeleter.java:530) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:456) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3680) [junit4] &gt; at org.apache.lucene.index.SerialMergeScheduler.merge(SerialMergeScheduler.java:40) [junit4] &gt; at org.apache.lucene.index.IndexWriter.maybeMerge(IndexWriter.java:1929) [junit4] &gt; at org.apache.lucene.index.IndexWriter.doAfterSegmentFlushed(IndexWriter.java:4731) [junit4] &gt; at org.apache.lucene.index.DocumentsWriter$MergePendingEvent.process(DocumentsWriter.java:695) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4757) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4748) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1476) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) [junit4] &gt; at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:429) [junit4] &gt; at org.apache.lucene.index.BaseSegmentInfoFormatTestCase.testRandomExceptions(BaseSegmentInfoFormatTestCase.java:48) [...] [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestLucene46FieldInfoFormat -Dtests.method=testRandomExceptions -Dtests.seed=DE5D0B60FB3DAD54 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=sr_BA -Dtests.timezone=Asia/Tashkent -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [junit4] FAILURE 0.48s J0 | TestLucene46FieldInfoFormat.testRandomExceptions &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError: hit unexpected FileNotFoundException: file=_5k.si [junit4] &gt; at __randomizedtesting.SeedInfo.seed([DE5D0B60FB3DAD54:B67265A46533F4F4]:0) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deleteFile(IndexFileDeleter.java:753) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deletePendingFiles(IndexFileDeleter.java:530) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:456) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3680) [junit4] &gt; at org.apache.lucene.index.SerialMergeScheduler.merge(SerialMergeScheduler.java:40) [junit4] &gt; at org.apache.lucene.index.IndexWriter.maybeMerge(IndexWriter.java:1929) [junit4] &gt; at org.apache.lucene.index.IndexWriter.doAfterSegmentFlushed(IndexWriter.java:4731) [junit4] &gt; at org.apache.lucene.index.DocumentsWriter$MergePendingEvent.process(DocumentsWriter.java:695) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4757) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4748) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1476) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) [junit4] &gt; at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:429) [junit4] &gt; at org.apache.lucene.index.BaseFieldInfoFormatTestCase.testRandomExceptions(BaseFieldInfoFormatTestCase.java:50) </pre> </div></div> <p>From <a href="https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/939/" class="external-link" rel="nofollow">https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/939/</a> (again, I'll attach the <tt>consoleText</tt>):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestLucene46SegmentInfoFormat -Dtests.method=testRandomExceptions -Dtests.seed=1A10EDD0B2491A33 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=fr -Dtests.timezone=BET -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] FAILURE 0.20s J2 | TestLucene46SegmentInfoFormat.testRandomExceptions &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError: hit unexpected FileNotFoundException: file=_3g.si [junit4] &gt; at __randomizedtesting.SeedInfo.seed([1A10EDD0B2491A33:723F83142C474393]:0) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deleteFile(IndexFileDeleter.java:753) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deletePendingFiles(IndexFileDeleter.java:530) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deleteNewFiles(IndexFileDeleter.java:733) [junit4] &gt; at org.apache.lucene.index.IndexWriter.deleteNewFiles(IndexWriter.java:4700) [junit4] &gt; at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4218) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3664) [junit4] &gt; at org.apache.lucene.index.SerialMergeScheduler.merge(SerialMergeScheduler.java:40) [junit4] &gt; at org.apache.lucene.index.IndexWriter.maybeMerge(IndexWriter.java:1929) [junit4] &gt; at org.apache.lucene.index.IndexWriter.doAfterSegmentFlushed(IndexWriter.java:4731) [junit4] &gt; at org.apache.lucene.index.DocumentsWriter$MergePendingEvent.process(DocumentsWriter.java:695) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4757) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4748) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1476) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) [junit4] &gt; at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:429) [junit4] &gt; at org.apache.lucene.index.BaseSegmentInfoFormatTestCase.testRandomExceptions(BaseSegmentInfoFormatTestCase.java:48) </pre> </div></div> <p>From <a href="http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/13710/" class="external-link" rel="nofollow">http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/13710/</a> (which has since expired on Policeman Jenkins - below is from <a href="http://markmail.org/message/dw4hvvpreyr4jimi" class="external-link" rel="nofollow">http://markmail.org/message/dw4hvvpreyr4jimi</a>):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Build: http://jenkins.thetaphi.de/job/Lucene-Solr-5.x-Linux/13710/ Java: 64bit/jdk1.7.0_80 -XX:+UseCompressedOops -XX:+UseG1GC 1 tests failed. FAILED: org.apache.lucene.codecs.blocktree.TestLucene40BlockFormat.testRandomExceptions Error Message: hit unexpected FileNotFoundException: file=_9.si Stack Trace: java.lang.AssertionError: hit unexpected FileNotFoundException: file=_9.si at __randomizedtesting.SeedInfo.seed([E3D1B260C7119B4B:8BFEDCA4591FC2EB]:0) at org.apache.lucene.index.IndexFileDeleter.deleteFile(IndexFileDeleter.java:753) at org.apache.lucene.index.IndexFileDeleter.deletePendingFiles(IndexFileDeleter.java:530) at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:456) at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3680) at org.apache.lucene.index.SerialMergeScheduler.merge(SerialMergeScheduler.java:40) at org.apache.lucene.index.IndexWriter.maybeMerge(IndexWriter.java:1929) at org.apache.lucene.index.IndexWriter.doAfterSegmentFlushed(IndexWriter.java:4731) at org.apache.lucene.index.DocumentsWriter$MergePendingEvent.process(DocumentsWriter.java:695) at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4757) at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4748) at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1476) at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:429) at org.apache.lucene.index.BasePostingsFormatTestCase.testRandomExceptions(BasePostingsFormatTestCase.java:86) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:606) at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1627) at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:836) at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:872) at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:886) at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:798) at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:458) at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:845) at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:747) at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:781) at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:792) at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54) at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55) at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) at java.lang.Thread.run(Thread.java:745) Build Log: [...truncated 4475 lines...] [junit4] Suite: org.apache.lucene.codecs.blocktree.TestLucene40BlockFormat [junit4] 1&gt; Unexpected exception: dumping fake-exception-log:... [junit4] 1&gt; [junit4] 1&gt; TEST: got expected fake exc:a random IOException (_7.cfe) [junit4] 1&gt; java.io.FileNotFoundException: a random IOException (_7.cfe) [junit4] 1&gt; at org.apache.lucene.store.MockDirectoryWrapper.maybeThrowIOExceptionOnOpen(MockDirectoryWrapper.java:458) [junit4] 1&gt; at org.apache.lucene.store.MockDirectoryWrapper.createOutput(MockDirectoryWrapper.java:548) [junit4] 1&gt; at org.apache.lucene.store.LockValidatingDirectoryWrapper.createOutput(LockValidatingDirectoryWrapper.java:44) [junit4] 1&gt; at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) [junit4] 1&gt; at org.apache.lucene.store.TrackingDirectoryWrapper.createOutput(TrackingDirectoryWrapper.java:43) [junit4] 1&gt; at org.apache.lucene.codecs.lucene40.Lucene40CompoundWriter.close(Lucene40CompoundWriter.java:163) [junit4] 1&gt; at org.apache.lucene.codecs.lucene40.Lucene40CompoundReader.close(Lucene40CompoundReader.java:160) [junit4] 1&gt; at org.apache.lucene.codecs.lucene40.Lucene40CompoundFormat.write(Lucene40CompoundFormat.java:53) [junit4] 1&gt; at org.apache.lucene.index.IndexWriter.createCompoundFile(IndexWriter.java:4680) [junit4] 1&gt; at org.apache.lucene.index.DocumentsWriterPerThread.sealFlushedSegment(DocumentsWriterPerThread.java:492) [junit4] 1&gt; at org.apache.lucene.index.DocumentsWriterPerThread.flush(DocumentsWriterPerThread.java:459) [junit4] 1&gt; at org.apache.lucene.index.DocumentsWriter.doFlush(DocumentsWriter.java:503) [junit4] 1&gt; at org.apache.lucene.index.DocumentsWriter.flushAllThreads(DocumentsWriter.java:615) [junit4] 1&gt; at org.apache.lucene.index.IndexWriter.getReader(IndexWriter.java:423) [junit4] 1&gt; at org.apache.lucene.index.DirectoryReader.open(DirectoryReader.java:86) [junit4] 1&gt; at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:459) [junit4] 1&gt; at org.apache.lucene.index.BasePostingsFormatTestCase.testRandomExceptions(BasePostingsFormatTestCase.java:86) [junit4] 1&gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [junit4] 1&gt; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [junit4] 1&gt; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [junit4] 1&gt; at java.lang.reflect.Method.invoke(Method.java:606) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1627) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:836) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:872) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:886) [junit4] 1&gt; at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50) [junit4] 1&gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [junit4] 1&gt; at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49) [junit4] 1&gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [junit4] 1&gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:798) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:458) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:845) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:747) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:781) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:792) [junit4] 1&gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54) [junit4] 1&gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [junit4] 1&gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [junit4] 1&gt; at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [junit4] 1&gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [junit4] 1&gt; at java.lang.Thread.run(Thread.java:745) [junit4] 1&gt; [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestLucene40BlockFormat -Dtests.method=testRandomExceptions -Dtests.seed=E3D1B260C7119B4B -Dtests.multiplier=3 -Dtests.slow=true -Dtests.locale=en_IE -Dtests.timezone=America/Virgin -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] FAILURE 0.04s J0 | TestLucene40BlockFormat.testRandomExceptions &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.AssertionError: hit unexpected FileNotFoundException: file=_9.si [junit4] &gt; at __randomizedtesting.SeedInfo.seed([E3D1B260C7119B4B:8BFEDCA4591FC2EB]:0) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deleteFile(IndexFileDeleter.java:753) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.deletePendingFiles(IndexFileDeleter.java:530) [junit4] &gt; at org.apache.lucene.index.IndexFileDeleter.refresh(IndexFileDeleter.java:456) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3680) [junit4] &gt; at org.apache.lucene.index.SerialMergeScheduler.merge(SerialMergeScheduler.java:40) [junit4] &gt; at org.apache.lucene.index.IndexWriter.maybeMerge(IndexWriter.java:1929) [junit4] &gt; at org.apache.lucene.index.IndexWriter.doAfterSegmentFlushed(IndexWriter.java:4731) [junit4] &gt; at org.apache.lucene.index.DocumentsWriter$MergePendingEvent.process(DocumentsWriter.java:695) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4757) [junit4] &gt; at org.apache.lucene.index.IndexWriter.processEvents(IndexWriter.java:4748) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1476) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) [junit4] &gt; at org.apache.lucene.index.BaseIndexFileFormatTestCase.testRandomExceptions(BaseIndexFileFormatTestCase.java:429) [junit4] &gt; at org.apache.lucene.index.BasePostingsFormatTestCase.testRandomExceptions(BasePostingsFormatTestCase.java:86) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] 2&gt; NOTE: leaving temporary files on disk at: /home/jenkins/workspace/Lucene-Solr-5.x-Linux/lucene/build/backward-codecs/test/J0/temp/lucene.codecs.blocktree.TestLucene40BlockFormat_E3D1B260C7119B4B-001 [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene53): {}, docValues:{}, sim=RandomSimilarityProvider(queryNorm=false,coord=crazy): {body=DFR I(F)1, f_DOCS_AND_FREQS_AND_POSITIONS=IB LL-D3(800.0), field=DFR I(ne)B1, f_DOCS=DFR I(F)LZ(0.3), f_DOCS_AND_FREQS=DFR I(n)B2, f_DOCS_AND_FREQS_AND_POSITIONS_AND_OFFSETS=DFR I(ne)L1, titleTokenized=IB LL-L2}, locale=en_IE, timezone=America/Virgin [junit4] 2&gt; NOTE: Linux 3.19.0-26-generic amd64/Oracle Corporation 1.7.0_80 (64-bit)/cpus=12,threads=1,free=196792272,total=525336576 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestReuseDocsEnum, TestMaxPositionInOldIndex, TestLucene40TermVectorsFormat, TestLucene40SegmentInfoFormat, TestLucene42NormsFormat, TestBackwardsCompatibility, TestBitVector, TestLucene40PostingsFormat, TestLucene40BlockFormat] [junit4] Completed [19/30] on J0 in 3.12s, 31 tests, 1 failure &lt;&lt;&lt; FAILURES! </pre> </div></div> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikemccand" class="user-hover" rel="mikemccand">Michael McCandless</a> previously looked at a couple of these: <a href="http://markmail.org/message/ogykur7itwihn36q" class="external-link" rel="nofollow">http://markmail.org/message/ogykur7itwihn36q</a> and <a href="http://markmail.org/message/tmh2ul74esybvwvr" class="external-link" rel="nofollow">http://markmail.org/message/tmh2ul74esybvwvr</a>.</p> <p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikemccand" class="user-hover" rel="mikemccand">Michael McCandless</a> noted when fixing one from July (from <a href="https://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3CCAL8PwkYXTs8cxgS1r_uBoFx6M7EvJezVsRg__64y7ZWO8PmzTA@mail.gmail.com%3E" class="external-link" rel="nofollow">https://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3CCAL8PwkYXTs8cxgS1r_uBoFx6M7EvJezVsRg__64y7ZWO8PmzTA@mail.gmail.com%3E</a> - oddly this email is not findable in markmail.org's archive):</p> <blockquote> <p>I just committed a fix. This was caused by a new assert from<br/> <a href="https://issues.apache.org/jira/browse/LUCENE-6616" title="IndexWriter should list files once on init, and IFD should not suppress FNFE" class="issue-link" data-issue-key="LUCENE-6616"><del>LUCENE-6616</del></a>, basically making IndexWriter more picky such that a codec<br/> is not allowed to have created a file if in fact it didn't create it.</p> <p>In this case the SimpleTextSIFormat was claiming to have created a<br/> file (si.addFile) before createOutput succeeded, but then createOutput<br/> hit an exc (and the Directory impl took care of removing the file<br/> itself)...</p></blockquote>
</description>
<environment/>
<key id="12859648">LUCENE-6769</key>
<summary>
Various codec formats' testRandomExceptions() are failing with unexpected FileNotFoundException
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Thu, 27 Aug 2015 16:43:34 +0000</created>
<updated>Tue, 27 Oct 2015 09:24:00 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14717026" author="steve_rowe" created="Thu, 27 Aug 2015 16:44:46 +0000"><p>attaching two runs' <tt>consoleText</tt>-s</p></comment>
<comment id="14717047" author="mikemccand" created="Thu, 27 Aug 2015 16:54:03 +0000">
<blockquote><p>oddly this email is not findable in markmail.org's archive</p></blockquote> <p>I've also seen some recent emails missing from markmail.org ... bad. We should ask them to re-index <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14717083" author="steve_rowe" created="Thu, 27 Aug 2015 17:12:32 +0000">
<p>On the ASF Infra mailing list, several Apache project members have noted the problem. Three days ago one of them mentioned that five days previously they sent a message to the MarkMail discussion mailing list (i.e. eight days ago), but at that point there had been no reply. The last archived post for that list is from four years ago: <a href="http://markmail.org/search/list:org.markmail.discuss" class="external-link" rel="nofollow">http://markmail.org/search/list:org.markmail.discuss</a>.</p> <p>And the "Feedback" link is broken.</p> <p>RIP MarkMail? That would be sad.</p>
</comment>
<comment id="14717143" author="mikemccand" created="Thu, 27 Aug 2015 17:42:55 +0000">
<blockquote><p>RIP MarkMail? That would be sad.</p></blockquote> <p>Oh no that would be sad.</p>
</comment>
<comment id="14717145" author="jira-bot" created="Thu, 27 Aug 2015 17:43:43 +0000">
<p>Commit 1698201 from <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=mikemccand" class="user-hover" rel="mikemccand">Michael McCandless</a> in branch 'dev/branches/branch_5x'<br/> [ <a href="https://svn.apache.org/r1698201" class="external-link" rel="nofollow">https://svn.apache.org/r1698201</a> ]</p> <p><a href="https://issues.apache.org/jira/browse/LUCENE-6769" title="Various codec formats&#39; testRandomExceptions() are failing with unexpected FileNotFoundException" class="issue-link" data-issue-key="LUCENE-6769">LUCENE-6769</a>: don't claim to have created a file until createOutput in fact succeeded</p>
</comment>
<comment id="14717147" author="mikemccand" created="Thu, 27 Aug 2015 17:44:29 +0000">
<p>I can't repro these failures, but I think I found the cause of the Lucene40/Lucene46 failures, I just committed a fix ... but let's leave this open to see if Jenkins agrees.</p>
</comment>
<comment id="14717200" author="steve_rowe" created="Thu, 27 Aug 2015 18:11:14 +0000">
<p>I sent the following through MarkLogic's "Contact Us" form (<a href="http://www.marklogic.com/company/contact-us/" class="external-link" rel="nofollow">http://www.marklogic.com/company/contact-us/</a>):</p> <blockquote> <p>The feedback link on Markmail.org &lt;<a href="http://markmail.org/docs/feedback.xqy" class="external-link" rel="nofollow">http://markmail.org/docs/feedback.xqy</a>&gt; is broken: I get a 500 Internal Server Error. Nobody from MarkLogic is responding on the Markmail.org discussion list, and the most recent post in the archive for that list is from four years ago &lt;<a href="http://markmail.org/search/list:org.markmail.discuss" class="external-link" rel="nofollow">http://markmail.org/search/list:org.markmail.discuss</a>&gt;. I'm attempting to contact you through this form because I can't find another alternative.</p> <p>The problem several people on projects at the Apache Software Foundation have noted, myself included (I'm an Apache member and a member of the Lucene PMC): Markmail.org is missing some emails from its archive. Here's one example I noticed, dated 14 July 2015, that should be in the org.apache.lucene.java-dev archive, but is not: </p> <p>&lt;<a href="https://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3CCAL8PwkYXTs8cxgS1r_uBoFx6M7EvJezVsRg__64y7ZWO8PmzTA@mail.gmail.com%3E" class="external-link" rel="nofollow">https://mail-archives.apache.org/mod_mbox/lucene-dev/201507.mbox/%3CCAL8PwkYXTs8cxgS1r_uBoFx6M7EvJezVsRg__64y7ZWO8PmzTA@mail.gmail.com%3E</a>&gt;</p> <p>Maybe you need to reindex?</p></blockquote>
</comment>
<comment id="14717427" author="mikemccand" created="Thu, 27 Aug 2015 20:09:30 +0000">
<p>Thanks <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steve_rowe" class="user-hover" rel="steve_rowe">Steve Rowe</a>!</p>
</comment>
<comment id="14719324" author="steve_rowe" created="Fri, 28 Aug 2015 15:10:39 +0000">
<p>ASF Jenkins found a failure in <tt>TestIndexWriterOutOfFileDescriptors</tt> <a href="https://builds.apache.org/job/Lucene-Solr-Tests-5.x-Java7/3463/" class="external-link" rel="nofollow">https://builds.apache.org/job/Lucene-Solr-Tests-5.x-Java7/3463/</a> from a random <tt>IOException</tt>, so I initially thought that it might not be related to this issue:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestIndexWriterOutOfFileDescriptors -Dtests.method=test -Dtests.seed=E47F9D72A7E8EF8E -Dtests.multiplier=2 -Dtests.slow=true -Dtests.locale=fr_CH -Dtests.timezone=America/Miquelon -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [junit4] ERROR 2.50s J0 | TestIndexWriterOutOfFileDescriptors.test &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.IllegalStateException: this writer hit an unrecoverable error; cannot commit [junit4] &gt; at __randomizedtesting.SeedInfo.seed([E47F9D72A7E8EF8E:6C2BA2A809148276]:0) [junit4] &gt; at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:2791) [junit4] &gt; at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:2977) [junit4] &gt; at org.apache.lucene.index.IndexWriter.shutdown(IndexWriter.java:1080) [junit4] &gt; at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1123) [junit4] &gt; at org.apache.lucene.index.TestIndexWriterOutOfFileDescriptors.test(TestIndexWriterOutOfFileDescriptors.java:87) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] &gt; Caused by: java.io.IOException: a random IOException (_r_Lucene50_0.tim) [junit4] &gt; at org.apache.lucene.store.MockDirectoryWrapper.maybeThrowIOExceptionOnOpen(MockDirectoryWrapper.java:456) [junit4] &gt; at org.apache.lucene.store.MockDirectoryWrapper.openInput(MockDirectoryWrapper.java:635) [junit4] &gt; at org.apache.lucene.codecs.blocktree.BlockTreeTermsReader.&lt;init&gt;(BlockTreeTermsReader.java:150) [junit4] &gt; at org.apache.lucene.codecs.lucene50.Lucene50PostingsFormat.fieldsProducer(Lucene50PostingsFormat.java:446) [junit4] &gt; at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat$FieldsReader.&lt;init&gt;(PerFieldPostingsFormat.java:261) [junit4] &gt; at org.apache.lucene.codecs.perfield.PerFieldPostingsFormat.fieldsProducer(PerFieldPostingsFormat.java:341) [junit4] &gt; at org.apache.lucene.index.SegmentCoreReaders.&lt;init&gt;(SegmentCoreReaders.java:104) [junit4] &gt; at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:65) [junit4] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) [junit4] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReaderForMerge(ReadersAndUpdates.java:617) [junit4] &gt; at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4020) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3664) [junit4] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:588) [junit4] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:626) [junit4] 2&gt; NOTE: leaving temporary files on disk at: /x1/jenkins/jenkins-slave/workspace/Lucene-Solr-Tests-5.x-Java7/lucene/build/core/test/J0/temp/lucene.index.TestIndexWriterOutOfFileDescriptors_E47F9D72A7E8EF8E-001 [junit4] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=1, maxDocsPerChunk=6, blockSize=4), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=1, blockSize=4)), sim=RandomSimilarityProvider(queryNorm=true,coord=yes): {titleTokenized=DFR I(F)B2, body=DFR GZ(0.3)}, locale=fr_CH, timezone=America/Miquelon [junit4] 2&gt; NOTE: Linux 3.13.0-52-generic amd64/Oracle Corporation 1.7.0_72 (64-bit)/cpus=4,threads=1,free=157853504,total=274726912 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestNativeFSLockFactory, TestSetOnce, TestTerms, TestByteBlockPool, TestFieldType, TestStringHelper, TestIndexFileDeleter, TestIntBlockPool, TestSpanNotQuery, TestSnapshotDeletionPolicy, TestUnicodeUtil, TestDeterminism, TestFieldReuse, TestIOUtils, TestTerm, TestSegmentReader, TestCustomSearcherSort, TestCodecHoldsOpenFiles, TestDisjunctionMaxQuery, TestRegexpRandom2, TestByteArrayDataInput, TestPersistentSnapshotDeletionPolicy, TestAllFilesHaveChecksumFooter, TestRollingBuffer, TestManyFields, TestSimilarityBase, TestUniqueTermCount, TestDocBoost, Test2BPostings, TestIndexWriterDeleteByQuery, TestIndexWriterConfig, TestAllFilesHaveCodecHeader, TestBlendedTermQuery, TestIndexWriterOnJRECrash, TestLucene50FieldInfoFormat, TestDirectoryReader, TestShardSearching, TestTermScorer, TestDocValuesScoring, Test2BBinaryDocValues, TestWindowsMMap, TestNeverDelete, TestDocValues, TestMaxPosition, TestPayloadNearQuery, TestDoc, TestNumericRangeQuery64, TestCollectionUtil, TestDocument, TestSpansAdvanced, TestFilterIterator, TestDirectory, TestSpanCollection, TestFilterDirectory, TestDefaultSimilarity, TestSearchForDuplicates, TestIndexWriter, TestPositionIncrement, TestParallelTermEnum, TestPrefixFilter, TestMultiPhraseEnum, TestVirtualMethod, TestBlockPostingsFormat2, TestIndexWriterCommit, TestBinaryDocValuesUpdates, TestIndexWriterDelete, TestUTF32ToUTF8, TestSpanTermQuery, TestPerFieldDocValuesFormat, TestAddIndexes, TestMultiMMap, TestSearcherManager, TestDeletionPolicy, TestIndexWriterMergePolicy, TestTimeLimitingCollector, TestTopDocsMerge, TestIndexWriterUnicode, TestArrayUtil, TestPhraseQuery, TestComplexExplanations, TestPagedBytes, TestSegmentTermDocs, TestPerFieldPostingsFormat2, TestIndexWriterOnDiskFull, TestCustomNorms, TestPostingsOffsets, TestTransactionRollback, TestFlex, TestRAMDirectory, TestMultiPhraseQuery, TestLazyProxSkipping, TestOmitPositions, TestParallelLeafReader, TestBytesRefHash, TestIndexInput, TestNearSpansOrdered, TestScorerPerf, TestSpansAdvanced2, TestBooleanQuery, TestSortRandom, TestSentinelIntSet, TestMultiLevelSkipList, TestCheckIndex, TestFieldValueFilter, TestSpanMultiTermQueryWrapper, TestCompiledAutomaton, TestPrefixQuery, TestTotalHitCountCollector, TestBooleanScorer, TestSpanFirstQuery, TestNoMergeScheduler, TestIndexWriterLockRelease, TestRollback, TestCloseableThreadLocal, MultiCollectorTest, TestSimpleAttributeImpl, TestPositiveScoresOnlyCollector, TestReusableStringReader, TestLucene50CompoundFormat, TestLucene53NormsFormat, TestCodecUtil, TestDocInverterPerFieldErrorInfo, TestExitableDirectoryReader, TestFilterDirectoryReader, TestIndexReaderClose, TestIndexWriterFromReader, TestIndexWriterOutOfFileDescriptors] [junit4] Completed [359/411] on J0 in 2.51s, 1 test, 1 error &lt;&lt;&lt; FAILURES! </pre> </div></div> <p>A single run on my OS X laptop didn't fail, but the first beasting round with the above seed (dups=4, iters=10) failed twice with <tt>FileNotFoundException</tt>:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [beaster] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestIndexWriterOutOfFileDescriptors -Dtests.method=test -Dtests.seed=E47F9D72A7E8EF8E -Dtests.multiplier=2 -Dtests.slow=true -Dtests.locale=fr_CH -Dtests.timezone=America/Miquelon -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [beaster] [10:54:05.256] ERROR 5.33s J2 | TestIndexWriterOutOfFileDescriptors.test {#0 seed=[E47F9D72A7E8EF8E:6C2BA2A809148276]} &lt;&lt;&lt; [beaster] &gt; Throwable #1: java.lang.IllegalStateException: this writer hit an unrecoverable error; cannot commit [beaster] &gt; at __randomizedtesting.SeedInfo.seed([E47F9D72A7E8EF8E:6C2BA2A809148276]:0) [beaster] &gt; at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:2791) [beaster] &gt; at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:2977) [beaster] &gt; at org.apache.lucene.index.IndexWriter.shutdown(IndexWriter.java:1080) [beaster] &gt; at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1123) [beaster] &gt; at org.apache.lucene.index.TestIndexWriterOutOfFileDescriptors.test(TestIndexWriterOutOfFileDescriptors.java:87) [beaster] &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [beaster] &gt; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [beaster] &gt; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [beaster] &gt; at java.lang.reflect.Method.invoke(Method.java:606) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1627) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:836) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:872) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:886) [beaster] &gt; at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50) [beaster] &gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [beaster] &gt; at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [beaster] &gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:798) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:458) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:845) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:747) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:781) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:792) [beaster] &gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54) [beaster] &gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [beaster] &gt; at java.lang.Thread.run(Thread.java:745) [beaster] &gt; Caused by: java.io.FileNotFoundException: a random IOException (_n.nvm) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.maybeThrowIOExceptionOnOpen(MockDirectoryWrapper.java:458) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.openInput(MockDirectoryWrapper.java:635) [beaster] &gt; at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:109) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.openChecksumInput(MockDirectoryWrapper.java:1009) [beaster] &gt; at org.apache.lucene.codecs.lucene53.Lucene53NormsProducer.&lt;init&gt;(Lucene53NormsProducer.java:58) [beaster] &gt; at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsProducer(Lucene53NormsFormat.java:82) [beaster] &gt; at org.apache.lucene.index.SegmentCoreReaders.&lt;init&gt;(SegmentCoreReaders.java:111) [beaster] &gt; at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:65) [beaster] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) [beaster] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReaderForMerge(ReadersAndUpdates.java:617) [beaster] &gt; at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4020) [beaster] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3664) [beaster] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:588) [beaster] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:626) [beaster] 2&gt; NOTE: leaving temporary files on disk at: /Users/sarowe/svn/lucene/dev/branches/branch_5x/lucene/build/core/test/J2/temp/lucene.index.TestIndexWriterOutOfFileDescriptors_E47F9D72A7E8EF8E-001 [beaster] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=1, maxDocsPerChunk=6, blockSize=4), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=1, blockSize=4)), sim=RandomSimilarityProvider(queryNorm=true,coord=yes): {body=DFR GZ(0.3), titleTokenized=DFR I(F)B2}, locale=fr_CH, timezone=America/Miquelon [beaster] 2&gt; NOTE: Mac OS X 10.10.5 x86_64/Oracle Corporation 1.7.0_71 (64-bit)/cpus=8,threads=1,free=150186288,total=211812352 [beaster] 2&gt; NOTE: All tests run in this JVM: [TestIndexWriterOutOfFileDescriptors] [beaster] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestIndexWriterOutOfFileDescriptors -Dtests.method=test -Dtests.seed=E47F9D72A7E8EF8E -Dtests.multiplier=2 -Dtests.slow=true -Dtests.locale=fr_CH -Dtests.timezone=America/Miquelon -Dtests.asserts=true -Dtests.file.encoding=US-ASCII [beaster] [10:54:54.695] ERROR 2.34s J2 | TestIndexWriterOutOfFileDescriptors.test {#0 seed=[E47F9D72A7E8EF8E:6C2BA2A809148276]} &lt;&lt;&lt; [beaster] &gt; Throwable #1: java.lang.IllegalStateException: this writer hit an unrecoverable error; cannot commit [beaster] &gt; at __randomizedtesting.SeedInfo.seed([E47F9D72A7E8EF8E:6C2BA2A809148276]:0) [beaster] &gt; at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:2791) [beaster] &gt; at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:2977) [beaster] &gt; at org.apache.lucene.index.IndexWriter.shutdown(IndexWriter.java:1080) [beaster] &gt; at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:1123) [beaster] &gt; at org.apache.lucene.index.TestIndexWriterOutOfFileDescriptors.test(TestIndexWriterOutOfFileDescriptors.java:87) [beaster] &gt; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) [beaster] &gt; at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) [beaster] &gt; at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) [beaster] &gt; at java.lang.reflect.Method.invoke(Method.java:606) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.invoke(RandomizedRunner.java:1627) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$6.evaluate(RandomizedRunner.java:836) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$7.evaluate(RandomizedRunner.java:872) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$8.evaluate(RandomizedRunner.java:886) [beaster] &gt; at org.apache.lucene.util.TestRuleSetupTeardownChained$1.evaluate(TestRuleSetupTeardownChained.java:50) [beaster] &gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [beaster] &gt; at org.apache.lucene.util.TestRuleThreadAndTestName$1.evaluate(TestRuleThreadAndTestName.java:49) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [beaster] &gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl.forkTimeoutingTask(ThreadLeakControl.java:798) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$3.evaluate(ThreadLeakControl.java:458) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner.runSingleTest(RandomizedRunner.java:845) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$3.evaluate(RandomizedRunner.java:747) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$4.evaluate(RandomizedRunner.java:781) [beaster] &gt; at com.carrotsearch.randomizedtesting.RandomizedRunner$5.evaluate(RandomizedRunner.java:792) [beaster] &gt; at org.apache.lucene.util.AbstractBeforeAfterRule$1.evaluate(AbstractBeforeAfterRule.java:46) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at org.apache.lucene.util.TestRuleStoreClassName$1.evaluate(TestRuleStoreClassName.java:42) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.NoShadowingOrOverridesOnMethodsRule$1.evaluate(NoShadowingOrOverridesOnMethodsRule.java:39) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at org.apache.lucene.util.TestRuleAssertionsRequired$1.evaluate(TestRuleAssertionsRequired.java:54) [beaster] &gt; at org.apache.lucene.util.TestRuleMarkFailure$1.evaluate(TestRuleMarkFailure.java:48) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreAfterMaxFailures$1.evaluate(TestRuleIgnoreAfterMaxFailures.java:65) [beaster] &gt; at org.apache.lucene.util.TestRuleIgnoreTestSuites$1.evaluate(TestRuleIgnoreTestSuites.java:55) [beaster] &gt; at com.carrotsearch.randomizedtesting.rules.StatementAdapter.evaluate(StatementAdapter.java:36) [beaster] &gt; at com.carrotsearch.randomizedtesting.ThreadLeakControl$StatementRunner.run(ThreadLeakControl.java:365) [beaster] &gt; at java.lang.Thread.run(Thread.java:745) [beaster] &gt; Caused by: java.io.FileNotFoundException: a random IOException (_n.nvm) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.maybeThrowIOExceptionOnOpen(MockDirectoryWrapper.java:458) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.openInput(MockDirectoryWrapper.java:635) [beaster] &gt; at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:109) [beaster] &gt; at org.apache.lucene.store.MockDirectoryWrapper.openChecksumInput(MockDirectoryWrapper.java:1009) [beaster] &gt; at org.apache.lucene.codecs.lucene53.Lucene53NormsProducer.&lt;init&gt;(Lucene53NormsProducer.java:58) [beaster] &gt; at org.apache.lucene.codecs.lucene53.Lucene53NormsFormat.normsProducer(Lucene53NormsFormat.java:82) [beaster] &gt; at org.apache.lucene.index.SegmentCoreReaders.&lt;init&gt;(SegmentCoreReaders.java:111) [beaster] &gt; at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:65) [beaster] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReader(ReadersAndUpdates.java:145) [beaster] &gt; at org.apache.lucene.index.ReadersAndUpdates.getReaderForMerge(ReadersAndUpdates.java:617) [beaster] &gt; at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4020) [beaster] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3664) [beaster] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:588) [beaster] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:626) [beaster] 2&gt; NOTE: leaving temporary files on disk at: /Users/sarowe/svn/lucene/dev/branches/branch_5x/lucene/build/core/test/J2/temp/lucene.index.TestIndexWriterOutOfFileDescriptors_E47F9D72A7E8EF8E-002 [beaster] 2&gt; NOTE: test params are: codec=DummyCompressingStoredFields(storedFieldsFormat=CompressingStoredFieldsFormat(compressionMode=DUMMY, chunkSize=1, maxDocsPerChunk=6, blockSize=4), termVectorsFormat=CompressingTermVectorsFormat(compressionMode=DUMMY, chunkSize=1, blockSize=4)), sim=RandomSimilarityProvider(queryNorm=true,coord=yes): {body=DFR GZ(0.3), titleTokenized=DFR I(F)B2}, locale=fr_CH, timezone=America/Miquelon [beaster] 2&gt; NOTE: Mac OS X 10.10.5 x86_64/Oracle Corporation 1.7.0_71 (64-bit)/cpus=8,threads=1,free=128790824,total=211812352 [beaster] 2&gt; NOTE: All tests run in this JVM: [TestIndexWriterOutOfFileDescriptors, TestIndexWriterOutOfFileDescriptors] </pre> </div></div> <p>So that's weird.</p>
</comment>
<comment id="14720278" author="mikemccand" created="Fri, 28 Aug 2015 17:24:06 +0000">
<p>Thanks <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steve_rowe" class="user-hover" rel="steve_rowe">Steve Rowe</a>, this is a different failure: that FNFE is a randomly created one by this test. Really the test should use MockDirectoryWrapper.FakeIOException to prevent confusion like this.</p>
</comment>
<comment id="14720283" author="mikemccand" created="Fri, 28 Aug 2015 17:26:53 +0000">
<p>Actually, this is <tt>MockDirectoryWrapper.maybeThrowIOExceptionOnOpen</tt>, and it looks like it's intentionally throwing FNFE or NSFE to tickle and code we have that specifically handles these exceptions ... so we should leave it. But still this failure is different from the original ones on this issue ...</p>
</comment>
<comment id="14974940" author="steve_rowe" created="Mon, 26 Oct 2015 20:13:41 +0000">
<p>Never got a response from them, but somebody else at the ASF asked MarkLogic about the situation on Twitter and got this reply: <a href="https://twitter.com/wikier/status/643682546551779328" class="external-link" rel="nofollow">https://twitter.com/wikier/status/643682546551779328</a></p>
</comment>
<comment id="14976072" author="mikemccand" created="Tue, 27 Oct 2015 09:24:00 +0000">
<p>Thanks for the update <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=steve_rowe" class="user-hover" rel="steve_rowe">Steve Rowe</a>.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12840850">LUCENE-6616</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12752799" name="Lucene-Solr-NightlyTests-5.x-934-consoleText.txt" size="744012" author="steve_rowe" created="Thu, 27 Aug 2015 16:44:46 +0000"/>
<attachment id="12752798" name="Lucene-Solr-NightlyTests-5.x-939-consoleText.txt" size="412293" author="steve_rowe" created="Thu, 27 Aug 2015 16:44:46 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 27 Aug 2015 16:54:03 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2jgfz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6943] Jvm Crashes occassionaly with Lucene 4.6.1
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6943</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>#</p> <ol> <li>A fatal error has been detected by the Java Runtime Environment:<br/> #</li> <li>SIGSEGV (0xb) at pc=0x00007f5625212cd7, pid=9889, tid=139920130201344<br/> #</li> <li>JRE version: Java(TM) SE Runtime Environment (7.0_60-b19) (build 1.7.0_60-b19)</li> <li>Java VM: Java HotSpot(TM) 64-Bit Server VM (24.60-b09 mixed mode linux-amd64 )</li> <li>Problematic frame:</li> <li>J 11490 C2 org.apache.lucene.store.ByteBufferIndexInput.readByte()B (126 bytes) @ 0x00007f5625212cd7 <span class="error">&#91;0x00007f5625212c80+0x57&#93;</span><br/> #</li> <li>Failed to write core dump. Core dumps have been disabled. To enable core dumping, try "ulimit -c unlimited" before starting Java again<br/> #</li> <li>If you would like to submit a bug report, please visit:</li> <li><a href="http://bugreport.sun.com/bugreport/crash.jsp" class="external-link" rel="nofollow">http://bugreport.sun.com/bugreport/crash.jsp</a><br/> #</li> </ol> <p>Register to memory mapping:</p> <p>RAX=0x00007f55de053510 is an oop</p> {instance class} <ul class="alternate" type="square"> <li>klass: {other class} <p>RBX=0x00007f549dffc028 is an oop<br/> org.apache.lucene.codecs.lucene41.Lucene41PostingsReader </p></li> <li>klass: 'org/apache/lucene/codecs/lucene41/Lucene41PostingsReader'<br/> RCX=0x0000000000000004 is an unknown value<br/> RDX=0x0000000000000080 is an unknown value<br/> RSP=0x00007f41b1a7f640 is pointing into the stack for thread: 0x00007f48f81a4000<br/> RBP=0x00007f4b1bff3630 is an oop<br/> java.nio.DirectByteBufferR </li> <li>klass: 'java/nio/DirectByteBufferR'<br/> RSI=0x00007f4b1bff35a8 is an oop<br/> org.apache.lucene.store.MMapDirectory$MMapIndexInput </li> <li>klass: 'org/apache/lucene/store/MMapDirectory$MMapIndexInput'<br/> RDI=0x00000000237c532a is an unknown value<br/> R8 =0x00000000237c4da3 is an unknown value<br/> R9 =0x00007f4b1bff35a8 is an oop<br/> org.apache.lucene.store.MMapDirectory$MMapIndexInput </li> <li>klass: 'org/apache/lucene/store/MMapDirectory$MMapIndexInput'<br/> R10=0x00007f3a8f98a000 is an unknown value<br/> R11=0x00000000237c4da3 is an unknown value<br/> R12=0x00007f41b1a81f30 is pointing into the stack for thread: 0x00007f48f81a4000<br/> R13=0x0000000000000093 is an unknown value<br/> R14=0x000000000000431f is an unknown value<br/> R15=0x00007f48f81a4000 is a thread</li> </ul> <p>Stack: <span class="error">&#91;0x00007f41b1985000,0x00007f41b1a86000&#93;</span>, sp=0x00007f41b1a7f640, free space=1001k<br/> Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code)<br/> J 11490 C2 org.apache.lucene.store.ByteBufferIndexInput.readByte()B (126 bytes) @ 0x00007f5625212cd7 <span class="error">&#91;0x00007f5625212c80+0x57&#93;</span><br/> J 4940 C2 org.apache.lucene.codecs.lucene41.Lucene41PostingsReader$BlockDocsAndPositionsEnum.nextPosition()I (118 bytes) @ 0x00007f5624515cb4 <span class="error">&#91;0x00007f5624515980+0x334&#93;</span><br/> J 10578 C2 org.apache.lucene.search.ExactPhraseScorer.phraseFreq()I (624 bytes) @ 0x00007f56256de588 <span class="error">&#91;0x00007f56256de4e0+0xa8&#93;</span><br/> J 10629 C2 org.apache.lucene.search.ExactPhraseScorer.advance(I)I (152 bytes) @ 0x00007f5625729d84 <span class="error">&#91;0x00007f5625729ba0+0x1e4&#93;</span><br/> J 10433 C2 org.apache.lucene.search.MinShouldMatchSumScorer.advance(I)I (113 bytes) @ 0x00007f5625653c34 <span class="error">&#91;0x00007f5625653ae0+0x154&#93;</span><br/> J 5630 C2 org.apache.lucene.search.BooleanScorer2.advance(I)I (14 bytes) @ 0x00007f5624642a10 <span class="error">&#91;0x00007f5624642820+0x1f0&#93;</span><br/> J 5826 C2 org.apache.lucene.search.DisjunctionScorer.advance(I)I (87 bytes) @ 0x00007f56246f140c <span class="error">&#91;0x00007f56246f13c0+0x4c&#93;</span><br/> J 8801 C2 org.apache.lucene.search.join.FkToChildBlockJoinQuery$FkToChildBlockJoinScorer.advance(I)I (284 bytes) @ 0x00007f56251274c0 <span class="error">&#91;0x00007f5625127440+0x80&#93;</span><br/> J 5630 C2 org.apache.lucene.search.BooleanScorer2.advance(I)I (14 bytes) @ 0x00007f56246429fc <span class="error">&#91;0x00007f5624642820+0x1dc&#93;</span><br/> J 4797 C2 org.apache.lucene.search.FilteredQuery$LeapFrogScorer.score(Lorg/apache/lucene/search/Collector;)V (91 bytes) @ 0x00007f56244e9ccc <span class="error">&#91;0x00007f56244e9c40+0x8c&#93;</span><br/> J 4613 C2 org.apache.lucene.search.IndexSearcher.search(Ljava/util/List;Lorg/apache/lucene/search/Weight;Lorg/apache/lucene/search/Collector;)V (93 bytes) @ 0x00007f562446cbec <span class="error">&#91;0x00007f562446ca80+0x16c&#93;</span><br/> J 6159 C2 org.apache.solr.search.SolrIndexSearcher.getDocListNC(Lorg/apache/solr/search/SolrIndexSearcher$QueryResult;Lorg/apache/solr/search/SolrIndexSearcher$QueryCommand;)V (708 bytes) @ 0x00007f562486cc30 <span class="error">&#91;0x00007f562486c9a0+0x290&#93;</span><br/> J 11811 C2 org.apache.solr.search.SolrIndexSearcher.getDocListC(Lorg/apache/solr/search/SolrIndexSearcher$QueryResult;Lorg/apache/solr/search/SolrIndexSearcher$QueryCommand;)V (696 bytes) @ 0x00007f5625c957c0 <span class="error">&#91;0x00007f5625c955c0+0x200&#93;</span><br/> J 9702 C2 org.apache.solr.search.SolrIndexSearcher.search(Lorg/apache/solr/search/SolrIndexSearcher$QueryResult;Lorg/apache/solr/search/SolrIndexSearcher$QueryCommand;)Lorg/apache/solr/search/SolrIndexSearcher$QueryResult; (8 bytes) @ 0x00007f5625461404 <span class="error">&#91;0x00007f56254613e0+0x24&#93;</span><br/> j org.apache.solr.handler.component.QueryComponent.process(Lorg/apache/solr/handler/component/ResponseBuilder;)V+1537</p>
</description>
<environment/>
<key id="12923447">LUCENE-6943</key>
<summary>Jvm Crashes occassionaly with Lucene 4.6.1</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="bhengra.amit@gmail.com">amit bhengra</reporter>
<labels></labels>
<created>Mon, 21 Dec 2015 14:49:23 +0000</created>
<updated>Thu, 24 Dec 2015 13:16:55 +0000</updated>
<version>4.6.1</version>
<component>core/query/scoring</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15066514" author="bhengra.amit@gmail.com" created="Mon, 21 Dec 2015 14:52:49 +0000">
<p>will be providing core dump file in some time as I am unable to reproduce the crash</p>
</comment>
<comment id="15066589" author="mikemccand" created="Mon, 21 Dec 2015 15:43:50 +0000">
<p>Is it possible you are closing readers while searches are still running against them? If you switch to <tt>NIOFSDirectory</tt> instead of {{MMapDirectory} do the crashes still happen?</p>
</comment>
<comment id="15066610" author="bhengra.amit@gmail.com" created="Mon, 21 Dec 2015 15:56:07 +0000">
<p>Haven't tried that, will try that and post here.</p>
</comment>
<comment id="15067705" author="bhengra.amit@gmail.com" created="Tue, 22 Dec 2015 07:47:02 +0000">
<p>Hey Michael, We are using Solr+lucene for our search, can there be an issue with Solr in this case?</p>
</comment>
<comment id="15067860" author="mikemccand" created="Tue, 22 Dec 2015 09:40:41 +0000">
<p>&gt; can there be an issue with Solr in this case?</p> <p>Hmm maybe it's possible there were Solr bugs in 4.6.1 around closing searchers that are still in use by active searches (4.6.1 is quite old by now) ... did switching to <tt>NIOFSDirectory</tt> avoid the crash?</p>
</comment>
<comment id="15067892" author="bhengra.amit@gmail.com" created="Tue, 22 Dec 2015 10:08:05 +0000">
<p>Have run with NIOFSDirectory haven't seen the issue so far, but have to wait more as in one instance it took around 7 days for this issue to surface and in another it was within hours.</p>
</comment>
<comment id="15069636" author="bhengra.amit@gmail.com" created="Wed, 23 Dec 2015 13:51:24 +0000">
<p>Hi Michael,</p> <p>We tried with NIOFSDirectory, we didn't get any jvm crash yet but we see there are heap issues now, this is probably due to file buffers being stored in heap now from my understanding and it is not getting completely collected during GC, any particular GC setting/solr cache setting you would suggest to resolve this ?</p>
</comment>
<comment id="15070909" author="bhengra.amit@gmail.com" created="Thu, 24 Dec 2015 11:29:56 +0000">
<p>Hi Michael,</p> <p>The box with NIOFS has crashed today, I am attaching the error log.</p>
</comment>
<comment id="15070932" author="thetaphi" created="Thu, 24 Dec 2015 11:51:13 +0000">
<p>Hi,<br/> according to the crash log, you are using MMapDirectory! This stack trace cannot come from NIOFSDirectory.</p> <p>In any case, this error can <b>only</b> happen, if something else closes IndexReader while searches are running. As you are using Solr in an embedded way, t looks like you may shutdown Solr Cores / close SolrIndexSearcher / ... in parallel threads. We can also give no real support, as you are using Solr inside some Clojure scripts, which is not an officially supported config. It could be that this setup corrupts your JVM.</p> <p>I'd also strongly suggest to update to latest Java 7u80 (or later if you have payed Oracle support) or better upgrade to Java 8u66.</p>
</comment>
<comment id="15070934" author="thetaphi" created="Thu, 24 Dec 2015 11:55:04 +0000">
<p>Hi,<br/> if this only affects one of your boxes, it may also be a hardware problem!</p>
</comment>
<comment id="15070951" author="bhengra.amit@gmail.com" created="Thu, 24 Dec 2015 12:23:29 +0000">
<p>Hi Uwe,</p> <p>Yes Uwe we were earlier using MMapDirectory but we switched to NIOFS if you check the latest log file here : <a href="https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log" class="external-link" rel="nofollow">https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log</a></p> <p>Also we will checkout the options mentioned by you.</p>
</comment>
<comment id="15070953" author="bhengra.amit@gmail.com" created="Thu, 24 Dec 2015 12:32:31 +0000">
<p>And yes we have checked with hardware issues also, there was no problem and this has occurred in 3 boxes now.</p>
</comment>
<comment id="15070955" author="mikemccand" created="Thu, 24 Dec 2015 12:38:53 +0000">
<blockquote><p>we were earlier using MMapDirectory but we switched to NIOFS if you check the latest log file here : <a href="https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log" class="external-link" rel="nofollow">https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log</a></p></blockquote> <p>That error log shows that you are still using <tt>MMapDirectory</tt> because <tt>ByteBufferIndexInput</tt> (where the crash happens) is only used by <tt>MMapDirectory</tt>.</p> <p>Please triple-check your configuration and try again to switch to <tt>NIOFSDirectory</tt>...</p>
</comment>
<comment id="15070960" author="thetaphi" created="Thu, 24 Dec 2015 12:44:31 +0000">
<blockquote><p>we were earlier using MMapDirectory but we switched to NIOFS if you check the latest log file here: <a href="https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log" class="external-link" rel="nofollow">https://issues.apache.org/jira/secure/attachment/12779429/hs_err_pid9254.log</a></p></blockquote> <p>Sorry, this is definitely using MMapDirectory, because this one uses ByteBufferIndexInput as implementation class!</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Stack: [0x00007fc83191e000,0x00007fc831a1f000], sp=0x00007fc831a195c0, free space=1005k Native frames: (J=compiled Java code, j=interpreted, Vv=VM code, C=native code) J 1583 C2 org.apache.lucene.store.ByteBufferIndexInput.readByte()B (126 bytes) @ 0x00007fe487f50c0c [0x00007fe487f50bc0+0x4c] </pre> </div></div> <p>Please check your solrconfig.xml!</p> <p>In addition: MMapDirectory tries its best to prevent SIGSEGV by early throwing AlreadyClosedException. Can you check the log files if you see any occurence of stuff like AlreadyClosedException or other IOExceptions? If you see those, the SIGSEGV was prevented by the tracking code, but under high load with high concurrency this cannot be safely tracked, as we would otherwise significantly slowdown searches. So it may throw AlreadyClosed/IOExceptions or crash. But both tell you that there is a programming error (because something closes IndexReaders while searches are running).</p> <p>Switching to NIOFSDirectory would just prevent hard crushes by slowing down searches, but the error in your / Solr's code is still there. So please look for IO/AlreadyClosed exceptions in the logs (with MMap or NIO doesnt matter).</p>
</comment>
<comment id="15070991" author="bhengra.amit@gmail.com" created="Thu, 24 Dec 2015 13:16:55 +0000">
<p>Sure Uwe and Michael, we will double check this and revert.</p>
</comment>
</comments>
<attachments>
<attachment id="12779429" name="hs_err_pid9254.log" size="350795" author="bhengra.amit@gmail.com" created="Thu, 24 Dec 2015 11:30:38 +0000"/>
<attachment id="12778837" name="hs_err_pid9889.log" size="516401" author="bhengra.amit@gmail.com" created="Mon, 21 Dec 2015 14:52:49 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 21 Dec 2015 15:43:50 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2q5vb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6941] TestStressIndexing2.testMultiConfig() failure: all instances of a given field name must have the same term vectors settings
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6941</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>ASF Jenkins found this failure: <a href="https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/1050/" class="external-link" rel="nofollow">https://builds.apache.org/job/Lucene-Solr-NightlyTests-5.x/1050/</a>. I was able to reproduce by beasting (1/10 dups failed on the first beast iteration):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[junit4] Suite: org.apache.lucene.index.TestStressIndexing2 [junit4] 2&gt; NOTE: download the large Jenkins line-docs file by running 'ant get-jenkins-line-docs' in the lucene directory. [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestStressIndexing2 -Dtests.method=testMultiConfig -Dtests.seed=337C1E3DCE453481 -Dtests.multiplier=2 -Dtests.nightly=true -Dtests.slow=true -Dtests.linedocsfile=/x1/jenkins/lucene-data/enwiki.random.lines.txt -Dtests.locale=hr_HR -Dtests.timezone=Asia/Shanghai -Dtests.asserts=true -Dtests.file.encoding=UTF-8 [junit4] ERROR 1.92s J1 | TestStressIndexing2.testMultiConfig &lt;&lt;&lt; [junit4] &gt; Throwable #1: java.lang.IllegalArgumentException: all instances of a given field name must have the same term vectors settings (storeTermVectorOffsets changed for field="f0") [junit4] &gt; at __randomizedtesting.SeedInfo.seed([337C1E3DCE453481:FEEE68E563132BCF]:0) [junit4] &gt; at org.apache.lucene.index.TermVectorsConsumerPerField.start(TermVectorsConsumerPerField.java:170) [junit4] &gt; at org.apache.lucene.index.TermsHashPerField.start(TermsHashPerField.java:292) [junit4] &gt; at org.apache.lucene.index.FreqProxTermsWriterPerField.start(FreqProxTermsWriterPerField.java:74) [junit4] &gt; at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:611) [junit4] &gt; at org.apache.lucene.index.DefaultIndexingChain.processField(DefaultIndexingChain.java:344) [junit4] &gt; at org.apache.lucene.index.DefaultIndexingChain.processDocument(DefaultIndexingChain.java:300) [junit4] &gt; at org.apache.lucene.index.DocumentsWriterPerThread.updateDocument(DocumentsWriterPerThread.java:234) [junit4] &gt; at org.apache.lucene.index.DocumentsWriter.updateDocument(DocumentsWriter.java:450) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1477) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1256) [junit4] &gt; at org.apache.lucene.index.TestStressIndexing2.indexSerial(TestStressIndexing2.java:250) [junit4] &gt; at org.apache.lucene.index.TestStressIndexing2.testMultiConfig(TestStressIndexing2.java:106) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] &gt; Suppressed: java.lang.IllegalStateException: close() called in wrong state: RESET [junit4] &gt; at org.apache.lucene.analysis.MockTokenizer.fail(MockTokenizer.java:126) [junit4] &gt; at org.apache.lucene.analysis.MockTokenizer.close(MockTokenizer.java:293) [junit4] &gt; at org.apache.lucene.analysis.TokenFilter.close(TokenFilter.java:58) [junit4] &gt; at org.apache.lucene.index.DefaultIndexingChain$PerField.invert(DefaultIndexingChain.java:687) [junit4] &gt; ... 44 more [junit4] 2&gt; NOTE: leaving temporary files on disk at: /x1/jenkins/jenkins-slave/workspace/Lucene-Solr-NightlyTests-5.x/lucene/build/core/test/J1/temp/lucene.index.TestStressIndexing2_337C1E3DCE453481-001 [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene54): {f25=FSTOrd50, f32=FSTOrd50, id=PostingsFormat(name=LuceneVarGapDocFreqInterval), f19=Lucene50(blocksize=128), f68=Lucene50(blocksize=128), f43=FSTOrd50, f15=Lucene50(blocksize=128), f14=FSTOrd50, f95=Lucene50(blocksize=128), f33=Lucene50(blocksize=128), f65=FSTOrd50, f93=Lucene50(blocksize=128), f77=Lucene50(blocksize=128), f12=PostingsFormat(name=LuceneVarGapDocFreqInterval), f71=Lucene50(blocksize=128), f83=FSTOrd50, f91=Lucene50(blocksize=128), f2=Lucene50(blocksize=128), f40=Lucene50(blocksize=128), f10=FSTOrd50, f28=Lucene50(blocksize=128), f92=PostingsFormat(name=LuceneVarGapDocFreqInterval), f81=PostingsFormat(name=LuceneVarGapDocFreqInterval), f57=Lucene50(blocksize=128), f22=Lucene50(blocksize=128), f58=FSTOrd50, f23=PostingsFormat(name=LuceneVarGapDocFreqInterval), f13=Lucene50(blocksize=128), f46=Lucene50(blocksize=128), f48=Lucene50(blocksize=128), f82=Lucene50(blocksize=128), f36=FSTOrd50, f52=PostingsFormat(name=LuceneVarGapDocFreqInterval), f31=Lucene50(blocksize=128), f27=PostingsFormat(name=LuceneVarGapDocFreqInterval), f90=FSTOrd50, f69=FSTOrd50, f80=Lucene50(blocksize=128), f73=Lucene50(blocksize=128), f17=Lucene50(blocksize=128), f1=PostingsFormat(name=LuceneVarGapDocFreqInterval), f86=Lucene50(blocksize=128), f63=PostingsFormat(name=LuceneVarGapDocFreqInterval), f26=Lucene50(blocksize=128), f64=Lucene50(blocksize=128), f51=Lucene50(blocksize=128), f84=Lucene50(blocksize=128), f5=PostingsFormat(name=LuceneVarGapDocFreqInterval), f8=Lucene50(blocksize=128), f49=PostingsFormat(name=LuceneVarGapDocFreqInterval), f20=Lucene50(blocksize=128), f29=FSTOrd50, f59=Lucene50(blocksize=128), f39=Lucene50(blocksize=128), f9=PostingsFormat(name=LuceneVarGapDocFreqInterval), f55=Lucene50(blocksize=128), f94=FSTOrd50, f99=Lucene50(blocksize=128), f74=PostingsFormat(name=LuceneVarGapDocFreqInterval), f47=FSTOrd50, f41=PostingsFormat(name=LuceneVarGapDocFreqInterval), f37=Lucene50(blocksize=128), f98=FSTOrd50, f21=FSTOrd50, f42=Lucene50(blocksize=128), f62=Lucene50(blocksize=128), f89=PostingsFormat(name=LuceneVarGapDocFreqInterval), f7=FSTOrd50, f67=PostingsFormat(name=LuceneVarGapDocFreqInterval), f78=PostingsFormat(name=LuceneVarGapDocFreqInterval), f24=Lucene50(blocksize=128), f56=PostingsFormat(name=LuceneVarGapDocFreqInterval), f76=FSTOrd50, f0=Lucene50(blocksize=128), f38=PostingsFormat(name=LuceneVarGapDocFreqInterval), f53=Lucene50(blocksize=128), f16=PostingsFormat(name=LuceneVarGapDocFreqInterval), f72=FSTOrd50, f54=FSTOrd50, f45=PostingsFormat(name=LuceneVarGapDocFreqInterval)}, docValues:{}, sim=DefaultSimilarity, locale=hr_HR, timezone=Asia/Shanghai [junit4] 2&gt; NOTE: Linux 3.13.0-52-generic amd64/Oracle Corporation 1.7.0_80 (64-bit)/cpus=4,threads=1,free=199000432,total=376963072 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestNRTCachingDirectory, TestCodecs, TestIntArrayDocIdSet, TestPayloads, TestFastDecompressionMode, TestScoreCachingWrappingScorer, TestDateTools, TestIntBlockPool, TestIndexWriterForceMerge, TestUnicodeUtil, TestIndexWriterDeleteByQuery, TestBinaryDocument, TestCachingTokenFilter, TestLongBitSet, TestAddIndexes, TestDisjunctionMaxQuery, TestLucene50TermVectorsFormat, TestMergeSchedulerExternal, Test2BNumericDocValues, TestMultiCollector, TestIndexWriterMaxDocs, TestDirectoryReaderReopen, TestFieldReuse, TestDocument, TestSpanExplanationsOfNonMatches, TestSameScoresWithThreads, TestOmitPositions, TestBytesRefArray, TestDuelingCodecsAtNight, TestTermVectors, TestWeakIdentityMap, TestTermdocPerf, TestSegmentMerger, TestNIOFSDirectory, TestNewestSegment, TestNeedsScores, TestNotDocIdSet, TestDemoParallelLeafReader, TestBooleanMinShouldMatch, TestPositiveScoresOnlyCollector, TestFieldMaskingSpanQuery, TestSpanSearchEquivalence, TestFieldValueQuery, TestFilteredSearch, TestFieldType, TestForceMergeForever, TestFixedBitDocIdSet, TestStressIndexing2] [junit4] Completed [91/414 (1!)] on J1 in 2.28s, 3 tests, 1 error &lt;&lt;&lt; FAILURES! </pre> </div></div>
</description>
<environment/>
<key id="12923183">LUCENE-6941</key>
<summary>
TestStressIndexing2.testMultiConfig() failure: all instances of a given field name must have the same term vectors settings
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Sat, 19 Dec 2015 00:15:18 +0000</created>
<updated>Sat, 19 Dec 2015 00:15:18 +0000</updated>
<version>5.5</version>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2q48n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6934] java.io.EOFException: read past EOF: MMapIndexInput [slice=_342.fdx]
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6934</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>We are getting following exception when we are trying to commit the changes done on the index.</p> <p>java.io.EOFException: read past EOF: MMapIndexInput(path="&lt;cache-directory&gt;/_342.cfs") <span class="error">&#91;slice=_342.fdx&#93;</span><br/> at org.apache.lucene.store.ByteBufferIndexInput.readByte(ByteBufferIndexInput.java:78)<br/> at org.apache.lucene.store.DataInput.readInt(DataInput.java:84)<br/> at org.apache.lucene.store.ByteBufferIndexInput.readInt(ByteBufferIndexInput.java:129)<br/> at org.apache.lucene.codecs.CodecUtil.checkHeader(CodecUtil.java:126)<br/> at org.apache.lucene.codecs.compressing.CompressingStoredFieldsReader.&lt;init&gt;(CompressingStoredFieldsReader.java:102)<br/> at org.apache.lucene.codecs.compressing.CompressingStoredFieldsFormat.fieldsReader(CompressingStoredFieldsFormat.java:113)<br/> at org.apache.lucene.index.SegmentCoreReaders.&lt;init&gt;(SegmentCoreReaders.java:147)<br/> at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:56)<br/> at org.apache.lucene.index.ReadersAndLiveDocs.getReader(ReadersAndLiveDocs.java:121)<br/> at org.apache.lucene.index.BufferedDeletesStream.applyDeletes(BufferedDeletesStream.java:216)<br/> at org.apache.lucene.index.IndexWriter.applyAllDeletes(IndexWriter.java:2961)<br/> at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:2952)<br/> at org.apache.lucene.index.IndexWriter.prepareCommitInternal(IndexWriter.java:2692)<br/> at org.apache.lucene.index.IndexWriter.commitInternal(IndexWriter.java:2827)<br/> at org.apache.lucene.index.IndexWriter.commit(IndexWriter.java:2807)</p> <p>This is the exception when we tried to close after commit failed:</p> <p>java.io.FileNotFoundException: &lt;cache-directory&gt;/_342.cfs (No such file or directory)<br/> at java.io.RandomAccessFile.open(Native Method)<br/> at java.io.RandomAccessFile.&lt;init&gt;(RandomAccessFile.java:241)<br/> at org.apache.lucene.store.MMapDirectory.openInput(MMapDirectory.java:193)<br/> at org.apache.lucene.store.MMapDirectory.createSlicer(MMapDirectory.java:203)<br/> at org.apache.lucene.store.CompoundFileDirectory.&lt;init&gt;(CompoundFileDirectory.java:102)<br/> at org.apache.lucene.index.SegmentCoreReaders.&lt;init&gt;(SegmentCoreReaders.java:116)<br/> at org.apache.lucene.index.SegmentReader.&lt;init&gt;(SegmentReader.java:56)<br/> at org.apache.lucene.index.ReadersAndLiveDocs.getReader(ReadersAndLiveDocs.java:121)<br/> at org.apache.lucene.index.BufferedDeletesStream.applyDeletes(BufferedDeletesStream.java:216)<br/> at org.apache.lucene.index.IndexWriter.applyAllDeletes(IndexWriter.java:2961)<br/> at org.apache.lucene.index.IndexWriter.maybeApplyDeletes(IndexWriter.java:2952)<br/> at org.apache.lucene.index.IndexWriter.doFlush(IndexWriter.java:2925)<br/> at org.apache.lucene.index.IndexWriter.flush(IndexWriter.java:2894)<br/> at org.apache.lucene.index.IndexWriter.closeInternal(IndexWriter.java:928)<br/> at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:883)<br/> at org.apache.lucene.index.IndexWriter.close(IndexWriter.java:845)</p> <p>Could you please point us what might be possible cause of this?</p>
</description>
<environment/>
<key id="12922329">LUCENE-6934</key>
<summary>
java.io.EOFException: read past EOF: MMapIndexInput [slice=_342.fdx]
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tejas.jethva">Tejas Jethva</reporter>
<labels></labels>
<created>Wed, 16 Dec 2015 10:38:24 +0000</created>
<updated>Fri, 18 Dec 2015 20:29:44 +0000</updated>
<version>4.2</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15064712" author="mikemccand" created="Fri, 18 Dec 2015 20:29:44 +0000">
<p>Hi, can you instead send an email to the Lucene user's list (java-user@lucene.apache.org)? This looks like index corruption, and there could be various causes (maybe including bugs that have been fixed since 4.2, which is quite old).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 18 Dec 2015 20:29:44 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2pyz3:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6914] DecimalDigitFilter skips characters in some cases (supplemental?)
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6914</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Found this while writing up the solr ref guide for DecimalDigitFilter. </p> <p>With input like "��������" ("Double Struck" 1984) the filter produces "1��8��" (1, double struck 9, 8, double struck 4) add some non-decimal characters in between the digits (ie: "��x��x��x��") and you get the expected output ("1x9x8x4"). This doesn't affect all decimal characters though, as evident by the existing test cases.</p> <p>Perhaps this is an off by one bug in the "if the original was supplementary, shrink the string" code path?</p>
</description>
<environment/>
<key id="12917076">LUCENE-6914</key>
<summary>
DecimalDigitFilter skips characters in some cases (supplemental?)
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="hossman">Hoss Man</reporter>
<labels></labels>
<created>Mon, 30 Nov 2015 21:54:47 +0000</created>
<updated>Wed, 2 Dec 2015 17:29:40 +0000</updated>
<version>5.4</version>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="15032559" author="hossman" created="Mon, 30 Nov 2015 21:57:51 +0000">
<p>failure produced by attached test patch...</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestDecimalDigitFilter -Dtests.method=testDoubleStruck -Dtests.seed=3126DECB8CE805E -Dtests.slow=true -Dtests.locale=ga -Dtests.timezone=Africa/Juba -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1 [junit4] FAILURE 0.03s | TestDecimalDigitFilter.testDoubleStruck &lt;&lt;&lt; [junit4] &gt; Throwable #1: org.junit.ComparisonFailure: term 0 expected:&lt;1[984]&gt; but was:&lt;1[��8��]&gt; [junit4] &gt; at __randomizedtesting.SeedInfo.seed([3126DECB8CE805E:92961DD9D4C68E38]:0) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:186) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:301) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:305) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertTokenStreamContents(BaseTokenStreamTestCase.java:309) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertAnalyzesTo(BaseTokenStreamTestCase.java:359) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.assertAnalyzesTo(BaseTokenStreamTestCase.java:368) [junit4] &gt; at org.apache.lucene.analysis.BaseTokenStreamTestCase.checkOneTerm(BaseTokenStreamTestCase.java:429) [junit4] &gt; at org.apache.lucene.analysis.core.TestDecimalDigitFilter.testDoubleStruck(TestDecimalDigitFilter.java:74) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) </pre> </div></div>
</comment>
<comment id="15032625" author="hossman" created="Mon, 30 Nov 2015 22:37:52 +0000">
<p>updated patch with beefed up randomized testing to reproduce the problem that way (either that or some other problem that looks similar to my naked eye)</p> <p>Then I took a shot in the dark at a fix to the call to StemmerUtil.delete and that seems to make the beast happy.</p> <p>Since i'm way out of my depth here i don't intend on commiting w/o explicit feedback from someone who understands this code. (i'm mainly worried i may have introduced some other equally bad bug w/o realizing it).</p> <p>Anybody who understands this and thinks my patch looks good is welcome to run with it for 5.4, no need to wait for me.</p>
</comment>
<comment id="15032825" author="hossman" created="Tue, 1 Dec 2015 00:55:44 +0000">
<p>the redundancy in the two randomized tests (and wasteful int[] I introduced) was bugging me, so I refactored some logic into determininghte set of all decimal digits for reuse in both tests.</p>
</comment>
<comment id="15035905" author="rcmuir" created="Wed, 2 Dec 2015 14:56:06 +0000">
<p>looks buggy indeed. Can we also add a simple test (��x��x��x�� -&gt; 1x9x8x4) ?</p>
</comment>
<comment id="15035911" author="rcmuir" created="Wed, 2 Dec 2015 14:57:49 +0000">
<p>or maybe the doubleStruck test is good enough? i guess the only oddity is, it actually has whitespace in between the characters, but at a glance its hard to tell its not e.g. full-width digits. Maybe we should just replace the spaces with x's.</p>
</comment>
<comment id="15036156" author="hossman" created="Wed, 2 Dec 2015 17:13:11 +0000">
<p>i wrote it thinking it would be helpful to first demonstrate what worked (x, or space, or some non candidate char in between digits as a "gap"), but then when you replace those "gaps" when empty <del>space</del> strings it breaks. now that we know the problem and can trivially reproduce with randomized tests, i'm not sure it's really relevant &#8211; but you could always just clone those asserts and do a bunch of different varieties for the "gap" (single space, x, some wide supplemental character that isn't a digit, etc...)</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12856015">LUCENE-6737</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12774917" name="LUCENE-6914.patch" size="7891" author="hossman" created="Tue, 1 Dec 2015 00:55:44 +0000"/>
<attachment id="12774898" name="LUCENE-6914.patch" size="4219" author="hossman" created="Mon, 30 Nov 2015 22:37:52 +0000"/>
<attachment id="12774891" name="LUCENE-6914.patch" size="944" author="hossman" created="Mon, 30 Nov 2015 21:55:15 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>3.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 2 Dec 2015 14:56:06 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2p347:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6808] Term(Ord)ValComparator.value return BytesRefs that are re-used internally
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6808</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>While working on <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a>, which involves some non-trivial usage of <tt>FieldComparator</tt>, I discovered some weird bugs anytime I was using TermOrdValComparator. I ultimately tracked this down to the fact that the <tt>BytesRef</tt> instances returned by <tt>TermOrdValComparator.value(int slot)</tt> are backed by <tt>BytesRefBuilder</tt> instances that the Comparator hangs on to and re-uses &#8211; so the values a caller gets back from <tt>FieldComparator.value(slot)</tt> might be changed out from under it before it has a chance to use that value in something like <tt>FieldComparator.compareValues(first,second)</tt>.</p> <p>The general approach when dealing with BytesRef instances (as i understand it) is that the caller is responsible for making a copy if it wants to hang on to it &#8211; but in this case that would violate the generic API of FieldComparator &#8211; callers would have to pay attention to when a <tt>FieldComparator</tt> is a <br/> <tt>FieldComparator&lt;BytesRef&gt;</tt> and do casting to copy the BytesRef.</p> <p>It seems like the right solution is for <tt>TermOrdValComparator.value(slot)</tt> (and <tt>TermValComparator.value(slot)</tt> which has a similar BytesRef usage) to return <tt>BytesRef.deepCopyOf(values[slot])</tt></p>
</description>
<environment/>
<key id="12875676">LUCENE-6808</key>
<summary>
Term(Ord)ValComparator.value return BytesRefs that are re-used internally
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="hossman">Hoss Man</reporter>
<labels></labels>
<created>Thu, 17 Sep 2015 20:30:18 +0000</created>
<updated>Tue, 22 Sep 2015 01:42:21 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14804445" author="hossman" created="Thu, 17 Sep 2015 20:30:55 +0000">
<p>Here's a patch which includes:</p> <ul> <li>A new testcase <tt>TestFieldComparatorValues</tt> demonstrating the problem when using <tt>TermOrdValComparator</tt> and <tt>TermValComparator</tt> and how the behavior of these two are inconsistent with the other existing impls.</li> <li>the previously mentioned fix to the <tt>value(slot)</tt> methods</li> <li>some other misc test coverage additions of <tt>FieldComparator.values(slot)</tt> and <tt>fieldComparator.compareValues(first,second)</tt> (These don't demonstrate the problem at all &#8211; there were test improvements i attempted before i fullyer understood the problem but they seemed like useful additions ot leave in)</li> </ul> <p>There are still a few nocommits in FieldComparator.java related to the one other place where a BytesRef is "shared" with the caller: <tt>setTopValue(value)</tt> ... it's not clear to me if this should make a defensive copy or not. If i understand correctly, the theory is that this value is either coming from a previous call to <tt>value(slot)</tt> from the same, or another instance of the same type of, FieldComparator (ie: FieldDoc from searchAfter) and so we're safe since we already have a defensive copy (introduced by this patch); or it's coming from a more complex client that knows it's dealing with BytesRef and that client should have passed setTopValue a "safe" copy to use internally. ... but maybe i'm wrong, maybe <tt>setTopValue</tt> should make it's own copy?</p>
</comment>
<comment id="14804589" author="mikemccand" created="Thu, 17 Sep 2015 21:51:01 +0000">
<p>The intention of the <tt>FieldComparator.value</tt> API is that you would use it to look up a value after all collection is complete, e.g. to fill the fields to create the <tt>FieldDoc</tt> for this hit, and so the comparator would naturally not be changing it anymore.</p> <p>I don't think this API should have to make a deep clone of the value it returns; this is just extra per-hit garbage created for searches sorting by field ...</p> <p>But I don't really understand what <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a> is trying to do ... maybe there is another way to do it w/o abusing this API?</p>
</comment>
<comment id="14877262" author="hossman" created="Sat, 19 Sep 2015 18:41:19 +0000">
<p>Weird, i wrote this comment yesterday, but aparently something failed when my browser tried to submit it...</p> <div class="panel" style="border-width: 1px;"><div class="panelContent"> <blockquote><p>The intention of the FieldComparator.value API is that you would use it to look up a value after all collection is complete, e.g. to fill the fields to create the FieldDoc for this hit, and so the comparator would naturally not be changing it anymore.</p></blockquote> <p>ok, but that's not clear/enforced anywhere in the API itself &#8211; if you are only suppose to fetch back all the slots after the search is complete, why support fetching the individual slots (and compareValues()) at all?</p> <blockquote><p>But I don't really understand what <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a> is trying to do ... maybe there is another way to do it w/o abusing this API?</p></blockquote> <p>In a nutshell the CollapseQParser is another style of "group collapsing" where it picks a single best representative doc for each group on the fly as docs are collected &#8211; currently it does this only based on a single field via DocValues, <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a> is about making this work with any arbitrary "Sort" object. The code in the patch (in <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a>) is analogous to the type of logic that FieldValueHitQueue does, but instead of tracking the "N best docs" (according to the sort) in a single priority queue (which re-orders on the fly), it tracks the <b>1</b> best doc for every "group" as it makes a single pass collection uses value() + compareValues to know when a "better" doc has been found for that group.</p> <p>(The most trivial implementation would be to use a FieldValueHitQueue of size '1' for each group, but this approach unwinds the logic a track the values directly. When i was first looking at this approach, i initially considered using a FieldComparator "slot" for each group, but the number of groups isn't neccessarly known in advance and there's no way to "grow" a FieldComparator)</p> <p>It doesn't feel like an abuse of the FieldComparator API to do this ... every other Comparator works fine as is. As i mentioned I could always put hacks in the caller code (ColapseQParser) to do instanceof/casting/deepCopy when the FieldComparator returns BytesRefs &#8211; but fixing Term(Ord)ValComparator.value to return "safe" objects seemed saner.</p> <p>&#8212;</p> <p>Forgetting <a href="https://issues.apache.org/jira/browse/SOLR-6168" title="enhance collapse QParser so that &quot;group head&quot; documents can be selected by more complex sort options" class="issue-link" data-issue-key="SOLR-6168"><del>SOLR-6168</del></a>, even if you asssume that all callers should know that the result of FieldComparator.value is only usable afte the end of a search, the BytesRefs returned by Term(Ord)ValComparator.value don't really seem to be safe for a caller to hang on to (for later use searchAfter, etc...) in any situation where the FieldComparator itself might get re-used &#8211; ie: re-using a FieldValueHitQueue (or Collector that uses FieldValueHitQueue) in a subsequent search.</p> <p>what protects the user from those values being changed out from under them in that situation?</p> </div></div> <p>...but beyond that, this morning a slightly diff impl occurred to me that should still address my Comparator re-use concerns w/o the "extra per-hit garbage" mike was worded about in the more common case...</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> BytesRef value(<span class="code-object">int</span> slot) { <span class="code-comment">// <span class="code-keyword">null</span> out the corrisponding Builder to prevent <span class="code-keyword">future</span> changes to returned BytesRef instance </span> <span class="code-comment">// in cases where the user makes additional slot changes after calling value </span> tempBRs[slot] = <span class="code-keyword">null</span>; <span class="code-keyword">return</span> values[slot]; } </pre> </div></div> <p>...any concerns with this mike? A new BytesRefBuilder instance will be created in tempBRs[slot] if and only if the FieldComparator gets re-used after the call to value(slot).</p>
</comment>
<comment id="14877278" author="yseeley@gmail.com" created="Sat, 19 Sep 2015 19:05:20 +0000">
<p>I was going to reply that having to make a copy of BytesRef objects returned to you (because they may be reused) was standard practice across our APIs... but then I noticed that this case is different since FieldComparator returns a generic object. So this case does seem pretty trappy and should be fixed IMO.</p>
</comment>
<comment id="14877337" author="rcmuir" created="Sat, 19 Sep 2015 22:47:51 +0000">
<p>I agree with Mike, I don't think we should create extra garbage here, the documentation says:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> /** * Return the actual value in the slot. * * @param slot the value * @<span class="code-keyword">return</span> value in <span class="code-keyword">this</span> slot */ <span class="code-keyword">public</span> <span class="code-keyword">abstract</span> T value(<span class="code-object">int</span> slot); </pre> </div></div> <p>It says the value "in the slot" which isn't trappy at all. Its not a copy of the value or something else.</p> <p>Also docs at the start of the class reiterate what Mike said, that its only called at the end of the search:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> &lt;li&gt; {@link #value} Return the sort value stored in the specified slot. This is only called at the end of the search, in order to populate {@link FieldDoc#fields} when returning the top results. </pre> </div></div>
</comment>
<comment id="14877340" author="yseeley@gmail.com" created="Sat, 19 Sep 2015 23:28:01 +0000">
<div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> BytesRef value(<span class="code-object">int</span> slot) { <span class="code-comment">// <span class="code-keyword">null</span> out the corrisponding Builder to prevent <span class="code-keyword">future</span> changes to returned BytesRef instance </span> <span class="code-comment">// in cases where the user makes additional slot changes after calling value </span> tempBRs[slot] = <span class="code-keyword">null</span>; <span class="code-keyword">return</span> values[slot]; } </pre> </div></div> <p>+1 to this... seems to have no downsides when used as lucene currenly uses it (i.e. only called at the end of search)</p>
</comment>
<comment id="14900420" author="mikemccand" created="Mon, 21 Sep 2015 09:19:09 +0000">
<p>I know that's a compromise (thank you), in that it would in fact create no new garbage, but I think it's dangerous/unexpected for what is supposed to be a "getter" like API to have unexpected side effects like that.</p> <p>And it's not clear on first inspection that this is a safe thing to do (nowhere else do we set this to null) ... all to support what I think is really an abuse case of this API (peeking into the slots while collection is still running).</p>
</comment>
<comment id="14901500" author="yseeley@gmail.com" created="Mon, 21 Sep 2015 22:08:15 +0000">
<blockquote><p>And it's not clear on first inspection that this is a safe thing to do</p></blockquote> <p>OK, in that case I just did a thorough code review to investigate any issues. The approach Hoss came up with is completely safe.</p> <p>The array being modified is defined as</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">private</span> <span class="code-keyword">final</span> BytesRefBuilder[] tempBRs; </pre> </div></div> <p>And it's only used in this little block of code, and nowhere else:<br/> <a href="https://github.com/apache/lucene-solr/blob/72aa5784ecd7024dce7599c358b658bed4b31596/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java#L914-L918" class="external-link" rel="nofollow">https://github.com/apache/lucene-solr/blob/72aa5784ecd7024dce7599c358b658bed4b31596/lucene/core/src/java/org/apache/lucene/search/FieldComparator.java#L914-L918</a></p> <p>So the fix prevents the trap that Hoss found (and actually, I think I just found another place where we fell into that same trap), turns out to be trivial and has no downsides!</p>
</comment>
<comment id="14901752" author="mikemccand" created="Tue, 22 Sep 2015 01:42:21 +0000">
<blockquote><p>OK, in that case I just did a thorough code review to investigate any issues. </p></blockquote> <p>Thank you for the thorough code review / explanation ...</p> <p>But my concern wasn't that we can convince ourselves today that setting to null (this change) is OK, it's that the code, to future devs looking at it, looks bad/buggy because a getter really should not have side effects. This class is already scary enough, I don't think we should make it worse ...</p> <blockquote><p>So the fix prevents the trap that Hoss found</p></blockquote> <p>I don't think this is a trap: I think it's abusing the API.</p> <blockquote><p>I think I just found another place where we fell into that same trap</p></blockquote> <p>Hmm, where?</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10032">
<name>Blocker</name>
<outwardlinks description="blocks">
<issuelink>
<issuekey id="12721235">SOLR-6168</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12761300" name="LUCENE-6808.patch" size="20548" author="hossman" created="Sat, 19 Sep 2015 18:41:19 +0000"/>
<attachment id="12757149" name="LUCENE-6808.patch" size="20436" author="hossman" created="Thu, 17 Sep 2015 20:30:55 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 17 Sep 2015 21:51:01 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2kcvj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6703] IllegalArgumentException in QueryParserBase.parse()
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6703</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I have encountered a very special case where parsing a certain String with the <tt>MultiFieldQueryParser</tt> causes an <tt>IllegalArgumentException</tt> thrown in the constructor of <tt>org.apache.lucene.util.automaton.RegExp</tt>. I would have expected a <tt>ParseException</tt> instead (as stated in the API doc).</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> QueryParser parser = <span class="code-keyword">new</span> MultiFieldQueryParser(...); parser.parse(<span class="code-quote">"/x)/"</span>); </pre> </div></div> <p>The "evil" search string is <b><tt>/x)/</tt></b>.</p>
</description>
<environment/>
<key id="12849946">LUCENE-6703</key>
<summary>
IllegalArgumentException in QueryParserBase.parse()
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="obecker">Oliver Becker</reporter>
<labels></labels>
<created>Wed, 29 Jul 2015 14:34:40 +0000</created>
<updated>Wed, 29 Jul 2015 14:34:40 +0000</updated>
<version>4.10.4</version>
<component>core/queryparser</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2i2m7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6788] Mishandling of Integer.MIN_VALUE in FuzzySet leads to AssertionError
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6788</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Reindexing some data in the DataStax Enterprise Search product (which uses Solr) led to these stack traces:</p> <p>ERROR <a href="#13430">Lucene Merge Thread #13430</a> 2015-09-08 11:14:36,582 CassandraDaemon.java (line 258) Exception in thread Thread<a href="#13430,6,main">Lucene Merge Thread #13430,6,main</a><br/> org.apache.lucene.index.MergePolicy$MergeException: java.lang.AssertionError<br/> at org.apache.lucene.index.ConcurrentMergeScheduler.handleMergeException(ConcurrentMergeScheduler.java:545)<br/> at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:518)<br/> Caused by: java.lang.AssertionError<br/> at org.apache.lucene.codecs.bloom.FuzzySet.mayContainValue(FuzzySet.java:216)<br/> at org.apache.lucene.codecs.bloom.FuzzySet.contains(FuzzySet.java:165)<br/> at org.apache.lucene.codecs.bloom.BloomFilteringPostingsFormat$BloomFilteredFieldsProducer$BloomFilteredTermsEnum.seekExact(BloomFilteringPostingsFormat.java:351)<br/> at org.apache.lucene.index.BufferedUpdatesStream.applyTermDeletes(BufferedUpdatesStream.java:414)<br/> at org.apache.lucene.index.BufferedUpdatesStream.applyDeletesAndUpdates(BufferedUpdatesStream.java:283)<br/> at org.apache.lucene.index.IndexWriter._mergeInit(IndexWriter.java:3838)<br/> at org.apache.lucene.index.IndexWriter.mergeInit(IndexWriter.java:3799)<br/> at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3651)<br/> at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:405)<br/> at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:482)</p> <p>In tracking down the cause of the stack trace, I noticed this:<br/> <a href="https://github.com/apache/lucene-solr/blob/trunk/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java#L164" class="external-link" rel="nofollow">https://github.com/apache/lucene-solr/blob/trunk/lucene/codecs/src/java/org/apache/lucene/codecs/bloom/FuzzySet.java#L164</a></p> <p>It is possible for the Murmur2 hash to return Integer.MIN_VALUE (e.g. when hashing "WeH44wlbCK"). Multiplying Integer.MIN_VALUE by -1 returns Integer.MIN_VALUE again, so the "positiveHash &gt;= 0" assertion at line 217 fails.</p> <p>We could special-case Integer.MIN_VALUE, map it to 42 or some other magic number... since the same "* -1" logic appears on line 236 perhaps it should be part of the hash function?</p>
</description>
<environment/>
<key id="12862639">LUCENE-6788</key>
<summary>
Mishandling of Integer.MIN_VALUE in FuzzySet leads to AssertionError
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="tarrall">Robert Tarrall</reporter>
<labels></labels>
<created>Wed, 9 Sep 2015 03:50:34 +0000</created>
<updated>Wed, 9 Sep 2015 16:22:41 +0000</updated>
<version>4.10.4</version>
<version>master</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14736443" author="jpountz" created="Wed, 9 Sep 2015 08:29:19 +0000">
<p>Hmm actually it looks to me that having a positive value is not necessary as the only thing we are doing with the result of the hash is to and it with the bloom size, which would work fine with a negative number too.</p>
</comment>
<comment id="14737126" author="tarrall" created="Wed, 9 Sep 2015 16:22:41 +0000">
<p>After sleeping on it... if we need a positive value, "hash = hash &amp; Integer.MAX_VALUE" would be the correct way to force it positive, rather than using a magic number.</p> <p>That said, yeah, I'm not able to follow the logic well enough to know whether it needs to be positive, or even an integer. Overall it seems like using all 32 bits available from the hashing function would be a win.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 9 Sep 2015 08:29:19 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2jxen:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6726] TestIndexWriterOnDiskFull.testAddDocumentOnDiskFull() failure
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6726</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>My Linux Jenkins found a seed that reproduces 100% for me on OS X w/Java7, but only if I run the whole suite (i.e., exclude <tt>-Dtests.method=testAddDocumentOnDiskFull</tt> from the repro line) <a href="http://jenkins.sarowe.net/job/Lucene-core-nightly-monster-5.x-Java7/68/" class="external-link" rel="nofollow">http://jenkins.sarowe.net/job/Lucene-core-nightly-monster-5.x-Java7/68/</a>:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>[junit4:pickseed] Seed property 'tests.seed' already defined: 6B36AD57BB5A1779 [junit4] &lt;JUnit4&gt; says שלום! Master seed: 6B36AD57BB5A1779 [junit4] Executing 1 suite with 1 JVM. [junit4] [junit4] Started J0 PID(86114@localhost). [junit4] Suite: org.apache.lucene.index.TestIndexWriterOnDiskFull [junit4] HEARTBEAT J0 PID(86114@localhost): 2015-08-06T09:44:03, stalled for 70.7s at: TestIndexWriterOnDiskFull.testAddIndexOnDiskFull [junit4] OK 73.8s | TestIndexWriterOnDiskFull.testAddIndexOnDiskFull [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestIndexWriterOnDiskFull -Dtests.method=testAddDocumentOnDiskFull -Dtests.seed=6B36AD57BB5A1779 -Dtests.nightly=true -Dtests.slow=true -Dtests.locale=ar_AE -Dtests.timezone=America/Boa_Vista -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1 [junit4] ERROR 0.25s | TestIndexWriterOnDiskFull.testAddDocumentOnDiskFull &lt;&lt;&lt; [junit4] &gt; Throwable #1: org.apache.lucene.store.AlreadyClosedException: this IndexWriter is closed [junit4] &gt; at __randomizedtesting.SeedInfo.seed([6B36AD57BB5A1779:E72E952846CFC1BD]:0) [junit4] &gt; at org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:719) [junit4] &gt; at org.apache.lucene.index.IndexWriter.ensureOpen(IndexWriter.java:733) [junit4] &gt; at org.apache.lucene.index.IndexWriter.updateDocument(IndexWriter.java:1471) [junit4] &gt; at org.apache.lucene.index.IndexWriter.addDocument(IndexWriter.java:1254) [junit4] &gt; at org.apache.lucene.index.TestIndexWriterOnDiskFull.addDoc(TestIndexWriterOnDiskFull.java:575) [junit4] &gt; at org.apache.lucene.index.TestIndexWriterOnDiskFull.testAddDocumentOnDiskFull(TestIndexWriterOnDiskFull.java:80) [junit4] &gt; at java.lang.Thread.run(Thread.java:745) [junit4] &gt; Caused by: java.io.IOException: fake disk full at 7402 bytes when writing _4_Lucene50_0.dvm (file length=0) [junit4] &gt; at org.apache.lucene.store.MockIndexOutputWrapper.checkDiskFull(MockIndexOutputWrapper.java:88) [junit4] &gt; at org.apache.lucene.store.MockIndexOutputWrapper.writeBytes(MockIndexOutputWrapper.java:134) [junit4] &gt; at org.apache.lucene.store.MockIndexOutputWrapper.writeByte(MockIndexOutputWrapper.java:127) [junit4] &gt; at org.apache.lucene.store.RateLimitedIndexOutput.writeByte(RateLimitedIndexOutput.java:66) [junit4] &gt; at org.apache.lucene.store.DataOutput.writeInt(DataOutput.java:70) [junit4] &gt; at org.apache.lucene.codecs.CodecUtil.writeHeader(CodecUtil.java:91) [junit4] &gt; at org.apache.lucene.codecs.CodecUtil.writeIndexHeader(CodecUtil.java:134) [junit4] &gt; at org.apache.lucene.codecs.lucene50.Lucene50DocValuesConsumer.&lt;init&gt;(Lucene50DocValuesConsumer.java:68) [junit4] &gt; at org.apache.lucene.codecs.lucene50.Lucene50DocValuesFormat.fieldsConsumer(Lucene50DocValuesFormat.java:197) [junit4] &gt; at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsWriter.getInstance(PerFieldDocValuesFormat.java:187) [junit4] &gt; at org.apache.lucene.codecs.perfield.PerFieldDocValuesFormat$FieldsWriter.addNumericField(PerFieldDocValuesFormat.java:111) [junit4] &gt; at org.apache.lucene.codecs.DocValuesConsumer.mergeNumericField(DocValuesConsumer.java:252) [junit4] &gt; at org.apache.lucene.codecs.DocValuesConsumer.merge(DocValuesConsumer.java:163) [junit4] &gt; at org.apache.lucene.index.SegmentMerger.mergeDocValues(SegmentMerger.java:150) [junit4] &gt; at org.apache.lucene.index.SegmentMerger.merge(SegmentMerger.java:105) [junit4] &gt; at org.apache.lucene.index.IndexWriter.mergeMiddle(IndexWriter.java:4089) [junit4] &gt; at org.apache.lucene.index.IndexWriter.merge(IndexWriter.java:3664) [junit4] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler.doMerge(ConcurrentMergeScheduler.java:588) [junit4] &gt; at org.apache.lucene.index.ConcurrentMergeScheduler$MergeThread.run(ConcurrentMergeScheduler.java:626) [junit4] OK 0.12s | TestIndexWriterOnDiskFull.testCorruptionAfterDiskFullDuringMerge [junit4] OK 0.00s | TestIndexWriterOnDiskFull.testImmediateDiskFull [junit4] 2&gt; NOTE: leaving temporary files on disk at: /Users/sarowe/svn/lucene/dev/branches/branch_5x/lucene/build/core/test/J0/temp/lucene.index.TestIndexWriterOnDiskFull_6B36AD57BB5A1779-002 [junit4] 2&gt; NOTE: test params are: codec=Asserting(Lucene53): {id=PostingsFormat(name=MockRandom), f=PostingsFormat(name=Memory doPackFST= false), content=PostingsFormat(name=SimpleText)}, docValues:{numericdv=DocValuesFormat(name=Lucene50)}, sim=RandomSimilarityProvider(queryNorm=false,coord=crazy): {id=LM Jelinek-Mercer(0.700000), f=DFR I(ne)3(800.0), content=DFR GL2}, locale=ar_AE, timezone=America/Boa_Vista [junit4] 2&gt; NOTE: Mac OS X 10.10.4 x86_64/Oracle Corporation 1.7.0_71 (64-bit)/cpus=8,threads=1,free=159451480,total=211288064 [junit4] 2&gt; NOTE: All tests run in this JVM: [TestIndexWriterOnDiskFull] [junit4] Completed [1/1] in 74.53s, 4 tests, 1 error &lt;&lt;&lt; FAILURES! </pre> </div></div> <p>Not sure if they're related, but the most recent changes to this test were made under <a href="https://issues.apache.org/jira/browse/LUCENE-6579" title="Unexpected merge exceptions should be tragic to IndexWriter" class="issue-link" data-issue-key="LUCENE-6579"><del>LUCENE-6579</del></a> and <a href="https://issues.apache.org/jira/browse/LUCENE-6616" title="IndexWriter should list files once on init, and IFD should not suppress FNFE" class="issue-link" data-issue-key="LUCENE-6616"><del>LUCENE-6616</del></a>.</p>
</description>
<environment/>
<key id="12852587">LUCENE-6726</key>
<summary>
TestIndexWriterOnDiskFull.testAddDocumentOnDiskFull() failure
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="steve_rowe">Steve Rowe</reporter>
<labels></labels>
<created>Thu, 6 Aug 2015 14:27:12 +0000</created>
<updated>Thu, 6 Aug 2015 14:27:12 +0000</updated>
<due/>
<votes>0</votes>
<watches>0</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2if73:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6687] MLT term frequency calculation bug</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6687</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>In <tt>org.apache.lucene.queries.mlt.MoreLikeThis</tt>, there's a method <tt>retrieveTerms</tt> that receives a <tt>Map</tt> of fields, i.e. a document basically, but it doesn't have to be an existing doc.</p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746063/12746063_solr-mlt-tf-doubling-bug.png" align="absmiddle" border="0" height="500" /></p> <p>There are 2 for loops, one inside the other, which both loop through the same set of fields.<br/> That effectively doubles the term frequency for all the terms from fields that we provide in MLT QP <tt>qf</tt> parameter. <br/> It basically goes two times over the list of fields and accumulates the term frequencies from all fields into <tt>termFreqMap</tt>.</p> <p>The private method <tt>retrieveTerms</tt> is only called from one public method, the version of overloaded method <tt>like</tt> that receives a Map: so that private class member <tt>fieldNames</tt> is always derived from <tt>retrieveTerms</tt>'s argument <tt>fields</tt>.</p> <p>Uh, I don't understand what I wrote myself, but that basically means that, by the time <tt>retrieveTerms</tt> method gets called, its parameter fields and private member <tt>fieldNames</tt> always contain the same list of fields.</p> <p>Here's the proof:<br/> These are the final results of the calculation:</p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746060/12746060_solr-mlt-tf-doubling-bug-results.png" align="absmiddle" border="0" height="700" /></p> <p>And this is the actual <tt>thread_id:TID0009</tt> document, where those values were derived from (from fields <tt>title_mlt</tt> and <tt>pagetext_mlt</tt>):</p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746066/12746066_terms-glass.png" align="absmiddle" border="0" height="100" /></p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746065/12746065_terms-angry.png" align="absmiddle" border="0" height="100" /></p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746067/12746067_terms-how.png" align="absmiddle" border="0" height="100" /></p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746064/12746064_terms-accumulator.png" align="absmiddle" border="0" height="100" /></p> <p>Now, let's further test this hypothesis by seeing MLT QP in action from the AdminUI.<br/> Let's try to find docs that are More Like doc <tt>TID0009</tt>. <br/> Here's the interesting part, the query:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> q={!mlt qf=pagetext_mlt,title_mlt mintf=14 mindf=2 minwl=3 maxwl=15}TID0009 </pre> </div></div> <p>We just saw, in the last image above, that the term accumulator appears <tt>7</tt> times in <tt>TID0009</tt> doc, but the <tt>accumulator</tt>'s TF was calculated as <tt>14</tt>.<br/> By using <tt>mintf=14</tt>, we say that, when calculating similarity, we don't want to consider terms that appear less than 14 times (when terms from fields <tt>title_mlt</tt> and <tt>pagetext_mlt</tt> are merged together) in <tt>TID0009</tt>.<br/> I added the term accumulator in only one other document (<tt>TID0004</tt>), where it appears only once, in the field <tt>title_mlt</tt>. </p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746061/12746061_solr-mlt-tf-doubling-bug-verify-accumulator-mintf14.png" align="absmiddle" border="0" height="500" /></p> <p>Let's see what happens when we use <tt>mintf=15</tt>:</p> <p><img src="https://issues.apache.org/jira/secure/attachment/12746072/12746072_solr-mlt-tf-doubling-bug-verify-accumulator-mintf15.png" align="absmiddle" border="0" height="500" /></p> <p>I should probably mention that multiple fields (<tt>qf</tt>) work because I applied the patch: <a href="https://issues.apache.org/jira/browse/SOLR-7143" class="external-link" rel="nofollow">SOLR-7143</a>.</p> <p>Bug, no?</p>
</description>
<environment><p>OS X v10.10.4; Solr 5.2.1</p></environment>
<key id="12846221">LUCENE-6687</key>
<summary>MLT term frequency calculation bug</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mbonaci">Marko Bonaci</reporter>
<labels></labels>
<created>Mon, 20 Jul 2015 09:10:46 +0000</created>
<updated>Mon, 20 Jul 2015 09:49:47 +0000</updated>
<version>5.2.1</version>
<version>master</version>
<fixVersion>5.2.2</fixVersion>
<component>core/query/scoring</component>
<component>core/queryparser</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12746070" name="LUCENE-6687.patch" size="2243" author="mbonaci" created="Mon, 20 Jul 2015 09:43:19 +0000"/>
<attachment id="12746059" name="buggy-method-usage.png" size="390654" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746060" name="solr-mlt-tf-doubling-bug-results.png" size="278567" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746061" name="solr-mlt-tf-doubling-bug-verify-accumulator-mintf14.png" size="509937" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746072" name="solr-mlt-tf-doubling-bug-verify-accumulator-mintf15.png" size="344430" author="mbonaci" created="Mon, 20 Jul 2015 09:49:47 +0000"/>
<attachment id="12746063" name="solr-mlt-tf-doubling-bug.png" size="423427" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746064" name="terms-accumulator.png" size="103150" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746065" name="terms-angry.png" size="101365" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746066" name="terms-glass.png" size="99350" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
<attachment id="12746067" name="terms-how.png" size="98917" author="mbonaci" created="Mon, 20 Jul 2015 09:14:55 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>10.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Flags</customfieldname>
<customfieldvalues>
<customfieldvalue key="10430">
<![CDATA[ Patch ]]>
</customfieldvalue>
<customfieldvalue key="10431">
<![CDATA[ Important ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2hfxj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6667] Custom attributes get cleared by SynonymFilter
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6667</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I believe the Lucene API enables users to define their custom attributes (by extending <tt>AttributeImpl</tt>) which may be added by custom Tokenizers. <br/> It seems, the <tt>clear</tt> and <tt>copyTo</tt> methods must be implemented to clear and restore the state of this custom attribute.</p> <p>However, some filters (in our case the SynonymFilter) simply call <tt>AttributeSource.clearAttributes</tt> without invoking <tt>copyTo</tt>. Instead the filter just resets some known attributes, simply ignoring all other custom attributes. In the end our custom attribute value is lost.</p> <p>Is this a bug in <tt>SynonymFilter</tt> (and others) or are we using the API in the wrong way?</p> <p>A solution might be of course to provide empty implementations of <tt>clear</tt> and <tt>copyTo</tt>, but I'm not sure if this has other unwanted effects.</p>
</description>
<environment/>
<key id="12843459">LUCENE-6667</key>
<summary>Custom attributes get cleared by SynonymFilter</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="obecker">Oliver Becker</reporter>
<labels></labels>
<created>Wed, 8 Jul 2015 09:04:20 +0000</created>
<updated>Wed, 8 Jul 2015 17:11:28 +0000</updated>
<version>4.10.4</version>
<due/>
<votes>0</votes>
<watches>4</watches>
<comments>
<comment id="14618292" author="mikemccand" created="Wed, 8 Jul 2015 09:35:35 +0000">
<p>Hmm, <tt>SynonymFilter</tt> tries to preserve all attributes of the original incoming tokens (it uses <tt>capture/restoreState</tt> to do this).</p> <p>But for the new tokens it inserts, it does use <tt>clearAttributes</tt> to make a completely blank slate, and then sets the term, offset, posInc/Length etc.</p> <p>Which tokens (original input tokens vs. the inserted ones) are missing your custom attribute?</p>
</comment>
<comment id="14618309" author="thetaphi" created="Wed, 8 Jul 2015 09:54:25 +0000">
<p>In filters the approach should be the following:</p> <ul class="alternate" type="square"> <li>Of the original token capture the state</li> <li>when you insert new tokens, restore the state instead of clearAttributes()</li> <li>set the "changed" attributes</li> </ul> <p>This approach is used by stemmers that insert stemmed tokens (preserve original), so the original attributes keep alive.</p> <p>clearAttributes should only be called in Tokenizers or root TokenStreams.</p>
</comment>
<comment id="14618312" author="thetaphi" created="Wed, 8 Jul 2015 09:56:22 +0000">
<p>I have not looked at SynonymFilter, but maybe there is a bug. In general the above is how all filters should call. Maybe we should somehow add some assertions that Filters never call clearAttributes(), but this is hard because of shared state between filters and root.</p>
</comment>
<comment id="14618512" author="mikemccand" created="Wed, 8 Jul 2015 12:29:22 +0000">
<blockquote><p>when you insert new tokens, restore the state instead of clearAttributes()</p></blockquote> <p>But e.g. if syn filter matched "domain name system" and wants to insert "dns" which token's attributes is it supposed to clone for the "dns" token?</p>
</comment>
<comment id="14618515" author="thetaphi" created="Wed, 8 Jul 2015 12:35:23 +0000">
<blockquote><p>But e.g. if syn filter matched "domain name system" and wants to insert "dns" which token's attributes is it supposed to clone for the "dns" token?</p></blockquote> <p>That's the problem with the multi word synonyms... It has to be defined (first, last,...). But I am not sure what the right thing to do is!</p>
</comment>
<comment id="14618517" author="obecker" created="Wed, 8 Jul 2015 12:39:00 +0000">
<p>Ah, ok, now I understand. Yes, this happens for tokens that will be replaced by the synonym filter, i.e. for inserted tokens (and it is a single token replacement). But I see the problem.</p>
</comment>
<comment id="14618542" author="mikemccand" created="Wed, 8 Jul 2015 13:04:59 +0000">
<p>Maybe we could special case the single-token case to always clone the attrs from the token it matched?</p>
</comment>
<comment id="14618574" author="rcmuir" created="Wed, 8 Jul 2015 13:29:23 +0000">
<p>you never know what the attribute is doing. this might be inappropriate.</p> <p>I don't think we should change it for synonymfilter in an inconsistent way, because it will be confusing, and then be confusing for other tokenfilters too.</p>
</comment>
<comment id="14618951" author="dsmiley" created="Wed, 8 Jul 2015 17:11:28 +0000">
<p>Yeah, it could be appropriate or it could be inappropriate; there is no API/mechanism for an attribute to specify what it wants. I think it's better to err on copying the attribute state for inserted tokens from the (first) input token, versus dropping attribute state. It needn't be done in an "inconsistent" way &#8211; we could do it in a documented consistent way &#8211; such as take from the first token. I've had to work around this problem (also in WordDelimiterFilter, and CommonGrams) with ugly hacks in a custom attribute &#8211; e.g. the clear() method not actually clearing, with my custom Tokenizer controlling the actual clearing.</p> <p>As an aside, when I was doing some custom attribute stuff, I couldn't help but think our approach to saving attribute state seemed a little heavy, since a call to capture() creates a linked list to hold each attribute impl. Maybe the state could be re-used with some ref-counting. I dunno.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 8 Jul 2015 09:35:35 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gzfr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6663] Null value dereference</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6663</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Found several cases of potential null dereference. Creating a single patch as suggested to fix them.</p>
</description>
<environment/>
<key id="12843044">LUCENE-6663</key>
<summary>Null value dereference</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rmp91">Rishabh Patel</reporter>
<labels></labels>
<created>Mon, 6 Jul 2015 23:39:33 +0000</created>
<updated>Tue, 7 Jul 2015 00:05:23 +0000</updated>
<version>master</version>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments>
<attachment id="12743846" name="LUCENE-6663.patch" size="13345" author="rmp91" created="Tue, 7 Jul 2015 00:05:23 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310250" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Flags</customfieldname>
<customfieldvalues>
<customfieldvalue key="10430">
<![CDATA[ Patch ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gwvr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6689] Odd analysis problem with WDF, appears to be triggered by preceding analysis components
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6689</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This problem shows up for me in Solr, but I believe the issue is down at the Lucene level, so I've opened the issue in the LUCENE project. We can move it if necessary.</p> <p>I've boiled the problem down to this minimum Solr fieldType:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> &lt;fieldType name="testType" class="solr.TextField" sortMissingLast="true" positionIncrementGap="100"&gt; &lt;analyzer type="index"&gt; &lt;tokenizer class="org.apache.lucene.analysis.icu.segmentation.ICUTokenizerFactory" rulefiles="Latn:Latin-break-only-on-whitespace.rbbi"/&gt; &lt;filter class="solr.PatternReplaceFilterFactory" pattern="^(\p{Punct}*)(.*?)(\p{Punct}*)$" replacement="$2" /&gt; &lt;filter class="solr.WordDelimiterFilterFactory" splitOnCaseChange="1" splitOnNumerics="1" stemEnglishPossessive="1" generateWordParts="1" generateNumberParts="1" catenateWords="1" catenateNumbers="1" catenateAll="0" preserveOriginal="1" /&gt; &lt;/analyzer&gt; &lt;analyzer type="query"&gt; &lt;tokenizer class="org.apache.lucene.analysis.icu.segmentation.ICUTokenizerFactory" rulefiles="Latn:Latin-break-only-on-whitespace.rbbi"/&gt; &lt;filter class="solr.PatternReplaceFilterFactory" pattern="^(\p{Punct}*)(.*?)(\p{Punct}*)$" replacement="$2" /&gt; &lt;filter class="solr.WordDelimiterFilterFactory" splitOnCaseChange="1" splitOnNumerics="1" stemEnglishPossessive="1" generateWordParts="1" generateNumberParts="1" catenateWords="0" catenateNumbers="0" catenateAll="0" preserveOriginal="0" /&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; </pre> </div></div> <p>On Solr 4.7, if this type is given the input "aaa-bbb: ccc" then index analysis puts aaa at term position 1 and bbb at term position 2. This seems perfectly reasonable to me. In Solr 4.9, both terms end up at position 2. This causes phrase queries which used to work to return zero hits. The exact text of the phrase query is in the original documents that match on 4.7.</p> <p>If the custom rbbi (which is included unmodified from the lucene icu analysis source code) is not used, then the problem doesn't happen, because the punctuation doesn't make it to the PRF. If the PatternReplaceFilterFactory is not present, then the problem doesn't happen.</p> <p>I can work around the problem by setting luceneMatchVersion to 4.7, but I think the behavior is a bug, and I would rather not continue to use 4.7 analysis when I upgrade to 5.x, which I hope to do soon.</p> <p>Whether luceneMatchversion is LUCENE_47 or LUCENE_4_9, query analysis puts aaa at term position 1 and bbb at term position 2.</p>
</description>
<environment/>
<key id="12846297">LUCENE-6689</key>
<summary>
Odd analysis problem with WDF, appears to be triggered by preceding analysis components
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="elyograg">Shawn Heisey</reporter>
<labels></labels>
<created>Mon, 20 Jul 2015 15:37:05 +0000</created>
<updated>Wed, 16 Sep 2015 13:14:10 +0000</updated>
<version>4.8</version>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14633706" author="elyograg" created="Mon, 20 Jul 2015 15:38:23 +0000">
<p><a href="https://issues.apache.org/jira/browse/LUCENE-5111" title="Fix WordDelimiterFilter" class="issue-link" data-issue-key="LUCENE-5111"><del>LUCENE-5111</del></a> seems to contain the commit that causes this behavior.</p>
</comment>
<comment id="14705543" author="elyograg" created="Thu, 20 Aug 2015 18:52:24 +0000">
<p>I can work around the specific queries that caused the problem if I make index and query WDF analysis exactly the same ... but there's a problem even then.</p> <p>As a test, I entirely removed the query analysis above and removed the "type" attribute from the index analysis so it applies to both. I put this fieldType into Solr 5.2.1 and went to the analysis screen.</p> <p>A phrase search for "aaa bbb" when the indexed value was "aaa-bbb: ccc" does not match, because the positions are wrong. I believe that it <b>should</b> match. A user would most likely expect it to match.</p>
</comment>
<comment id="14705820" author="elyograg" created="Thu, 20 Aug 2015 21:44:58 +0000">
<p>I have just confirmed that setting luceneMatchVersion to 4.7 when running the previously described test on 5.2.1 will fix the problem. This means I have a workaround, but it's not one that I'm really very happy with.</p>
</comment>
<comment id="14705977" author="elyograg" created="Thu, 20 Aug 2015 23:34:14 +0000">
<p>I have just found a better workaround: The luceneMatchVersion can be specified on each analysis component, so I can apply it <b>only</b> to the WordDelimiterFilterFactory on the index analysis.</p> <p>I hope this problem will still be fixed.</p>
</comment>
<comment id="14707408" author="elyograg" created="Fri, 21 Aug 2015 20:22:30 +0000">
<p>I have simplified the analysis chain, removing the ICU tokenizer and replacing it with the whitespace tokenizer. The root problem appears to be an interaction between PatternReplaceFilter and WordDelimiterFilter.</p> <p>With the following Solr analysis chain, an indexed value of "aaa-bbb: ccc" will not be found by a phrase search of "aaa bbb" because the positions on the two query terms don't match what's in the index. The positions go wrong on the WordDelimiterFilter step.</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> &lt;fieldType name=<span class="code-quote">"genText2"</span> class=<span class="code-quote">"solr.TextField"</span> sortMissingLast=<span class="code-quote">"<span class="code-keyword">true</span>"</span> positionIncrementGap=<span class="code-quote">"100"</span>&gt; &lt;analyzer&gt; &lt;tokenizer class=<span class="code-quote">"solr.WhitespaceTokenizerFactory"</span>/&gt; &lt;filter class=<span class="code-quote">"solr.PatternReplaceFilterFactory"</span> pattern=<span class="code-quote">"^(\p{Punct}*)(.*?)(\p{Punct}*)$"</span> replacement=<span class="code-quote">"$2"</span> /&gt; &lt;filter class=<span class="code-quote">"solr.WordDelimiterFilterFactory"</span> splitOnCaseChange=<span class="code-quote">"1"</span> splitOnNumerics=<span class="code-quote">"1"</span> stemEnglishPossessive=<span class="code-quote">"1"</span> generateWordParts=<span class="code-quote">"1"</span> generateNumberParts=<span class="code-quote">"1"</span> catenateWords=<span class="code-quote">"1"</span> catenateNumbers=<span class="code-quote">"1"</span> catenateAll=<span class="code-quote">"0"</span> preserveOriginal=<span class="code-quote">"1"</span> /&gt; &lt;/analyzer&gt; &lt;/fieldType&gt; </pre> </div></div> <p>If I remove PRFF from the above chain, the problem goes away. This filter is in the chain so that leading and trailing punctuation are removed from all terms, leaving punctuation inside the term for WDF to handle.</p> <p>An additional problem with the analysis quoted above is that the "aaabbb" term is indexed at position 2. I believe it should be at position 1. This problem is also fixed by removing PRFF.</p>
</comment>
<comment id="14707511" author="elyograg" created="Fri, 21 Aug 2015 21:53:43 +0000">
<p>Thinking about this in more detail, another workaround is to remove PRFF entirely, at least from analysis chains where it is followed by WDFF. WDF appears to remove that punctuation anyway, and it looks like it does it correctly for my purposes.</p> <p>I still believe that the behavior I'm seeing is a bug, even if there are at least two viable workarounds that will work for my situation. Use cases may exist (more valid than mine) where the user needs pattern replace filter right before word delimiter filter.</p>
</comment>
<comment id="14768911" author="elyograg" created="Wed, 16 Sep 2015 13:12:08 +0000">
<p>I chose the latter workaround &#8211; removing PRFF anywhere WDFF is also used.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<inwardlinks description="is related to">
<issuelink>
<issuekey id="12657682">LUCENE-5111</issuekey>
</issuelink>
</inwardlinks>
</issuelinktype>
</issuelinks>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2hgef:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6679] Filter's Weight.explain returns an explanation with isMatch==true even on documents that don't match
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6679</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This was reported by Trejkaz on the java-user list: <a href="http://search-lucene.com/m/l6pAi19h4Y3DclgB1&amp;subj=Re+What+on+earth+is+FilteredQuery+explain+doing+" class="external-link" rel="nofollow">http://search-lucene.com/m/l6pAi19h4Y3DclgB1&amp;subj=Re+What+on+earth+is+FilteredQuery+explain+doing+</a></p>
</description>
<environment/>
<key id="12845258">LUCENE-6679</key>
<summary>
Filter's Weight.explain returns an explanation with isMatch==true even on documents that don't match
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="jpountz">Adrien Grand</reporter>
<labels></labels>
<created>Wed, 15 Jul 2015 14:27:21 +0000</created>
<updated>Mon, 9 Nov 2015 19:37:34 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14628135" author="jpountz" created="Wed, 15 Jul 2015 14:29:58 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shebiki" class="user-hover" rel="shebiki">Terry Smith</a> On the email thread, you looked interested to work on this issue?</p>
</comment>
<comment id="14628153" author="shebiki" created="Wed, 15 Jul 2015 14:39:06 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpountz" class="user-hover" rel="jpountz">Adrien Grand</a> Absolutely, I'd love to give it a stab. Currently waiting for feedback from TX on the users list.</p> <p>I think you are spot on about adding some additional testing to the test suite to catch explanation mismatches. I'll take a peek at that also and see if I can figure out something worth submitting.</p>
</comment>
<comment id="14628155" author="jpountz" created="Wed, 15 Jul 2015 14:40:04 +0000">
<p>Awesome! <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14629956" author="shebiki" created="Thu, 16 Jul 2015 16:22:57 +0000">
<p>Trejkaz confirmed the patch referenced from the mailing list works.</p> <p>This bug is fixed as a side effect of <a href="https://issues.apache.org/jira/browse/LUCENE-6601" title="Change FilteredQuery.FilterStrategy to use the two-phase iteration API" class="issue-link" data-issue-key="LUCENE-6601"><del>LUCENE-6601</del></a> so will automatically be fixed as part of release 5.3.</p> <p>I'll work on cleaning up the new test contributed by Trejkaz for inclusion and then move onto a more generic hook to catch other explanation mistakes.</p>
</comment>
<comment id="14735400" author="shebiki" created="Tue, 8 Sep 2015 18:57:15 +0000">
<p>Here is a patch (against trunk) that adds test coverage for explanations on hits only.</p> <p>I'm looking for feedback to the approach used before expanding to cover explanations for misses.</p> <p>Currently I get a couple of failures when running just the Lucene tests:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Tests with failures: - org.apache.lucene.search.TestSortRandom.testRandomStringValSort - org.apache.lucene.search.TestSortRandom.testRandomStringSort JVM J0: 1.42 .. 284.75 = 283.33s JVM J1: 1.64 .. 284.77 = 283.13s JVM J2: 1.42 .. 284.70 = 283.28s JVM J3: 1.42 .. 284.68 = 283.26s Execution time total: 4 minutes 44 seconds Tests summary: 404 suites, 3235 tests, 2 failures, 104 ignored (100 assumptions) </pre> </div></div> <p>Happy to dig into these more once an approach has been found that people like.</p>
</comment>
<comment id="14737694" author="jpountz" created="Wed, 9 Sep 2015 22:15:54 +0000">
<p>I think it is a nice change: AssertingIndexSearcher is widely used in tests so it would be nice if it could catch explain bugs.</p>
</comment>
<comment id="14994369" author="kanarsky" created="Fri, 6 Nov 2015 20:22:23 +0000">
<p>It looks like the issue was not fixed as a part of <a href="https://issues.apache.org/jira/browse/LUCENE-6601" title="Change FilteredQuery.FilterStrategy to use the two-phase iteration API" class="issue-link" data-issue-key="LUCENE-6601"><del>LUCENE-6601</del></a> though; I opened <a href="https://issues.apache.org/jira/browse/SOLR-8245" title="Explain in Solr&#39;s Filter class should return noMatch if the document is not a match" class="issue-link" data-issue-key="SOLR-8245">SOLR-8245</a> to track it (did not see this ticket yesterday, but since it seems to be on a Solr side now, SOLR project ticket seems to be reasonable).</p>
</comment>
<comment id="14994430" author="shebiki" created="Fri, 6 Nov 2015 21:07:55 +0000">
<p>Darn, sorry I didn't get back to pushing these new tests into the source, they would have helped to catch this.</p> <p>It looks like branch_5x and trunk diverged here, this commit shows where this code was removed on branch_5x: <a href="https://github.com/apache/lucene-solr/commit/11cc6e53f85f7bc4b616bb38370ddfc704987337#diff-2b293bfd95e32f715a5c05b4e132f047L82" class="external-link" rel="nofollow">https://github.com/apache/lucene-solr/commit/11cc6e53f85f7bc4b616bb38370ddfc704987337#diff-2b293bfd95e32f715a5c05b4e132f047L82</a></p> <p>And this commit from trunk shows the move of Filter from Lucene to Solr: <a href="https://github.com/apache/lucene-solr/commit/98888f8d64d4fb34eb2480e9a667c45f262d20f0#diff-4bf1c256f49c1a4ee4a50b1f8aeda1ddL1" class="external-link" rel="nofollow">https://github.com/apache/lucene-solr/commit/98888f8d64d4fb34eb2480e9a667c45f262d20f0#diff-4bf1c256f49c1a4ee4a50b1f8aeda1ddL1</a></p> <p>You can see the trunk version of the file here: <a href="https://github.com/apache/lucene-solr/blob/98888f8d64d4fb34eb2480e9a667c45f262d20f0/solr/core/src/java/org/apache/solr/search/Filter.java" class="external-link" rel="nofollow">https://github.com/apache/lucene-solr/blob/98888f8d64d4fb34eb2480e9a667c45f262d20f0/solr/core/src/java/org/apache/solr/search/Filter.java</a></p> <p>The changes from the branch_5x commit are missing.</p> <p>I don't know why this is the case, perhaps <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpountz" class="user-hover" rel="jpountz">Adrien Grand</a> can chime in as the original commit that fixes the explain output as a side effect (<a href="https://issues.apache.org/jira/browse/LUCENE-6601" title="Change FilteredQuery.FilterStrategy to use the two-phase iteration API" class="issue-link" data-issue-key="LUCENE-6601"><del>LUCENE-6601</del></a>) looks like it ought to be on both branch_5x and trunk.</p>
</comment>
<comment id="14994622" author="kanarsky" created="Fri, 6 Nov 2015 22:52:11 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=shebiki" class="user-hover" rel="shebiki">Terry Smith</a> I agree, the code is different in the trunk and branch_5x but the explain issue is still present in both branches:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">if</span> (match) { <span class="code-keyword">assert</span> s.score() == 0f; <span class="code-keyword">return</span> Explanation.match(0f, <span class="code-quote">"Match on id "</span> + doc); } <span class="code-keyword">else</span> { <span class="code-keyword">return</span> Explanation.match(0f, <span class="code-quote">"No match on id "</span> + doc); <span class="code-comment">// here it should be Explanation.noMatch(<span class="code-quote">"No match on id "</span> + doc); </span>} </pre> </div></div> <p>In the branch_5x that code is in FilteredQuery (line 299), in the trunk it is in Filter.createWeight(...)</p>
</comment>
<comment id="14996491" author="jpountz" created="Mon, 9 Nov 2015 13:05:00 +0000">
<p>5.x and trunk are indeed different, mainly because of backward compatibility for FilteredQuery (which is gone in trunk but still exists in 5.x): since FilteredQuery has an option that lets control whether the filter should be executed before or after the query, Filter had to diverge a bit from trunk so that this would remain possible (while in trunk all decisions are made automatically now).</p> <p>Terry, please let us know if you need help fixing the tests that fail with your patch. I'd be happy to help.</p>
</comment>
<comment id="14996583" author="shebiki" created="Mon, 9 Nov 2015 14:23:19 +0000">
<p>Thanks Adrien, I'll give it a shot this morning and reach out as needed.</p> <p>As a reminder, my patch only checks hits and the bug reports are for misses. I'll need to expand upon it to get better coverage for those also.</p> <p>If I can't turn something around early this week I'll backup a little and at least get direct test for the underlying bug behind <a href="https://issues.apache.org/jira/browse/SOLR-8245" title="Explain in Solr&#39;s Filter class should return noMatch if the document is not a match" class="issue-link" data-issue-key="SOLR-8245">SOLR-8245</a> to go with it's fix.</p>
</comment>
<comment id="14997218" author="shebiki" created="Mon, 9 Nov 2015 19:37:34 +0000">
<p>Here is an updated patch against trunk that adds hit and miss explain checks to AssertingLeafCollector and hooks it up with the surrounding classes.</p> <p>I've also introduced a new annotation called SuppressExplainChecks that I've applied to the following tests that would fail without.</p> <ul> <li>TestSortRandom</li> <li>TestLazyProxSkipping</li> <li>TestDrillSideways</li> <li>TestRangeFacetCounts</li> <li>TestJoinUtil</li> <li>TestFieldCacheSortRandom</li> <li>TestCustomScoreQuery</li> <li>TestCustomScoreQueryExplanations</li> <li>TestFunctionQueryExplanations</li> <li>TestForTooMuchCloning</li> <li>TestTermAutomationQuery</li> </ul> <p>Once you are happy with this patch, I'd like to get it on trunk so the jenkins servers can shake out any more failures and we can create tickets for any uncovered bugs.</p>
</comment>
</comments>
<issuelinks>
<issuelinktype id="10030">
<name>Reference</name>
<outwardlinks description="relates to">
<issuelink>
<issuekey id="12910897">SOLR-8245</issuekey>
</issuelink>
</outwardlinks>
</issuelinktype>
</issuelinks>
<attachments>
<attachment id="12771412" name="LUCENE-6679.patch" size="22517" author="shebiki" created="Mon, 9 Nov 2015 19:37:34 +0000"/>
<attachment id="12754701" name="LUCENE-6679.patch" size="9340" author="shebiki" created="Tue, 8 Sep 2015 18:57:15 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 15 Jul 2015 14:39:06 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ha7b:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-6674] J9 assertion / crash in tests</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6674</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<blockquote> <p> 06:45:04.031 0x2518500 j9mm.107 * ** ASSERTION FAILED ** at ParallelScavenger.cpp:3053: ((false &amp;&amp; (_extensions-&gt;objectModel.isRemembered(objectPtr))))</p></blockquote> <p><a href="http://build-eu-00.elastic.co/job/lucene_linux_java8_64_test_only/55153/consoleFull" class="external-link" rel="nofollow">http://build-eu-00.elastic.co/job/lucene_linux_java8_64_test_only/55153/consoleFull</a></p>
</description>
<environment/>
<key id="12844162">LUCENE-6674</key>
<summary>J9 assertion / crash in tests</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Fri, 10 Jul 2015 12:48:33 +0000</created>
<updated>Tue, 21 Jul 2015 10:53:17 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14633451" author="bnekkare" created="Mon, 20 Jul 2015 11:40:28 +0000">
<p>We would require the following diagnostics created during the assertion failure to root cause this issue :<br/> core.20150710.084504.3376.0001.dmp, <br/> javacore.20150710.084504.3376.0002.txt and <br/> Snap.20150710.084504.3376.0003.trc</p> <p>Thanks and Regards<br/> Brijesh Nekkare<br/> IBM JRE team</p>
</comment>
<comment id="14634941" author="bnekkare" created="Tue, 21 Jul 2015 10:53:17 +0000">
<p>We would also need the coredump to be jextracted as detailed at <br/> <a href="http://www-01.ibm.com/support/docview.wss?uid=swg21577379" class="external-link" rel="nofollow">http://www-01.ibm.com/support/docview.wss?uid=swg21577379</a></p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 20 Jul 2015 11:40:28 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2h3of:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6656] StandardTokenizer.close() can leave the object in an uncloseable state
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6656</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The following pair of tests shows that if a reader throws IOException from the close() method, StandardTokenizer is left in an inconsistent state where it thinks you didn't call close on the tokeniser, even though you did. To make matters worse, it holds onto the reader so that any subsequent attempts to close the tokeniser will also fail.</p> <p>Possible workarounds:<br/> 1. Don't reuse tokenisers.<br/> 2. Still reuse tokenisers, but if close() throws anything, discard that tokeniser and create a new one.<br/> 3. Wrap every reader you pass in to ensure that close() can't throw an exception.</p> <p>Code follows:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> class TestStandardTokenizerCloseIssue { @Test <span class="code-keyword">public</span> void testStreamReuse() <span class="code-keyword">throws</span> Exception { <span class="code-comment">// Attempts to verify that consumeAndClose itself is not broken. </span> <span class="code-keyword">try</span> (Tokenizer stream = <span class="code-keyword">new</span> StandardTokenizer()) { stream.setReader(<span class="code-keyword">new</span> StringReader(<span class="code-quote">"reader #1"</span>)); assertThat(consumeAndClose(stream), contains(<span class="code-quote">"reader"</span>, <span class="code-quote">"1"</span>)); stream.setReader(<span class="code-keyword">new</span> StringReader(<span class="code-quote">"reader 2"</span>)); assertThat(consumeAndClose(stream), contains(<span class="code-quote">"reader"</span>, <span class="code-quote">"2"</span>)); } } @Test <span class="code-keyword">public</span> void testStreamReuseAfterFailure() <span class="code-keyword">throws</span> Exception { class FailingReader <span class="code-keyword">extends</span> Reader { @Override <span class="code-keyword">public</span> <span class="code-object">int</span> read(@NotNull <span class="code-object">char</span>[] buffer, <span class="code-object">int</span> off, <span class="code-object">int</span> len) <span class="code-keyword">throws</span> IOException { <span class="code-keyword">throw</span> <span class="code-keyword">new</span> IOException(<span class="code-quote">"Synthetic exception"</span>); } @Override <span class="code-keyword">public</span> void close() <span class="code-keyword">throws</span> IOException { <span class="code-keyword">throw</span> <span class="code-keyword">new</span> IOException(<span class="code-quote">"Synthetic exception"</span>); } } <span class="code-comment">// Simulating sharing the instance inside some factory. </span> <span class="code-keyword">try</span> (Tokenizer stream = <span class="code-keyword">new</span> StandardTokenizer()) { <span class="code-keyword">try</span> { stream.setReader(<span class="code-keyword">new</span> FailingReader()); consumeAndClose(stream); fail(<span class="code-quote">"Expected IOException"</span>); } <span class="code-keyword">catch</span> (IOException e) { <span class="code-comment">// Expected </span> } stream.setReader(<span class="code-keyword">new</span> StringReader(<span class="code-quote">"working reader"</span>)); <span class="code-comment">// Test fails here - even though the consumeAndClose above </span> <span class="code-comment">// did close the tokeniser, the tokeniser didn't clear its reference to </span> <span class="code-comment">// the reader. </span> assertThat(consumeAndClose(stream), contains(<span class="code-quote">"working"</span>, <span class="code-quote">"reader"</span>)); } } <span class="code-comment">// Attempts to implement the correct workflow <span class="code-keyword">for</span> consuming a </span> <span class="code-comment">// TokenStream. </span> <span class="code-keyword">private</span> List&lt;<span class="code-object">String</span>&gt; consumeAndClose(TokenStream stream) <span class="code-keyword">throws</span> Exception { ImmutableList.Builder&lt;<span class="code-object">String</span>&gt; tokens = ImmutableList.builder(); <span class="code-comment">//The consumer calls reset(). </span> stream.reset(); <span class="code-keyword">try</span> { <span class="code-comment">// The consumer retrieves attributes from the stream and stores </span> <span class="code-comment">// local references to all attributes it wants to access. </span> CharTermAttribute termAttribute = stream.getAttribute(CharTermAttribute.class); <span class="code-comment">// The consumer calls incrementToken() until it returns <span class="code-keyword">false</span> </span> <span class="code-comment">// consuming the attributes after each call. </span> <span class="code-keyword">while</span> (stream.incrementToken()) { tokens.add(termAttribute.toString()); } <span class="code-comment">// The consumer calls end() so that any end-of-stream operations </span> <span class="code-comment">// can be performed. </span> stream.end(); } <span class="code-keyword">finally</span> { <span class="code-comment">// The consumer calls close() to release any resource when finished </span> <span class="code-comment">// using the TokenStream. </span> stream.close(); } <span class="code-keyword">return</span> tokens.build(); } } </pre> </div></div> <p>Originally discovered on 4.10.4. Code has been ported to work on 5.1 since initially created and sooner or later I'll get to test 5.2.1, but I don't see anyone else having reported a similar issue yet, so I'm guessing it won't be fixed yet.</p>
</description>
<environment/>
<key id="12842493">LUCENE-6656</key>
<summary>
StandardTokenizer.close() can leave the object in an uncloseable state
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="trejkaz">Trejkaz</reporter>
<labels></labels>
<created>Fri, 3 Jul 2015 04:13:42 +0000</created>
<updated>Fri, 3 Jul 2015 04:13:42 +0000</updated>
<version>4.10.4</version>
<version>5.1</version>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gtk7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6655] All analysis factory constructors fail if the passed in map is immutable
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6655</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>One of our tests tried to initialise a StandardTokenizer by passing a version into the factory. Unfortunately, this required passing a map:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">return</span> <span class="code-keyword">new</span> StandardTokenizerFactory(ImmutableMap.of( AbstractAnalysisFactory.LUCENE_MATCH_VERSION_PARAM, Version.LUCENE_4_6_1.toString() )).create(); </pre> </div></div> <p>This then fails:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>java.lang.UnsupportedOperationException at com.google.common.collect.ImmutableMap.remove(ImmutableMap.java:338) at org.apache.lucene.analysis.util.AbstractAnalysisFactory.get(AbstractAnalysisFactory.java:122) at org.apache.lucene.analysis.util.AbstractAnalysisFactory.&lt;init&gt;(AbstractAnalysisFactory.java:71) at org.apache.lucene.analysis.util.TokenizerFactory.&lt;init&gt;(TokenizerFactory.java:70) at org.apache.lucene.analysis.standard.StandardTokenizerFactory.&lt;init&gt;(StandardTokenizerFactory.java:42) </pre> </div></div> <p>I suspect that someone put in a `remove` when it should have been a `get`... bit of a weird mistake to make, especially when you don't know whether the map will permit it.</p> <p>I haven't verified whether the same occurs in later versions but getting updated to 5.2.1 will probably be the next thing on my list.</p>
</description>
<environment/>
<key id="12842490">LUCENE-6655</key>
<summary>
All analysis factory constructors fail if the passed in map is immutable
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="trejkaz">Trejkaz</reporter>
<labels></labels>
<created>Fri, 3 Jul 2015 02:51:29 +0000</created>
<updated>Fri, 3 Jul 2015 05:54:53 +0000</updated>
<version>5.1</version>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14612804" author="rjernst" created="Fri, 3 Jul 2015 03:41:04 +0000">
<p>This is intentional. All of the analysis factories do this: remove the parameters they have processed, and then error if there are unknown parameters left at the end.</p>
</comment>
<comment id="14612864" author="trejkaz" created="Fri, 3 Jul 2015 05:54:53 +0000">
<p>There are ways to track that which don't require mutating a map that doesn't belong to you.</p> <p>If all the analysis factories do that by mutating <b>my</b> map, then they're all broken. I'll update the summary accordingly.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 3 Jul 2015 03:41:04 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2gtjr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-7022] smokeTestRelease.py should confirm the git revision is "recognized"
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-7022</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Spinoff from <a href="https://issues.apache.org/jira/browse/LUCENE-7021" title="buildAndPushRelease.py should ensure you have no unpushed git changes" class="issue-link" data-issue-key="LUCENE-7021">LUCENE-7021</a>, but this issue aims to catch release bits built on unpushed changes in the smoke tester, by having it verify that the revision the bits were built from (stored in the JAR's META-INF) is in fact pushed to the public Apache git repository (git-wip-us.apache.org/repos/asf/lucene-solr.git).</p> <p>This seems very important, since a git newbie like myself could easily mess something up and somehow push a release containing local (not pushed) commits that I then lose when deleting my local clone.</p>
</description>
<environment/>
<key id="12938555">LUCENE-7022</key>
<summary>
smokeTestRelease.py should confirm the git revision is "recognized"
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Thu, 11 Feb 2016 16:41:00 +0000</created>
<updated>Thu, 11 Feb 2016 16:41:00 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqan:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-7021] buildAndPushRelease.py should ensure you have no unpushed git changes
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-7021</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I'm just a git newbie so I'm not sure how to add this to our release scripts, but I think it's quite important that we don't up and release something the world containing changes I had only committed locally and then failed to push. What if I then remove that directory after we've released?</p> <p>We should also fix the release smoke tester to confirm the git revision is known ... I'll open a separate issue for that.</p> <p>I'm trying to be super careful not to do this for 5.5.0, but really the release script should catch this.</p> <p>I did a bit of googling and found the magic command <tt>git cherry -v origin/branch_5_5</tt> seemed to work (at least, it showed my one local commit), but e.g. "origin" is just a label I use (others use "upstream"), etc., so I'm not sure how to reliably do this... maybe we have to run <tt>git remote -v</tt> and figure out what label use use for the "official" (wip) Apache git instance?</p>
</description>
<environment/>
<key id="12938553">LUCENE-7021</key>
<summary>
buildAndPushRelease.py should ensure you have no unpushed git changes
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Thu, 11 Feb 2016 16:36:29 +0000</created>
<updated>Thu, 11 Feb 2016 17:31:05 +0000</updated>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="15142997" author="mikemccand" created="Thu, 11 Feb 2016 16:41:43 +0000">
<p>I opened <a href="https://issues.apache.org/jira/browse/LUCENE-7022" title="smokeTestRelease.py should confirm the git revision is &quot;recognized&quot;" class="issue-link" data-issue-key="LUCENE-7022">LUCENE-7022</a> for the same fix to the smoke tester.</p>
</comment>
<comment id="15143028" author="dweiss" created="Thu, 11 Feb 2016 16:56:35 +0000">
<p>&gt; maybe we have to run git remote -v and figure out what label use use for the "official" (wip) Apache git instance?</p> <p>Doesn't matter what the remote is &#8211; the commit hash says it all (it will be the same regardless of the origin of the commit tree).</p>
</comment>
<comment id="15143111" author="romseygeek" created="Thu, 11 Feb 2016 17:31:05 +0000">
<p>The output of <tt>git status</tt> should tell you if you're up-to-date or ahead of your remote tracking branch. eg:<br/> {{<br/> $ git status<br/> On branch master<br/> Your branch is up-to-date with 'origin/master'.<br/> nothing to commit, working directory clean<br/> }}</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 11 Feb 2016 16:56:35 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqa7:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-7023] Implementation-Version spans 2 lines in MANIFEST.MF in our JARs
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-7023</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>The release smoke tester is angry about this.</p> <p>In the core Lucene jar for 5.4.1 we have this:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Manifest-Version: 1.0 Ant-Version: Apache Ant 1.8.4 Created-By: 1.7.0_55-b13 (Oracle Corporation) Extension-Name: org.apache.lucene Specification-Title: Lucene Search Engine: core Specification-Version: 5.4.1 Specification-Vendor: The Apache Software Foundation Implementation-Title: org.apache.lucene Implementation-Version: 5.4.1 1725212 - jpountz - 2016-01-18 11:44:59 Implementation-Vendor: The Apache Software Foundation X-Compile-Source-JDK: 1.7 X-Compile-Target-JDK: 1.7 </pre> </div></div> <p>But in the RC0 I'm building, I see this:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>Ant-Version: Apache Ant 1.8.4 Created-By: 1.7.0_71-b14 (Oracle Corporation) Extension-Name: org.apache.lucene Specification-Title: Lucene Search Engine: queryparser Specification-Version: 5.5.0 Specification-Vendor: The Apache Software Foundation Implementation-Title: org.apache.lucene Implementation-Version: 5.5.0 850c6c248373d80617e771f776041fd0d59ac31a - mike - 2016-02-11 11:48:18 Implementation-Vendor: The Apache Software Foundation X-Compile-Source-JDK: 1.7 X-Compile-Target-JDK: 1.7 </pre> </div></div> <p>The <tt>Implementation-Version</tt> spans two lines ... maybe this OK, maybe it's even required (is there a max line length in the MANIFEST.MF spec?) but it makes me nervous...</p>
</description>
<environment/>
<key id="12938610">LUCENE-7023</key>
<summary>
Implementation-Version spans 2 lines in MANIFEST.MF in our JARs
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Thu, 11 Feb 2016 20:11:40 +0000</created>
<updated>Fri, 12 Feb 2016 19:31:29 +0000</updated>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15143418" author="mikemccand" created="Thu, 11 Feb 2016 20:12:06 +0000">
<p>I can fix the smoke tester to deal with this, if we decide it's in fact OK ...</p>
</comment>
<comment id="15145113" author="rjernst" created="Fri, 12 Feb 2016 19:15:21 +0000">
<p>The spec for manifest files has a limit of 72 bytes on a line, which can be continued to the next by using a single space at the beginning of the next line. See <a href="http://docs.oracle.com/javase/7/docs/technotes/guides/jar/jar.html#Manifest_Specification" class="external-link" rel="nofollow">http://docs.oracle.com/javase/7/docs/technotes/guides/jar/jar.html#Manifest_Specification</a>.</p> <p>Specifically, the spec says:</p> <blockquote> <p>Line length:<br/> No line may be longer than 72 bytes (not characters), in its UTF8-encoded form. If a value would make the initial line longer than this, it should be continued on extra lines (each starting with a single SPACE).</p></blockquote> <p>So I think we just need to update the smoke tester to understand line continuation?</p>
</comment>
<comment id="15145143" author="mikemccand" created="Fri, 12 Feb 2016 19:31:29 +0000">
<p>OK thanks <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rjernst" class="user-hover" rel="rjernst">Ryan Ernst</a>, so this is actually OK for 5.5.0 release. I'll fix the smoke tester to handle this properly, but that's not a blocker for 5.5.0.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 12 Feb 2016 19:15:21 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2sqmn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-7017] TestGeoPointQuery failure</title>
<link>https://issues.apache.org/jira/browse/LUCENE-7017</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>I hit this while beasting for another issue:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>-test: [mkdir] Created dir: /l/trunk/lucene/build/sandbox/test [junit4:pickseed] Seed property 'tests.seed' already defined: 1EAB921E0532F649 [mkdir] Created dir: /l/trunk/lucene/build/sandbox/test/temp [mkdir] Created dir: /l/trunk/.caches/test-stats/sandbox [junit4] &lt;JUnit4&gt; says שלום! Master seed: 1EAB921E0532F649 [junit4] Executing 1 suite with 1 JVM. [junit4] [junit4] Started J0 PID(19596@localhost). [junit4] Suite: org.apache.lucene.search.TestGeoPointQuery [junit4] OK 0.02s | TestGeoPointQuery.testInvalidGeoDistanceQuery [junit4] OK 0.07s | TestGeoPointQuery.testTooBigRadius [junit4] OK 0.03s | TestGeoPointQuery.testGeoDistanceQuery [junit4] OK 0.01s | TestGeoPointQuery.testPolyQuery [junit4] OK 0.02s | TestGeoPointQuery.testMultiValuedQuery [junit4] OK 0.27s | TestGeoPointQuery.testWholeMap [junit4] IGNOR/A 0.01s | TestGeoPointQuery.testRandomBig [junit4] &gt; Assumption #1: 'nightly' test group is disabled (@Nightly()) [junit4] OK 0.01s | TestGeoPointQuery.testNonEmptyTermsEnum [junit4] OK 0.24s | TestGeoPointQuery.testEncodeDecode [junit4] OK 5.82s | TestGeoPointQuery.testMultiValued [junit4] 2&gt; veebr 05, 2016 6:10:36 PM com.carrotsearch.randomizedtesting.RandomizedRunner$QueueUncaughtExceptionsHandler uncaughtException [junit4] 2&gt; WARNING: Uncaught exception in thread: Thread[T0,5,TGRP-TestGeoPointQuery] [junit4] 2&gt; java.lang.AssertionError [junit4] 2&gt; at __randomizedtesting.SeedInfo.seed([1EAB921E0532F649]:0) [junit4] 2&gt; at org.apache.lucene.search.GeoPointTermsEnum.&lt;init&gt;(GeoPointTermsEnum.java:65) [junit4] 2&gt; at org.apache.lucene.search.GeoPointDistanceQueryImpl$GeoPointRadiusTermsEnum.&lt;init&gt;(GeoPointDistanceQueryImpl.java:58) [junit4] 2&gt; at org.apache.lucene.search.GeoPointDistanceQueryImpl.getTermsEnum(GeoPointDistanceQueryImpl.java:47) [junit4] 2&gt; at org.apache.lucene.search.MultiTermQuery.getTermsEnum(MultiTermQuery.java:304) [junit4] 2&gt; at org.apache.lucene.search.GeoPointTermQueryConstantScoreWrapper$1.getDocIDs(GeoPointTermQueryConstantScoreWrapper.java:71) [junit4] 2&gt; at org.apache.lucene.search.GeoPointTermQueryConstantScoreWrapper$1.scorer(GeoPointTermQueryConstantScoreWrapper.java:125) [junit4] 2&gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:617) [junit4] 2&gt; at org.apache.lucene.search.AssertingWeight.scorer(AssertingWeight.java:61) [junit4] 2&gt; at org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:389) [junit4] 2&gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:617) [junit4] 2&gt; at org.apache.lucene.search.AssertingWeight.scorer(AssertingWeight.java:61) [junit4] 2&gt; at org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:343) [junit4] 2&gt; at org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:364) [junit4] 2&gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.bulkScorer(LRUQueryCache.java:644) [junit4] 2&gt; at org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:68) [junit4] 2&gt; at org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:68) [junit4] 2&gt; at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:666) [junit4] 2&gt; at org.apache.lucene.search.AssertingIndexSearcher.search(AssertingIndexSearcher.java:91) [junit4] 2&gt; at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:473) [junit4] 2&gt; at org.apache.lucene.util.BaseGeoPointTestCase$VerifyHits.test(BaseGeoPointTestCase.java:485) [junit4] 2&gt; at org.apache.lucene.util.BaseGeoPointTestCase$2._run(BaseGeoPointTestCase.java:741) [junit4] 2&gt; at org.apache.lucene.util.BaseGeoPointTestCase$2.run(BaseGeoPointTestCase.java:608) [junit4] 2&gt; [junit4] 2&gt; NOTE: reproduce with: ant test -Dtestcase=TestGeoPointQuery -Dtests.method=testRandomMedium -Dtests.seed=1EAB921E0532F649 -Dtests.locale=et-EE -Dtests.timezone=Europe/Budapest -Dtests.asserts=true -Dtests.file.encoding=ISO-8859-1 [junit4] ERROR 5.66s | TestGeoPointQuery.testRandomMedium &lt;&lt;&lt; [junit4] &gt; Throwable #1: com.carrotsearch.randomizedtesting.UncaughtExceptionError: Captured an uncaught exception in thread: Thread[id=16, name=T0, state=RUNNABLE, group=TGRP-TestGeoPointQuery] [junit4] &gt; at __randomizedtesting.SeedInfo.seed([1EAB921E0532F649:A375A5B64457952F]:0) [junit4] &gt; Caused by: java.lang.AssertionError [junit4] &gt; at __randomizedtesting.SeedInfo.seed([1EAB921E0532F649]:0) [junit4] &gt; at org.apache.lucene.search.GeoPointTermsEnum.&lt;init&gt;(GeoPointTermsEnum.java:65) [junit4] &gt; at org.apache.lucene.search.GeoPointDistanceQueryImpl$GeoPointRadiusTermsEnum.&lt;init&gt;(GeoPointDistanceQueryImpl.java:58) [junit4] &gt; at org.apache.lucene.search.GeoPointDistanceQueryImpl.getTermsEnum(GeoPointDistanceQueryImpl.java:47) [junit4] &gt; at org.apache.lucene.search.MultiTermQuery.getTermsEnum(MultiTermQuery.java:304) [junit4] &gt; at org.apache.lucene.search.GeoPointTermQueryConstantScoreWrapper$1.getDocIDs(GeoPointTermQueryConstantScoreWrapper.java:71) [junit4] &gt; at org.apache.lucene.search.GeoPointTermQueryConstantScoreWrapper$1.scorer(GeoPointTermQueryConstantScoreWrapper.java:125) [junit4] &gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:617) [junit4] &gt; at org.apache.lucene.search.AssertingWeight.scorer(AssertingWeight.java:61) [junit4] &gt; at org.apache.lucene.search.BooleanWeight.scorer(BooleanWeight.java:389) [junit4] &gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.scorer(LRUQueryCache.java:617) [junit4] &gt; at org.apache.lucene.search.AssertingWeight.scorer(AssertingWeight.java:61) [junit4] &gt; at org.apache.lucene.search.BooleanWeight.booleanScorer(BooleanWeight.java:343) [junit4] &gt; at org.apache.lucene.search.BooleanWeight.bulkScorer(BooleanWeight.java:364) [junit4] &gt; at org.apache.lucene.search.LRUQueryCache$CachingWrapperWeight.bulkScorer(LRUQueryCache.java:644) [junit4] &gt; at org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:68) [junit4] &gt; at org.apache.lucene.search.AssertingWeight.bulkScorer(AssertingWeight.java:68) [junit4] &gt; at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:666) [junit4] &gt; at org.apache.lucene.search.AssertingIndexSearcher.search(AssertingIndexSearcher.java:91) [junit4] &gt; at org.apache.lucene.search.IndexSearcher.search(IndexSearcher.java:473) [junit4] &gt; at org.apache.lucene.util.BaseGeoPointTestCase$VerifyHits.test(BaseGeoPointTestCase.java:485) [junit4] &gt; at org.apache.lucene.util.BaseGeoPointTestCase$2._run(BaseGeoPointTestCase.java:741) [junit4] &gt; at org.apache.lucene.util.BaseGeoPointTestCase$2.run(BaseGeoPointTestCase.java:608) </pre> </div></div> <p>This is on commit #4569fd732aa1406763ed94f5df830b324a584a6b on master.</p>
</description>
<environment/>
<key id="12937083">LUCENE-7017</key>
<summary>TestGeoPointQuery failure</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Fri, 5 Feb 2016 17:12:55 +0000</created>
<updated>Fri, 5 Feb 2016 17:12:55 +0000</updated>
<fixVersion>6.0</fixVersion>
<fixVersion>trunk</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2shfz:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-7044] Range faceting fails on SortedNumericDocValuesField
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-7044</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Hi,</p> <p>Context: <a href="https://hibernate.atlassian.net/browse/HSEARCH-1927" class="external-link" rel="nofollow">https://hibernate.atlassian.net/browse/HSEARCH-1927</a></p> <p>By using <tt>SortedNumericDocValuesField</tt>, we can index several numeric values for the same field.</p> <p>But we can't execute a range query on it using <tt>LongRangeFacetCounts</tt>.</p> <p>Lucene fails with the following stacktrace:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> java.lang.IllegalStateException: unexpected docvalues type SORTED_NUMERIC <span class="code-keyword">for</span> field 'ingredients.price' (expected=NUMERIC). Use UninvertingReader or index with docvalues. at org.apache.lucene.index.DocValues.checkField(DocValues.java:208) at org.apache.lucene.index.DocValues.getNumeric(DocValues.java:227) at org.apache.lucene.queries.function.valuesource.LongFieldSource.getValues(LongFieldSource.java:67) at org.apache.lucene.facet.range.LongRangeFacetCounts.count(LongRangeFacetCounts.java:80) at org.apache.lucene.facet.range.LongRangeFacetCounts.&lt;init&gt;(LongRangeFacetCounts.java:69) </pre> </div></div> <p>Either <tt>LongRangeFacetCounts</tt> needs some tweaking to accept <tt>SORTED_NUMERIC</tt> or we need another implementation to deal with <tt>SortedNumericDocValuesField</tt> (and probably an implementation of both for Doubles).</p> <p>&#8211; <br/> Guillaume</p>
</description>
<environment/>
<key id="12941452">LUCENE-7044</key>
<summary>
Range faceting fails on SortedNumericDocValuesField
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="gsmet">Guillaume Smet</reporter>
<labels></labels>
<created>Tue, 23 Feb 2016 16:55:38 +0000</created>
<updated>Tue, 23 Feb 2016 17:03:05 +0000</updated>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2t84f:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6994] GeoUtils Distance accuracy degrades with irregular rectangles
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6994</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This is a continuation of <a href="https://issues.apache.org/jira/browse/LUCENE-6908" title="TestGeoUtils.testGeoRelations is buggy with irregular rectangles" class="issue-link" data-issue-key="LUCENE-6908"><del>LUCENE-6908</del></a> which validates USGS accuracy of 0.5% for Sinnott haversine distance calculation. The issue also introduced a space segmentation approach for BKD distance queries near the poles. In <a href="https://issues.apache.org/jira/browse/LUCENE-6956" title="TestBKDTree.testRandomMedium() failure: some hits were wrong" class="issue-link" data-issue-key="LUCENE-6956"><del>LUCENE-6956</del></a> a restriction on distance size was initially removed to randomly test BKD distance queries at any range. This revealed an issue where distance error nearly doubles for exotic rectangles created by BKD's split algorithm. This issue will investigate potential distance error caused by the segmentation approach introduced in the second part of <a href="https://issues.apache.org/jira/browse/LUCENE-6908" title="TestGeoUtils.testGeoRelations is buggy with irregular rectangles" class="issue-link" data-issue-key="LUCENE-6908"><del>LUCENE-6908</del></a>.</p>
</description>
<environment/>
<key id="12933967">LUCENE-6994</key>
<summary>
GeoUtils Distance accuracy degrades with irregular rectangles
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="nknize">Nicholas Knize</reporter>
<labels></labels>
<created>Mon, 25 Jan 2016 22:51:49 +0000</created>
<updated>Mon, 1 Feb 2016 17:41:22 +0000</updated>
<component>modules/spatial</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2ry8v:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-6972] QueryBuilder should not differentiate single position and multiple positions queries when the analyzer produces synonyms.
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-6972</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>When synonyms are involved the querybuilder differentiate two cases. When there is only one position the query is composed of one BooleanQuery which contains multiple should clauses. This does not interact well when trying to apply a minimum_should_match to the query. For instance if a field has a synonym rule like "foo,bar" the query "foo" will produce:</p> <blockquote><p>(foo bar)</p></blockquote> <p>... two optional clauses at the root level. If we apply a minimum should match of 50% then the query becomes:</p> <blockquote><p>(foo bar)~1 </p></blockquote> <p>This seems wrong, the terms are at the same position.<br/> IMO the querybuilder should produce the following query:</p> <blockquote><p>((foo bar))</p></blockquote> <p>... and a minimum should match of 50% should be not applicable to a query with only one optional clause at the root level.<br/> The case with multiple positions works as expected. <br/> The user query "test foo" generates:</p> <blockquote><p>(test (foo bar)) </p></blockquote> <p>... and if we apply a minimum should match of 50%:</p> <blockquote><p>(test (foo bar))~1</p></blockquote>
</description>
<environment/>
<key id="12929315">LUCENE-6972</key>
<summary>
QueryBuilder should not differentiate single position and multiple positions queries when the analyzer produces synonyms.
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="jpountz">Adrien Grand</assignee>
<reporter username="jim.ferenczi">Ferenczi Jim</reporter>
<labels></labels>
<created>Mon, 11 Jan 2016 23:02:51 +0000</created>
<updated>Tue, 23 Feb 2016 10:36:02 +0000</updated>
<version>5.4</version>
<version>5.5</version>
<fixVersion>6.0</fixVersion>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="15096437" author="jpountz" created="Wed, 13 Jan 2016 16:10:04 +0000">
<p>Thanks Jim, the change looks good to me. I'll merge it soon.</p>
</comment>
<comment id="15096648" author="jpountz" created="Wed, 13 Jan 2016 17:38:13 +0000">
<p>Hmm actually I'm seeing failures in the queryparser module with these changes on trunk (patch attached, I had to do some changes due to the new SynonymQuery):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre> [junit4] Tests with failures [seed: 551E3E67CB732A19]: [junit4] - org.apache.lucene.queryparser.classic.TestMultiAnalyzer.testMultiAnalyzer [junit4] - org.apache.lucene.queryparser.ext.TestExtendableQueryParser.testSynonyms [junit4] - org.apache.lucene.queryparser.classic.TestQueryParser.testSynonyms [junit4] - org.apache.lucene.queryparser.ext.TestExtendableQueryParser.testNewFieldQuery [junit4] - org.apache.lucene.queryparser.ext.TestExtendableQueryParser.testCJKSynonym [junit4] - org.apache.lucene.queryparser.classic.TestQueryParser.testCJKSynonym [junit4] - org.apache.lucene.queryparser.classic.TestQueryParser.testNewFieldQuery </pre> </div></div>
</comment>
<comment id="15096811" author="jim.ferenczi" created="Wed, 13 Jan 2016 19:04:53 +0000">
<p>Sorry I forgot to add a comment about merging into trunk. I don't think it is needed because the new SynonymQuery packs all the synonyms in the same query so minimum should match is not affected. Though there would be things to do (not in this issue) to handle single word synonyms that appear in a multi position query with a SynonymQuery (the analyzeMultiBoolean does not use the SynonymQuery).</p>
</comment>
<comment id="15097072" author="jpountz" created="Wed, 13 Jan 2016 21:53:55 +0000">
<p>OK I see! Maybe we should still add your new test to trunk?</p>
</comment>
<comment id="15097152" author="rcmuir" created="Wed, 13 Jan 2016 22:30:55 +0000">
<p>I got confused by the patch being converted to trunk. I agree, the fix should be for 5.x only.</p> <p>The reason it happens, createMinShouldMatch does this:</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">if</span> (query <span class="code-keyword">instanceof</span> BooleanQuery) { ... </pre> </div></div> <p>And this gets confused by the 5.x "SynonymQuery" (which is a BooleanQuery with coord disabled).</p> <p>I think rather than change the structure of the queries we generate here, we should just check for enabled coordination factor in that instanceof instead. It contains the change better, to just the minShouldMatch logic, vs adding additional unnecessary boxing / changing the shape of many queries.</p>
</comment>
<comment id="15105807" author="jpountz" created="Mon, 18 Jan 2016 20:43:41 +0000">
<p><a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jim.ferenczi" class="user-hover" rel="jim.ferenczi">Ferenczi Jim</a> How do you feel about changing the patch to check the coord factor as suggested by Robert?</p>
</comment>
<comment id="15105867" author="jim.ferenczi" created="Mon, 18 Jan 2016 21:58:27 +0000">
<p>Rewrote the patch after <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=rcmuir" class="user-hover" rel="rcmuir">Robert Muir</a> suggestion about checking coordination factor instead. <a href="https://issues.apache.org/jira/secure/ViewProfile.jspa?name=jpountz" class="user-hover" rel="jpountz">Adrien Grand</a> can you check ? </p>
</comment>
<comment id="15105888" author="rcmuir" created="Mon, 18 Jan 2016 22:20:38 +0000"><p>+1</p></comment>
</comments>
<attachments>
<attachment id="12782944" name="LUCENE-6972.patch" size="3867" author="jim.ferenczi" created="Mon, 18 Jan 2016 21:58:27 +0000"/>
<attachment id="12781675" name="LUCENE-6972.patch" size="6226" author="jim.ferenczi" created="Mon, 11 Jan 2016 23:12:09 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 13 Jan 2016 16:10:04 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
<customfieldvalue key="10120">
<![CDATA[ Patch Available ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i2r5lb:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>9223372036854775807</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5885] MergeScheduler should not implement Closeable
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5885</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>MergeScheduler implements Closeable and IndexWriter calls ms.close() when it's closed. But MergeScheduler can be shared between several writers, which means closing it by any particular writer is wrong. We should rather implement some ref-counting logic such that each IW will call incRef() in the ctor, and decRef() on close(), and MergeScheduler will truly close when the ref-count hits 0.</p> <p>As it is now, if you share a MergeScheduler between writers and close() does something terminating, I doubt if it really works.</p> <p>Also, when I look at ConcurrentMergeScheduler.close(), it calls sync() which joins all MergeThreads. But if that CMS instance is shared between few IWs, doesn't it mean that a single IW calling close() waits on MergeThreads that execute merges of other IWs!?!? This seems ... wrong?</p>
</description>
<environment/>
<key id="12734043">LUCENE-5885</key>
<summary>MergeScheduler should not implement Closeable</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="shaie">Shai Erera</reporter>
<labels></labels>
<created>Thu, 14 Aug 2014 12:18:31 +0000</created>
<updated>Thu, 14 Aug 2014 18:56:53 +0000</updated>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14096926" author="mikemccand" created="Thu, 14 Aug 2014 12:49:45 +0000">
<p>+1 to remove Closeable.</p> <p>I think the sync() that CMS does in close today can be dropped: IW already finishes all merges itself.</p>
</comment>
<comment id="14096931" author="shaie" created="Thu, 14 Aug 2014 12:56:56 +0000">
<p>Oh, that simplifies things a lot. I started to look into adding MS.decRef(IndexWriter) and such horrible API <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/>. But if we can drop the call to sync() from CMS.close(), then it simplifies things.</p> <p>I wonder if we need to have CMS.sync() at all, rather than having the user call IndexWriter.waitForMerges() &#8211; this seems like a better API. It also ensures that IW isn't closed before CMS.sync() is called?</p>
</comment>
<comment id="14096933" author="mikemccand" created="Thu, 14 Aug 2014 12:57:58 +0000"><p>+1 to drop CMS.sync!</p></comment>
<comment id="14096936" author="shaie" created="Thu, 14 Aug 2014 13:07:07 +0000">
<p>I had a chat w/ Mike about this - we think that perhaps it's better if MergeScheduler doesn't implement close as well as any reference counting. Since IndexWriter either waits or aborts merges itself, there's nothing to close() about CMS. And if you have a custom MS, which e.g. uses a ThreadPool, you can implement a close() or ref-counting mechanism yourself.</p>
</comment>
<comment id="14097003" author="shaie" created="Thu, 14 Aug 2014 14:25:49 +0000">
<p>Patch removes CMS.sync() and Closeable from MergeScheduler. Note that this cannot be committed yet, since it depends on the fix Mike's working on on <a href="https://issues.apache.org/jira/browse/LUCENE-5871" title="Simplify or remove use of Version in IndexWriterConfig" class="issue-link" data-issue-key="LUCENE-5871"><del>LUCENE-5871</del></a>. Currently, without that fix, when you call IW.close() and commitOnClose=true, IW flushes, finishes merges and then commits. But that commit may spawn merges itself, and so if we don't wait/abort them in IW.rollbackInternal, some tests complain about still running merges, or hit AlreadyClosedExceptions. With the fix on <a href="https://issues.apache.org/jira/browse/LUCENE-5871" title="Simplify or remove use of Version in IndexWriterConfig" class="issue-link" data-issue-key="LUCENE-5871"><del>LUCENE-5871</del></a>, that commit won't spawn new merges, which is silly since IW is closing...</p> <p>I'll wait for that fix before I assert this patch really works. I also didn't add a CHANGES entry - the migration from CMS.sync() is to simply call IW.waitForMerges(), which I think is better to do anyway.</p>
</comment>
<comment id="14097149" author="shaie" created="Thu, 14 Aug 2014 16:07:47 +0000">
<p>I ran tests after the fix on <a href="https://issues.apache.org/jira/browse/LUCENE-5871" title="Simplify or remove use of Version in IndexWriterConfig" class="issue-link" data-issue-key="LUCENE-5871"><del>LUCENE-5871</del></a>, but I get this failure:</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>ant test -Dtestcase=TestIndexWriter -Dtests.method=testThreadInterruptDeadlock -Dtests.seed=80C0F4CAF8F7E5D8 -Dtests.slow=true -Dtests.locale=bg_BG -Dtests.timezone=Africa/Blantyre -Dtests.file.encoding=US-ASCII </pre> </div></div> <p>The test fails because a MergeThread hits AlreadyClosedException. I added some sops and I think that's because of how this test interrupts the indexing thread. So what I see is that the indexing thread enters IW.shutdown(), calls flush, then finishMerges, but doesn't get to call commitInternal, because it hits an interrupt. Therefore, I assume the indexing thread is inside flushMerges(true), which waitForMerges(). But since it hits an interrupt, it throws a ThreadInterruptedException.</p> <p>With this patch, it means there are still pending or running merges, and since in IW.rollbackInternal I no longer call MS.close() (which for CMS meant finishing those merges, while ignoring InterruptedException), there is a merge still running, and hence the exception.</p> <p>In fact, I think that the way we abortMerges() isn't safe. After we notify all merges to abort, we wait on the running merges. But if we hit an InterruptedException while waiting, we just throw this exception further, and in fact leave running merges behind. At some point they will die, since we marked their merges as aborted, but since this is rollback and we do EVERYTHING to close this writer, we proceed, and so the background running merge hits the AlreadyClosedException. I tried to quickly wait and ignore InterruptedException until success, but the test failed on being interrupted ... I'll debug it later.</p>
</comment>
<comment id="14097379" author="shaie" created="Thu, 14 Aug 2014 18:56:53 +0000">
<p>Patch fixes the bug - finishMerges(false) is more robust now, and waits for all runningMerges to abort, ignoring ThreadInterruptedExceptions (but restoring in the end).</p> <p>But, our assumption that this is enough to release a MergeScheduler's resources was wrong. What happens is that IW waits until all <b>runningMerges</b> are done, but that doesn't mean all <b>MergeThreads</b> have died. So under some cases, this is what can happen (CTX = context switch):</p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>IW.finishMerges(false) calls merge.abort() CTX MergeThread.merge() hits a MergeAbortedException (expected) MergeThread.merge() enters finally {} and calls IW.mergeFinish IW.mergeFinish removes that merge from runningMerges CTX runningMerges.size() == 0, so thread exits finishMerges() rollbackInternal continues, finishes test continues, finishes (NOTE: MergeThread is still alive, as it didn't exit yet!!) test-framework complains about thread leak </pre> </div></div> <p>So I now wonder if we should add a ref-counting mechanism to MS. It's not simple, we cannot just add a decRef(), we need a decRef(IndexWriter) and then in CMS we need to handle only the MergeThreads that are associated with this IndexWriter instance. This may be easy for CMS, but is it a good API for our users? Is it clear that they need to handle only the resources that are associated with that IW instance?</p> <p>Thoughts?</p>
</comment>
</comments>
<attachments>
<attachment id="12661766" name="LUCENE-5885.patch" size="16006" author="shaie" created="Thu, 14 Aug 2014 18:56:53 +0000"/>
<attachment id="12661717" name="LUCENE-5885.patch" size="13996" author="shaie" created="Thu, 14 Aug 2014 14:25:49 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>2.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Thu, 14 Aug 2014 12:49:45 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>412071</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1yw1z:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>412060</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5888] FSTOrdPostingsFormat doesnt support ord()
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5888</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This is sort of the point of this PF, but it doesn't implement ord() or seek(ord).</p>
</description>
<environment/>
<key id="12734385">LUCENE-5888</key>
<summary>FSTOrdPostingsFormat doesnt support ord()</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Fri, 15 Aug 2014 10:22:11 +0000</created>
<updated>Fri, 15 Aug 2014 13:18:17 +0000</updated>
<due/>
<votes>1</votes>
<watches>1</watches>
<comments>
<comment id="14098530" author="rcmuir" created="Fri, 15 Aug 2014 13:15:19 +0000">
<p>I looked at trying to fix this: a big missing piece I think is to be able to seek the FSTEnum by output?</p> <p>If we can do this, we can fix the stupidity in MemoryDocValues and Lucene42DocValues as well: they currently find-by-output separately (the Util method), then seek the enum to the bytes <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/sad.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14098533" author="rcmuir" created="Fri, 15 Aug 2014 13:18:17 +0000">
<p>Maybe a solution here is to make a OrdFSTEnum that extends BytesRefFSTEnum&lt;Long&gt; ? Util.getByOutput is hardcoded at Long, so to avoid generics hell we can just have this subclass that solves the issue for our terms dictionaries/docvalues.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>412325</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1yxkv:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>412312</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>[LUCENE-5876] NPE in BoostQueryNodeBuilder.build</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5876</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> Query build(QueryNode queryNode) <span class="code-keyword">throws</span> QueryNodeException { BoostQueryNode boostNode = (BoostQueryNode) queryNode; QueryNode child = boostNode.getChild(); <span class="code-keyword">if</span> (child == <span class="code-keyword">null</span>) { <span class="code-keyword">return</span> <span class="code-keyword">null</span>; } Query query = (Query) child .getTag(QueryTreeBuilder.QUERY_TREE_BUILDER_TAGID); query.setBoost(boostNode.getValue()); <span class="code-keyword">return</span> query; } </pre> </div></div> <p>In BoostQueryNodeBuilder.build, the return variable, "query" can be null, but there is no error handling code for the return variable. I think there should be a null checker for query like for child. </p> <p>&lt;Test Case&gt;</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> <span class="code-keyword">public</span> void test1() <span class="code-keyword">throws</span> Throwable { BoostQueryNodeBuilder builder = <span class="code-keyword">new</span> BoostQueryNodeBuilder(); QuotedFieldQueryNode quotedNode = <span class="code-keyword">new</span> QuotedFieldQueryNode((java.lang.CharSequence)<span class="code-quote">"hi!"</span>, (java.lang.CharSequence)"", 10, 100); BoostQueryNode node = <span class="code-keyword">new</span> BoostQueryNode((QueryNode)quotedNode, 2.0f); builder.build((QueryNode)node); } </pre> </div></div> <p>&lt;Stack Trace&gt;</p> <div class="code panel" style="border-width: 1px;"><div class="codeContent panelContent"> <pre class="code-java"> 1) test1(Test0)java.lang.NullPointerException at org.apache.lucene.queryparser.flexible.standard.builders.BoostQueryNodeBuilder.build(BoostQueryNodeBuilder.java:49) at Test0.test1(Test0.java:4809) </pre> </div></div>
</description>
<environment/>
<key id="12732617">LUCENE-5876</key>
<summary>NPE in BoostQueryNodeBuilder.build</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mjkim0324">M Kim</reporter>
<labels></labels>
<created>Thu, 7 Aug 2014 17:39:19 +0000</created>
<updated>Mon, 16 Feb 2015 18:36:07 +0000</updated>
<version>4.9</version>
<component>core/queryparser</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>410645</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1ynfj:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>410639</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5787] LuceneTestCase static leak checker interferes with Groovy unit tests
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5787</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p><tt>LuceneTestCase</tt>'s static memory leak checker can break Groovy subclasses. Specifically, Groovy classes have a synthetic static member variable of type <tt>org.codehaus.groovy.reflection.ClassInfo</tt>. If this variable grows too large then LTC will fail the test. Because the variable is added by the Groovy runtime instead of by the developer there is no way for the developer to clear the field themselves.</p> <p>Also note that the static leak checker does not ignore memory held by soft or weak references. These should be ignored because the memory retained by such fields will be reclaimed instead of triggering OutOfMemoryErrors.</p> <p>Note that because LTC is a base class for Solr's testing support classes this also affects <tt>SolrTestCaseJ4</tt> and <tt>AbstractSolrTestCase</tt>.</p>
</description>
<environment><p>Maven 3.0.5<br/> JUnit 4.11</p></environment>
<key id="12723178">LUCENE-5787</key>
<summary>
LuceneTestCase static leak checker interferes with Groovy unit tests
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="dweiss">Dawid Weiss</assignee>
<reporter username="jgibson">John Gibson</reporter>
<labels></labels>
<created>Mon, 23 Jun 2014 18:22:06 +0000</created>
<updated>Tue, 24 Jun 2014 05:46:06 +0000</updated>
<version>4.7</version>
<version>4.8.1</version>
<due/>
<votes>0</votes>
<watches>3</watches>
<comments>
<comment id="14041145" author="thetaphi" created="Mon, 23 Jun 2014 19:09:11 +0000">
<p>This means you want to subclass LuceneTestCase with Groovy as basis for your own Solr/Lucene tests?</p>
</comment>
<comment id="14041150" author="dweiss" created="Mon, 23 Jun 2014 19:12:50 +0000">
<p>We could exclude this particular reference by field class's name. As for weak/ soft refs &#8211; I agree, these should also be excluded from the count. What do you think, Uwe?</p>
</comment>
<comment id="14041167" author="thetaphi" created="Mon, 23 Jun 2014 19:25:43 +0000">
<p>I agree with all subclasses of Reference. The main usecase of WeakRefs is in static fields <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/> - see for example the pointers to classes for static caches.</p> <p>The particular reference to the groovy class could be added a String to the leak checker. On the other hand, if you subclass LTC for Groovy, you can add the annotation to prevent the leakchecker from running. This bug does not affect Lucene, it is a problem of 3rd party infrastructures using our test framework. So the big question: What does other scripting laguages do? Scala? JRuby? The list is endless. Maybe add an annotation like <tt>@SuppressLeakChecks(<span class="error">&#91;fieldname, fieldname, fieldname&#93;</span>)</tt>.</p>
</comment>
<comment id="14041202" author="dweiss" created="Mon, 23 Jun 2014 19:52:47 +0000">
<p>I think (didn't check) the leak checker is a test rule, so it cannot be easily replaced/ modified (you'd have to shadow the rule chain field and replace all the logic in there). Yet another JUnit dead-end corner case I guess.</p>
</comment>
<comment id="14041224" author="jgibson" created="Mon, 23 Jun 2014 20:07:24 +0000">
<blockquote> <p>This means you want to subclass LuceneTestCase with Groovy as basis for your own Solr/Lucene tests?</p></blockquote> <p>Yes, exactly. Although in my case it was subclassing AbstractSolrTestCase (which is a descendent of LuceneTestCase).</p> <blockquote> <p>I think (didn't check) the leak checker is a test rule, so it cannot be easily replaced/ modified (you'd have to shadow the rule chain field and replace all the logic in there). Yet another JUnit dead-end corner case I guess.</p></blockquote> <p>Dawid, I believe that you're correct. When I first looked into this I couldn't figure out how to disable the check, so I ended up copying LTC into my project and whitelisting the necessary fields manually.</p> <p>The most annoying part about this bug was that initially the test worked fine, then as I added more fields and code to the suite the ClassInfo reference passed the 10 MiB mark and suddenly it stopped working.</p> <blockquote> <p>This bug does not affect Lucene, it is a problem of 3rd party infrastructures using our test framework. So the big question: What does other scripting laguages do? Scala? JRuby? The list is endless. Maybe add an annotation like </p> <div class="preformatted panel" style="border-width: 1px;"><div class="preformattedContent panelContent"> <pre>@SuppressLeakChecks([fieldname, fieldname, fieldname])</pre> </div></div></blockquote> <p>This is an excellent observation that I hadn't thought of. An annotation may be the correct route. Another option would be to ignore all <a href="http://docs.oracle.com/javase/7/docs/api/java/lang/reflect/Field.html#isSynthetic%28%29" class="external-link" rel="nofollow">synthetic fields</a>. (Note that I'm just assuming that Groovy's ClassInfo field is synthetic, given that it's generated by the groovy compiler/runtime.)</p>
</comment>
<comment id="14041256" author="dweiss" created="Mon, 23 Jun 2014 20:26:24 +0000">
<p>Can you check if this is indeed the case (synthetic field), John? It makes sense to exclude these I think.</p>
</comment>
<comment id="14041264" author="dweiss" created="Mon, 23 Jun 2014 20:30:54 +0000">
<p>I changed my mind; synthetic fields may be actually useful to capture (in case of some awkward compiler generated stuff we do want to include these, unless explicitly excluded).</p> <p>I think Uwe's idea is better &#8211; an annotation to exclude whatever needs to be excluded. I'd make it more flexible by specifying a list of filter classes (much like we do with leak thread exclusions); this allows people to write code to exclude whatever they need.</p>
</comment>
<comment id="14041305" author="jgibson" created="Mon, 23 Jun 2014 20:56:47 +0000">
<p>I just checked and Groovy's ClassInfo field is synthetic. However, I agree that Uwe's annotation idea is more flexible and will save you from the case where the compiler inexplicably generates gigantic static fields which later cause OOMs.</p>
</comment>
<comment id="14041341" author="thetaphi" created="Mon, 23 Jun 2014 21:28:50 +0000">
<p>I would allow to use the annotation, but fields explicitely marked as "synthetic" should always be excluded from the leak checker. Those fields/methods are defined to be <em>any constructs introduced by the compiler that do not have a corresponding construct in the source code must be marked as synthetic, except for default constructors and the class initialization method</em> (like Java 8 lambda methods and fields, access$-methods, the magic assertions enabled static final,...)</p>
</comment>
<comment id="14041344" author="thetaphi" created="Mon, 23 Jun 2014 21:30:30 +0000">
<blockquote><p>here the compiler inexplicably generates gigantic static fields which later cause OOMs</p></blockquote> <p>The leak checker is meant for stuff in our tests that leak in static fields after test class has finished execution. Stuff the compiler adds is nt part of that.</p>
</comment>
<comment id="14041726" author="dweiss" created="Tue, 24 Jun 2014 05:46:06 +0000">
<p>Synthetic fields are also used to pass final variables to the context of an anonymous inner class; not that I envision such constructs to be used as a test case from Java level, but if somebody wants to use a scripting language then who knows what gets passed (and how).</p> <p>I think we should keep it &#8211; if we hit something absurd we can always filter it away, but before we do who knows what's lurking out there.</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Mon, 23 Jun 2014 19:09:11 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>401365</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1x34n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>401440</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5781] don't create unused states in LevenshteinAutomata
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5781</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>While working on <a href="https://issues.apache.org/jira/browse/LUCENE-5752" title="Explore light weight Automaton replacement" class="issue-link" data-issue-key="LUCENE-5752"><del>LUCENE-5752</del></a> I discovered that LevenshteinAutomata creates unused states with cycles. I think they are basically harmless but we still shouldn't create them?</p>
</description>
<environment/>
<key id="12722889">LUCENE-5781</key>
<summary>don't create unused states in LevenshteinAutomata</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="mikemccand">Michael McCandless</assignee>
<reporter username="mikemccand">Michael McCandless</reporter>
<labels></labels>
<created>Fri, 20 Jun 2014 22:14:28 +0000</created>
<updated>Sat, 21 Jun 2014 22:25:32 +0000</updated>
<fixVersion>4.10</fixVersion>
<fixVersion>master</fixVersion>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14039448" author="mikemccand" created="Fri, 20 Jun 2014 22:15:09 +0000">
<p>Simple patch that just creates each state lazily when we "really" need to add transitions to/from it.</p>
</comment>
<comment id="14039772" author="rcmuir" created="Sat, 21 Jun 2014 11:15:02 +0000">
<p>If this is committed, then the comments should be fixed to.</p> <p>What are the concrete benefits? I think the laziness makes the code significantly harder to read: this is probably already our most complex code. Can we do it in a simpler way? If we must do it this way, can the method have proper docs (like all other methods in this class)?</p>
</comment>
<comment id="14039788" author="mikemccand" created="Sat, 21 Jun 2014 12:00:13 +0000">
<p>Actually I thought this approach was clear? I.e. it doesn't really<br/> make the code complex.</p> <p>If you can think of a simpler way I'm all for it ... really I'd like<br/> to understand why the ParametricDescription is creating these dead<br/> states in the first place. That doesn't seem right; maybe a fix there<br/> would be simpler.</p> <p>I'll add more comments and remove the TODO.</p>
</comment>
<comment id="14039795" author="rcmuir" created="Sat, 21 Jun 2014 12:37:56 +0000">
<p>Exactly: I am just very suspicious that the bug is in the python code.</p>
</comment>
<comment id="14039907" author="mikemccand" created="Sat, 21 Jun 2014 17:59:42 +0000">
<blockquote><p>Exactly: I am just very suspicious that the bug is in the python code.</p></blockquote> <p>I am too.</p> <p>I measured the dead states for the N=2 case and length 6 string: 80 of 210 states are dead, and 640 out of 1336 transitions.</p> <p>Also, those are just the "obviously dead" states (they cycle to themselves). There are further non-obvious dead states: once I remove those the automaton has 73 states (down from 130) and 279 transitions (down from 499, after reducing the 696 transitions created by LevA).</p> <p>We never noticed this before because the previous automaton impl couldn't "see" states created that are unreachable from the initial node.</p>
</comment>
<comment id="14039924" author="rcmuir" created="Sat, 21 Jun 2014 19:13:19 +0000">
<p>Well, they were never part of the automaton before <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p>
</comment>
<comment id="14039971" author="mikemccand" created="Sat, 21 Jun 2014 22:25:32 +0000">
<blockquote><p>Well, they were never part of the automaton before </p></blockquote> <p>Right, ignorance was bliss <img class="emoticon" src="https://issues.apache.org/jira/images/icons/emoticons/smile.gif" height="16" width="16" align="absmiddle" alt="" border="0"/></p> <p>I mean, we can continue to ignore this... I was just surprised to discover it.</p> <p>I think it's crazy ~65% of the states and ~79% of the transitions in this case are "born dead".</p>
</comment>
</comments>
<attachments>
<attachment id="12651751" name="LUCENE-5781.patch" size="3172" author="mikemccand" created="Fri, 20 Jun 2014 22:15:09 +0000"/>
</attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>1.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Sat, 21 Jun 2014 11:15:02 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>401076</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1x1en:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>401159</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5753] Domain lists for UAX_URL_EMAIL analyzer are incomplete - cannot recognize ".local" among others
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5753</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>uax_url_email analyzer appears unable to recognize the ".local" TLD among others. Bug can be reproduced by</p> <p>curl -XGET "ADDRESS/INDEX/_analyze?text=First%20Last%20lname@section.mycorp.local&amp;pretty&amp;analyzer=uax_url_email"</p> <p>will parse "lname@section.my" and "corp.local" as separate tokens, as opposed to</p> <p>curl -XGET "ADDRESS/INDEX/_analyze?text=First%20Last%20lname@section.mycorp.org&amp;pretty&amp;analyzer=uax_url_email"</p> <p>which will recognize "lname@section.mycorp.org".</p> <p>Can this be fixed by updating to a newer version? I am running ElasticSearch 0.90.5 and whatever Lucene version sits underneath that. My suspicion is that the TLD list the analyzer relies on (<a href="http://www.internic.net/zones/root.zone" class="external-link" rel="nofollow">http://www.internic.net/zones/root.zone</a>, I think?) is incomplete and needs updating. </p>
</description>
<environment/>
<key id="12720674">LUCENE-5753</key>
<summary>
Domain lists for UAX_URL_EMAIL analyzer are incomplete - cannot recognize ".local" among others
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="stevemer">Steve Merritt</reporter>
<labels></labels>
<created>Wed, 11 Jun 2014 20:06:27 +0000</created>
<updated>Wed, 11 Jun 2014 22:04:43 +0000</updated>
<component>modules/analysis</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<comments>
<comment id="14028339" author="rcmuir" created="Wed, 11 Jun 2014 20:24:12 +0000"><p>.local isnt a valid TLD.</p></comment>
<comment id="14028361" author="rcmuir" created="Wed, 11 Jun 2014 20:39:21 +0000">
<p>disregarding .local, the zones are indeed ~6 months behind and there are quite a few new ones.</p> <p>I saw on the jflex list they were preparing a new release, so maybe its best to time the upgrade with that (we currently provide backwards compatibility here so there is a size cost to each update of this tokenizer).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Wed, 11 Jun 2014 20:24:12 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>398873</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1wo4n:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>398995</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5732] Possible order violation in lucene library version 2.4.1
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5732</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Hi,</p> <p>I am working on a research project on data race detection, and am using the DaCapo benchmarks for evaluation. I am using the benchmark lusearch from the 2009 suite, which uses lucene library 2.4.1.</p> <p>For one test case, I am monitoring a pair of accesses<br/> say, Lorg/apache/lucene/store/Directory;.&lt;init&gt; ()V:40(6) and<br/> Lorg/apache/lucene/store/FSDirectory;.close ()V:524(1). The format is &lt;class name&gt;.&lt;method name&gt; &lt;method desc&gt;:line(byte code index).</p> <p>During my work, I am getting AlreadyClosedExceptions on the FSDirectory from the ensureOpen() method for some threads, which I think is probably due to an order violation. I have actually introduced delays<br/> in my instrumentation which delays threads that execute the code in<br/> Lorg/apache/lucene/store/FSDirectory;.close ()V. This is causing the other query threads to throw an exception.</p> <p>Here is the exception trace:</p> <p>org.apache.lucene.store.AlreadyClosedException: this Directory is closed<br/> at org.apache.lucene.store.Directory.ensureOpen(Directory.java:220)<br/> at org.apache.lucene.store.FSDirectory.list(FSDirectory.java:320)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:533)<br/> at org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:115)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:316)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:206)<br/> at org.dacapo.lusearch.Search$QueryProcessor.&lt;init&gt;(Search.java:207)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)<br/> org.apache.lucene.store.AlreadyClosedException: this Directory is closed<br/> at org.apache.lucene.store.Directory.ensureOpen(Directory.java:220)<br/> at org.apache.lucene.store.FSDirectory.list(FSDirectory.java:320)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:533)<br/> at org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:115)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:316)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:206)<br/> at org.dacapo.lusearch.Search$QueryProcessor.&lt;init&gt;(Search.java:207)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)<br/> java.lang.NullPointerException<br/> at org.dacapo.lusearch.Search$QueryProcessor.run(Search.java:226)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)<br/> java.lang.NullPointerException<br/> at org.dacapo.lusearch.Search$QueryProcessor.run(Search.java:226)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)<br/> org.apache.lucene.store.AlreadyClosedException: this Directory is closed<br/> at org.apache.lucene.store.Directory.ensureOpen(Directory.java:220)<br/> at org.apache.lucene.store.FSDirectory.list(FSDirectory.java:320)<br/> at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:533)<br/> at org.apache.lucene.index.DirectoryIndexReader.open(DirectoryIndexReader.java:115)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:316)<br/> at org.apache.lucene.index.IndexReader.open(IndexReader.java:206)<br/> at org.dacapo.lusearch.Search$QueryProcessor.&lt;init&gt;(Search.java:207)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)<br/> java.lang.NullPointerException<br/> at org.dacapo.lusearch.Search$QueryProcessor.run(Search.java:226)<br/> at org.dacapo.lusearch.Search$QueryThread.run(Search.java:179)</p> <p>This exception does not happen during normal instrumentation, but can easily be reproduced by introducing just delays in the instrumentation. </p>
</description>
<environment><p>RHEL 6.5, 64 bit, Intel i5</p></environment>
<key id="12718284">LUCENE-5732</key>
<summary>
Possible order violation in lucene library version 2.4.1
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="swarnendubiswas">Swarnendu Biswas</reporter>
<labels></labels>
<created>Wed, 4 Jun 2014 00:49:19 +0000</created>
<updated>Wed, 4 Jun 2014 00:49:19 +0000</updated>
<version>2.4.1</version>
<component>core/store</component>
<due/>
<votes>0</votes>
<watches>1</watches>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>396486</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1w9en:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>396607</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5726] Make all resourceDescriptions of indexinputs consistent
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5726</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>This was weakly tested in a roundabout way by an assert that tried to read a lucene 2.x index.</p> <p>We should try to make these consistent, on the other hand we should be careful about keeping the overhead of slice() relatively low (it would be nice to use this api in more places).</p> <p>And such things should be tested elsewhere, e.g. BaseDirectoryTestCase</p>
</description>
<environment/>
<key id="12717950">LUCENE-5726</key>
<summary>
Make all resourceDescriptions of indexinputs consistent
</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="rcmuir">Robert Muir</reporter>
<labels></labels>
<created>Mon, 2 Jun 2014 18:03:09 +0000</created>
<updated>Mon, 2 Jun 2014 18:06:58 +0000</updated>
<due/>
<votes>0</votes>
<watches>0</watches>
<comments>
<comment id="14015668" author="rcmuir" created="Mon, 2 Jun 2014 18:06:58 +0000">
<p>I think for this issue, the trick is to make CompoundFileDirectory not pass just the filename (_1.fdt) as the resource description, but instead something more complex. it should be a nicely named string that makes it clear its a CFS slice (ideally including the original handle description completely).</p> <p>I think its ok to build a good string here, because this is not called per query or anything. We can enhance the javadocs of slice() to say that the caller is responsible for passing the description in or something like that (caller has the original indexinput to toString() if it wants to use that).</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>396152</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1w7dr:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>396277</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
<item>
<title>
[LUCENE-5742] size of frq record is very huge in the table
</title>
<link>https://issues.apache.org/jira/browse/LUCENE-5742</link>
<project id="12310110" key="LUCENE">Lucene - Core</project>
<description>
<p>Hi, <br/> We are trying the use the lucene with jdbcstore, In production, the <br/> 'frq' and 'tis' record size had grown too huge, <br/> We are unable to resize the these records to smaller size eventhough we try to call reindex and optimize using different mergeFactor and maxMergeDocs</p>
</description>
<environment><p>Linux, Jboss, Oracle database</p></environment>
<key id="12718831">LUCENE-5742</key>
<summary>size of frq record is very huge in the table</summary>
<type id="1" iconUrl="https://issues.apache.org/jira/images/icons/issuetypes/bug.png">Bug</type>
<priority id="3" iconUrl="https://issues.apache.org/jira/images/icons/priorities/major.png">Major</priority>
<status id="1" iconUrl="https://issues.apache.org/jira/images/icons/statuses/open.png" description="The issue is open and ready for the assignee to start work on it.">Open</status>
<statusCategory id="2" key="new" colorName="blue-gray"/>
<resolution id="-1">Unresolved</resolution>
<assignee username="-1">Unassigned</assignee>
<reporter username="mahesh_reddy77@yahoo.com">Maheshwara Reddy</reporter>
<labels>
<label>performance</label>
</labels>
<created>Fri, 6 Jun 2014 12:40:50 +0000</created>
<updated>Fri, 6 Jun 2014 19:51:13 +0000</updated>
<version>4.2.1</version>
<component>core/index</component>
<due/>
<votes>0</votes>
<watches>2</watches>
<comments>
<comment id="14020286" author="mikemccand" created="Fri, 6 Jun 2014 19:51:13 +0000">
<p>Try setting TieredMergePolicy.maxMergedSegmentMB? This will limit the max sized segment...</p>
</comment>
</comments>
<attachments></attachments>
<subtasks></subtasks>
<customfields>
<customfield id="customfield_12310310" key="com.atlassian.jira.toolkit:attachments">
<customfieldname>Attachment count</customfieldname>
<customfieldvalues>
<customfieldvalue>0.0</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310220" key="com.atlassian.jira.ext.charting:firstresponsedate">
<customfieldname>Date of First Response</customfieldname>
<customfieldvalues>
<customfieldvalue>Fri, 6 Jun 2014 19:51:13 +0000</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310420" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Global Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>397030</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310120" key="com.atlassian.jira.plugin.system.customfieldtypes:multicheckboxes">
<customfieldname>Lucene Fields</customfieldname>
<customfieldvalues>
<customfieldvalue key="10121">
<![CDATA[ New ]]>
</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12311820" key="com.pyxis.greenhopper.jira:gh-lexo-rank">
<customfieldname>Rank</customfieldname>
<customfieldvalues>
<customfieldvalue>0|i1wcqn:</customfieldvalue>
</customfieldvalues>
</customfield>
<customfield id="customfield_12310920" key="com.pyxis.greenhopper.jira:gh-global-rank">
<customfieldname>Rank (Obsolete)</customfieldname>
<customfieldvalues>
<customfieldvalue>397148</customfieldvalue>
</customfieldvalues>
</customfield>
</customfields>
</item>
</channel>
</rss>